{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage_3_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "i1yjzfMOZEND",
        "hx3UTW27nJa4",
        "kh9iAu5PX4lL",
        "Pqeph7TIXnCs"
      ],
      "authorship_tag": "ABX9TyOko+3Uyl0mvLopNbvr0paV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XingxinHE/FinalThesis_DL-GA/blob/master/Stage_3_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTxgp4izTN0j",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxHz82xPo63m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a36b5613-1879-4bbc-c054-aeecf74f9f22"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV9asYKxyxN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8636949a-05ba-4b3b-f046-b857d5b9af22"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uisTtYdxS8h-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cab3a61-cea7-4bce-aed6-d80f00b985d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3m1cig3TDmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/Final Thesis/data/stage3\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80y1T2cGX5nD",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1yjzfMOZEND",
        "colab_type": "text"
      },
      "source": [
        "### Loading Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YG9VicuX5JS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = pd.read_csv('605_coord.csv', index_col=0)\n",
        "train_x.drop(columns=list('2568'), axis=1, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNZ6co9qZ2a_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77c950c1-de16-400b-97c4-fd65f9e9d0a9"
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h1O7ZjLBkio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0f63688d-5a68-48ed-b8de-965d435c8da8"
      },
      "source": [
        "train_x.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     3     4     7\n",
              "0  40.0  35.0  30.0  20.0  35.0\n",
              "1  40.0  40.0  40.0  15.0  35.0\n",
              "2  30.0  30.0  40.0  20.0  20.0\n",
              "3  10.0  40.0  40.0  20.0  25.0\n",
              "4  35.0  40.0  30.0  10.0  30.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecO6GbLJA2Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = pd.read_csv('10_coord.csv', index_col=0)\n",
        "test_x.drop(columns=list('2568'), axis=1, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1LYg1x9A_b3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2be788c6-82c7-44ef-cee6-99aa1b67db85"
      },
      "source": [
        "test_x.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAeQFbp8BehP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "24e0d248-679f-4083-d10b-d62e43dd476b"
      },
      "source": [
        "test_x.tail()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>25.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     3     4     7\n",
              "5  30.0  40.0  15.0  10.0  20.0\n",
              "6  40.0  35.0  35.0  20.0  30.0\n",
              "7  35.0  40.0  25.0  15.0  20.0\n",
              "8  25.0  35.0  30.0  15.0  15.0\n",
              "9  20.0  40.0  10.0  10.0  35.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt6bDAU-BGHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "abe4e27d-7444-4ef4-fba1-3c7a77e07ccb"
      },
      "source": [
        "train_test = pd.concat([train_x, test_x])\n",
        "train_test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>25.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>615 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1     3     4     7\n",
              "0   40.0  35.0  30.0  20.0  35.0\n",
              "1   40.0  40.0  40.0  15.0  35.0\n",
              "2   30.0  30.0  40.0  20.0  20.0\n",
              "3   10.0  40.0  40.0  20.0  25.0\n",
              "4   35.0  40.0  30.0  10.0  30.0\n",
              "..   ...   ...   ...   ...   ...\n",
              "5   30.0  40.0  15.0  10.0  20.0\n",
              "6   40.0  35.0  35.0  20.0  30.0\n",
              "7   35.0  40.0  25.0  15.0  20.0\n",
              "8   25.0  35.0  30.0  15.0  15.0\n",
              "9   20.0  40.0  10.0  10.0  35.0\n",
              "\n",
              "[615 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx3UTW27nJa4",
        "colab_type": "text"
      },
      "source": [
        "### Loading output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pOk9oIYa92P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "98b41d9c-c102-4211-9508-2944e9fd9cc3"
      },
      "source": [
        "train_y = pd.read_csv('optimal_605.csv', index_col=0)\n",
        "train_y.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAd58oRClUff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1c1a48ff-14ec-4863-c29e-f537c2268c92"
      },
      "source": [
        "train_y.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bar_orders</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.83810870599491, 0.6358100457084843, 1.591918...</td>\n",
              "      <td>103.451705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.8345770523120521, 0.9756589343833298, 2.6056...</td>\n",
              "      <td>111.959005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.957788117293222, 2.724991772207066, 1.764825...</td>\n",
              "      <td>119.747432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.438750738336929, 0.0004908677138951938, 1.38...</td>\n",
              "      <td>101.092659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.2559104201266245, 1.5397079930733486, 1.6019...</td>\n",
              "      <td>111.386501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          bar_orders      weight\n",
              "0  2.83810870599491, 0.6358100457084843, 1.591918...  103.451705\n",
              "1  0.8345770523120521, 0.9756589343833298, 2.6056...  111.959005\n",
              "2  2.957788117293222, 2.724991772207066, 1.764825...  119.747432\n",
              "3  3.438750738336929, 0.0004908677138951938, 1.38...  101.092659\n",
              "4  0.2559104201266245, 1.5397079930733486, 1.6019...  111.386501"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DdbbqmGCp7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fab96a7f-3753-428e-b133-5f10872be000"
      },
      "source": [
        "test_y = pd.read_csv('testing_10.csv', index_col=0)\n",
        "test_y.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76gM9IY9l7Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function convert np of object to np of float\n",
        "def f(x):\n",
        "    return np.array(x.replace('[', '').replace(']', '').replace(',', ' ').split()).astype(float)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5ZRNLSbqtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "abb18848-8897-4c27-b4fe-3e03391ea21b"
      },
      "source": [
        "train_y = np.array([f(t) for t in train_y['bar_orders']])\n",
        "train_y = np.floor(train_y)\n",
        "train_y = train_y.astype(int)\n",
        "train_y.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bawNEeUXlMs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b625e57d-9e8e-479e-a5be-e5679325288f"
      },
      "source": [
        "train_y"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 1, ..., 0, 2, 1],\n",
              "       [0, 0, 2, ..., 2, 0, 1],\n",
              "       [2, 2, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [0, 1, 3, ..., 0, 3, 1],\n",
              "       [1, 1, 2, ..., 0, 1, 2],\n",
              "       [2, 3, 2, ..., 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKNbyYvdGqZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7015cd11-e097-4361-af81-ee53b5d97684"
      },
      "source": [
        "test_y = np.array([f(t) for t in test_y['bar_orders']])\n",
        "test_y = np.floor(test_y)\n",
        "test_y = test_y.astype(int)\n",
        "test_y.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMSdhe9RGzzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a013af2c-4b0c-442b-e62f-77325827ebef"
      },
      "source": [
        "test_y"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 2, ..., 0, 0, 2],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 3, ..., 1, 0, 0],\n",
              "       ...,\n",
              "       [2, 0, 1, ..., 2, 0, 2],\n",
              "       [2, 2, 1, ..., 0, 0, 2],\n",
              "       [0, 1, 2, ..., 2, 1, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh9iAu5PX4lL",
        "colab_type": "text"
      },
      "source": [
        "### One-hot coding input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmHZd7b-RHpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f5d9c03-9e68-4c07-a594-741ce42c3d9e"
      },
      "source": [
        "intput_features = len(train_x.columns)\n",
        "intput_features"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EvGdyT2STA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9285d7fe-e1dc-4916-b3fd-f15ed2421744"
      },
      "source": [
        "sorted(pd.unique(train_test[train_test.columns].values.ravel('K')))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10.0, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrIr31FdShM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intput_features_possibilities = sorted(pd.unique(train_test[train_test.columns].values.ravel('K')))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZ8UuO1SoFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9e807c6-5db2-4e2a-bc24-37116b7fa587"
      },
      "source": [
        "intput_features_possibilities = [int(i) for i in intput_features_possibilities]\n",
        "intput_features_possibilities"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 15, 20, 25, 30, 35, 40]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gf1Rkr2RpuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ba3f9f7-71c9-4d61-9d54-f60f4ceee537"
      },
      "source": [
        "intput_features_possibilities_indices = dict((feature, intput_features_possibilities.index(feature)) for feature in intput_features_possibilities)\n",
        "intput_features_possibilities_indices"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 0, 15: 1, 20: 2, 25: 3, 30: 4, 35: 5, 40: 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqOzD5ldUYLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_onehot = np.zeros((len(train_x.index), intput_features, len(intput_features_possibilities)), dtype=np.bool)\n",
        "test_x_onehot = np.zeros((len(test_x.index), intput_features, len(intput_features_possibilities)), dtype=np.bool)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIOIGMYoVNx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32202c55-66b8-4223-d3b4-bde5b43716ae"
      },
      "source": [
        "train_x_onehot.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BJ099Z9VNii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b212d33-0a53-4676-a9ed-f7c921211ca8"
      },
      "source": [
        "test_x_onehot.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WTecJl1VrsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_x.index)):\n",
        "  for j in range(len(train_x.columns)):\n",
        "    train_x_onehot[i, j, intput_features_possibilities_indices[train_x.iloc[i,j]]] = 1"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axDPHyC_WtT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(test_x.index)):\n",
        "  for j in range(len(test_x.columns)):\n",
        "    test_x_onehot[i, j, intput_features_possibilities_indices[test_x.iloc[i,j]]] = 1"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqeph7TIXnCs",
        "colab_type": "text"
      },
      "source": [
        "### One-hot coding output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2VuMvmf3YAOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f5d9c03-9e68-4c07-a594-741ce42c3d9e"
      },
      "source": [
        "intput_features = len(train_x.columns)\n",
        "intput_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZmPU9W_VYAOJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9285d7fe-e1dc-4916-b3fd-f15ed2421744"
      },
      "source": [
        "sorted(pd.unique(train_test[train_test.columns].values.ravel('K')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10.0, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nvgCj8GZYAOM",
        "colab": {}
      },
      "source": [
        "intput_features_possibilities = sorted(pd.unique(train_test[train_test.columns].values.ravel('K')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kz94O9_RYAOP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9e807c6-5db2-4e2a-bc24-37116b7fa587"
      },
      "source": [
        "intput_features_possibilities = [int(i) for i in intput_features_possibilities]\n",
        "intput_features_possibilities"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 15, 20, 25, 30, 35, 40]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gTxmCOeJYAOS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ba3f9f7-71c9-4d61-9d54-f60f4ceee537"
      },
      "source": [
        "intput_features_possibilities_indices = dict((feature, intput_features_possibilities.index(feature)) for feature in intput_features_possibilities)\n",
        "intput_features_possibilities_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 0, 15: 1, 20: 2, 25: 3, 30: 4, 35: 5, 40: 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ij-LF08GYAOV",
        "colab": {}
      },
      "source": [
        "train_x_onehot = np.zeros((len(train_x.index), intput_features, len(intput_features_possibilities)), dtype=np.bool)\n",
        "test_x_onehot = np.zeros((len(test_x.index), intput_features, len(intput_features_possibilities)), dtype=np.bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JfrgnzEsYAOY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32202c55-66b8-4223-d3b4-bde5b43716ae"
      },
      "source": [
        "train_x_onehot.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtawtHl3YAOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b212d33-0a53-4676-a9ed-f7c921211ca8"
      },
      "source": [
        "test_x_onehot.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUQGuinFYAOd",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_x.index)):\n",
        "  for j in range(len(train_x.columns)):\n",
        "    train_x_onehot[i, j, intput_features_possibilities_indices[train_x.iloc[i,j]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4jPn0svkYAOg",
        "colab": {}
      },
      "source": [
        "for i in range(len(test_x.index)):\n",
        "  for j in range(len(test_x.columns)):\n",
        "    test_x_onehot[i, j, intput_features_possibilities_indices[test_x.iloc[i,j]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwB0Dt7yXgi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa583ed0-7137-4abd-fdc6-7d86fb4e1d43"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[False,  True, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [False, False, False,  True, False, False, False],\n",
              "        [False,  True, False, False, False, False, False],\n",
              "        [False,  True, False, False, False, False, False]],\n",
              "\n",
              "       [[False, False, False, False,  True, False, False],\n",
              "        [False, False, False, False,  True, False, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [ True, False, False, False, False, False, False],\n",
              "        [False, False, False,  True, False, False, False]],\n",
              "\n",
              "       [[ True, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [False, False,  True, False, False, False, False],\n",
              "        [False, False, False, False,  True, False, False]],\n",
              "\n",
              "       [[False, False, False, False, False,  True, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [False, False, False, False,  True, False, False],\n",
              "        [False, False,  True, False, False, False, False],\n",
              "        [False, False, False, False, False,  True, False]],\n",
              "\n",
              "       [[False, False,  True, False, False, False, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [False, False, False,  True, False, False, False],\n",
              "        [False, False,  True, False, False, False, False],\n",
              "        [False, False,  True, False, False, False, False]],\n",
              "\n",
              "       [[False, False, False, False,  True, False, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [False,  True, False, False, False, False, False],\n",
              "        [ True, False, False, False, False, False, False],\n",
              "        [False, False,  True, False, False, False, False]],\n",
              "\n",
              "       [[False, False, False, False, False, False,  True],\n",
              "        [False, False, False, False, False,  True, False],\n",
              "        [False, False, False, False, False,  True, False],\n",
              "        [False, False,  True, False, False, False, False],\n",
              "        [False, False, False, False,  True, False, False]],\n",
              "\n",
              "       [[False, False, False, False, False,  True, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [False, False, False,  True, False, False, False],\n",
              "        [False,  True, False, False, False, False, False],\n",
              "        [False, False,  True, False, False, False, False]],\n",
              "\n",
              "       [[False, False, False,  True, False, False, False],\n",
              "        [False, False, False, False, False,  True, False],\n",
              "        [False, False, False, False,  True, False, False],\n",
              "        [False,  True, False, False, False, False, False],\n",
              "        [False,  True, False, False, False, False, False]],\n",
              "\n",
              "       [[False, False,  True, False, False, False, False],\n",
              "        [False, False, False, False, False, False,  True],\n",
              "        [ True, False, False, False, False, False, False],\n",
              "        [ True, False, False, False, False, False, False],\n",
              "        [False, False, False, False, False,  True, False]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0w4MW9hpLhz",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Model （Dense,SGD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i7nSYmppOb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71e81420-dda5-4f1d-cfe7-61598b0c8cb1"
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=5)) #输入5个\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(220, )) #输出220个\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='mse',\n",
        "              optimizer=sgd\n",
        "              )\n",
        "\n",
        "history = model.fit(train_x, train_y,\n",
        "          epochs=1000,\n",
        "          batch_size=32,\n",
        "          #validation_data = (x_test, y_test)\n",
        "          validation_split = 0.2,\n",
        "          callbacks=[early_stop, tfdocs.modeling.EpochDots()],\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 2.4768\n",
            "Epoch: 0, loss:2.5068,  val_loss:2.4115,  \n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.5068 - val_loss: 2.4115\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.3918 - val_loss: 2.3036\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.2680 - val_loss: 2.1734\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.1168 - val_loss: 1.9925\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.9253 - val_loss: 1.7417\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.6675 - val_loss: 1.4337\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.1654\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.2975 - val_loss: 1.0272\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.2316 - val_loss: 0.9846\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1820 - val_loss: 0.9598\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1553 - val_loss: 0.9523\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1397 - val_loss: 0.9386\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1310 - val_loss: 0.9352\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1003 - val_loss: 0.9287\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0903 - val_loss: 0.9167\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0875 - val_loss: 0.9133\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0711 - val_loss: 0.9144\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0666 - val_loss: 0.9073\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0553 - val_loss: 0.9026\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0506 - val_loss: 0.8984\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0461 - val_loss: 0.8938\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0379 - val_loss: 0.8941\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0333 - val_loss: 0.8962\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0233 - val_loss: 0.8947\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0267 - val_loss: 0.8877\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0050 - val_loss: 0.8875\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0158 - val_loss: 0.8863\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0107 - val_loss: 0.8873\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0098 - val_loss: 0.8868\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9988 - val_loss: 0.8878\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9929 - val_loss: 0.8893\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9871 - val_loss: 0.8908\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9866 - val_loss: 0.8845\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9794 - val_loss: 0.8788\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9719 - val_loss: 0.8765\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9935 - val_loss: 0.8792\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9796 - val_loss: 0.8765\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9768 - val_loss: 0.8792\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9731 - val_loss: 0.8771\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9652 - val_loss: 0.8752\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9613 - val_loss: 0.8729\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9644 - val_loss: 0.8755\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9631 - val_loss: 0.8726\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9590 - val_loss: 0.8723\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9579 - val_loss: 0.8724\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9549 - val_loss: 0.8723\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9594 - val_loss: 0.8722\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9584 - val_loss: 0.8705\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9483 - val_loss: 0.8703\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 0.8700\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9512 - val_loss: 0.8712\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9465 - val_loss: 0.8707\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9491 - val_loss: 0.8688\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9478 - val_loss: 0.8674\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.8671\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.8664\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.8671\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.9368 - val_loss: 0.8710\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.8692\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.8682\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.8681\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9361 - val_loss: 0.8674\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.9344 - val_loss: 0.8681\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.8690\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.8696\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9291 - val_loss: 0.8672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgooluCFZCTO",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Model (Softmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqcI2GXY_Iv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96c7ffc3-99ae-41db-f2e6-644b755b2389"
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=5)) #输入5个\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(220, activation='softmax')) #输出220个\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "       optimizer='rmsprop',\n",
        "       metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "history = model.fit(train_x, train_y,\n",
        "          epochs=1000,\n",
        "          batch_size=32,\n",
        "          #validation_data = (x_test, y_test)\n",
        "          validation_split = 0.2,\n",
        "          callbacks=tfdocs.modeling.EpochDots(),\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 1543.4539 - accuracy: 0.0000e+00\n",
            "Epoch: 0, accuracy:0.0062,  loss:1532.5759,  val_accuracy:0.0165,  val_loss:1522.6447,  \n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1532.5759 - accuracy: 0.0062 - val_loss: 1522.6447 - val_accuracy: 0.0165\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1561.4824 - accuracy: 0.0041 - val_loss: 1539.9374 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1612.6146 - accuracy: 0.0083 - val_loss: 1569.3284 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1681.5049 - accuracy: 0.0041 - val_loss: 1615.4117 - val_accuracy: 0.0083\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1794.6479 - accuracy: 0.0062 - val_loss: 1677.1671 - val_accuracy: 0.0083\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1946.1494 - accuracy: 0.0041 - val_loss: 1756.9821 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2108.8262 - accuracy: 0.0083 - val_loss: 1863.8933 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2345.2632 - accuracy: 0.0062 - val_loss: 1988.8264 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2619.2800 - accuracy: 0.0145 - val_loss: 2137.2200 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2929.0327 - accuracy: 0.0062 - val_loss: 2297.8262 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3272.1106 - accuracy: 0.0041 - val_loss: 2493.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3552.8201 - accuracy: 0.0083 - val_loss: 2717.5583 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4034.8364 - accuracy: 0.0124 - val_loss: 2933.6846 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4479.3765 - accuracy: 0.0103 - val_loss: 3166.6472 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4933.2168 - accuracy: 0.0083 - val_loss: 3446.0684 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5362.7656 - accuracy: 0.0083 - val_loss: 3733.9204 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5803.9468 - accuracy: 0.0041 - val_loss: 4038.6699 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6374.7051 - accuracy: 0.0083 - val_loss: 4309.9448 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7023.5913 - accuracy: 0.0041 - val_loss: 4688.2739 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7618.6357 - accuracy: 0.0000e+00 - val_loss: 5039.9619 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8231.4932 - accuracy: 0.0021 - val_loss: 5495.7896 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8684.4805 - accuracy: 0.0062 - val_loss: 5800.1694 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9492.3242 - accuracy: 0.0021 - val_loss: 6131.8687 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10125.1680 - accuracy: 0.0103 - val_loss: 6434.9253 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10662.4111 - accuracy: 0.0145 - val_loss: 6783.4990 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11311.8828 - accuracy: 0.0124 - val_loss: 7365.6748 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12222.5703 - accuracy: 0.0083 - val_loss: 7785.9546 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12986.3613 - accuracy: 0.0000e+00 - val_loss: 8121.0342 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13753.3311 - accuracy: 0.0083 - val_loss: 8332.9043 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14319.5273 - accuracy: 0.0062 - val_loss: 8843.8584 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 15216.8760 - accuracy: 0.0083 - val_loss: 9484.4707 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 16161.7910 - accuracy: 0.0083 - val_loss: 9842.4619 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 17198.6621 - accuracy: 0.0083 - val_loss: 10305.2783 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 17696.9727 - accuracy: 0.0021 - val_loss: 10735.9600 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 18685.8496 - accuracy: 0.0021 - val_loss: 11502.7910 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 19505.6680 - accuracy: 0.0103 - val_loss: 12009.9365 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20812.2852 - accuracy: 0.0124 - val_loss: 12514.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 21785.8203 - accuracy: 0.0165 - val_loss: 13171.4053 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 22647.1016 - accuracy: 0.0021 - val_loss: 13629.5762 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 24021.0020 - accuracy: 0.0103 - val_loss: 14343.1504 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 24851.7891 - accuracy: 0.0041 - val_loss: 14471.3057 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 25677.8906 - accuracy: 0.0124 - val_loss: 15254.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 27045.5820 - accuracy: 0.0041 - val_loss: 15449.2754 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 27966.6387 - accuracy: 0.0083 - val_loss: 16675.0566 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 28940.6367 - accuracy: 0.0062 - val_loss: 17114.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 30454.2266 - accuracy: 0.0041 - val_loss: 18236.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 31156.3828 - accuracy: 0.0083 - val_loss: 18593.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 32877.0625 - accuracy: 0.0083 - val_loss: 18971.0586 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 33894.7305 - accuracy: 0.0083 - val_loss: 19812.0859 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 34878.0078 - accuracy: 0.0083 - val_loss: 20362.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 34867.5195 - accuracy: 0.0103 - val_loss: 21176.7129 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 37144.2383 - accuracy: 0.0021 - val_loss: 21928.2852 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 37880.4805 - accuracy: 0.0041 - val_loss: 22212.0859 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 40832.2734 - accuracy: 0.0083 - val_loss: 23439.7285 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 41800.1094 - accuracy: 0.0021 - val_loss: 24189.3809 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 43074.9102 - accuracy: 0.0124 - val_loss: 24430.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 43908.9336 - accuracy: 0.0103 - val_loss: 25176.1172 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 44662.9961 - accuracy: 0.0021 - val_loss: 26380.6328 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 47161.2344 - accuracy: 0.0103 - val_loss: 27831.0859 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 48536.1367 - accuracy: 0.0021 - val_loss: 28409.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 49203.1016 - accuracy: 0.0083 - val_loss: 28653.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 49744.0898 - accuracy: 0.0103 - val_loss: 28610.7734 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52859.2773 - accuracy: 0.0062 - val_loss: 29404.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54470.3164 - accuracy: 0.0124 - val_loss: 30805.9277 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 55472.1367 - accuracy: 0.0041 - val_loss: 30515.6836 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 56299.1406 - accuracy: 0.0083 - val_loss: 31216.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 59111.4141 - accuracy: 0.0103 - val_loss: 31401.5234 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 58952.2539 - accuracy: 0.0103 - val_loss: 33763.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61841.2188 - accuracy: 0.0021 - val_loss: 34638.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63949.5547 - accuracy: 0.0021 - val_loss: 35388.3008 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66309.2500 - accuracy: 0.0083 - val_loss: 35400.2148 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 67449.3438 - accuracy: 0.0041 - val_loss: 36931.5156 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 69289.3203 - accuracy: 0.0062 - val_loss: 37434.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 70880.3906 - accuracy: 0.0000e+00 - val_loss: 39522.1367 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 72057.3281 - accuracy: 0.0062 - val_loss: 39124.3281 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 75073.5625 - accuracy: 0.0021 - val_loss: 40084.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76485.0625 - accuracy: 0.0062 - val_loss: 41554.6953 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76444.9922 - accuracy: 0.0083 - val_loss: 41441.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 79340.1172 - accuracy: 0.0041 - val_loss: 42430.9688 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81367.9141 - accuracy: 0.0083 - val_loss: 43859.0586 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84724.8047 - accuracy: 0.0083 - val_loss: 44089.2578 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84734.5781 - accuracy: 0.0041 - val_loss: 44798.9883 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 85883.4375 - accuracy: 0.0103 - val_loss: 46581.4102 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90606.8047 - accuracy: 0.0103 - val_loss: 48236.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90642.2422 - accuracy: 0.0041 - val_loss: 48424.9961 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94551.8047 - accuracy: 0.0041 - val_loss: 50240.9258 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95039.3750 - accuracy: 0.0103 - val_loss: 50857.3359 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97222.0391 - accuracy: 0.0041 - val_loss: 51216.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99393.2656 - accuracy: 0.0000e+00 - val_loss: 52390.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99423.5703 - accuracy: 0.0145 - val_loss: 53001.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105573.0312 - accuracy: 0.0083 - val_loss: 54077.2812 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105658.5703 - accuracy: 0.0021 - val_loss: 56083.3320 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106949.6562 - accuracy: 0.0083 - val_loss: 57445.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106826.7266 - accuracy: 0.0083 - val_loss: 58222.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112865.0781 - accuracy: 0.0041 - val_loss: 60648.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113309.8906 - accuracy: 0.0062 - val_loss: 61621.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117493.4922 - accuracy: 0.0103 - val_loss: 63818.4336 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119247.6172 - accuracy: 0.0062 - val_loss: 65535.3867 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119245.4844 - accuracy: 0.0103 - val_loss: 66102.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122453.3359 - accuracy: 0.0103 - val_loss: 68280.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 126493.6094 - accuracy: 0.0041    \n",
            "Epoch: 100, accuracy:0.0041,  loss:126493.6094,  val_accuracy:0.0000,  val_loss:64292.2617,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126493.6094 - accuracy: 0.0041 - val_loss: 64292.2617 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127024.1406 - accuracy: 0.0083 - val_loss: 65505.5703 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127545.6328 - accuracy: 0.0041 - val_loss: 67423.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130481.4609 - accuracy: 0.0021 - val_loss: 69041.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134036.7344 - accuracy: 0.0165 - val_loss: 70849.4453 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137968.7656 - accuracy: 0.0021 - val_loss: 71847.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139505.7969 - accuracy: 0.0062 - val_loss: 72793.7734 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141427.6094 - accuracy: 0.0021 - val_loss: 75813.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145966.5469 - accuracy: 0.0103 - val_loss: 75949.6172 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146817.6562 - accuracy: 0.0062 - val_loss: 77171.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149112.6562 - accuracy: 0.0062 - val_loss: 76919.8672 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153214.6719 - accuracy: 0.0062 - val_loss: 79120.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155695.3594 - accuracy: 0.0041 - val_loss: 78158.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159745.1094 - accuracy: 0.0062 - val_loss: 78479.6172 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157718.2500 - accuracy: 0.0062 - val_loss: 81254.9141 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161039.8438 - accuracy: 0.0041 - val_loss: 81131.0391 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163171.9688 - accuracy: 0.0145 - val_loss: 83198.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166628.2344 - accuracy: 0.0041 - val_loss: 83684.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168971.5312 - accuracy: 0.0062 - val_loss: 87150.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174285.9531 - accuracy: 0.0021 - val_loss: 89228.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172926.5312 - accuracy: 0.0083 - val_loss: 87475.3047 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 178615.9375 - accuracy: 0.0062 - val_loss: 87819.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180382.8906 - accuracy: 0.0083 - val_loss: 88862.9922 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183363.0156 - accuracy: 0.0021 - val_loss: 92492.8828 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186972.1719 - accuracy: 0.0041 - val_loss: 92767.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189325.8125 - accuracy: 0.0083 - val_loss: 97569.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191117.6094 - accuracy: 0.0062 - val_loss: 98684.7578 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192292.7344 - accuracy: 0.0062 - val_loss: 98638.7266 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197729.3438 - accuracy: 0.0021 - val_loss: 99309.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199716.6875 - accuracy: 0.0021 - val_loss: 102999.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206634.2188 - accuracy: 0.0041 - val_loss: 105979.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206611.7656 - accuracy: 0.0041 - val_loss: 108755.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205767.0938 - accuracy: 0.0041 - val_loss: 108116.4141 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207490.6250 - accuracy: 0.0083 - val_loss: 107561.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219307.7031 - accuracy: 0.0062 - val_loss: 110889.5234 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219424.5469 - accuracy: 0.0062 - val_loss: 113094.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221671.7031 - accuracy: 0.0062 - val_loss: 113677.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 224557.7812 - accuracy: 0.0041 - val_loss: 116800.1328 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227288.6094 - accuracy: 0.0062 - val_loss: 118403.7188 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229915.4531 - accuracy: 0.0103 - val_loss: 121028.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233551.6875 - accuracy: 0.0103 - val_loss: 118425.5234 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239293.8906 - accuracy: 0.0062 - val_loss: 126013.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239629.4531 - accuracy: 0.0103 - val_loss: 125488.1484 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244088.2031 - accuracy: 0.0041 - val_loss: 124114.5703 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245105.6094 - accuracy: 0.0041 - val_loss: 121594.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250945.0625 - accuracy: 0.0021 - val_loss: 127149.9609 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253381.8438 - accuracy: 0.0083 - val_loss: 127673.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253541.7188 - accuracy: 0.0062 - val_loss: 128003.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 256077.0156 - accuracy: 0.0062 - val_loss: 131552.9219 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263980.5938 - accuracy: 0.0062 - val_loss: 135690.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 264271.2812 - accuracy: 0.0124 - val_loss: 136024.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 271341.1562 - accuracy: 0.0062 - val_loss: 137569.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 279233.7812 - accuracy: 0.0124 - val_loss: 139508.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278664.9688 - accuracy: 0.0062 - val_loss: 140354.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280980.8750 - accuracy: 0.0000e+00 - val_loss: 141047.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 285435.6875 - accuracy: 0.0041 - val_loss: 141576.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 286475.2812 - accuracy: 0.0021 - val_loss: 149638.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 289619.2188 - accuracy: 0.0021 - val_loss: 145322.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 291376.5312 - accuracy: 0.0103 - val_loss: 146985.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304710.0312 - accuracy: 0.0021 - val_loss: 149633.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 301323.0000 - accuracy: 0.0083 - val_loss: 153161.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 302194.6562 - accuracy: 0.0021 - val_loss: 155431.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316722.0938 - accuracy: 0.0000e+00 - val_loss: 151538.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 312378.3125 - accuracy: 0.0103 - val_loss: 154692.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 319804.1562 - accuracy: 0.0041 - val_loss: 153152.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 321012.5000 - accuracy: 0.0083 - val_loss: 159719.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328273.1250 - accuracy: 0.0021 - val_loss: 162185.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328658.7188 - accuracy: 0.0103 - val_loss: 159615.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335286.5938 - accuracy: 0.0041 - val_loss: 164363.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335161.1562 - accuracy: 0.0041 - val_loss: 162547.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 339210.1875 - accuracy: 0.0062 - val_loss: 164620.2969 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 346451.9062 - accuracy: 0.0021 - val_loss: 169778.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343964.6250 - accuracy: 0.0021 - val_loss: 172881.6406 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 352632.3438 - accuracy: 0.0083 - val_loss: 171624.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 353356.3438 - accuracy: 0.0083 - val_loss: 174440.5156 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 358735.3125 - accuracy: 0.0062 - val_loss: 173225.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 362033.9688 - accuracy: 0.0083 - val_loss: 175196.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 363963.1250 - accuracy: 0.0041 - val_loss: 178207.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375885.6562 - accuracy: 0.0103 - val_loss: 179427.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375454.4062 - accuracy: 0.0021 - val_loss: 187148.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 377457.3438 - accuracy: 0.0021 - val_loss: 188542.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 384429.5625 - accuracy: 0.0021 - val_loss: 187225.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 387841.8125 - accuracy: 0.0041 - val_loss: 190945.9844 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 393572.4375 - accuracy: 0.0083 - val_loss: 187164.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 394467.0938 - accuracy: 0.0124 - val_loss: 192712.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 392330.2188 - accuracy: 0.0083 - val_loss: 190576.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 402103.0625 - accuracy: 0.0145 - val_loss: 196434.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 409066.3438 - accuracy: 0.0021 - val_loss: 201674.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 411504.3438 - accuracy: 0.0083 - val_loss: 196874.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 412375.9062 - accuracy: 0.0062 - val_loss: 196064.9531 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 419635.8125 - accuracy: 0.0041 - val_loss: 200145.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420384.0938 - accuracy: 0.0062 - val_loss: 208509.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 437233.4688 - accuracy: 0.0041 - val_loss: 215608.2969 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 438593.3125 - accuracy: 0.0062 - val_loss: 214616.9844 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 441664.4062 - accuracy: 0.0041 - val_loss: 216060.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 437918.2812 - accuracy: 0.0041 - val_loss: 223909.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 445925.6562 - accuracy: 0.0041 - val_loss: 221274.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 454172.5312 - accuracy: 0.0041 - val_loss: 220925.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 445663.2188 - accuracy: 0.0021 - val_loss: 225206.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 459281.2188 - accuracy: 0.0000e+00 - val_loss: 228532.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 479792.9062 - accuracy: 0.0312\n",
            "Epoch: 200, accuracy:0.0062,  loss:464418.0625,  val_accuracy:0.0000,  val_loss:224614.4062,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 464418.0625 - accuracy: 0.0062 - val_loss: 224614.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 467843.2812 - accuracy: 0.0000e+00 - val_loss: 223072.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 466670.5312 - accuracy: 0.0021 - val_loss: 231128.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 476385.9688 - accuracy: 0.0021 - val_loss: 231878.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 480709.1250 - accuracy: 0.0062 - val_loss: 239643.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 478399.6875 - accuracy: 0.0021 - val_loss: 243632.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 489901.1250 - accuracy: 0.0124 - val_loss: 247934.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 487557.2188 - accuracy: 0.0000e+00 - val_loss: 248457.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 502864.5938 - accuracy: 0.0062 - val_loss: 253358.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 504822.6562 - accuracy: 0.0083 - val_loss: 248766.5781 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 510846.8750 - accuracy: 0.0062 - val_loss: 258377.3906 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 515362.4688 - accuracy: 0.0083 - val_loss: 259677.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 522071.8750 - accuracy: 0.0062 - val_loss: 265189.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 521570.7188 - accuracy: 0.0041 - val_loss: 267298.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 533750.7500 - accuracy: 0.0021 - val_loss: 262233.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 537902.2500 - accuracy: 0.0083 - val_loss: 264273.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 536141.5000 - accuracy: 0.0083 - val_loss: 271918.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 540310.3750 - accuracy: 0.0083 - val_loss: 275890.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 547094.0000 - accuracy: 0.0062 - val_loss: 271431.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 549429.5000 - accuracy: 0.0103 - val_loss: 275319.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 568203.0625 - accuracy: 0.0021 - val_loss: 279613.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 571273.0000 - accuracy: 0.0041 - val_loss: 277927.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 570545.1875 - accuracy: 0.0083 - val_loss: 275556.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 583982.9375 - accuracy: 0.0083 - val_loss: 281716.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 572956.2500 - accuracy: 0.0041 - val_loss: 293418.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 586212.6875 - accuracy: 0.0083 - val_loss: 295026.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 588904.1875 - accuracy: 0.0021 - val_loss: 307466.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 590741.9375 - accuracy: 0.0021 - val_loss: 307793.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 598236.6875 - accuracy: 0.0021 - val_loss: 295947.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 599697.0000 - accuracy: 0.0062 - val_loss: 302149.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 607458.2500 - accuracy: 0.0041 - val_loss: 308346.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 617270.1875 - accuracy: 0.0062 - val_loss: 308871.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 629963.4375 - accuracy: 0.0041 - val_loss: 315947.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 633572.2500 - accuracy: 0.0062 - val_loss: 318431.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 628337.3750 - accuracy: 0.0041 - val_loss: 320921.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 643387.2500 - accuracy: 0.0041 - val_loss: 319491.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 641149.6875 - accuracy: 0.0041 - val_loss: 326756.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 665522.2500 - accuracy: 0.0062 - val_loss: 319549.6562 - val_accuracy: 0.0083\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 644145.0000 - accuracy: 0.0000e+00 - val_loss: 331151.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 656277.8125 - accuracy: 0.0062 - val_loss: 326044.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 663963.8125 - accuracy: 0.0083 - val_loss: 326108.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 665675.0000 - accuracy: 0.0062 - val_loss: 328345.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 665807.1250 - accuracy: 0.0083 - val_loss: 336637.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 684737.8750 - accuracy: 0.0021 - val_loss: 341035.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 679979.9375 - accuracy: 0.0103 - val_loss: 358803.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 703054.3750 - accuracy: 0.0083 - val_loss: 343938.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 692808.6875 - accuracy: 0.0041 - val_loss: 339488.5000 - val_accuracy: 0.0083\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 700165.3750 - accuracy: 0.0000e+00 - val_loss: 348124.3125 - val_accuracy: 0.0165\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 719104.6250 - accuracy: 0.0083 - val_loss: 352189.7500 - val_accuracy: 0.0165\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 723359.0000 - accuracy: 0.0041 - val_loss: 348011.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 714901.3750 - accuracy: 0.0103 - val_loss: 355374.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 742039.1250 - accuracy: 0.0021 - val_loss: 352960.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 752146.3125 - accuracy: 0.0021 - val_loss: 360003.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 743643.1250 - accuracy: 0.0062 - val_loss: 368943.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 756219.3750 - accuracy: 0.0103 - val_loss: 369220.6562 - val_accuracy: 0.0165\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 747861.4375 - accuracy: 0.0000e+00 - val_loss: 375456.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 770928.6250 - accuracy: 0.0041 - val_loss: 377434.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 759526.1250 - accuracy: 0.0062 - val_loss: 381418.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 762474.2500 - accuracy: 0.0000e+00 - val_loss: 382331.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 779929.0625 - accuracy: 0.0062 - val_loss: 387958.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 784655.7500 - accuracy: 0.0083 - val_loss: 380814.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 790121.5000 - accuracy: 0.0103 - val_loss: 390825.5312 - val_accuracy: 0.0165\n",
            "Epoch 263/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 780618.0625 - accuracy: 0.0041 - val_loss: 388188.0312 - val_accuracy: 0.0083\n",
            "Epoch 264/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 796465.5625 - accuracy: 0.0103 - val_loss: 399886.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 809403.5625 - accuracy: 0.0041 - val_loss: 397717.6875 - val_accuracy: 0.0165\n",
            "Epoch 266/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 801781.2500 - accuracy: 0.0062 - val_loss: 405202.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 814521.3125 - accuracy: 0.0062 - val_loss: 406981.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 817783.5000 - accuracy: 0.0021 - val_loss: 410229.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 817818.1875 - accuracy: 0.0041 - val_loss: 408042.6250 - val_accuracy: 0.0083\n",
            "Epoch 270/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 858373.8125 - accuracy: 0.0041 - val_loss: 415525.5000 - val_accuracy: 0.0083\n",
            "Epoch 271/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 838334.3750 - accuracy: 0.0062 - val_loss: 420837.0625 - val_accuracy: 0.0165\n",
            "Epoch 272/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 862288.9375 - accuracy: 0.0021 - val_loss: 420386.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 859994.1875 - accuracy: 0.0083 - val_loss: 422240.0938 - val_accuracy: 0.0083\n",
            "Epoch 274/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 868455.3750 - accuracy: 0.0062 - val_loss: 432597.0938 - val_accuracy: 0.0165\n",
            "Epoch 275/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 871330.1250 - accuracy: 0.0021 - val_loss: 426591.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 873036.9375 - accuracy: 0.0021 - val_loss: 435167.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 897083.3750 - accuracy: 0.0062 - val_loss: 444741.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 889912.4375 - accuracy: 0.0062 - val_loss: 441577.7188 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 890193.8125 - accuracy: 0.0083 - val_loss: 447417.7188 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 908431.6250 - accuracy: 0.0124 - val_loss: 447954.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 922015.0625 - accuracy: 0.0124 - val_loss: 450400.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 931574.1875 - accuracy: 0.0103 - val_loss: 458811.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 915322.6875 - accuracy: 0.0083 - val_loss: 457716.3125 - val_accuracy: 0.0083\n",
            "Epoch 284/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 918537.2500 - accuracy: 0.0041 - val_loss: 466110.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 906195.5625 - accuracy: 0.0083 - val_loss: 473367.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 928162.0000 - accuracy: 0.0062 - val_loss: 477245.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 950773.0625 - accuracy: 0.0041 - val_loss: 472622.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 954795.0625 - accuracy: 0.0021 - val_loss: 474997.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 956971.7500 - accuracy: 0.0041 - val_loss: 482238.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 972623.8750 - accuracy: 0.0062 - val_loss: 483592.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 970646.9375 - accuracy: 0.0041 - val_loss: 476871.9062 - val_accuracy: 0.0165\n",
            "Epoch 292/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 976127.3750 - accuracy: 0.0021 - val_loss: 481897.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 994851.3750 - accuracy: 0.0062 - val_loss: 488844.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1001732.5000 - accuracy: 0.0041 - val_loss: 497678.6250 - val_accuracy: 0.0165\n",
            "Epoch 295/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 997075.7500 - accuracy: 0.0062 - val_loss: 498693.6875 - val_accuracy: 0.0165\n",
            "Epoch 296/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 993212.1875 - accuracy: 0.0103 - val_loss: 498222.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1032131.9375 - accuracy: 0.0103 - val_loss: 515207.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1041749.5625 - accuracy: 0.0021 - val_loss: 511612.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1030833.3125 - accuracy: 0.0041 - val_loss: 512504.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1041820.5000 - accuracy: 0.0083 - val_loss: 524363.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 1077281.5000 - accuracy: 0.0000e+00\n",
            "Epoch: 300, accuracy:0.0062,  loss:1038937.3750,  val_accuracy:0.0000,  val_loss:525295.7500,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1038937.3750 - accuracy: 0.0062 - val_loss: 525295.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1039776.3750 - accuracy: 0.0062 - val_loss: 524656.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1065169.3750 - accuracy: 0.0041 - val_loss: 526858.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1059898.7500 - accuracy: 0.0000e+00 - val_loss: 523771.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1076594.3750 - accuracy: 0.0062 - val_loss: 532861.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1061570.0000 - accuracy: 0.0062 - val_loss: 537492.3125 - val_accuracy: 0.0083\n",
            "Epoch 307/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1081809.2500 - accuracy: 0.0041 - val_loss: 548322.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1096657.3750 - accuracy: 0.0041 - val_loss: 541390.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1093914.3750 - accuracy: 0.0103 - val_loss: 552775.7500 - val_accuracy: 0.0165\n",
            "Epoch 310/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1121049.8750 - accuracy: 0.0041 - val_loss: 574635.9375 - val_accuracy: 0.0165\n",
            "Epoch 311/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1122724.5000 - accuracy: 0.0021 - val_loss: 575365.3125 - val_accuracy: 0.0165\n",
            "Epoch 312/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1150109.7500 - accuracy: 0.0021 - val_loss: 580613.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1131384.6250 - accuracy: 0.0041 - val_loss: 572794.5625 - val_accuracy: 0.0165\n",
            "Epoch 314/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1158175.1250 - accuracy: 0.0083 - val_loss: 579122.0625 - val_accuracy: 0.0165\n",
            "Epoch 315/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1134320.2500 - accuracy: 0.0103 - val_loss: 591354.0625 - val_accuracy: 0.0165\n",
            "Epoch 316/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1170148.0000 - accuracy: 0.0124 - val_loss: 599807.1875 - val_accuracy: 0.0083\n",
            "Epoch 317/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1169434.7500 - accuracy: 0.0083 - val_loss: 600935.1875 - val_accuracy: 0.0165\n",
            "Epoch 318/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1167114.0000 - accuracy: 0.0041 - val_loss: 604286.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1176942.1250 - accuracy: 0.0145 - val_loss: 602766.4375 - val_accuracy: 0.0165\n",
            "Epoch 320/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1198119.0000 - accuracy: 0.0000e+00 - val_loss: 606635.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1220272.0000 - accuracy: 0.0083 - val_loss: 630916.5625 - val_accuracy: 0.0165\n",
            "Epoch 322/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1183938.0000 - accuracy: 0.0083 - val_loss: 621251.9375 - val_accuracy: 0.0165\n",
            "Epoch 323/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1196243.8750 - accuracy: 0.0062 - val_loss: 623688.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1204221.2500 - accuracy: 0.0062 - val_loss: 642056.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1247179.6250 - accuracy: 0.0041 - val_loss: 636226.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1231727.1250 - accuracy: 0.0062 - val_loss: 635597.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1237556.3750 - accuracy: 0.0041 - val_loss: 637367.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1244061.6250 - accuracy: 0.0041 - val_loss: 660458.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1268908.1250 - accuracy: 0.0062 - val_loss: 645481.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1296546.3750 - accuracy: 0.0062 - val_loss: 659442.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1285728.6250 - accuracy: 0.0041 - val_loss: 677333.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1278547.0000 - accuracy: 0.0000e+00 - val_loss: 681997.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1298906.8750 - accuracy: 0.0000e+00 - val_loss: 671113.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1295612.3750 - accuracy: 0.0041 - val_loss: 687742.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1283351.2500 - accuracy: 0.0103 - val_loss: 698337.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1312731.7500 - accuracy: 0.0041 - val_loss: 694869.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1341585.2500 - accuracy: 0.0062 - val_loss: 686405.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1330818.1250 - accuracy: 0.0062 - val_loss: 699335.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1328746.8750 - accuracy: 0.0021 - val_loss: 694195.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1360561.0000 - accuracy: 0.0041 - val_loss: 713934.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1351889.2500 - accuracy: 0.0041 - val_loss: 709763.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1363254.6250 - accuracy: 0.0041 - val_loss: 723603.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1358542.1250 - accuracy: 0.0062 - val_loss: 716058.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1369789.5000 - accuracy: 0.0021 - val_loss: 739410.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1373375.7500 - accuracy: 0.0062 - val_loss: 742442.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1381531.7500 - accuracy: 0.0103 - val_loss: 737617.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1407290.0000 - accuracy: 0.0083 - val_loss: 744347.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1372293.6250 - accuracy: 0.0021 - val_loss: 754387.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1394996.3750 - accuracy: 0.0021 - val_loss: 752398.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1441745.2500 - accuracy: 0.0062 - val_loss: 742908.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1431893.3750 - accuracy: 0.0083 - val_loss: 753064.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1467235.1250 - accuracy: 0.0103 - val_loss: 761309.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1464950.7500 - accuracy: 0.0062 - val_loss: 781078.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1457490.1250 - accuracy: 0.0062 - val_loss: 786929.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1462056.6250 - accuracy: 0.0041 - val_loss: 794284.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1512595.1250 - accuracy: 0.0083 - val_loss: 789111.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1504116.5000 - accuracy: 0.0062 - val_loss: 807864.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1505533.5000 - accuracy: 0.0041 - val_loss: 796534.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1487520.5000 - accuracy: 0.0083 - val_loss: 820079.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1504891.3750 - accuracy: 0.0041 - val_loss: 836235.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1535902.2500 - accuracy: 0.0041 - val_loss: 829873.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1546518.8750 - accuracy: 0.0041 - val_loss: 825539.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1543014.6250 - accuracy: 0.0041 - val_loss: 839654.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1532400.3750 - accuracy: 0.0000e+00 - val_loss: 829998.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1566573.3750 - accuracy: 0.0062 - val_loss: 847116.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1539255.8750 - accuracy: 0.0021 - val_loss: 860380.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1572968.6250 - accuracy: 0.0124 - val_loss: 883061.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1583023.0000 - accuracy: 0.0021 - val_loss: 867174.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1571966.6250 - accuracy: 0.0062 - val_loss: 881843.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1590961.0000 - accuracy: 0.0000e+00 - val_loss: 860236.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1614873.8750 - accuracy: 0.0021 - val_loss: 861034.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1624097.8750 - accuracy: 0.0021 - val_loss: 843626.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1630673.0000 - accuracy: 0.0062 - val_loss: 866614.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1648409.0000 - accuracy: 0.0021 - val_loss: 874387.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1641288.3750 - accuracy: 0.0103 - val_loss: 862042.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1654012.0000 - accuracy: 0.0103 - val_loss: 874613.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1633827.6250 - accuracy: 0.0000e+00 - val_loss: 883771.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1681588.0000 - accuracy: 0.0124 - val_loss: 904854.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1715347.2500 - accuracy: 0.0062 - val_loss: 910949.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1722348.3750 - accuracy: 0.0000e+00 - val_loss: 915317.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1722627.1250 - accuracy: 0.0062 - val_loss: 909856.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1716026.3750 - accuracy: 0.0062 - val_loss: 932890.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1746587.5000 - accuracy: 0.0041 - val_loss: 933814.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1773039.0000 - accuracy: 0.0062 - val_loss: 953207.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1763765.3750 - accuracy: 0.0062 - val_loss: 945998.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1768155.5000 - accuracy: 0.0021 - val_loss: 960696.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1769657.8750 - accuracy: 0.0021 - val_loss: 958382.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1791477.1250 - accuracy: 0.0041 - val_loss: 972640.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1794467.5000 - accuracy: 0.0021 - val_loss: 986501.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1802026.1250 - accuracy: 0.0062 - val_loss: 1003911.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1809292.2500 - accuracy: 0.0062 - val_loss: 1013292.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1833631.8750 - accuracy: 0.0083 - val_loss: 1036049.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1826756.3750 - accuracy: 0.0021 - val_loss: 1052906.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1829401.7500 - accuracy: 0.0062 - val_loss: 1048061.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1837502.7500 - accuracy: 0.0041 - val_loss: 1049869.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1876489.0000 - accuracy: 0.0041 - val_loss: 1038262.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1891119.0000 - accuracy: 0.0000e+00 - val_loss: 1052945.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1906193.6250 - accuracy: 0.0103 - val_loss: 1051799.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1865361.8750 - accuracy: 0.0041 - val_loss: 1059124.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1888116.7500 - accuracy: 0.0083 - val_loss: 1049584.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 1911927.8750 - accuracy: 0.0021    \n",
            "Epoch: 400, accuracy:0.0021,  loss:1911927.8750,  val_accuracy:0.0000,  val_loss:1065924.7500,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1911927.8750 - accuracy: 0.0021 - val_loss: 1065924.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1894836.5000 - accuracy: 0.0062 - val_loss: 1085548.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1925922.1250 - accuracy: 0.0000e+00 - val_loss: 1105069.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1927978.7500 - accuracy: 0.0041 - val_loss: 1102257.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1915764.8750 - accuracy: 0.0000e+00 - val_loss: 1096693.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1958225.7500 - accuracy: 0.0083 - val_loss: 1102438.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1984477.6250 - accuracy: 0.0041 - val_loss: 1118834.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1967017.2500 - accuracy: 0.0083 - val_loss: 1138450.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1985839.5000 - accuracy: 0.0103 - val_loss: 1103589.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2010983.0000 - accuracy: 0.0083 - val_loss: 1136884.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1982102.5000 - accuracy: 0.0021 - val_loss: 1115266.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2000303.3750 - accuracy: 0.0083 - val_loss: 1146964.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2032029.2500 - accuracy: 0.0062 - val_loss: 1140475.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2033721.0000 - accuracy: 0.0062 - val_loss: 1151193.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2024497.3750 - accuracy: 0.0062 - val_loss: 1161024.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2051412.8750 - accuracy: 0.0062 - val_loss: 1128157.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2056389.8750 - accuracy: 0.0000e+00 - val_loss: 1156884.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2083791.5000 - accuracy: 0.0083 - val_loss: 1182966.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2110589.5000 - accuracy: 0.0041 - val_loss: 1195019.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2092279.6250 - accuracy: 0.0000e+00 - val_loss: 1178551.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2089897.0000 - accuracy: 0.0124 - val_loss: 1203498.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2139816.0000 - accuracy: 0.0041 - val_loss: 1186698.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2110681.7500 - accuracy: 0.0000e+00 - val_loss: 1203037.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2116932.7500 - accuracy: 0.0041 - val_loss: 1211211.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2126511.0000 - accuracy: 0.0041 - val_loss: 1214478.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2148911.7500 - accuracy: 0.0000e+00 - val_loss: 1221526.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2180453.0000 - accuracy: 0.0083 - val_loss: 1230025.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2162871.0000 - accuracy: 0.0000e+00 - val_loss: 1232719.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2220400.7500 - accuracy: 0.0145 - val_loss: 1200845.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2172241.2500 - accuracy: 0.0041 - val_loss: 1248969.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2247286.2500 - accuracy: 0.0062 - val_loss: 1233684.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2208356.0000 - accuracy: 0.0062 - val_loss: 1254089.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2244218.7500 - accuracy: 0.0041 - val_loss: 1262169.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2293376.2500 - accuracy: 0.0062 - val_loss: 1272659.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2281878.2500 - accuracy: 0.0000e+00 - val_loss: 1259173.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2257694.2500 - accuracy: 0.0041 - val_loss: 1306374.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2276325.2500 - accuracy: 0.0083 - val_loss: 1259765.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2275749.7500 - accuracy: 0.0062 - val_loss: 1269226.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2304444.0000 - accuracy: 0.0000e+00 - val_loss: 1310088.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2269075.0000 - accuracy: 0.0021 - val_loss: 1290426.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2311971.5000 - accuracy: 0.0083 - val_loss: 1289318.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2326263.5000 - accuracy: 0.0021 - val_loss: 1304080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2370446.2500 - accuracy: 0.0021 - val_loss: 1300851.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2361092.2500 - accuracy: 0.0083 - val_loss: 1324711.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2374063.2500 - accuracy: 0.0041 - val_loss: 1331815.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2367264.2500 - accuracy: 0.0021 - val_loss: 1361563.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2399730.5000 - accuracy: 0.0021 - val_loss: 1306540.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2401581.5000 - accuracy: 0.0041 - val_loss: 1348447.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2411809.0000 - accuracy: 0.0021 - val_loss: 1357608.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2474188.0000 - accuracy: 0.0021 - val_loss: 1365310.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2483269.2500 - accuracy: 0.0062 - val_loss: 1357644.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2443584.2500 - accuracy: 0.0062 - val_loss: 1411067.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2475799.0000 - accuracy: 0.0062 - val_loss: 1384392.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2473262.5000 - accuracy: 0.0021 - val_loss: 1389273.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2505307.7500 - accuracy: 0.0124 - val_loss: 1403348.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2477829.2500 - accuracy: 0.0021 - val_loss: 1413665.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2542940.0000 - accuracy: 0.0021 - val_loss: 1420287.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2518924.7500 - accuracy: 0.0062 - val_loss: 1389685.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2483539.7500 - accuracy: 0.0021 - val_loss: 1412813.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2513718.0000 - accuracy: 0.0103 - val_loss: 1400530.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2535645.0000 - accuracy: 0.0021 - val_loss: 1413001.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2595435.7500 - accuracy: 0.0000e+00 - val_loss: 1404078.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2595222.0000 - accuracy: 0.0041 - val_loss: 1418625.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2541085.5000 - accuracy: 0.0041 - val_loss: 1453655.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2636095.7500 - accuracy: 0.0021 - val_loss: 1441915.5000 - val_accuracy: 0.0083\n",
            "Epoch 466/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2593876.0000 - accuracy: 0.0021 - val_loss: 1451034.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2593420.7500 - accuracy: 0.0062 - val_loss: 1476642.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2609403.7500 - accuracy: 0.0041 - val_loss: 1475495.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2663163.5000 - accuracy: 0.0062 - val_loss: 1492562.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2661475.5000 - accuracy: 0.0083 - val_loss: 1491660.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2694810.7500 - accuracy: 0.0041 - val_loss: 1497979.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2709251.7500 - accuracy: 0.0041 - val_loss: 1515700.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2676951.0000 - accuracy: 0.0021 - val_loss: 1507131.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2726339.5000 - accuracy: 0.0041 - val_loss: 1534116.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2736190.7500 - accuracy: 0.0021 - val_loss: 1556262.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2755378.2500 - accuracy: 0.0083 - val_loss: 1528391.8750 - val_accuracy: 0.0165\n",
            "Epoch 477/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2788211.7500 - accuracy: 0.0041 - val_loss: 1546410.6250 - val_accuracy: 0.0165\n",
            "Epoch 478/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2772740.2500 - accuracy: 0.0021 - val_loss: 1558225.5000 - val_accuracy: 0.0165\n",
            "Epoch 479/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2787215.5000 - accuracy: 0.0000e+00 - val_loss: 1587156.1250 - val_accuracy: 0.0165\n",
            "Epoch 480/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2752500.0000 - accuracy: 0.0083 - val_loss: 1557389.7500 - val_accuracy: 0.0165\n",
            "Epoch 481/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2783068.5000 - accuracy: 0.0021 - val_loss: 1563430.7500 - val_accuracy: 0.0165\n",
            "Epoch 482/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2809578.5000 - accuracy: 0.0062 - val_loss: 1623042.8750 - val_accuracy: 0.0165\n",
            "Epoch 483/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2867421.5000 - accuracy: 0.0062 - val_loss: 1570794.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2848262.2500 - accuracy: 0.0083 - val_loss: 1631243.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2857507.5000 - accuracy: 0.0124 - val_loss: 1627035.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2914757.0000 - accuracy: 0.0021 - val_loss: 1641111.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2894634.7500 - accuracy: 0.0021 - val_loss: 1625293.8750 - val_accuracy: 0.0165\n",
            "Epoch 488/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2898841.5000 - accuracy: 0.0041 - val_loss: 1648991.7500 - val_accuracy: 0.0165\n",
            "Epoch 489/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2886468.2500 - accuracy: 0.0041 - val_loss: 1637752.8750 - val_accuracy: 0.0165\n",
            "Epoch 490/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2927319.5000 - accuracy: 0.0103 - val_loss: 1665541.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2954999.2500 - accuracy: 0.0041 - val_loss: 1654790.2500 - val_accuracy: 0.0165\n",
            "Epoch 492/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2929616.7500 - accuracy: 0.0083 - val_loss: 1671435.5000 - val_accuracy: 0.0165\n",
            "Epoch 493/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2983512.2500 - accuracy: 0.0041 - val_loss: 1713088.0000 - val_accuracy: 0.0165\n",
            "Epoch 494/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2939893.5000 - accuracy: 0.0021 - val_loss: 1660111.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2945402.7500 - accuracy: 0.0083 - val_loss: 1732217.7500 - val_accuracy: 0.0165\n",
            "Epoch 496/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3038813.0000 - accuracy: 0.0062 - val_loss: 1705202.2500 - val_accuracy: 0.0165\n",
            "Epoch 497/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3011964.5000 - accuracy: 0.0062 - val_loss: 1691465.0000 - val_accuracy: 0.0165\n",
            "Epoch 498/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2979382.7500 - accuracy: 0.0062 - val_loss: 1700053.3750 - val_accuracy: 0.0165\n",
            "Epoch 499/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3108579.2500 - accuracy: 0.0041 - val_loss: 1726028.1250 - val_accuracy: 0.0083\n",
            "Epoch 500/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3046058.0000 - accuracy: 0.0041 - val_loss: 1761545.0000 - val_accuracy: 0.0165\n",
            "Epoch 501/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 3047791.7500 - accuracy: 0.0000e+00\n",
            "Epoch: 500, accuracy:0.0083,  loss:3075899.2500,  val_accuracy:0.0165,  val_loss:1770960.3750,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3075899.2500 - accuracy: 0.0083 - val_loss: 1770960.3750 - val_accuracy: 0.0165\n",
            "Epoch 502/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3091991.5000 - accuracy: 0.0062 - val_loss: 1751219.0000 - val_accuracy: 0.0083\n",
            "Epoch 503/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3068161.7500 - accuracy: 0.0041 - val_loss: 1790805.2500 - val_accuracy: 0.0165\n",
            "Epoch 504/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3073038.0000 - accuracy: 0.0021 - val_loss: 1789340.2500 - val_accuracy: 0.0165\n",
            "Epoch 505/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3114906.2500 - accuracy: 0.0062 - val_loss: 1820025.6250 - val_accuracy: 0.0165\n",
            "Epoch 506/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3135495.2500 - accuracy: 0.0062 - val_loss: 1803073.3750 - val_accuracy: 0.0165\n",
            "Epoch 507/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3136681.0000 - accuracy: 0.0000e+00 - val_loss: 1816607.7500 - val_accuracy: 0.0165\n",
            "Epoch 508/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3122850.5000 - accuracy: 0.0062 - val_loss: 1813436.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3201309.5000 - accuracy: 0.0041 - val_loss: 1843019.1250 - val_accuracy: 0.0165\n",
            "Epoch 510/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3176543.2500 - accuracy: 0.0062 - val_loss: 1826896.1250 - val_accuracy: 0.0165\n",
            "Epoch 511/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3165899.0000 - accuracy: 0.0062 - val_loss: 1836995.1250 - val_accuracy: 0.0165\n",
            "Epoch 512/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3237698.5000 - accuracy: 0.0021 - val_loss: 1875055.3750 - val_accuracy: 0.0165\n",
            "Epoch 513/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3253496.5000 - accuracy: 0.0083 - val_loss: 1871781.5000 - val_accuracy: 0.0165\n",
            "Epoch 514/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3231826.2500 - accuracy: 0.0103 - val_loss: 1872207.8750 - val_accuracy: 0.0165\n",
            "Epoch 515/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3242631.0000 - accuracy: 0.0021 - val_loss: 1874369.6250 - val_accuracy: 0.0165\n",
            "Epoch 516/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3237660.2500 - accuracy: 0.0062 - val_loss: 1919707.5000 - val_accuracy: 0.0165\n",
            "Epoch 517/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3293711.7500 - accuracy: 0.0000e+00 - val_loss: 1899247.1250 - val_accuracy: 0.0165\n",
            "Epoch 518/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3273010.2500 - accuracy: 0.0083 - val_loss: 1901666.1250 - val_accuracy: 0.0165\n",
            "Epoch 519/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3298448.7500 - accuracy: 0.0021 - val_loss: 1923585.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3379546.2500 - accuracy: 0.0041 - val_loss: 1904515.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3315496.5000 - accuracy: 0.0021 - val_loss: 1928467.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3327755.0000 - accuracy: 0.0021 - val_loss: 1953884.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3335868.5000 - accuracy: 0.0041 - val_loss: 1989682.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3392207.0000 - accuracy: 0.0021 - val_loss: 1997393.6250 - val_accuracy: 0.0165\n",
            "Epoch 525/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3451785.0000 - accuracy: 0.0083 - val_loss: 2021281.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3439548.7500 - accuracy: 0.0083 - val_loss: 2009699.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3424004.5000 - accuracy: 0.0062 - val_loss: 2019273.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3429676.2500 - accuracy: 0.0021 - val_loss: 2035101.6250 - val_accuracy: 0.0165\n",
            "Epoch 529/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3396686.7500 - accuracy: 0.0021 - val_loss: 2040515.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3438542.7500 - accuracy: 0.0041 - val_loss: 2020005.0000 - val_accuracy: 0.0165\n",
            "Epoch 531/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3461564.2500 - accuracy: 0.0041 - val_loss: 2047452.0000 - val_accuracy: 0.0083\n",
            "Epoch 532/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3548848.5000 - accuracy: 0.0062 - val_loss: 2107225.7500 - val_accuracy: 0.0165\n",
            "Epoch 533/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3508115.5000 - accuracy: 0.0041 - val_loss: 2092805.1250 - val_accuracy: 0.0165\n",
            "Epoch 534/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3532454.0000 - accuracy: 0.0041 - val_loss: 2070873.8750 - val_accuracy: 0.0165\n",
            "Epoch 535/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3520991.0000 - accuracy: 0.0083 - val_loss: 2066171.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3502774.7500 - accuracy: 0.0083 - val_loss: 2100369.0000 - val_accuracy: 0.0165\n",
            "Epoch 537/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3539462.5000 - accuracy: 0.0083 - val_loss: 2109315.0000 - val_accuracy: 0.0165\n",
            "Epoch 538/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3598206.2500 - accuracy: 0.0062 - val_loss: 2154188.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3552305.2500 - accuracy: 0.0103 - val_loss: 2101837.0000 - val_accuracy: 0.0165\n",
            "Epoch 540/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3606796.0000 - accuracy: 0.0021 - val_loss: 2113111.0000 - val_accuracy: 0.0165\n",
            "Epoch 541/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3628003.0000 - accuracy: 0.0062 - val_loss: 2137875.2500 - val_accuracy: 0.0165\n",
            "Epoch 542/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3651833.5000 - accuracy: 0.0021 - val_loss: 2154505.5000 - val_accuracy: 0.0165\n",
            "Epoch 543/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3692146.0000 - accuracy: 0.0186 - val_loss: 2181425.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3656042.0000 - accuracy: 0.0083 - val_loss: 2192368.5000 - val_accuracy: 0.0165\n",
            "Epoch 545/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3734558.2500 - accuracy: 0.0062 - val_loss: 2171946.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3726762.5000 - accuracy: 0.0021 - val_loss: 2211252.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3743256.2500 - accuracy: 0.0041 - val_loss: 2197304.2500 - val_accuracy: 0.0165\n",
            "Epoch 548/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3743520.5000 - accuracy: 0.0021 - val_loss: 2205364.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3765271.2500 - accuracy: 0.0103 - val_loss: 2212135.0000 - val_accuracy: 0.0165\n",
            "Epoch 550/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3757540.5000 - accuracy: 0.0124 - val_loss: 2210999.5000 - val_accuracy: 0.0165\n",
            "Epoch 551/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3741538.5000 - accuracy: 0.0083 - val_loss: 2200802.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3749077.0000 - accuracy: 0.0000e+00 - val_loss: 2245479.7500 - val_accuracy: 0.0165\n",
            "Epoch 553/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3752787.0000 - accuracy: 0.0021 - val_loss: 2291037.2500 - val_accuracy: 0.0165\n",
            "Epoch 554/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3834518.5000 - accuracy: 0.0083 - val_loss: 2265204.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3883917.2500 - accuracy: 0.0041 - val_loss: 2217841.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3880760.5000 - accuracy: 0.0062 - val_loss: 2277896.2500 - val_accuracy: 0.0165\n",
            "Epoch 557/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3872544.7500 - accuracy: 0.0021 - val_loss: 2272152.5000 - val_accuracy: 0.0165\n",
            "Epoch 558/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3805582.0000 - accuracy: 0.0000e+00 - val_loss: 2316035.5000 - val_accuracy: 0.0165\n",
            "Epoch 559/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3937487.7500 - accuracy: 0.0124 - val_loss: 2323487.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3927668.2500 - accuracy: 0.0062 - val_loss: 2323691.7500 - val_accuracy: 0.0165\n",
            "Epoch 561/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3884241.0000 - accuracy: 0.0041 - val_loss: 2368658.5000 - val_accuracy: 0.0165\n",
            "Epoch 562/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3964195.0000 - accuracy: 0.0021 - val_loss: 2342989.7500 - val_accuracy: 0.0165\n",
            "Epoch 563/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3927337.0000 - accuracy: 0.0021 - val_loss: 2341897.5000 - val_accuracy: 0.0165\n",
            "Epoch 564/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3935860.7500 - accuracy: 0.0062 - val_loss: 2356373.2500 - val_accuracy: 0.0165\n",
            "Epoch 565/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4017017.7500 - accuracy: 0.0000e+00 - val_loss: 2416495.5000 - val_accuracy: 0.0165\n",
            "Epoch 566/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4106972.7500 - accuracy: 0.0041 - val_loss: 2363715.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4029310.5000 - accuracy: 0.0021 - val_loss: 2400774.2500 - val_accuracy: 0.0165\n",
            "Epoch 568/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4019778.7500 - accuracy: 0.0103 - val_loss: 2426488.0000 - val_accuracy: 0.0165\n",
            "Epoch 569/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4079733.7500 - accuracy: 0.0021 - val_loss: 2419135.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4060484.0000 - accuracy: 0.0062 - val_loss: 2413936.5000 - val_accuracy: 0.0165\n",
            "Epoch 571/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4114781.2500 - accuracy: 0.0021 - val_loss: 2409637.0000 - val_accuracy: 0.0165\n",
            "Epoch 572/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4103692.5000 - accuracy: 0.0062 - val_loss: 2473773.2500 - val_accuracy: 0.0165\n",
            "Epoch 573/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4157510.0000 - accuracy: 0.0083 - val_loss: 2532538.2500 - val_accuracy: 0.0165\n",
            "Epoch 574/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4114790.2500 - accuracy: 0.0021 - val_loss: 2503363.7500 - val_accuracy: 0.0165\n",
            "Epoch 575/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4148455.5000 - accuracy: 0.0041 - val_loss: 2464017.5000 - val_accuracy: 0.0165\n",
            "Epoch 576/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4174396.5000 - accuracy: 0.0103 - val_loss: 2478439.2500 - val_accuracy: 0.0165\n",
            "Epoch 577/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4126508.5000 - accuracy: 0.0021 - val_loss: 2536361.7500 - val_accuracy: 0.0165\n",
            "Epoch 578/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4204463.5000 - accuracy: 0.0000e+00 - val_loss: 2493538.5000 - val_accuracy: 0.0165\n",
            "Epoch 579/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4227295.0000 - accuracy: 0.0021 - val_loss: 2520598.5000 - val_accuracy: 0.0165\n",
            "Epoch 580/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4231857.5000 - accuracy: 0.0000e+00 - val_loss: 2527146.2500 - val_accuracy: 0.0165\n",
            "Epoch 581/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4202857.0000 - accuracy: 0.0041 - val_loss: 2507746.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4204885.0000 - accuracy: 0.0062 - val_loss: 2513644.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4286796.5000 - accuracy: 0.0083 - val_loss: 2541870.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4251713.0000 - accuracy: 0.0083 - val_loss: 2559918.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4324711.5000 - accuracy: 0.0083 - val_loss: 2561115.7500 - val_accuracy: 0.0165\n",
            "Epoch 586/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4308504.0000 - accuracy: 0.0062 - val_loss: 2539473.5000 - val_accuracy: 0.0165\n",
            "Epoch 587/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4338234.0000 - accuracy: 0.0041 - val_loss: 2573977.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4321983.0000 - accuracy: 0.0083 - val_loss: 2590997.7500 - val_accuracy: 0.0165\n",
            "Epoch 589/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4353846.5000 - accuracy: 0.0000e+00 - val_loss: 2606173.5000 - val_accuracy: 0.0165\n",
            "Epoch 590/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4333850.0000 - accuracy: 0.0041 - val_loss: 2606506.0000 - val_accuracy: 0.0165\n",
            "Epoch 591/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4349020.5000 - accuracy: 0.0021 - val_loss: 2587438.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4384760.5000 - accuracy: 0.0021 - val_loss: 2672222.7500 - val_accuracy: 0.0165\n",
            "Epoch 593/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4403304.5000 - accuracy: 0.0021 - val_loss: 2688024.7500 - val_accuracy: 0.0165\n",
            "Epoch 594/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4394439.0000 - accuracy: 0.0041 - val_loss: 2691009.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4472959.0000 - accuracy: 0.0021 - val_loss: 2745685.7500 - val_accuracy: 0.0165\n",
            "Epoch 596/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4500675.5000 - accuracy: 0.0041 - val_loss: 2669783.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4508118.0000 - accuracy: 0.0041 - val_loss: 2691609.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4576281.0000 - accuracy: 0.0021 - val_loss: 2725591.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4538143.5000 - accuracy: 0.0021 - val_loss: 2739586.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4629312.0000 - accuracy: 0.0021 - val_loss: 2756843.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 601/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 5113765.0000 - accuracy: 0.0000e+00\n",
            "Epoch: 600, accuracy:0.0041,  loss:4552255.5000,  val_accuracy:0.0000,  val_loss:2817260.2500,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4552255.5000 - accuracy: 0.0041 - val_loss: 2817260.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4579722.5000 - accuracy: 0.0103 - val_loss: 2793457.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4570755.5000 - accuracy: 0.0000e+00 - val_loss: 2790519.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4678867.0000 - accuracy: 0.0041 - val_loss: 2797305.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4600514.0000 - accuracy: 0.0124 - val_loss: 2875801.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4659729.5000 - accuracy: 0.0062 - val_loss: 2797479.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4698666.5000 - accuracy: 0.0000e+00 - val_loss: 2796446.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4696785.5000 - accuracy: 0.0000e+00 - val_loss: 2834012.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4713755.5000 - accuracy: 0.0062 - val_loss: 2876325.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4763859.0000 - accuracy: 0.0041 - val_loss: 2840822.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4740120.0000 - accuracy: 0.0062 - val_loss: 2869822.2500 - val_accuracy: 0.0083\n",
            "Epoch 612/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4696698.5000 - accuracy: 0.0062 - val_loss: 2890312.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4799907.0000 - accuracy: 0.0041 - val_loss: 2878017.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4805608.5000 - accuracy: 0.0021 - val_loss: 2869812.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4802739.0000 - accuracy: 0.0062 - val_loss: 2884609.7500 - val_accuracy: 0.0165\n",
            "Epoch 616/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4730078.0000 - accuracy: 0.0062 - val_loss: 2955510.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4831155.0000 - accuracy: 0.0021 - val_loss: 2992558.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4885440.5000 - accuracy: 0.0021 - val_loss: 2948613.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4915273.0000 - accuracy: 0.0062 - val_loss: 2926950.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4849583.0000 - accuracy: 0.0021 - val_loss: 3002924.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4885614.5000 - accuracy: 0.0041 - val_loss: 2987809.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4972894.5000 - accuracy: 0.0021 - val_loss: 2994515.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4940060.0000 - accuracy: 0.0041 - val_loss: 3022331.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4975783.5000 - accuracy: 0.0021 - val_loss: 3062624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4943726.0000 - accuracy: 0.0062 - val_loss: 3056227.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5019207.0000 - accuracy: 0.0000e+00 - val_loss: 3073932.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4957428.5000 - accuracy: 0.0000e+00 - val_loss: 3067376.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5036491.5000 - accuracy: 0.0021 - val_loss: 3084619.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5114574.5000 - accuracy: 0.0041 - val_loss: 3114199.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4998582.5000 - accuracy: 0.0021 - val_loss: 3082613.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5091573.0000 - accuracy: 0.0021 - val_loss: 3091020.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5113443.0000 - accuracy: 0.0062 - val_loss: 3019598.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5106011.0000 - accuracy: 0.0062 - val_loss: 3113100.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5213087.0000 - accuracy: 0.0041 - val_loss: 3098650.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5200690.0000 - accuracy: 0.0041 - val_loss: 3094990.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5200439.0000 - accuracy: 0.0021 - val_loss: 3160949.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5213565.5000 - accuracy: 0.0103 - val_loss: 3129745.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5126191.0000 - accuracy: 0.0000e+00 - val_loss: 3190326.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5205098.5000 - accuracy: 0.0000e+00 - val_loss: 3166599.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5252806.5000 - accuracy: 0.0000e+00 - val_loss: 3131428.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5241365.0000 - accuracy: 0.0062 - val_loss: 3135342.0000 - val_accuracy: 0.0083\n",
            "Epoch 642/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5329660.5000 - accuracy: 0.0021 - val_loss: 3153121.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5298532.0000 - accuracy: 0.0041 - val_loss: 3177088.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5327435.0000 - accuracy: 0.0062 - val_loss: 3210858.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5423514.0000 - accuracy: 0.0000e+00 - val_loss: 3227302.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5318856.5000 - accuracy: 0.0021 - val_loss: 3233376.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5429656.0000 - accuracy: 0.0062 - val_loss: 3254445.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5384239.5000 - accuracy: 0.0083 - val_loss: 3285326.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5368540.5000 - accuracy: 0.0041 - val_loss: 3296660.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5461467.5000 - accuracy: 0.0083 - val_loss: 3295990.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5464805.0000 - accuracy: 0.0062 - val_loss: 3295387.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5542674.5000 - accuracy: 0.0041 - val_loss: 3345838.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5429409.0000 - accuracy: 0.0021 - val_loss: 3375796.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5449684.0000 - accuracy: 0.0041 - val_loss: 3363620.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5477907.0000 - accuracy: 0.0041 - val_loss: 3364876.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5547827.0000 - accuracy: 0.0021 - val_loss: 3373599.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5507948.0000 - accuracy: 0.0000e+00 - val_loss: 3428127.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5675451.0000 - accuracy: 0.0041 - val_loss: 3431932.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5636441.0000 - accuracy: 0.0000e+00 - val_loss: 3428529.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5607454.5000 - accuracy: 0.0021 - val_loss: 3512687.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5606188.5000 - accuracy: 0.0083 - val_loss: 3520346.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5644133.0000 - accuracy: 0.0000e+00 - val_loss: 3440690.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5641768.5000 - accuracy: 0.0041 - val_loss: 3521811.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5683166.0000 - accuracy: 0.0021 - val_loss: 3533173.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5706865.0000 - accuracy: 0.0021 - val_loss: 3528248.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5721143.5000 - accuracy: 0.0062 - val_loss: 3539787.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5766257.0000 - accuracy: 0.0041 - val_loss: 3570601.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5775705.5000 - accuracy: 0.0124 - val_loss: 3599297.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5718873.0000 - accuracy: 0.0021 - val_loss: 3590415.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5714663.0000 - accuracy: 0.0021 - val_loss: 3589941.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5884870.5000 - accuracy: 0.0041 - val_loss: 3593354.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5785057.0000 - accuracy: 0.0021 - val_loss: 3639935.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5870462.5000 - accuracy: 0.0021 - val_loss: 3605720.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5833037.0000 - accuracy: 0.0062 - val_loss: 3679835.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5910484.0000 - accuracy: 0.0021 - val_loss: 3701991.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5826728.5000 - accuracy: 0.0021 - val_loss: 3697372.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5936311.5000 - accuracy: 0.0021 - val_loss: 3733517.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5951988.0000 - accuracy: 0.0021 - val_loss: 3686662.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5941430.0000 - accuracy: 0.0021 - val_loss: 3749003.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6085908.5000 - accuracy: 0.0021 - val_loss: 3787377.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5988702.0000 - accuracy: 0.0041 - val_loss: 3847925.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5996415.0000 - accuracy: 0.0021 - val_loss: 3820859.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6096272.0000 - accuracy: 0.0083 - val_loss: 3886315.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6070369.5000 - accuracy: 0.0000e+00 - val_loss: 3863873.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6097204.0000 - accuracy: 0.0062 - val_loss: 3844933.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6059358.0000 - accuracy: 0.0000e+00 - val_loss: 3917570.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6155161.5000 - accuracy: 0.0021 - val_loss: 3888428.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6177482.5000 - accuracy: 0.0000e+00 - val_loss: 3986236.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6210737.0000 - accuracy: 0.0041 - val_loss: 3937742.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6230965.5000 - accuracy: 0.0062 - val_loss: 4046555.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6196614.0000 - accuracy: 0.0103 - val_loss: 3966822.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6284032.5000 - accuracy: 0.0041 - val_loss: 3948615.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6296819.0000 - accuracy: 0.0000e+00 - val_loss: 3945068.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6257812.5000 - accuracy: 0.0062 - val_loss: 4068196.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6367583.5000 - accuracy: 0.0041 - val_loss: 4002413.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6308484.0000 - accuracy: 0.0041 - val_loss: 3982940.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6437727.0000 - accuracy: 0.0021 - val_loss: 3994094.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6443176.0000 - accuracy: 0.0000e+00 - val_loss: 3983395.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6473645.0000 - accuracy: 0.0041 - val_loss: 4058726.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6505047.5000 - accuracy: 0.0062 - val_loss: 4038262.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 701/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 6549527.0000 - accuracy: 0.0000e+00\n",
            "Epoch: 700, accuracy:0.0021,  loss:6458816.0000,  val_accuracy:0.0000,  val_loss:4072174.5000,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6458816.0000 - accuracy: 0.0021 - val_loss: 4072174.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6444021.0000 - accuracy: 0.0062 - val_loss: 4066041.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6453446.0000 - accuracy: 0.0041 - val_loss: 4099873.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6484469.5000 - accuracy: 0.0062 - val_loss: 4162496.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6528929.0000 - accuracy: 0.0021 - val_loss: 4181686.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6549994.5000 - accuracy: 0.0021 - val_loss: 4146289.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6598474.5000 - accuracy: 0.0000e+00 - val_loss: 4157208.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6695502.0000 - accuracy: 0.0000e+00 - val_loss: 4235554.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6664284.5000 - accuracy: 0.0000e+00 - val_loss: 4203589.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6605041.0000 - accuracy: 0.0021 - val_loss: 4253070.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6824445.0000 - accuracy: 0.0000e+00 - val_loss: 4306790.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6679032.5000 - accuracy: 0.0041 - val_loss: 4277869.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6705686.0000 - accuracy: 0.0062 - val_loss: 4270871.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6719269.5000 - accuracy: 0.0103 - val_loss: 4241453.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6696519.0000 - accuracy: 0.0124 - val_loss: 4286910.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6737914.5000 - accuracy: 0.0000e+00 - val_loss: 4360605.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6799800.5000 - accuracy: 0.0062 - val_loss: 4239173.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6836112.0000 - accuracy: 0.0021 - val_loss: 4284065.5000 - val_accuracy: 0.0083\n",
            "Epoch 719/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6797365.0000 - accuracy: 0.0041 - val_loss: 4311557.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6800469.5000 - accuracy: 0.0041 - val_loss: 4350985.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6801029.5000 - accuracy: 0.0041 - val_loss: 4379776.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6815151.0000 - accuracy: 0.0000e+00 - val_loss: 4366449.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6940651.5000 - accuracy: 0.0021 - val_loss: 4374803.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6865748.0000 - accuracy: 0.0062 - val_loss: 4401137.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6948156.5000 - accuracy: 0.0021 - val_loss: 4491666.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7064645.0000 - accuracy: 0.0083 - val_loss: 4493026.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7049791.0000 - accuracy: 0.0041 - val_loss: 4496772.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7127848.0000 - accuracy: 0.0000e+00 - val_loss: 4509856.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7051341.0000 - accuracy: 0.0062 - val_loss: 4508267.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6996090.0000 - accuracy: 0.0041 - val_loss: 4638567.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7167689.5000 - accuracy: 0.0000e+00 - val_loss: 4564564.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7201392.0000 - accuracy: 0.0041 - val_loss: 4631441.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7278152.0000 - accuracy: 0.0000e+00 - val_loss: 4613867.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7254438.0000 - accuracy: 0.0000e+00 - val_loss: 4594863.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7199100.0000 - accuracy: 0.0041 - val_loss: 4561567.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7232793.5000 - accuracy: 0.0000e+00 - val_loss: 4620077.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7233461.0000 - accuracy: 0.0021 - val_loss: 4619469.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7342109.5000 - accuracy: 0.0000e+00 - val_loss: 4617072.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7391114.0000 - accuracy: 0.0041 - val_loss: 4629940.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7304924.0000 - accuracy: 0.0021 - val_loss: 4665446.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7395187.0000 - accuracy: 0.0000e+00 - val_loss: 4718352.5000 - val_accuracy: 0.0083\n",
            "Epoch 742/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7549262.0000 - accuracy: 0.0021 - val_loss: 4671455.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7367836.5000 - accuracy: 0.0021 - val_loss: 4708408.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7382796.0000 - accuracy: 0.0021 - val_loss: 4794589.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7461658.5000 - accuracy: 0.0041 - val_loss: 4724433.5000 - val_accuracy: 0.0083\n",
            "Epoch 746/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7395029.0000 - accuracy: 0.0083 - val_loss: 4762776.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7552500.0000 - accuracy: 0.0021 - val_loss: 4839013.5000 - val_accuracy: 0.0083\n",
            "Epoch 748/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7596877.0000 - accuracy: 0.0083 - val_loss: 4748708.5000 - val_accuracy: 0.0083\n",
            "Epoch 749/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7510756.5000 - accuracy: 0.0083 - val_loss: 4807918.5000 - val_accuracy: 0.0083\n",
            "Epoch 750/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7575562.0000 - accuracy: 0.0021 - val_loss: 4866793.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7511009.0000 - accuracy: 0.0062 - val_loss: 4784599.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7469974.5000 - accuracy: 0.0000e+00 - val_loss: 4816163.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7672590.0000 - accuracy: 0.0000e+00 - val_loss: 4842855.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7775354.5000 - accuracy: 0.0021 - val_loss: 4816194.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7722037.0000 - accuracy: 0.0083 - val_loss: 4825023.0000 - val_accuracy: 0.0083\n",
            "Epoch 756/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7666920.0000 - accuracy: 0.0041 - val_loss: 4824249.5000 - val_accuracy: 0.0083\n",
            "Epoch 757/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7818618.0000 - accuracy: 0.0062 - val_loss: 4879042.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7670830.5000 - accuracy: 0.0041 - val_loss: 4948454.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7711393.0000 - accuracy: 0.0062 - val_loss: 4913250.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7885818.0000 - accuracy: 0.0083 - val_loss: 4937428.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7786808.5000 - accuracy: 0.0021 - val_loss: 4975768.0000 - val_accuracy: 0.0083\n",
            "Epoch 762/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7856275.0000 - accuracy: 0.0000e+00 - val_loss: 4951092.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7835342.5000 - accuracy: 0.0041 - val_loss: 4922030.5000 - val_accuracy: 0.0083\n",
            "Epoch 764/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7790188.5000 - accuracy: 0.0000e+00 - val_loss: 4949955.5000 - val_accuracy: 0.0083\n",
            "Epoch 765/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7882296.5000 - accuracy: 0.0000e+00 - val_loss: 5030081.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7954040.0000 - accuracy: 0.0000e+00 - val_loss: 5016433.0000 - val_accuracy: 0.0083\n",
            "Epoch 767/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7962394.5000 - accuracy: 0.0083 - val_loss: 5084335.0000 - val_accuracy: 0.0083\n",
            "Epoch 768/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7866902.5000 - accuracy: 0.0041 - val_loss: 5075837.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8062308.5000 - accuracy: 0.0041 - val_loss: 5022043.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7945916.0000 - accuracy: 0.0041 - val_loss: 5097145.5000 - val_accuracy: 0.0083\n",
            "Epoch 771/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8087828.0000 - accuracy: 0.0021 - val_loss: 5098538.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8003129.5000 - accuracy: 0.0021 - val_loss: 5164414.0000 - val_accuracy: 0.0083\n",
            "Epoch 773/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8057871.0000 - accuracy: 0.0021 - val_loss: 5162151.0000 - val_accuracy: 0.0083\n",
            "Epoch 774/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8134507.5000 - accuracy: 0.0083 - val_loss: 5206102.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8114013.5000 - accuracy: 0.0083 - val_loss: 5131417.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8115807.5000 - accuracy: 0.0041 - val_loss: 5133820.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8107579.0000 - accuracy: 0.0062 - val_loss: 5193931.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8293813.5000 - accuracy: 0.0041 - val_loss: 5205918.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8138011.0000 - accuracy: 0.0062 - val_loss: 5255175.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8146250.5000 - accuracy: 0.0021 - val_loss: 5237814.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8243641.0000 - accuracy: 0.0021 - val_loss: 5284695.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8252595.0000 - accuracy: 0.0083 - val_loss: 5341580.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8305959.5000 - accuracy: 0.0021 - val_loss: 5267138.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8327306.5000 - accuracy: 0.0041 - val_loss: 5357022.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8332071.5000 - accuracy: 0.0062 - val_loss: 5298768.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8375877.0000 - accuracy: 0.0021 - val_loss: 5362687.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8319177.0000 - accuracy: 0.0021 - val_loss: 5467371.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8524980.0000 - accuracy: 0.0021 - val_loss: 5380906.0000 - val_accuracy: 0.0083\n",
            "Epoch 789/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8400193.0000 - accuracy: 0.0041 - val_loss: 5356169.5000 - val_accuracy: 0.0083\n",
            "Epoch 790/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8547609.0000 - accuracy: 0.0103 - val_loss: 5358540.5000 - val_accuracy: 0.0083\n",
            "Epoch 791/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8411332.0000 - accuracy: 0.0041 - val_loss: 5471311.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8532977.0000 - accuracy: 0.0021 - val_loss: 5448656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8497342.0000 - accuracy: 0.0021 - val_loss: 5475968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8553117.0000 - accuracy: 0.0062 - val_loss: 5493192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8664592.0000 - accuracy: 0.0041 - val_loss: 5567903.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8653682.0000 - accuracy: 0.0041 - val_loss: 5538192.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8516314.0000 - accuracy: 0.0041 - val_loss: 5539816.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8617571.0000 - accuracy: 0.0021 - val_loss: 5538287.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8661723.0000 - accuracy: 0.0021 - val_loss: 5562156.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8735747.0000 - accuracy: 0.0000e+00 - val_loss: 5587703.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 801/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 8634698.0000 - accuracy: 0.0000e+00\n",
            "Epoch: 800, accuracy:0.0021,  loss:8716851.0000,  val_accuracy:0.0083,  val_loss:5600697.0000,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8716851.0000 - accuracy: 0.0021 - val_loss: 5600697.0000 - val_accuracy: 0.0083\n",
            "Epoch 802/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8904458.0000 - accuracy: 0.0041 - val_loss: 5701941.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8926453.0000 - accuracy: 0.0021 - val_loss: 5554581.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8955523.0000 - accuracy: 0.0041 - val_loss: 5675032.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8778202.0000 - accuracy: 0.0062 - val_loss: 5662188.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8814911.0000 - accuracy: 0.0021 - val_loss: 5717531.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8817973.0000 - accuracy: 0.0021 - val_loss: 5717609.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9132470.0000 - accuracy: 0.0021 - val_loss: 5648736.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8960304.0000 - accuracy: 0.0062 - val_loss: 5770663.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8898399.0000 - accuracy: 0.0021 - val_loss: 5671848.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9028081.0000 - accuracy: 0.0021 - val_loss: 5704867.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9039901.0000 - accuracy: 0.0021 - val_loss: 5711539.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9129812.0000 - accuracy: 0.0041 - val_loss: 5699515.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9058574.0000 - accuracy: 0.0083 - val_loss: 5772362.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9139684.0000 - accuracy: 0.0062 - val_loss: 5760449.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9082863.0000 - accuracy: 0.0021 - val_loss: 5770226.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8985988.0000 - accuracy: 0.0041 - val_loss: 5730494.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9079443.0000 - accuracy: 0.0041 - val_loss: 5794788.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9257683.0000 - accuracy: 0.0000e+00 - val_loss: 5875016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9011055.0000 - accuracy: 0.0021 - val_loss: 5896570.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9188199.0000 - accuracy: 0.0021 - val_loss: 5925153.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9446197.0000 - accuracy: 0.0021 - val_loss: 5954065.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9311378.0000 - accuracy: 0.0041 - val_loss: 5938115.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9333884.0000 - accuracy: 0.0021 - val_loss: 6038840.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9506816.0000 - accuracy: 0.0000e+00 - val_loss: 6000567.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9347400.0000 - accuracy: 0.0000e+00 - val_loss: 6025533.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9335389.0000 - accuracy: 0.0021 - val_loss: 6088266.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9500014.0000 - accuracy: 0.0000e+00 - val_loss: 6050577.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9324877.0000 - accuracy: 0.0021 - val_loss: 6149582.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9451559.0000 - accuracy: 0.0041 - val_loss: 6145795.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9683203.0000 - accuracy: 0.0021 - val_loss: 6032190.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9510727.0000 - accuracy: 0.0021 - val_loss: 6130731.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9617128.0000 - accuracy: 0.0041 - val_loss: 6080326.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9624895.0000 - accuracy: 0.0083 - val_loss: 6168003.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9563160.0000 - accuracy: 0.0021 - val_loss: 6236766.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9473571.0000 - accuracy: 0.0083 - val_loss: 6212766.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9591989.0000 - accuracy: 0.0062 - val_loss: 6183847.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9853519.0000 - accuracy: 0.0041 - val_loss: 6162424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9735705.0000 - accuracy: 0.0021 - val_loss: 6225828.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9708528.0000 - accuracy: 0.0041 - val_loss: 6338907.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9963761.0000 - accuracy: 0.0000e+00 - val_loss: 6281063.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9711140.0000 - accuracy: 0.0000e+00 - val_loss: 6314069.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9901852.0000 - accuracy: 0.0000e+00 - val_loss: 6310256.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9919471.0000 - accuracy: 0.0062 - val_loss: 6389203.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9941283.0000 - accuracy: 0.0083 - val_loss: 6401067.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9897418.0000 - accuracy: 0.0103 - val_loss: 6428229.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10107562.0000 - accuracy: 0.0041 - val_loss: 6473895.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9869758.0000 - accuracy: 0.0021 - val_loss: 6414883.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10118110.0000 - accuracy: 0.0000e+00 - val_loss: 6554482.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10004152.0000 - accuracy: 0.0021 - val_loss: 6604021.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9886607.0000 - accuracy: 0.0041 - val_loss: 6649899.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10263231.0000 - accuracy: 0.0083 - val_loss: 6565686.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10305807.0000 - accuracy: 0.0000e+00 - val_loss: 6681247.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10324191.0000 - accuracy: 0.0062 - val_loss: 6712196.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10203147.0000 - accuracy: 0.0041 - val_loss: 6683812.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10208038.0000 - accuracy: 0.0062 - val_loss: 6584045.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10201796.0000 - accuracy: 0.0041 - val_loss: 6721395.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10218915.0000 - accuracy: 0.0062 - val_loss: 6641010.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10246638.0000 - accuracy: 0.0041 - val_loss: 6620476.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10194389.0000 - accuracy: 0.0000e+00 - val_loss: 6605479.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10448799.0000 - accuracy: 0.0000e+00 - val_loss: 6638354.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10500078.0000 - accuracy: 0.0000e+00 - val_loss: 6751829.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10362637.0000 - accuracy: 0.0021 - val_loss: 6780927.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10399587.0000 - accuracy: 0.0021 - val_loss: 6662977.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10614000.0000 - accuracy: 0.0041 - val_loss: 6698486.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10417713.0000 - accuracy: 0.0041 - val_loss: 6711080.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10619472.0000 - accuracy: 0.0062 - val_loss: 6729435.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10389171.0000 - accuracy: 0.0000e+00 - val_loss: 6764802.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10257806.0000 - accuracy: 0.0021 - val_loss: 6818468.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10496786.0000 - accuracy: 0.0062 - val_loss: 6914834.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10652470.0000 - accuracy: 0.0041 - val_loss: 6952246.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10721431.0000 - accuracy: 0.0000e+00 - val_loss: 7030661.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10533469.0000 - accuracy: 0.0000e+00 - val_loss: 7025124.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10686326.0000 - accuracy: 0.0041 - val_loss: 7055653.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10736318.0000 - accuracy: 0.0021 - val_loss: 7052647.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10630507.0000 - accuracy: 0.0021 - val_loss: 7149049.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10776716.0000 - accuracy: 0.0041 - val_loss: 7113698.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10718078.0000 - accuracy: 0.0000e+00 - val_loss: 7032118.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10732657.0000 - accuracy: 0.0041 - val_loss: 7200391.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10944445.0000 - accuracy: 0.0041 - val_loss: 7231836.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10859077.0000 - accuracy: 0.0041 - val_loss: 7234481.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10627683.0000 - accuracy: 0.0000e+00 - val_loss: 7118638.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10832025.0000 - accuracy: 0.0041 - val_loss: 7205030.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10673366.0000 - accuracy: 0.0000e+00 - val_loss: 7129011.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10724293.0000 - accuracy: 0.0041 - val_loss: 7327531.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11009862.0000 - accuracy: 0.0000e+00 - val_loss: 7317619.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11101164.0000 - accuracy: 0.0062 - val_loss: 7325761.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11207097.0000 - accuracy: 0.0041 - val_loss: 7287998.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11161936.0000 - accuracy: 0.0062 - val_loss: 7428973.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11288953.0000 - accuracy: 0.0041 - val_loss: 7276437.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11110883.0000 - accuracy: 0.0041 - val_loss: 7446160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10932148.0000 - accuracy: 0.0021 - val_loss: 7478946.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11193948.0000 - accuracy: 0.0083 - val_loss: 7334985.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11109169.0000 - accuracy: 0.0021 - val_loss: 7512700.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11341395.0000 - accuracy: 0.0041 - val_loss: 7442757.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11342448.0000 - accuracy: 0.0041 - val_loss: 7315552.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11265132.0000 - accuracy: 0.0041 - val_loss: 7354144.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11359995.0000 - accuracy: 0.0062 - val_loss: 7421583.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11267681.0000 - accuracy: 0.0041 - val_loss: 7530444.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11538785.0000 - accuracy: 0.0041 - val_loss: 7462284.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 11444752.0000 - accuracy: 0.0041    \n",
            "Epoch: 900, accuracy:0.0041,  loss:11444752.0000,  val_accuracy:0.0000,  val_loss:7468289.0000,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11444752.0000 - accuracy: 0.0041 - val_loss: 7468289.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11633877.0000 - accuracy: 0.0062 - val_loss: 7549111.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11498865.0000 - accuracy: 0.0041 - val_loss: 7633528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11584127.0000 - accuracy: 0.0021 - val_loss: 7695551.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11618272.0000 - accuracy: 0.0041 - val_loss: 7715856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11397898.0000 - accuracy: 0.0083 - val_loss: 7654564.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11618266.0000 - accuracy: 0.0021 - val_loss: 7790052.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11620750.0000 - accuracy: 0.0041 - val_loss: 7784289.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11737059.0000 - accuracy: 0.0000e+00 - val_loss: 7694227.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11660768.0000 - accuracy: 0.0021 - val_loss: 7680850.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11719705.0000 - accuracy: 0.0041 - val_loss: 7738805.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11764496.0000 - accuracy: 0.0062 - val_loss: 7754981.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11519657.0000 - accuracy: 0.0041 - val_loss: 7870566.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11791943.0000 - accuracy: 0.0021 - val_loss: 7715354.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11967880.0000 - accuracy: 0.0021 - val_loss: 7738151.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12010680.0000 - accuracy: 0.0021 - val_loss: 7875077.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11787845.0000 - accuracy: 0.0021 - val_loss: 7942169.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12043659.0000 - accuracy: 0.0062 - val_loss: 7964726.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11819391.0000 - accuracy: 0.0021 - val_loss: 8015697.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11747565.0000 - accuracy: 0.0021 - val_loss: 7956269.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12146959.0000 - accuracy: 0.0083 - val_loss: 7999828.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11944168.0000 - accuracy: 0.0062 - val_loss: 8011775.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12036814.0000 - accuracy: 0.0041 - val_loss: 8121785.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12259329.0000 - accuracy: 0.0083 - val_loss: 8150270.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12177586.0000 - accuracy: 0.0000e+00 - val_loss: 8127296.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12122874.0000 - accuracy: 0.0041 - val_loss: 8178561.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12358569.0000 - accuracy: 0.0062 - val_loss: 8142090.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12457607.0000 - accuracy: 0.0000e+00 - val_loss: 8031315.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12382742.0000 - accuracy: 0.0021 - val_loss: 8276774.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12294203.0000 - accuracy: 0.0083 - val_loss: 8165351.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12322237.0000 - accuracy: 0.0021 - val_loss: 8202782.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12541251.0000 - accuracy: 0.0062 - val_loss: 8320012.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12614797.0000 - accuracy: 0.0000e+00 - val_loss: 8261509.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12339779.0000 - accuracy: 0.0000e+00 - val_loss: 8384071.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12479258.0000 - accuracy: 0.0062 - val_loss: 8384026.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12518751.0000 - accuracy: 0.0021 - val_loss: 8307987.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12677638.0000 - accuracy: 0.0021 - val_loss: 8413114.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12520651.0000 - accuracy: 0.0062 - val_loss: 8386310.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12564810.0000 - accuracy: 0.0083 - val_loss: 8580515.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12440491.0000 - accuracy: 0.0083 - val_loss: 8305328.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12647410.0000 - accuracy: 0.0021 - val_loss: 8301973.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12573865.0000 - accuracy: 0.0062 - val_loss: 8392470.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12812792.0000 - accuracy: 0.0041 - val_loss: 8476465.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12762388.0000 - accuracy: 0.0041 - val_loss: 8506795.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12763239.0000 - accuracy: 0.0041 - val_loss: 8476871.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12706788.0000 - accuracy: 0.0021 - val_loss: 8450154.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12933771.0000 - accuracy: 0.0062 - val_loss: 8495143.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12761503.0000 - accuracy: 0.0000e+00 - val_loss: 8472126.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12900564.0000 - accuracy: 0.0041 - val_loss: 8529593.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13039748.0000 - accuracy: 0.0041 - val_loss: 8595322.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12768395.0000 - accuracy: 0.0000e+00 - val_loss: 8688373.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12915354.0000 - accuracy: 0.0021 - val_loss: 8651740.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13297478.0000 - accuracy: 0.0041 - val_loss: 8763663.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12885406.0000 - accuracy: 0.0000e+00 - val_loss: 8776697.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13139839.0000 - accuracy: 0.0062 - val_loss: 8943091.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13205386.0000 - accuracy: 0.0062 - val_loss: 8688206.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13198877.0000 - accuracy: 0.0041 - val_loss: 8806410.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13215941.0000 - accuracy: 0.0041 - val_loss: 8807838.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13326584.0000 - accuracy: 0.0021 - val_loss: 8858529.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13234342.0000 - accuracy: 0.0124 - val_loss: 9100881.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13335380.0000 - accuracy: 0.0124 - val_loss: 8882493.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13231648.0000 - accuracy: 0.0021 - val_loss: 9065111.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13508469.0000 - accuracy: 0.0021 - val_loss: 8859300.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13477622.0000 - accuracy: 0.0021 - val_loss: 8945554.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13382330.0000 - accuracy: 0.0000e+00 - val_loss: 9046180.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13526596.0000 - accuracy: 0.0021 - val_loss: 9039745.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13724802.0000 - accuracy: 0.0041 - val_loss: 9003826.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13523298.0000 - accuracy: 0.0041 - val_loss: 9039791.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13463641.0000 - accuracy: 0.0000e+00 - val_loss: 9139558.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13664754.0000 - accuracy: 0.0021 - val_loss: 9167082.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13809726.0000 - accuracy: 0.0041 - val_loss: 9197232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13847756.0000 - accuracy: 0.0000e+00 - val_loss: 9155610.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13801937.0000 - accuracy: 0.0041 - val_loss: 9302222.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13647604.0000 - accuracy: 0.0000e+00 - val_loss: 9242069.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13770494.0000 - accuracy: 0.0083 - val_loss: 9257415.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13492499.0000 - accuracy: 0.0000e+00 - val_loss: 9225452.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13681608.0000 - accuracy: 0.0021 - val_loss: 9285460.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13634073.0000 - accuracy: 0.0021 - val_loss: 9315566.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13826511.0000 - accuracy: 0.0021 - val_loss: 9216000.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13735965.0000 - accuracy: 0.0041 - val_loss: 9385937.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13886212.0000 - accuracy: 0.0041 - val_loss: 9431723.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13978629.0000 - accuracy: 0.0041 - val_loss: 9335605.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14137909.0000 - accuracy: 0.0103 - val_loss: 9460135.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13964298.0000 - accuracy: 0.0041 - val_loss: 9359766.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14059281.0000 - accuracy: 0.0041 - val_loss: 9440203.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14347242.0000 - accuracy: 0.0041 - val_loss: 9405262.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14198844.0000 - accuracy: 0.0083 - val_loss: 9574749.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14396522.0000 - accuracy: 0.0062 - val_loss: 9618091.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14065510.0000 - accuracy: 0.0000e+00 - val_loss: 9616255.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14366916.0000 - accuracy: 0.0041 - val_loss: 9535137.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14182365.0000 - accuracy: 0.0000e+00 - val_loss: 9788099.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14264276.0000 - accuracy: 0.0062 - val_loss: 9737060.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14203495.0000 - accuracy: 0.0041 - val_loss: 9700618.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14047650.0000 - accuracy: 0.0000e+00 - val_loss: 9623937.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14381487.0000 - accuracy: 0.0062 - val_loss: 9672716.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14718197.0000 - accuracy: 0.0021 - val_loss: 9809090.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14401390.0000 - accuracy: 0.0000e+00 - val_loss: 9834434.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14525954.0000 - accuracy: 0.0041 - val_loss: 9808740.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14628212.0000 - accuracy: 0.0041 - val_loss: 9769460.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14777649.0000 - accuracy: 0.0000e+00 - val_loss: 9781457.0000 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7mg0A_wlnif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "c027873e-143e-48df-ddbd-5d4c0555c72a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 64)                384       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 220)               14300     \n",
            "=================================================================\n",
            "Total params: 18,844\n",
            "Trainable params: 18,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu5-G0YkpJWX",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ2op0IDKtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bc22e928-e694-423e-e05a-a7883355b94f"
      },
      "source": [
        "test_predictions = model.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7f40173488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57FnCwYfu9ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af203d66-250e-4604-a48c-06e5a0f5242d"
      },
      "source": [
        "test_predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMdxdYIaurjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = pd.DataFrame(test_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ2w_yAoMSfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "1edbc127-2753-435c-e01c-162eb2ba11f0"
      },
      "source": [
        "test_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.297256</td>\n",
              "      <td>1.189361</td>\n",
              "      <td>1.132536</td>\n",
              "      <td>1.302260</td>\n",
              "      <td>1.169439</td>\n",
              "      <td>1.252599</td>\n",
              "      <td>1.184923</td>\n",
              "      <td>1.103148</td>\n",
              "      <td>1.212186</td>\n",
              "      <td>1.266332</td>\n",
              "      <td>1.232296</td>\n",
              "      <td>1.308228</td>\n",
              "      <td>1.209856</td>\n",
              "      <td>1.217574</td>\n",
              "      <td>1.318938</td>\n",
              "      <td>1.273919</td>\n",
              "      <td>1.206169</td>\n",
              "      <td>1.248824</td>\n",
              "      <td>1.181691</td>\n",
              "      <td>1.110913</td>\n",
              "      <td>1.253744</td>\n",
              "      <td>1.262384</td>\n",
              "      <td>1.140153</td>\n",
              "      <td>1.252629</td>\n",
              "      <td>1.164091</td>\n",
              "      <td>1.189390</td>\n",
              "      <td>1.206530</td>\n",
              "      <td>1.194076</td>\n",
              "      <td>1.282547</td>\n",
              "      <td>1.289580</td>\n",
              "      <td>1.080059</td>\n",
              "      <td>1.260352</td>\n",
              "      <td>1.149923</td>\n",
              "      <td>1.124912</td>\n",
              "      <td>1.232630</td>\n",
              "      <td>1.179067</td>\n",
              "      <td>1.298462</td>\n",
              "      <td>1.258388</td>\n",
              "      <td>1.173152</td>\n",
              "      <td>1.192249</td>\n",
              "      <td>...</td>\n",
              "      <td>1.186101</td>\n",
              "      <td>1.213589</td>\n",
              "      <td>1.196523</td>\n",
              "      <td>1.168819</td>\n",
              "      <td>1.234037</td>\n",
              "      <td>1.253356</td>\n",
              "      <td>1.228481</td>\n",
              "      <td>1.280059</td>\n",
              "      <td>1.203528</td>\n",
              "      <td>1.197553</td>\n",
              "      <td>1.206674</td>\n",
              "      <td>1.199048</td>\n",
              "      <td>1.267492</td>\n",
              "      <td>1.189786</td>\n",
              "      <td>1.162275</td>\n",
              "      <td>1.096708</td>\n",
              "      <td>1.123636</td>\n",
              "      <td>1.122166</td>\n",
              "      <td>1.167188</td>\n",
              "      <td>1.184142</td>\n",
              "      <td>1.243164</td>\n",
              "      <td>1.269007</td>\n",
              "      <td>1.231575</td>\n",
              "      <td>1.088177</td>\n",
              "      <td>1.230852</td>\n",
              "      <td>1.173689</td>\n",
              "      <td>1.297969</td>\n",
              "      <td>1.060149</td>\n",
              "      <td>1.313246</td>\n",
              "      <td>1.228178</td>\n",
              "      <td>1.331168</td>\n",
              "      <td>1.276224</td>\n",
              "      <td>1.211964</td>\n",
              "      <td>1.215018</td>\n",
              "      <td>1.194930</td>\n",
              "      <td>1.211493</td>\n",
              "      <td>1.153677</td>\n",
              "      <td>1.117755</td>\n",
              "      <td>1.139819</td>\n",
              "      <td>1.260445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.327115</td>\n",
              "      <td>1.142003</td>\n",
              "      <td>1.163430</td>\n",
              "      <td>1.270357</td>\n",
              "      <td>1.130347</td>\n",
              "      <td>1.195816</td>\n",
              "      <td>1.120640</td>\n",
              "      <td>1.103970</td>\n",
              "      <td>1.219769</td>\n",
              "      <td>1.181871</td>\n",
              "      <td>1.223658</td>\n",
              "      <td>1.332418</td>\n",
              "      <td>1.186794</td>\n",
              "      <td>1.183458</td>\n",
              "      <td>1.272051</td>\n",
              "      <td>1.241971</td>\n",
              "      <td>1.225142</td>\n",
              "      <td>1.268425</td>\n",
              "      <td>1.194432</td>\n",
              "      <td>1.156589</td>\n",
              "      <td>1.241038</td>\n",
              "      <td>1.224666</td>\n",
              "      <td>1.096950</td>\n",
              "      <td>1.196099</td>\n",
              "      <td>1.143495</td>\n",
              "      <td>1.153259</td>\n",
              "      <td>1.142155</td>\n",
              "      <td>1.184550</td>\n",
              "      <td>1.233270</td>\n",
              "      <td>1.261168</td>\n",
              "      <td>1.058254</td>\n",
              "      <td>1.175549</td>\n",
              "      <td>1.140278</td>\n",
              "      <td>1.085573</td>\n",
              "      <td>1.213219</td>\n",
              "      <td>1.178857</td>\n",
              "      <td>1.240433</td>\n",
              "      <td>1.221825</td>\n",
              "      <td>1.199255</td>\n",
              "      <td>1.149395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.166261</td>\n",
              "      <td>1.223579</td>\n",
              "      <td>1.183960</td>\n",
              "      <td>1.156094</td>\n",
              "      <td>1.273979</td>\n",
              "      <td>1.254469</td>\n",
              "      <td>1.220472</td>\n",
              "      <td>1.265917</td>\n",
              "      <td>1.220980</td>\n",
              "      <td>1.229691</td>\n",
              "      <td>1.223691</td>\n",
              "      <td>1.149421</td>\n",
              "      <td>1.274404</td>\n",
              "      <td>1.186850</td>\n",
              "      <td>1.141265</td>\n",
              "      <td>1.103994</td>\n",
              "      <td>1.163800</td>\n",
              "      <td>1.108644</td>\n",
              "      <td>1.147498</td>\n",
              "      <td>1.130603</td>\n",
              "      <td>1.210496</td>\n",
              "      <td>1.255641</td>\n",
              "      <td>1.193401</td>\n",
              "      <td>1.101594</td>\n",
              "      <td>1.231972</td>\n",
              "      <td>1.238052</td>\n",
              "      <td>1.253018</td>\n",
              "      <td>1.078172</td>\n",
              "      <td>1.244361</td>\n",
              "      <td>1.220966</td>\n",
              "      <td>1.259896</td>\n",
              "      <td>1.267038</td>\n",
              "      <td>1.210528</td>\n",
              "      <td>1.207428</td>\n",
              "      <td>1.189874</td>\n",
              "      <td>1.149068</td>\n",
              "      <td>1.092033</td>\n",
              "      <td>1.119489</td>\n",
              "      <td>1.134648</td>\n",
              "      <td>1.242739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.366864</td>\n",
              "      <td>1.169779</td>\n",
              "      <td>1.198631</td>\n",
              "      <td>1.307396</td>\n",
              "      <td>1.224856</td>\n",
              "      <td>1.279887</td>\n",
              "      <td>1.173073</td>\n",
              "      <td>1.178774</td>\n",
              "      <td>1.306439</td>\n",
              "      <td>1.273728</td>\n",
              "      <td>1.270337</td>\n",
              "      <td>1.370119</td>\n",
              "      <td>1.241489</td>\n",
              "      <td>1.243023</td>\n",
              "      <td>1.352678</td>\n",
              "      <td>1.315099</td>\n",
              "      <td>1.209998</td>\n",
              "      <td>1.317940</td>\n",
              "      <td>1.235593</td>\n",
              "      <td>1.191536</td>\n",
              "      <td>1.314927</td>\n",
              "      <td>1.270892</td>\n",
              "      <td>1.169984</td>\n",
              "      <td>1.285327</td>\n",
              "      <td>1.196757</td>\n",
              "      <td>1.216472</td>\n",
              "      <td>1.236964</td>\n",
              "      <td>1.222694</td>\n",
              "      <td>1.320738</td>\n",
              "      <td>1.352087</td>\n",
              "      <td>1.105927</td>\n",
              "      <td>1.212589</td>\n",
              "      <td>1.198550</td>\n",
              "      <td>1.139443</td>\n",
              "      <td>1.264057</td>\n",
              "      <td>1.224962</td>\n",
              "      <td>1.349521</td>\n",
              "      <td>1.282406</td>\n",
              "      <td>1.275052</td>\n",
              "      <td>1.216791</td>\n",
              "      <td>...</td>\n",
              "      <td>1.208878</td>\n",
              "      <td>1.293635</td>\n",
              "      <td>1.222590</td>\n",
              "      <td>1.228574</td>\n",
              "      <td>1.291061</td>\n",
              "      <td>1.304609</td>\n",
              "      <td>1.294303</td>\n",
              "      <td>1.308733</td>\n",
              "      <td>1.272877</td>\n",
              "      <td>1.211273</td>\n",
              "      <td>1.273798</td>\n",
              "      <td>1.221198</td>\n",
              "      <td>1.302945</td>\n",
              "      <td>1.196652</td>\n",
              "      <td>1.176506</td>\n",
              "      <td>1.155794</td>\n",
              "      <td>1.197688</td>\n",
              "      <td>1.086556</td>\n",
              "      <td>1.173920</td>\n",
              "      <td>1.172170</td>\n",
              "      <td>1.291111</td>\n",
              "      <td>1.293598</td>\n",
              "      <td>1.256632</td>\n",
              "      <td>1.163860</td>\n",
              "      <td>1.207528</td>\n",
              "      <td>1.254616</td>\n",
              "      <td>1.293296</td>\n",
              "      <td>1.101834</td>\n",
              "      <td>1.301377</td>\n",
              "      <td>1.269699</td>\n",
              "      <td>1.353710</td>\n",
              "      <td>1.314361</td>\n",
              "      <td>1.261687</td>\n",
              "      <td>1.249773</td>\n",
              "      <td>1.291845</td>\n",
              "      <td>1.195573</td>\n",
              "      <td>1.164096</td>\n",
              "      <td>1.161016</td>\n",
              "      <td>1.224749</td>\n",
              "      <td>1.289310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.329310</td>\n",
              "      <td>1.181041</td>\n",
              "      <td>1.167684</td>\n",
              "      <td>1.241564</td>\n",
              "      <td>1.142548</td>\n",
              "      <td>1.229880</td>\n",
              "      <td>1.143544</td>\n",
              "      <td>1.101485</td>\n",
              "      <td>1.207441</td>\n",
              "      <td>1.264979</td>\n",
              "      <td>1.194637</td>\n",
              "      <td>1.278807</td>\n",
              "      <td>1.233290</td>\n",
              "      <td>1.198820</td>\n",
              "      <td>1.273201</td>\n",
              "      <td>1.283649</td>\n",
              "      <td>1.220910</td>\n",
              "      <td>1.250398</td>\n",
              "      <td>1.191236</td>\n",
              "      <td>1.181810</td>\n",
              "      <td>1.309355</td>\n",
              "      <td>1.235784</td>\n",
              "      <td>1.168283</td>\n",
              "      <td>1.244176</td>\n",
              "      <td>1.204378</td>\n",
              "      <td>1.240948</td>\n",
              "      <td>1.191147</td>\n",
              "      <td>1.180547</td>\n",
              "      <td>1.277906</td>\n",
              "      <td>1.260639</td>\n",
              "      <td>1.084857</td>\n",
              "      <td>1.257480</td>\n",
              "      <td>1.110626</td>\n",
              "      <td>1.099000</td>\n",
              "      <td>1.229652</td>\n",
              "      <td>1.186714</td>\n",
              "      <td>1.333432</td>\n",
              "      <td>1.272419</td>\n",
              "      <td>1.170872</td>\n",
              "      <td>1.136378</td>\n",
              "      <td>...</td>\n",
              "      <td>1.194533</td>\n",
              "      <td>1.237542</td>\n",
              "      <td>1.168100</td>\n",
              "      <td>1.184326</td>\n",
              "      <td>1.294242</td>\n",
              "      <td>1.292353</td>\n",
              "      <td>1.222468</td>\n",
              "      <td>1.251635</td>\n",
              "      <td>1.241282</td>\n",
              "      <td>1.225189</td>\n",
              "      <td>1.179232</td>\n",
              "      <td>1.191870</td>\n",
              "      <td>1.280598</td>\n",
              "      <td>1.173245</td>\n",
              "      <td>1.180964</td>\n",
              "      <td>1.166436</td>\n",
              "      <td>1.179450</td>\n",
              "      <td>1.090128</td>\n",
              "      <td>1.187284</td>\n",
              "      <td>1.175694</td>\n",
              "      <td>1.220266</td>\n",
              "      <td>1.261718</td>\n",
              "      <td>1.210505</td>\n",
              "      <td>1.163747</td>\n",
              "      <td>1.208758</td>\n",
              "      <td>1.185177</td>\n",
              "      <td>1.252824</td>\n",
              "      <td>1.120215</td>\n",
              "      <td>1.278781</td>\n",
              "      <td>1.285496</td>\n",
              "      <td>1.326240</td>\n",
              "      <td>1.304006</td>\n",
              "      <td>1.195950</td>\n",
              "      <td>1.172507</td>\n",
              "      <td>1.202718</td>\n",
              "      <td>1.192876</td>\n",
              "      <td>1.143127</td>\n",
              "      <td>1.178923</td>\n",
              "      <td>1.151727</td>\n",
              "      <td>1.258866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.285454</td>\n",
              "      <td>1.166745</td>\n",
              "      <td>1.124959</td>\n",
              "      <td>1.274007</td>\n",
              "      <td>1.150614</td>\n",
              "      <td>1.217064</td>\n",
              "      <td>1.141791</td>\n",
              "      <td>1.098535</td>\n",
              "      <td>1.208206</td>\n",
              "      <td>1.254137</td>\n",
              "      <td>1.209977</td>\n",
              "      <td>1.318646</td>\n",
              "      <td>1.180807</td>\n",
              "      <td>1.209292</td>\n",
              "      <td>1.310155</td>\n",
              "      <td>1.287302</td>\n",
              "      <td>1.148256</td>\n",
              "      <td>1.240628</td>\n",
              "      <td>1.183448</td>\n",
              "      <td>1.109997</td>\n",
              "      <td>1.248156</td>\n",
              "      <td>1.218959</td>\n",
              "      <td>1.173167</td>\n",
              "      <td>1.242317</td>\n",
              "      <td>1.151035</td>\n",
              "      <td>1.203702</td>\n",
              "      <td>1.172203</td>\n",
              "      <td>1.172990</td>\n",
              "      <td>1.302207</td>\n",
              "      <td>1.273484</td>\n",
              "      <td>1.068389</td>\n",
              "      <td>1.223353</td>\n",
              "      <td>1.141722</td>\n",
              "      <td>1.124560</td>\n",
              "      <td>1.203342</td>\n",
              "      <td>1.152227</td>\n",
              "      <td>1.295139</td>\n",
              "      <td>1.234600</td>\n",
              "      <td>1.173619</td>\n",
              "      <td>1.175376</td>\n",
              "      <td>...</td>\n",
              "      <td>1.180207</td>\n",
              "      <td>1.220034</td>\n",
              "      <td>1.161146</td>\n",
              "      <td>1.158836</td>\n",
              "      <td>1.211117</td>\n",
              "      <td>1.238383</td>\n",
              "      <td>1.218625</td>\n",
              "      <td>1.259559</td>\n",
              "      <td>1.186143</td>\n",
              "      <td>1.167219</td>\n",
              "      <td>1.193230</td>\n",
              "      <td>1.186719</td>\n",
              "      <td>1.253057</td>\n",
              "      <td>1.171997</td>\n",
              "      <td>1.132582</td>\n",
              "      <td>1.098605</td>\n",
              "      <td>1.125008</td>\n",
              "      <td>1.083232</td>\n",
              "      <td>1.128017</td>\n",
              "      <td>1.166911</td>\n",
              "      <td>1.234400</td>\n",
              "      <td>1.260356</td>\n",
              "      <td>1.210716</td>\n",
              "      <td>1.079162</td>\n",
              "      <td>1.205614</td>\n",
              "      <td>1.137698</td>\n",
              "      <td>1.281618</td>\n",
              "      <td>1.054016</td>\n",
              "      <td>1.303092</td>\n",
              "      <td>1.224458</td>\n",
              "      <td>1.306099</td>\n",
              "      <td>1.237522</td>\n",
              "      <td>1.196378</td>\n",
              "      <td>1.165671</td>\n",
              "      <td>1.194251</td>\n",
              "      <td>1.198773</td>\n",
              "      <td>1.105454</td>\n",
              "      <td>1.106809</td>\n",
              "      <td>1.151457</td>\n",
              "      <td>1.252445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.302743</td>\n",
              "      <td>1.187342</td>\n",
              "      <td>1.132481</td>\n",
              "      <td>1.284718</td>\n",
              "      <td>1.158201</td>\n",
              "      <td>1.225252</td>\n",
              "      <td>1.165443</td>\n",
              "      <td>1.070200</td>\n",
              "      <td>1.143733</td>\n",
              "      <td>1.251778</td>\n",
              "      <td>1.196060</td>\n",
              "      <td>1.294261</td>\n",
              "      <td>1.186139</td>\n",
              "      <td>1.208508</td>\n",
              "      <td>1.312217</td>\n",
              "      <td>1.258152</td>\n",
              "      <td>1.206250</td>\n",
              "      <td>1.199007</td>\n",
              "      <td>1.173769</td>\n",
              "      <td>1.122256</td>\n",
              "      <td>1.257588</td>\n",
              "      <td>1.241879</td>\n",
              "      <td>1.086644</td>\n",
              "      <td>1.249860</td>\n",
              "      <td>1.168296</td>\n",
              "      <td>1.195592</td>\n",
              "      <td>1.205566</td>\n",
              "      <td>1.205725</td>\n",
              "      <td>1.290261</td>\n",
              "      <td>1.257262</td>\n",
              "      <td>1.029428</td>\n",
              "      <td>1.285901</td>\n",
              "      <td>1.088705</td>\n",
              "      <td>1.144854</td>\n",
              "      <td>1.237754</td>\n",
              "      <td>1.141155</td>\n",
              "      <td>1.306091</td>\n",
              "      <td>1.228469</td>\n",
              "      <td>1.146040</td>\n",
              "      <td>1.166446</td>\n",
              "      <td>...</td>\n",
              "      <td>1.156057</td>\n",
              "      <td>1.205066</td>\n",
              "      <td>1.191464</td>\n",
              "      <td>1.146045</td>\n",
              "      <td>1.248221</td>\n",
              "      <td>1.250634</td>\n",
              "      <td>1.140499</td>\n",
              "      <td>1.273021</td>\n",
              "      <td>1.199648</td>\n",
              "      <td>1.231133</td>\n",
              "      <td>1.202052</td>\n",
              "      <td>1.181661</td>\n",
              "      <td>1.226832</td>\n",
              "      <td>1.189675</td>\n",
              "      <td>1.158190</td>\n",
              "      <td>1.081136</td>\n",
              "      <td>1.121633</td>\n",
              "      <td>1.128868</td>\n",
              "      <td>1.176809</td>\n",
              "      <td>1.217725</td>\n",
              "      <td>1.234118</td>\n",
              "      <td>1.223701</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.100417</td>\n",
              "      <td>1.215707</td>\n",
              "      <td>1.122318</td>\n",
              "      <td>1.263235</td>\n",
              "      <td>1.064600</td>\n",
              "      <td>1.304201</td>\n",
              "      <td>1.176788</td>\n",
              "      <td>1.279100</td>\n",
              "      <td>1.275166</td>\n",
              "      <td>1.171375</td>\n",
              "      <td>1.173712</td>\n",
              "      <td>1.104654</td>\n",
              "      <td>1.205126</td>\n",
              "      <td>1.162174</td>\n",
              "      <td>1.118234</td>\n",
              "      <td>1.134196</td>\n",
              "      <td>1.218161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.312949</td>\n",
              "      <td>1.152707</td>\n",
              "      <td>1.173616</td>\n",
              "      <td>1.230052</td>\n",
              "      <td>1.122915</td>\n",
              "      <td>1.198203</td>\n",
              "      <td>1.136683</td>\n",
              "      <td>1.123859</td>\n",
              "      <td>1.177624</td>\n",
              "      <td>1.231871</td>\n",
              "      <td>1.200690</td>\n",
              "      <td>1.294047</td>\n",
              "      <td>1.202878</td>\n",
              "      <td>1.184310</td>\n",
              "      <td>1.285229</td>\n",
              "      <td>1.263213</td>\n",
              "      <td>1.179320</td>\n",
              "      <td>1.215601</td>\n",
              "      <td>1.175799</td>\n",
              "      <td>1.178383</td>\n",
              "      <td>1.281241</td>\n",
              "      <td>1.214205</td>\n",
              "      <td>1.116455</td>\n",
              "      <td>1.217956</td>\n",
              "      <td>1.172074</td>\n",
              "      <td>1.194553</td>\n",
              "      <td>1.173418</td>\n",
              "      <td>1.175351</td>\n",
              "      <td>1.277497</td>\n",
              "      <td>1.282899</td>\n",
              "      <td>1.066393</td>\n",
              "      <td>1.211414</td>\n",
              "      <td>1.105075</td>\n",
              "      <td>1.090448</td>\n",
              "      <td>1.223337</td>\n",
              "      <td>1.179316</td>\n",
              "      <td>1.301328</td>\n",
              "      <td>1.235772</td>\n",
              "      <td>1.203604</td>\n",
              "      <td>1.147218</td>\n",
              "      <td>...</td>\n",
              "      <td>1.180854</td>\n",
              "      <td>1.232822</td>\n",
              "      <td>1.158216</td>\n",
              "      <td>1.176195</td>\n",
              "      <td>1.276887</td>\n",
              "      <td>1.261518</td>\n",
              "      <td>1.206230</td>\n",
              "      <td>1.237822</td>\n",
              "      <td>1.241415</td>\n",
              "      <td>1.211055</td>\n",
              "      <td>1.221822</td>\n",
              "      <td>1.138976</td>\n",
              "      <td>1.260928</td>\n",
              "      <td>1.163510</td>\n",
              "      <td>1.188803</td>\n",
              "      <td>1.118895</td>\n",
              "      <td>1.176214</td>\n",
              "      <td>1.070720</td>\n",
              "      <td>1.163067</td>\n",
              "      <td>1.181331</td>\n",
              "      <td>1.259237</td>\n",
              "      <td>1.248983</td>\n",
              "      <td>1.177200</td>\n",
              "      <td>1.145400</td>\n",
              "      <td>1.202927</td>\n",
              "      <td>1.172433</td>\n",
              "      <td>1.216428</td>\n",
              "      <td>1.108672</td>\n",
              "      <td>1.248153</td>\n",
              "      <td>1.221787</td>\n",
              "      <td>1.274739</td>\n",
              "      <td>1.259793</td>\n",
              "      <td>1.199676</td>\n",
              "      <td>1.187201</td>\n",
              "      <td>1.170950</td>\n",
              "      <td>1.131944</td>\n",
              "      <td>1.115962</td>\n",
              "      <td>1.149290</td>\n",
              "      <td>1.141987</td>\n",
              "      <td>1.261891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.272042</td>\n",
              "      <td>1.161499</td>\n",
              "      <td>1.105000</td>\n",
              "      <td>1.208269</td>\n",
              "      <td>1.121041</td>\n",
              "      <td>1.194464</td>\n",
              "      <td>1.124770</td>\n",
              "      <td>1.059695</td>\n",
              "      <td>1.179548</td>\n",
              "      <td>1.207051</td>\n",
              "      <td>1.167701</td>\n",
              "      <td>1.267485</td>\n",
              "      <td>1.167606</td>\n",
              "      <td>1.179757</td>\n",
              "      <td>1.275391</td>\n",
              "      <td>1.243271</td>\n",
              "      <td>1.155570</td>\n",
              "      <td>1.195873</td>\n",
              "      <td>1.122752</td>\n",
              "      <td>1.107901</td>\n",
              "      <td>1.247378</td>\n",
              "      <td>1.189238</td>\n",
              "      <td>1.106392</td>\n",
              "      <td>1.215609</td>\n",
              "      <td>1.148882</td>\n",
              "      <td>1.196050</td>\n",
              "      <td>1.162335</td>\n",
              "      <td>1.165663</td>\n",
              "      <td>1.231344</td>\n",
              "      <td>1.209415</td>\n",
              "      <td>1.043097</td>\n",
              "      <td>1.235725</td>\n",
              "      <td>1.105240</td>\n",
              "      <td>1.091018</td>\n",
              "      <td>1.183066</td>\n",
              "      <td>1.125704</td>\n",
              "      <td>1.281685</td>\n",
              "      <td>1.219738</td>\n",
              "      <td>1.136538</td>\n",
              "      <td>1.135447</td>\n",
              "      <td>...</td>\n",
              "      <td>1.129269</td>\n",
              "      <td>1.185239</td>\n",
              "      <td>1.146817</td>\n",
              "      <td>1.141200</td>\n",
              "      <td>1.225513</td>\n",
              "      <td>1.228177</td>\n",
              "      <td>1.165154</td>\n",
              "      <td>1.235542</td>\n",
              "      <td>1.200130</td>\n",
              "      <td>1.172702</td>\n",
              "      <td>1.170003</td>\n",
              "      <td>1.181468</td>\n",
              "      <td>1.209325</td>\n",
              "      <td>1.151763</td>\n",
              "      <td>1.126986</td>\n",
              "      <td>1.084336</td>\n",
              "      <td>1.105327</td>\n",
              "      <td>1.054265</td>\n",
              "      <td>1.131519</td>\n",
              "      <td>1.151902</td>\n",
              "      <td>1.210007</td>\n",
              "      <td>1.216188</td>\n",
              "      <td>1.202237</td>\n",
              "      <td>1.089815</td>\n",
              "      <td>1.198748</td>\n",
              "      <td>1.133165</td>\n",
              "      <td>1.238947</td>\n",
              "      <td>1.069440</td>\n",
              "      <td>1.264443</td>\n",
              "      <td>1.187663</td>\n",
              "      <td>1.254554</td>\n",
              "      <td>1.276242</td>\n",
              "      <td>1.160143</td>\n",
              "      <td>1.150916</td>\n",
              "      <td>1.156392</td>\n",
              "      <td>1.165118</td>\n",
              "      <td>1.115274</td>\n",
              "      <td>1.120895</td>\n",
              "      <td>1.107053</td>\n",
              "      <td>1.216963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.245005</td>\n",
              "      <td>1.095031</td>\n",
              "      <td>1.066996</td>\n",
              "      <td>1.223554</td>\n",
              "      <td>1.092505</td>\n",
              "      <td>1.193291</td>\n",
              "      <td>1.086480</td>\n",
              "      <td>1.061774</td>\n",
              "      <td>1.147933</td>\n",
              "      <td>1.162082</td>\n",
              "      <td>1.155488</td>\n",
              "      <td>1.261850</td>\n",
              "      <td>1.143899</td>\n",
              "      <td>1.146771</td>\n",
              "      <td>1.255115</td>\n",
              "      <td>1.207932</td>\n",
              "      <td>1.140553</td>\n",
              "      <td>1.183877</td>\n",
              "      <td>1.116593</td>\n",
              "      <td>1.077793</td>\n",
              "      <td>1.204877</td>\n",
              "      <td>1.176257</td>\n",
              "      <td>1.066314</td>\n",
              "      <td>1.169149</td>\n",
              "      <td>1.108769</td>\n",
              "      <td>1.108564</td>\n",
              "      <td>1.128189</td>\n",
              "      <td>1.142654</td>\n",
              "      <td>1.215107</td>\n",
              "      <td>1.200090</td>\n",
              "      <td>1.032804</td>\n",
              "      <td>1.149380</td>\n",
              "      <td>1.079056</td>\n",
              "      <td>1.071849</td>\n",
              "      <td>1.164294</td>\n",
              "      <td>1.103029</td>\n",
              "      <td>1.244072</td>\n",
              "      <td>1.177700</td>\n",
              "      <td>1.141413</td>\n",
              "      <td>1.114361</td>\n",
              "      <td>...</td>\n",
              "      <td>1.117163</td>\n",
              "      <td>1.151419</td>\n",
              "      <td>1.137154</td>\n",
              "      <td>1.100498</td>\n",
              "      <td>1.165041</td>\n",
              "      <td>1.180051</td>\n",
              "      <td>1.159889</td>\n",
              "      <td>1.195666</td>\n",
              "      <td>1.149879</td>\n",
              "      <td>1.132466</td>\n",
              "      <td>1.162562</td>\n",
              "      <td>1.116954</td>\n",
              "      <td>1.184695</td>\n",
              "      <td>1.106499</td>\n",
              "      <td>1.096013</td>\n",
              "      <td>1.039718</td>\n",
              "      <td>1.080715</td>\n",
              "      <td>1.026545</td>\n",
              "      <td>1.113891</td>\n",
              "      <td>1.115812</td>\n",
              "      <td>1.181763</td>\n",
              "      <td>1.184286</td>\n",
              "      <td>1.137551</td>\n",
              "      <td>1.046796</td>\n",
              "      <td>1.147440</td>\n",
              "      <td>1.127926</td>\n",
              "      <td>1.213161</td>\n",
              "      <td>1.029929</td>\n",
              "      <td>1.220058</td>\n",
              "      <td>1.163651</td>\n",
              "      <td>1.239461</td>\n",
              "      <td>1.218801</td>\n",
              "      <td>1.146123</td>\n",
              "      <td>1.142094</td>\n",
              "      <td>1.126157</td>\n",
              "      <td>1.142661</td>\n",
              "      <td>1.070654</td>\n",
              "      <td>1.082994</td>\n",
              "      <td>1.092018</td>\n",
              "      <td>1.176787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.377602</td>\n",
              "      <td>1.192639</td>\n",
              "      <td>1.159087</td>\n",
              "      <td>1.349648</td>\n",
              "      <td>1.162806</td>\n",
              "      <td>1.296877</td>\n",
              "      <td>1.144672</td>\n",
              "      <td>1.077177</td>\n",
              "      <td>1.165043</td>\n",
              "      <td>1.263292</td>\n",
              "      <td>1.227904</td>\n",
              "      <td>1.372473</td>\n",
              "      <td>1.190848</td>\n",
              "      <td>1.244898</td>\n",
              "      <td>1.310316</td>\n",
              "      <td>1.305556</td>\n",
              "      <td>1.284850</td>\n",
              "      <td>1.246700</td>\n",
              "      <td>1.217089</td>\n",
              "      <td>1.176630</td>\n",
              "      <td>1.347770</td>\n",
              "      <td>1.262972</td>\n",
              "      <td>1.149566</td>\n",
              "      <td>1.273995</td>\n",
              "      <td>1.235876</td>\n",
              "      <td>1.200477</td>\n",
              "      <td>1.233350</td>\n",
              "      <td>1.209856</td>\n",
              "      <td>1.335611</td>\n",
              "      <td>1.322443</td>\n",
              "      <td>1.078280</td>\n",
              "      <td>1.282241</td>\n",
              "      <td>1.099767</td>\n",
              "      <td>1.189579</td>\n",
              "      <td>1.255586</td>\n",
              "      <td>1.222229</td>\n",
              "      <td>1.332308</td>\n",
              "      <td>1.295802</td>\n",
              "      <td>1.191689</td>\n",
              "      <td>1.158546</td>\n",
              "      <td>...</td>\n",
              "      <td>1.205154</td>\n",
              "      <td>1.220090</td>\n",
              "      <td>1.193041</td>\n",
              "      <td>1.200653</td>\n",
              "      <td>1.292048</td>\n",
              "      <td>1.275637</td>\n",
              "      <td>1.166908</td>\n",
              "      <td>1.276114</td>\n",
              "      <td>1.275403</td>\n",
              "      <td>1.245753</td>\n",
              "      <td>1.226302</td>\n",
              "      <td>1.219027</td>\n",
              "      <td>1.273993</td>\n",
              "      <td>1.209785</td>\n",
              "      <td>1.178717</td>\n",
              "      <td>1.154198</td>\n",
              "      <td>1.167725</td>\n",
              "      <td>1.167801</td>\n",
              "      <td>1.238903</td>\n",
              "      <td>1.235727</td>\n",
              "      <td>1.232981</td>\n",
              "      <td>1.258385</td>\n",
              "      <td>1.254689</td>\n",
              "      <td>1.113910</td>\n",
              "      <td>1.233173</td>\n",
              "      <td>1.180340</td>\n",
              "      <td>1.299005</td>\n",
              "      <td>1.112757</td>\n",
              "      <td>1.377053</td>\n",
              "      <td>1.290832</td>\n",
              "      <td>1.314692</td>\n",
              "      <td>1.326672</td>\n",
              "      <td>1.177432</td>\n",
              "      <td>1.153992</td>\n",
              "      <td>1.156601</td>\n",
              "      <td>1.264157</td>\n",
              "      <td>1.217663</td>\n",
              "      <td>1.173379</td>\n",
              "      <td>1.205707</td>\n",
              "      <td>1.297691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       217       218       219\n",
              "0  1.297256  1.189361  1.132536  ...  1.117755  1.139819  1.260445\n",
              "1  1.327115  1.142003  1.163430  ...  1.119489  1.134648  1.242739\n",
              "2  1.366864  1.169779  1.198631  ...  1.161016  1.224749  1.289310\n",
              "3  1.329310  1.181041  1.167684  ...  1.178923  1.151727  1.258866\n",
              "4  1.285454  1.166745  1.124959  ...  1.106809  1.151457  1.252445\n",
              "5  1.302743  1.187342  1.132481  ...  1.118234  1.134196  1.218161\n",
              "6  1.312949  1.152707  1.173616  ...  1.149290  1.141987  1.261891\n",
              "7  1.272042  1.161499  1.105000  ...  1.120895  1.107053  1.216963\n",
              "8  1.245005  1.095031  1.066996  ...  1.082994  1.092018  1.176787\n",
              "9  1.377602  1.192639  1.159087  ...  1.173379  1.205707  1.297691\n",
              "\n",
              "[10 rows x 220 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBitr2f3LVcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "3b1dc2b4-1e25-45df-89c2-2c3b974634b2"
      },
      "source": [
        "test_predictions * train_y_test_y_stats['std'] + train_y_test_y_stats['mean']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.628733</td>\n",
              "      <td>2.308827</td>\n",
              "      <td>2.281555</td>\n",
              "      <td>2.619576</td>\n",
              "      <td>2.290637</td>\n",
              "      <td>2.387015</td>\n",
              "      <td>2.269662</td>\n",
              "      <td>2.280428</td>\n",
              "      <td>2.550808</td>\n",
              "      <td>2.413184</td>\n",
              "      <td>2.429984</td>\n",
              "      <td>2.587444</td>\n",
              "      <td>2.400849</td>\n",
              "      <td>2.378126</td>\n",
              "      <td>2.565844</td>\n",
              "      <td>2.525153</td>\n",
              "      <td>2.369223</td>\n",
              "      <td>2.509301</td>\n",
              "      <td>2.348417</td>\n",
              "      <td>2.332151</td>\n",
              "      <td>2.500804</td>\n",
              "      <td>2.452207</td>\n",
              "      <td>2.199232</td>\n",
              "      <td>2.418787</td>\n",
              "      <td>2.350722</td>\n",
              "      <td>2.319492</td>\n",
              "      <td>2.308131</td>\n",
              "      <td>2.337476</td>\n",
              "      <td>2.551229</td>\n",
              "      <td>2.612617</td>\n",
              "      <td>2.125126</td>\n",
              "      <td>2.360901</td>\n",
              "      <td>2.253608</td>\n",
              "      <td>2.122853</td>\n",
              "      <td>2.476902</td>\n",
              "      <td>2.268956</td>\n",
              "      <td>2.558829</td>\n",
              "      <td>2.428721</td>\n",
              "      <td>2.400394</td>\n",
              "      <td>2.312306</td>\n",
              "      <td>...</td>\n",
              "      <td>2.418033</td>\n",
              "      <td>2.435334</td>\n",
              "      <td>2.373111</td>\n",
              "      <td>2.464767</td>\n",
              "      <td>2.441807</td>\n",
              "      <td>2.508824</td>\n",
              "      <td>2.377651</td>\n",
              "      <td>2.488770</td>\n",
              "      <td>2.401070</td>\n",
              "      <td>2.415385</td>\n",
              "      <td>2.357364</td>\n",
              "      <td>2.370675</td>\n",
              "      <td>2.508624</td>\n",
              "      <td>2.351369</td>\n",
              "      <td>2.279599</td>\n",
              "      <td>2.209681</td>\n",
              "      <td>2.250709</td>\n",
              "      <td>2.159618</td>\n",
              "      <td>2.214695</td>\n",
              "      <td>2.345911</td>\n",
              "      <td>2.452912</td>\n",
              "      <td>2.461107</td>\n",
              "      <td>2.439569</td>\n",
              "      <td>2.189150</td>\n",
              "      <td>2.434983</td>\n",
              "      <td>2.254537</td>\n",
              "      <td>2.519381</td>\n",
              "      <td>2.185282</td>\n",
              "      <td>2.500601</td>\n",
              "      <td>2.427163</td>\n",
              "      <td>2.607009</td>\n",
              "      <td>2.562439</td>\n",
              "      <td>2.502143</td>\n",
              "      <td>2.331126</td>\n",
              "      <td>2.368241</td>\n",
              "      <td>2.323990</td>\n",
              "      <td>2.215729</td>\n",
              "      <td>2.201903</td>\n",
              "      <td>2.321458</td>\n",
              "      <td>2.430239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.688621</td>\n",
              "      <td>2.327542</td>\n",
              "      <td>2.287974</td>\n",
              "      <td>2.595419</td>\n",
              "      <td>2.352269</td>\n",
              "      <td>2.388644</td>\n",
              "      <td>2.266447</td>\n",
              "      <td>2.276934</td>\n",
              "      <td>2.606352</td>\n",
              "      <td>2.473355</td>\n",
              "      <td>2.425833</td>\n",
              "      <td>2.650512</td>\n",
              "      <td>2.357382</td>\n",
              "      <td>2.440268</td>\n",
              "      <td>2.582072</td>\n",
              "      <td>2.522901</td>\n",
              "      <td>2.417977</td>\n",
              "      <td>2.573590</td>\n",
              "      <td>2.366508</td>\n",
              "      <td>2.329349</td>\n",
              "      <td>2.526825</td>\n",
              "      <td>2.499411</td>\n",
              "      <td>2.251157</td>\n",
              "      <td>2.453767</td>\n",
              "      <td>2.371553</td>\n",
              "      <td>2.344712</td>\n",
              "      <td>2.305493</td>\n",
              "      <td>2.372750</td>\n",
              "      <td>2.616004</td>\n",
              "      <td>2.603236</td>\n",
              "      <td>2.191947</td>\n",
              "      <td>2.421958</td>\n",
              "      <td>2.257647</td>\n",
              "      <td>2.140655</td>\n",
              "      <td>2.470683</td>\n",
              "      <td>2.338836</td>\n",
              "      <td>2.567429</td>\n",
              "      <td>2.478099</td>\n",
              "      <td>2.475107</td>\n",
              "      <td>2.316432</td>\n",
              "      <td>...</td>\n",
              "      <td>2.455583</td>\n",
              "      <td>2.482214</td>\n",
              "      <td>2.362702</td>\n",
              "      <td>2.451276</td>\n",
              "      <td>2.508717</td>\n",
              "      <td>2.531386</td>\n",
              "      <td>2.433935</td>\n",
              "      <td>2.539505</td>\n",
              "      <td>2.378102</td>\n",
              "      <td>2.408430</td>\n",
              "      <td>2.439497</td>\n",
              "      <td>2.414135</td>\n",
              "      <td>2.500997</td>\n",
              "      <td>2.384116</td>\n",
              "      <td>2.265472</td>\n",
              "      <td>2.274704</td>\n",
              "      <td>2.236005</td>\n",
              "      <td>2.172168</td>\n",
              "      <td>2.298446</td>\n",
              "      <td>2.323144</td>\n",
              "      <td>2.519212</td>\n",
              "      <td>2.486149</td>\n",
              "      <td>2.443498</td>\n",
              "      <td>2.250358</td>\n",
              "      <td>2.410727</td>\n",
              "      <td>2.317104</td>\n",
              "      <td>2.519462</td>\n",
              "      <td>2.232438</td>\n",
              "      <td>2.480605</td>\n",
              "      <td>2.374739</td>\n",
              "      <td>2.574420</td>\n",
              "      <td>2.593884</td>\n",
              "      <td>2.537404</td>\n",
              "      <td>2.364128</td>\n",
              "      <td>2.397650</td>\n",
              "      <td>2.305927</td>\n",
              "      <td>2.243525</td>\n",
              "      <td>2.269905</td>\n",
              "      <td>2.407200</td>\n",
              "      <td>2.488512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.681221</td>\n",
              "      <td>2.362780</td>\n",
              "      <td>2.307868</td>\n",
              "      <td>2.650259</td>\n",
              "      <td>2.327815</td>\n",
              "      <td>2.437772</td>\n",
              "      <td>2.314506</td>\n",
              "      <td>2.325528</td>\n",
              "      <td>2.585402</td>\n",
              "      <td>2.434379</td>\n",
              "      <td>2.447038</td>\n",
              "      <td>2.661682</td>\n",
              "      <td>2.422856</td>\n",
              "      <td>2.449665</td>\n",
              "      <td>2.567882</td>\n",
              "      <td>2.534542</td>\n",
              "      <td>2.418365</td>\n",
              "      <td>2.558234</td>\n",
              "      <td>2.391165</td>\n",
              "      <td>2.360056</td>\n",
              "      <td>2.514274</td>\n",
              "      <td>2.492912</td>\n",
              "      <td>2.213658</td>\n",
              "      <td>2.475950</td>\n",
              "      <td>2.421412</td>\n",
              "      <td>2.333884</td>\n",
              "      <td>2.353368</td>\n",
              "      <td>2.384061</td>\n",
              "      <td>2.629268</td>\n",
              "      <td>2.627203</td>\n",
              "      <td>2.192982</td>\n",
              "      <td>2.406244</td>\n",
              "      <td>2.271990</td>\n",
              "      <td>2.172765</td>\n",
              "      <td>2.536330</td>\n",
              "      <td>2.332006</td>\n",
              "      <td>2.611233</td>\n",
              "      <td>2.433477</td>\n",
              "      <td>2.437378</td>\n",
              "      <td>2.321816</td>\n",
              "      <td>...</td>\n",
              "      <td>2.485378</td>\n",
              "      <td>2.483913</td>\n",
              "      <td>2.396026</td>\n",
              "      <td>2.499976</td>\n",
              "      <td>2.496846</td>\n",
              "      <td>2.552048</td>\n",
              "      <td>2.402235</td>\n",
              "      <td>2.545511</td>\n",
              "      <td>2.419465</td>\n",
              "      <td>2.448797</td>\n",
              "      <td>2.411865</td>\n",
              "      <td>2.385369</td>\n",
              "      <td>2.528933</td>\n",
              "      <td>2.354372</td>\n",
              "      <td>2.291564</td>\n",
              "      <td>2.253263</td>\n",
              "      <td>2.302175</td>\n",
              "      <td>2.216849</td>\n",
              "      <td>2.245082</td>\n",
              "      <td>2.367999</td>\n",
              "      <td>2.530126</td>\n",
              "      <td>2.516567</td>\n",
              "      <td>2.429734</td>\n",
              "      <td>2.253857</td>\n",
              "      <td>2.449277</td>\n",
              "      <td>2.289021</td>\n",
              "      <td>2.547288</td>\n",
              "      <td>2.235298</td>\n",
              "      <td>2.539273</td>\n",
              "      <td>2.436055</td>\n",
              "      <td>2.664647</td>\n",
              "      <td>2.605583</td>\n",
              "      <td>2.577544</td>\n",
              "      <td>2.385488</td>\n",
              "      <td>2.400878</td>\n",
              "      <td>2.368778</td>\n",
              "      <td>2.238636</td>\n",
              "      <td>2.213926</td>\n",
              "      <td>2.373105</td>\n",
              "      <td>2.466803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.731391</td>\n",
              "      <td>2.356005</td>\n",
              "      <td>2.324149</td>\n",
              "      <td>2.667740</td>\n",
              "      <td>2.358357</td>\n",
              "      <td>2.455835</td>\n",
              "      <td>2.324040</td>\n",
              "      <td>2.342363</td>\n",
              "      <td>2.577667</td>\n",
              "      <td>2.438117</td>\n",
              "      <td>2.476028</td>\n",
              "      <td>2.694395</td>\n",
              "      <td>2.418649</td>\n",
              "      <td>2.465576</td>\n",
              "      <td>2.533845</td>\n",
              "      <td>2.564945</td>\n",
              "      <td>2.443647</td>\n",
              "      <td>2.531897</td>\n",
              "      <td>2.415156</td>\n",
              "      <td>2.384091</td>\n",
              "      <td>2.548829</td>\n",
              "      <td>2.467165</td>\n",
              "      <td>2.242693</td>\n",
              "      <td>2.455238</td>\n",
              "      <td>2.396961</td>\n",
              "      <td>2.332330</td>\n",
              "      <td>2.351869</td>\n",
              "      <td>2.383345</td>\n",
              "      <td>2.610631</td>\n",
              "      <td>2.631703</td>\n",
              "      <td>2.229944</td>\n",
              "      <td>2.413333</td>\n",
              "      <td>2.250221</td>\n",
              "      <td>2.183137</td>\n",
              "      <td>2.574415</td>\n",
              "      <td>2.314832</td>\n",
              "      <td>2.612242</td>\n",
              "      <td>2.472943</td>\n",
              "      <td>2.464615</td>\n",
              "      <td>2.330389</td>\n",
              "      <td>...</td>\n",
              "      <td>2.474983</td>\n",
              "      <td>2.480676</td>\n",
              "      <td>2.401732</td>\n",
              "      <td>2.490711</td>\n",
              "      <td>2.500479</td>\n",
              "      <td>2.558294</td>\n",
              "      <td>2.409542</td>\n",
              "      <td>2.578413</td>\n",
              "      <td>2.392083</td>\n",
              "      <td>2.452992</td>\n",
              "      <td>2.442916</td>\n",
              "      <td>2.420330</td>\n",
              "      <td>2.511117</td>\n",
              "      <td>2.373852</td>\n",
              "      <td>2.330232</td>\n",
              "      <td>2.284878</td>\n",
              "      <td>2.263687</td>\n",
              "      <td>2.215357</td>\n",
              "      <td>2.266837</td>\n",
              "      <td>2.356448</td>\n",
              "      <td>2.524024</td>\n",
              "      <td>2.512902</td>\n",
              "      <td>2.454167</td>\n",
              "      <td>2.238013</td>\n",
              "      <td>2.428007</td>\n",
              "      <td>2.298153</td>\n",
              "      <td>2.539598</td>\n",
              "      <td>2.157871</td>\n",
              "      <td>2.524069</td>\n",
              "      <td>2.408281</td>\n",
              "      <td>2.625889</td>\n",
              "      <td>2.621409</td>\n",
              "      <td>2.578142</td>\n",
              "      <td>2.378295</td>\n",
              "      <td>2.394969</td>\n",
              "      <td>2.359993</td>\n",
              "      <td>2.247559</td>\n",
              "      <td>2.238639</td>\n",
              "      <td>2.412806</td>\n",
              "      <td>2.485888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.664892</td>\n",
              "      <td>2.320478</td>\n",
              "      <td>2.305416</td>\n",
              "      <td>2.611919</td>\n",
              "      <td>2.283757</td>\n",
              "      <td>2.402112</td>\n",
              "      <td>2.298400</td>\n",
              "      <td>2.276627</td>\n",
              "      <td>2.531204</td>\n",
              "      <td>2.409598</td>\n",
              "      <td>2.433290</td>\n",
              "      <td>2.600818</td>\n",
              "      <td>2.404902</td>\n",
              "      <td>2.427361</td>\n",
              "      <td>2.563756</td>\n",
              "      <td>2.515672</td>\n",
              "      <td>2.370514</td>\n",
              "      <td>2.506275</td>\n",
              "      <td>2.361457</td>\n",
              "      <td>2.310880</td>\n",
              "      <td>2.480618</td>\n",
              "      <td>2.449144</td>\n",
              "      <td>2.191924</td>\n",
              "      <td>2.418680</td>\n",
              "      <td>2.363302</td>\n",
              "      <td>2.305907</td>\n",
              "      <td>2.310084</td>\n",
              "      <td>2.358118</td>\n",
              "      <td>2.557789</td>\n",
              "      <td>2.597478</td>\n",
              "      <td>2.160092</td>\n",
              "      <td>2.367962</td>\n",
              "      <td>2.238756</td>\n",
              "      <td>2.135798</td>\n",
              "      <td>2.487470</td>\n",
              "      <td>2.286126</td>\n",
              "      <td>2.563347</td>\n",
              "      <td>2.425395</td>\n",
              "      <td>2.413856</td>\n",
              "      <td>2.298316</td>\n",
              "      <td>...</td>\n",
              "      <td>2.431139</td>\n",
              "      <td>2.447347</td>\n",
              "      <td>2.366244</td>\n",
              "      <td>2.462976</td>\n",
              "      <td>2.428822</td>\n",
              "      <td>2.518550</td>\n",
              "      <td>2.388343</td>\n",
              "      <td>2.498611</td>\n",
              "      <td>2.379842</td>\n",
              "      <td>2.410382</td>\n",
              "      <td>2.390763</td>\n",
              "      <td>2.355520</td>\n",
              "      <td>2.489175</td>\n",
              "      <td>2.329206</td>\n",
              "      <td>2.261226</td>\n",
              "      <td>2.230296</td>\n",
              "      <td>2.255379</td>\n",
              "      <td>2.195686</td>\n",
              "      <td>2.230423</td>\n",
              "      <td>2.354364</td>\n",
              "      <td>2.471234</td>\n",
              "      <td>2.480339</td>\n",
              "      <td>2.414530</td>\n",
              "      <td>2.214002</td>\n",
              "      <td>2.408349</td>\n",
              "      <td>2.254142</td>\n",
              "      <td>2.527125</td>\n",
              "      <td>2.188918</td>\n",
              "      <td>2.512064</td>\n",
              "      <td>2.417259</td>\n",
              "      <td>2.599769</td>\n",
              "      <td>2.569554</td>\n",
              "      <td>2.508104</td>\n",
              "      <td>2.325130</td>\n",
              "      <td>2.377856</td>\n",
              "      <td>2.340196</td>\n",
              "      <td>2.218839</td>\n",
              "      <td>2.211272</td>\n",
              "      <td>2.338783</td>\n",
              "      <td>2.438032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.639735</td>\n",
              "      <td>2.317055</td>\n",
              "      <td>2.302321</td>\n",
              "      <td>2.622239</td>\n",
              "      <td>2.298635</td>\n",
              "      <td>2.392957</td>\n",
              "      <td>2.273449</td>\n",
              "      <td>2.323811</td>\n",
              "      <td>2.525311</td>\n",
              "      <td>2.398386</td>\n",
              "      <td>2.448866</td>\n",
              "      <td>2.585497</td>\n",
              "      <td>2.407199</td>\n",
              "      <td>2.425073</td>\n",
              "      <td>2.606507</td>\n",
              "      <td>2.534373</td>\n",
              "      <td>2.383889</td>\n",
              "      <td>2.541100</td>\n",
              "      <td>2.347789</td>\n",
              "      <td>2.302148</td>\n",
              "      <td>2.510894</td>\n",
              "      <td>2.541412</td>\n",
              "      <td>2.231713</td>\n",
              "      <td>2.453932</td>\n",
              "      <td>2.373863</td>\n",
              "      <td>2.349997</td>\n",
              "      <td>2.316569</td>\n",
              "      <td>2.400376</td>\n",
              "      <td>2.581901</td>\n",
              "      <td>2.581204</td>\n",
              "      <td>2.127476</td>\n",
              "      <td>2.416077</td>\n",
              "      <td>2.304358</td>\n",
              "      <td>2.134857</td>\n",
              "      <td>2.468025</td>\n",
              "      <td>2.316912</td>\n",
              "      <td>2.595994</td>\n",
              "      <td>2.462182</td>\n",
              "      <td>2.435731</td>\n",
              "      <td>2.320461</td>\n",
              "      <td>...</td>\n",
              "      <td>2.435525</td>\n",
              "      <td>2.487414</td>\n",
              "      <td>2.388359</td>\n",
              "      <td>2.505295</td>\n",
              "      <td>2.465947</td>\n",
              "      <td>2.537507</td>\n",
              "      <td>2.397767</td>\n",
              "      <td>2.464769</td>\n",
              "      <td>2.410489</td>\n",
              "      <td>2.467981</td>\n",
              "      <td>2.420815</td>\n",
              "      <td>2.380174</td>\n",
              "      <td>2.491681</td>\n",
              "      <td>2.401989</td>\n",
              "      <td>2.291448</td>\n",
              "      <td>2.245397</td>\n",
              "      <td>2.286474</td>\n",
              "      <td>2.164872</td>\n",
              "      <td>2.248356</td>\n",
              "      <td>2.358002</td>\n",
              "      <td>2.483763</td>\n",
              "      <td>2.509187</td>\n",
              "      <td>2.452248</td>\n",
              "      <td>2.205246</td>\n",
              "      <td>2.442091</td>\n",
              "      <td>2.279219</td>\n",
              "      <td>2.512878</td>\n",
              "      <td>2.230914</td>\n",
              "      <td>2.539977</td>\n",
              "      <td>2.431489</td>\n",
              "      <td>2.579032</td>\n",
              "      <td>2.583972</td>\n",
              "      <td>2.534424</td>\n",
              "      <td>2.370871</td>\n",
              "      <td>2.396027</td>\n",
              "      <td>2.356696</td>\n",
              "      <td>2.277199</td>\n",
              "      <td>2.256001</td>\n",
              "      <td>2.382046</td>\n",
              "      <td>2.452692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.693933</td>\n",
              "      <td>2.325058</td>\n",
              "      <td>2.305252</td>\n",
              "      <td>2.626103</td>\n",
              "      <td>2.307819</td>\n",
              "      <td>2.406756</td>\n",
              "      <td>2.317334</td>\n",
              "      <td>2.295212</td>\n",
              "      <td>2.565705</td>\n",
              "      <td>2.446379</td>\n",
              "      <td>2.427427</td>\n",
              "      <td>2.616411</td>\n",
              "      <td>2.410523</td>\n",
              "      <td>2.401496</td>\n",
              "      <td>2.544093</td>\n",
              "      <td>2.525367</td>\n",
              "      <td>2.397446</td>\n",
              "      <td>2.529716</td>\n",
              "      <td>2.349498</td>\n",
              "      <td>2.364423</td>\n",
              "      <td>2.489083</td>\n",
              "      <td>2.463071</td>\n",
              "      <td>2.232035</td>\n",
              "      <td>2.435046</td>\n",
              "      <td>2.376403</td>\n",
              "      <td>2.318877</td>\n",
              "      <td>2.339039</td>\n",
              "      <td>2.375243</td>\n",
              "      <td>2.574953</td>\n",
              "      <td>2.629619</td>\n",
              "      <td>2.199202</td>\n",
              "      <td>2.383923</td>\n",
              "      <td>2.238214</td>\n",
              "      <td>2.149548</td>\n",
              "      <td>2.490688</td>\n",
              "      <td>2.299819</td>\n",
              "      <td>2.600949</td>\n",
              "      <td>2.433632</td>\n",
              "      <td>2.397446</td>\n",
              "      <td>2.314606</td>\n",
              "      <td>...</td>\n",
              "      <td>2.469366</td>\n",
              "      <td>2.470459</td>\n",
              "      <td>2.384240</td>\n",
              "      <td>2.471898</td>\n",
              "      <td>2.481369</td>\n",
              "      <td>2.507347</td>\n",
              "      <td>2.428987</td>\n",
              "      <td>2.524886</td>\n",
              "      <td>2.372645</td>\n",
              "      <td>2.438998</td>\n",
              "      <td>2.413595</td>\n",
              "      <td>2.386244</td>\n",
              "      <td>2.531328</td>\n",
              "      <td>2.340293</td>\n",
              "      <td>2.303746</td>\n",
              "      <td>2.261188</td>\n",
              "      <td>2.279646</td>\n",
              "      <td>2.167538</td>\n",
              "      <td>2.251159</td>\n",
              "      <td>2.315133</td>\n",
              "      <td>2.491263</td>\n",
              "      <td>2.504950</td>\n",
              "      <td>2.438565</td>\n",
              "      <td>2.232576</td>\n",
              "      <td>2.395410</td>\n",
              "      <td>2.245541</td>\n",
              "      <td>2.526970</td>\n",
              "      <td>2.158618</td>\n",
              "      <td>2.507912</td>\n",
              "      <td>2.404981</td>\n",
              "      <td>2.615475</td>\n",
              "      <td>2.579213</td>\n",
              "      <td>2.536266</td>\n",
              "      <td>2.380871</td>\n",
              "      <td>2.386730</td>\n",
              "      <td>2.337650</td>\n",
              "      <td>2.248416</td>\n",
              "      <td>2.232226</td>\n",
              "      <td>2.366100</td>\n",
              "      <td>2.482552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.651045</td>\n",
              "      <td>2.282344</td>\n",
              "      <td>2.287502</td>\n",
              "      <td>2.580246</td>\n",
              "      <td>2.288791</td>\n",
              "      <td>2.366195</td>\n",
              "      <td>2.266252</td>\n",
              "      <td>2.274518</td>\n",
              "      <td>2.540983</td>\n",
              "      <td>2.408945</td>\n",
              "      <td>2.428161</td>\n",
              "      <td>2.595615</td>\n",
              "      <td>2.380609</td>\n",
              "      <td>2.409137</td>\n",
              "      <td>2.561453</td>\n",
              "      <td>2.511296</td>\n",
              "      <td>2.351312</td>\n",
              "      <td>2.509626</td>\n",
              "      <td>2.354639</td>\n",
              "      <td>2.307070</td>\n",
              "      <td>2.486692</td>\n",
              "      <td>2.476223</td>\n",
              "      <td>2.201952</td>\n",
              "      <td>2.420922</td>\n",
              "      <td>2.341029</td>\n",
              "      <td>2.305369</td>\n",
              "      <td>2.301125</td>\n",
              "      <td>2.337557</td>\n",
              "      <td>2.545710</td>\n",
              "      <td>2.586149</td>\n",
              "      <td>2.154949</td>\n",
              "      <td>2.372856</td>\n",
              "      <td>2.241770</td>\n",
              "      <td>2.123743</td>\n",
              "      <td>2.447980</td>\n",
              "      <td>2.283077</td>\n",
              "      <td>2.560707</td>\n",
              "      <td>2.439927</td>\n",
              "      <td>2.416845</td>\n",
              "      <td>2.287903</td>\n",
              "      <td>...</td>\n",
              "      <td>2.397362</td>\n",
              "      <td>2.452360</td>\n",
              "      <td>2.344758</td>\n",
              "      <td>2.441683</td>\n",
              "      <td>2.433106</td>\n",
              "      <td>2.501659</td>\n",
              "      <td>2.403094</td>\n",
              "      <td>2.479644</td>\n",
              "      <td>2.382970</td>\n",
              "      <td>2.395834</td>\n",
              "      <td>2.405010</td>\n",
              "      <td>2.367781</td>\n",
              "      <td>2.478539</td>\n",
              "      <td>2.330229</td>\n",
              "      <td>2.277414</td>\n",
              "      <td>2.238420</td>\n",
              "      <td>2.232621</td>\n",
              "      <td>2.166054</td>\n",
              "      <td>2.244052</td>\n",
              "      <td>2.314632</td>\n",
              "      <td>2.457129</td>\n",
              "      <td>2.479737</td>\n",
              "      <td>2.419286</td>\n",
              "      <td>2.191889</td>\n",
              "      <td>2.393957</td>\n",
              "      <td>2.245881</td>\n",
              "      <td>2.512059</td>\n",
              "      <td>2.196070</td>\n",
              "      <td>2.493435</td>\n",
              "      <td>2.374002</td>\n",
              "      <td>2.547680</td>\n",
              "      <td>2.569074</td>\n",
              "      <td>2.501617</td>\n",
              "      <td>2.313068</td>\n",
              "      <td>2.377913</td>\n",
              "      <td>2.333770</td>\n",
              "      <td>2.239295</td>\n",
              "      <td>2.215763</td>\n",
              "      <td>2.367879</td>\n",
              "      <td>2.447322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.605788</td>\n",
              "      <td>2.278579</td>\n",
              "      <td>2.241837</td>\n",
              "      <td>2.565767</td>\n",
              "      <td>2.287902</td>\n",
              "      <td>2.353735</td>\n",
              "      <td>2.241373</td>\n",
              "      <td>2.239851</td>\n",
              "      <td>2.509410</td>\n",
              "      <td>2.397172</td>\n",
              "      <td>2.381341</td>\n",
              "      <td>2.573681</td>\n",
              "      <td>2.349527</td>\n",
              "      <td>2.357842</td>\n",
              "      <td>2.523156</td>\n",
              "      <td>2.488034</td>\n",
              "      <td>2.353868</td>\n",
              "      <td>2.497328</td>\n",
              "      <td>2.307749</td>\n",
              "      <td>2.283168</td>\n",
              "      <td>2.468245</td>\n",
              "      <td>2.423819</td>\n",
              "      <td>2.188546</td>\n",
              "      <td>2.397142</td>\n",
              "      <td>2.307926</td>\n",
              "      <td>2.287512</td>\n",
              "      <td>2.274276</td>\n",
              "      <td>2.309291</td>\n",
              "      <td>2.514840</td>\n",
              "      <td>2.567772</td>\n",
              "      <td>2.110024</td>\n",
              "      <td>2.337986</td>\n",
              "      <td>2.203098</td>\n",
              "      <td>2.100297</td>\n",
              "      <td>2.439166</td>\n",
              "      <td>2.261074</td>\n",
              "      <td>2.529406</td>\n",
              "      <td>2.412233</td>\n",
              "      <td>2.386598</td>\n",
              "      <td>2.276757</td>\n",
              "      <td>...</td>\n",
              "      <td>2.376387</td>\n",
              "      <td>2.407400</td>\n",
              "      <td>2.331784</td>\n",
              "      <td>2.417955</td>\n",
              "      <td>2.420333</td>\n",
              "      <td>2.477949</td>\n",
              "      <td>2.362639</td>\n",
              "      <td>2.467068</td>\n",
              "      <td>2.351375</td>\n",
              "      <td>2.377371</td>\n",
              "      <td>2.351963</td>\n",
              "      <td>2.347967</td>\n",
              "      <td>2.473979</td>\n",
              "      <td>2.327543</td>\n",
              "      <td>2.245626</td>\n",
              "      <td>2.199047</td>\n",
              "      <td>2.222196</td>\n",
              "      <td>2.128131</td>\n",
              "      <td>2.202982</td>\n",
              "      <td>2.298136</td>\n",
              "      <td>2.416329</td>\n",
              "      <td>2.424056</td>\n",
              "      <td>2.401894</td>\n",
              "      <td>2.167357</td>\n",
              "      <td>2.374169</td>\n",
              "      <td>2.233969</td>\n",
              "      <td>2.476960</td>\n",
              "      <td>2.164889</td>\n",
              "      <td>2.451635</td>\n",
              "      <td>2.353888</td>\n",
              "      <td>2.564833</td>\n",
              "      <td>2.524208</td>\n",
              "      <td>2.484733</td>\n",
              "      <td>2.296491</td>\n",
              "      <td>2.329283</td>\n",
              "      <td>2.273759</td>\n",
              "      <td>2.190300</td>\n",
              "      <td>2.188632</td>\n",
              "      <td>2.315411</td>\n",
              "      <td>2.425982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.668904</td>\n",
              "      <td>2.362790</td>\n",
              "      <td>2.337592</td>\n",
              "      <td>2.626224</td>\n",
              "      <td>2.361520</td>\n",
              "      <td>2.475432</td>\n",
              "      <td>2.336782</td>\n",
              "      <td>2.339533</td>\n",
              "      <td>2.534250</td>\n",
              "      <td>2.421600</td>\n",
              "      <td>2.470870</td>\n",
              "      <td>2.637891</td>\n",
              "      <td>2.397924</td>\n",
              "      <td>2.484679</td>\n",
              "      <td>2.625668</td>\n",
              "      <td>2.587656</td>\n",
              "      <td>2.435711</td>\n",
              "      <td>2.522063</td>\n",
              "      <td>2.387734</td>\n",
              "      <td>2.318504</td>\n",
              "      <td>2.555520</td>\n",
              "      <td>2.529078</td>\n",
              "      <td>2.231773</td>\n",
              "      <td>2.424821</td>\n",
              "      <td>2.396764</td>\n",
              "      <td>2.361172</td>\n",
              "      <td>2.354873</td>\n",
              "      <td>2.398949</td>\n",
              "      <td>2.595111</td>\n",
              "      <td>2.608216</td>\n",
              "      <td>2.157081</td>\n",
              "      <td>2.421194</td>\n",
              "      <td>2.289257</td>\n",
              "      <td>2.156608</td>\n",
              "      <td>2.556211</td>\n",
              "      <td>2.356318</td>\n",
              "      <td>2.640500</td>\n",
              "      <td>2.450664</td>\n",
              "      <td>2.479862</td>\n",
              "      <td>2.385079</td>\n",
              "      <td>...</td>\n",
              "      <td>2.470306</td>\n",
              "      <td>2.508566</td>\n",
              "      <td>2.392230</td>\n",
              "      <td>2.510005</td>\n",
              "      <td>2.476558</td>\n",
              "      <td>2.596264</td>\n",
              "      <td>2.357619</td>\n",
              "      <td>2.526068</td>\n",
              "      <td>2.395219</td>\n",
              "      <td>2.436071</td>\n",
              "      <td>2.450549</td>\n",
              "      <td>2.420079</td>\n",
              "      <td>2.502285</td>\n",
              "      <td>2.423220</td>\n",
              "      <td>2.291999</td>\n",
              "      <td>2.276872</td>\n",
              "      <td>2.326967</td>\n",
              "      <td>2.214158</td>\n",
              "      <td>2.250423</td>\n",
              "      <td>2.398300</td>\n",
              "      <td>2.501406</td>\n",
              "      <td>2.547882</td>\n",
              "      <td>2.424504</td>\n",
              "      <td>2.220450</td>\n",
              "      <td>2.479183</td>\n",
              "      <td>2.294289</td>\n",
              "      <td>2.543388</td>\n",
              "      <td>2.232281</td>\n",
              "      <td>2.559016</td>\n",
              "      <td>2.467163</td>\n",
              "      <td>2.649224</td>\n",
              "      <td>2.626092</td>\n",
              "      <td>2.617321</td>\n",
              "      <td>2.393450</td>\n",
              "      <td>2.372714</td>\n",
              "      <td>2.363334</td>\n",
              "      <td>2.287326</td>\n",
              "      <td>2.295925</td>\n",
              "      <td>2.427395</td>\n",
              "      <td>2.480248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       217       218       219\n",
              "0  2.628733  2.308827  2.281555  ...  2.201903  2.321458  2.430239\n",
              "1  2.688621  2.327542  2.287974  ...  2.269905  2.407200  2.488512\n",
              "2  2.681221  2.362780  2.307868  ...  2.213926  2.373105  2.466803\n",
              "3  2.731391  2.356005  2.324149  ...  2.238639  2.412806  2.485888\n",
              "4  2.664892  2.320478  2.305416  ...  2.211272  2.338783  2.438032\n",
              "5  2.639735  2.317055  2.302321  ...  2.256001  2.382046  2.452692\n",
              "6  2.693933  2.325058  2.305252  ...  2.232226  2.366100  2.482552\n",
              "7  2.651045  2.282344  2.287502  ...  2.215763  2.367879  2.447322\n",
              "8  2.605788  2.278579  2.241837  ...  2.188632  2.315411  2.425982\n",
              "9  2.668904  2.362790  2.337592  ...  2.295925  2.427395  2.480248\n",
              "\n",
              "[10 rows x 220 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP0Af54XC8kV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "07851fb7-606b-43f6-b5a8-dcd2142e364b"
      },
      "source": [
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(weight_pred, test_weight_label)\n",
        "plt.xlabel('True Values [weight]')\n",
        "plt.ylabel('Predictions [weight]')\n",
        "lims = [30, 60]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UQRubkHJOCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "87cdd4fa-6d2f-4928-f803-beab9bd4b109"
      },
      "source": [
        "test_weight_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141     49.664072\n",
              "178     46.876165\n",
              "180     46.752680\n",
              "188     49.893984\n",
              "207     46.951447\n",
              "          ...    \n",
              "2527    34.756029\n",
              "2528    35.064065\n",
              "2536    36.279261\n",
              "2541    34.114205\n",
              "2547    38.539278\n",
              "Name: weight, Length: 420, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOweFgdsI-eO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "c6b9a8eb-6016-43a9-fc13-3915a62c32ae"
      },
      "source": [
        "error = weight_pred.flatten() - test_weight_label\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [weight]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOiBgu0TDBm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "37bb57de-3b3e-4dd3-c8fa-f491f1c0a1db"
      },
      "source": [
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(displacement_pred, test_displacement_label)\n",
        "plt.xlabel('True Values [displacement]')\n",
        "plt.ylabel('Predictions [displacement]')\n",
        "lims = [0.2, 0.8]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OXrKZjAJaQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "284d4e67-cbb7-4f82-f673-551e94f71f34"
      },
      "source": [
        "error = displacement_pred.flatten() - test_displacement_label\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [displacement]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvBfL7fiDEDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7db6daa2-2a89-4a1f-c91b-6f6fa14e6303"
      },
      "source": [
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(util_pred, test_util_label)\n",
        "plt.xlabel('True Values [util]')\n",
        "plt.ylabel('Predictions [util]')\n",
        "lims = [10, 35]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcsWbnXxJmmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "98436a81-f0f1-4a2d-e1c6-ebe3de01fa6e"
      },
      "source": [
        "error = util_pred.flatten() - test_util_label\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [util]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}