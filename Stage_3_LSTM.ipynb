{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage_3_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "i1yjzfMOZEND",
        "kh9iAu5PX4lL"
      ],
      "authorship_tag": "ABX9TyOCvlIxp9THw+WSRhBMWDPa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XingxinHE/FinalThesis_DL-GA/blob/master/Stage_3_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTxgp4izTN0j",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxHz82xPo63m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "459ff948-0628-41d7-f850-07b8fc626084"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV9asYKxyxN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8a6c4652-5333-43e7-8a82-5092813dec31"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uisTtYdxS8h-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3836a70-7ae8-4a6f-81b4-f5e8ffc67e69"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3m1cig3TDmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/Final Thesis/data/stage3\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80y1T2cGX5nD",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1yjzfMOZEND",
        "colab_type": "text"
      },
      "source": [
        "### Loading Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YG9VicuX5JS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = pd.read_csv('605_coord.csv', index_col=0)\n",
        "train_x.drop(columns=list('2568'), axis=1, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNZ6co9qZ2a_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1f97939-0b1e-45ef-d529-50e4fa37cd7f"
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h1O7ZjLBkio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "995803f4-763a-4cf2-f7d4-53d6ba1e0b34"
      },
      "source": [
        "train_x.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     3     4     7\n",
              "0  40.0  35.0  30.0  20.0  35.0\n",
              "1  40.0  40.0  40.0  15.0  35.0\n",
              "2  30.0  30.0  40.0  20.0  20.0\n",
              "3  10.0  40.0  40.0  20.0  25.0\n",
              "4  35.0  40.0  30.0  10.0  30.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecO6GbLJA2Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = pd.read_csv('10_coord.csv', index_col=0)\n",
        "test_x.drop(columns=list('2568'), axis=1, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1LYg1x9A_b3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad1df785-8bac-44ac-d834-b6cb921c8020"
      },
      "source": [
        "test_x.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAeQFbp8BehP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6de25e89-bc66-4dfa-c54c-92b16b2a3873"
      },
      "source": [
        "test_x.tail()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>25.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     3     4     7\n",
              "5  30.0  40.0  15.0  10.0  20.0\n",
              "6  40.0  35.0  35.0  20.0  30.0\n",
              "7  35.0  40.0  25.0  15.0  20.0\n",
              "8  25.0  35.0  30.0  15.0  15.0\n",
              "9  20.0  40.0  10.0  10.0  35.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt6bDAU-BGHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "4368dd43-9130-44b7-9bfd-badcaa90fdd3"
      },
      "source": [
        "train_test = pd.concat([train_x, test_x])\n",
        "train_test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>25.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>615 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1     3     4     7\n",
              "0   40.0  35.0  30.0  20.0  35.0\n",
              "1   40.0  40.0  40.0  15.0  35.0\n",
              "2   30.0  30.0  40.0  20.0  20.0\n",
              "3   10.0  40.0  40.0  20.0  25.0\n",
              "4   35.0  40.0  30.0  10.0  30.0\n",
              "..   ...   ...   ...   ...   ...\n",
              "5   30.0  40.0  15.0  10.0  20.0\n",
              "6   40.0  35.0  35.0  20.0  30.0\n",
              "7   35.0  40.0  25.0  15.0  20.0\n",
              "8   25.0  35.0  30.0  15.0  15.0\n",
              "9   20.0  40.0  10.0  10.0  35.0\n",
              "\n",
              "[615 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx3UTW27nJa4",
        "colab_type": "text"
      },
      "source": [
        "### Loading output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pOk9oIYa92P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e01e6b58-8c1d-4184-ebb3-07f50b3cc39d"
      },
      "source": [
        "train_y = pd.read_csv('optimal_605.csv', index_col=0)\n",
        "train_y.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DdbbqmGCp7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42826642-1957-4c1b-fa5b-95a8e8b7dcf0"
      },
      "source": [
        "test_y = pd.read_csv('testing_10.csv', index_col=0)\n",
        "test_y.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76gM9IY9l7Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function convert np of object to np of float\n",
        "def f(x):\n",
        "    return np.array(x.replace('[', '').replace(']', '').replace(',', ' ').split()).astype(float)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5ZRNLSbqtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34f78ff7-ed4b-4bb0-ede8-2264c7cd0546"
      },
      "source": [
        "train_y = np.array([f(t) for t in train_y['bar_orders']])\n",
        "train_y = np.floor(train_y)\n",
        "train_y = train_y.astype(int)\n",
        "train_y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bawNEeUXlMs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "db9d768c-5111-4e08-b37d-fa0ec20f7899"
      },
      "source": [
        "train_y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 1, ..., 0, 2, 1],\n",
              "       [0, 0, 2, ..., 2, 0, 1],\n",
              "       [2, 2, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [0, 1, 3, ..., 0, 3, 1],\n",
              "       [1, 1, 2, ..., 0, 1, 2],\n",
              "       [2, 3, 2, ..., 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKNbyYvdGqZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d34ee91-a591-4a87-eb21-1fe6a2dec987"
      },
      "source": [
        "test_y = np.array([f(t) for t in test_y['bar_orders']])\n",
        "test_y = np.floor(test_y)\n",
        "test_y = test_y.astype(int)\n",
        "test_y.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMSdhe9RGzzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "575bcb36-0f6e-44ec-af27-68d8147cda8c"
      },
      "source": [
        "test_y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 2, ..., 0, 0, 2],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 3, ..., 1, 0, 0],\n",
              "       ...,\n",
              "       [2, 0, 1, ..., 2, 0, 2],\n",
              "       [2, 2, 1, ..., 0, 0, 2],\n",
              "       [0, 1, 2, ..., 2, 1, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh9iAu5PX4lL",
        "colab_type": "text"
      },
      "source": [
        "### One-hot coding input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmHZd7b-RHpJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0eeeac85-d2d4-4490-a0d4-c070dfb6dde0"
      },
      "source": [
        "intput_features = len(train_x.columns)\n",
        "intput_features"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EvGdyT2STA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1a571676-3991-44fe-d656-e43db88784bc"
      },
      "source": [
        "sorted(pd.unique(train_test[train_test.columns].values.ravel('K')))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10.0, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrIr31FdShM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intput_features_possibilities = sorted(pd.unique(train_test[train_test.columns].values.ravel('K')))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TZ8UuO1SoFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5655f747-d23e-489a-8b0c-fd7bdd3357c3"
      },
      "source": [
        "intput_features_possibilities = [int(i) for i in intput_features_possibilities]\n",
        "intput_features_possibilities"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 15, 20, 25, 30, 35, 40]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gf1Rkr2RpuU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3263c7ab-53f3-4d3a-cd8f-beae3cf3afd0"
      },
      "source": [
        "intput_features_possibilities_indices = dict((feature, intput_features_possibilities.index(feature)) for feature in intput_features_possibilities)\n",
        "intput_features_possibilities_indices"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: 0, 15: 1, 20: 2, 25: 3, 30: 4, 35: 5, 40: 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqOzD5ldUYLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x_onehot = np.zeros((len(train_x.index), intput_features, len(intput_features_possibilities)), dtype=np.bool)\n",
        "test_x_onehot = np.zeros((len(test_x.index), intput_features, len(intput_features_possibilities)), dtype=np.bool)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIOIGMYoVNx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6811fabe-59fc-4274-b9c4-3d3666538a9d"
      },
      "source": [
        "train_x_onehot.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BJ099Z9VNii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "41224d60-ad82-415e-d548-9f44331f78d4"
      },
      "source": [
        "test_x_onehot.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WTecJl1VrsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_x.index)):\n",
        "  for j in range(len(train_x.columns)):\n",
        "    train_x_onehot[i, j, intput_features_possibilities_indices[train_x.iloc[i,j]]] = 1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axDPHyC_WtT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(test_x.index)):\n",
        "  for j in range(len(test_x.columns)):\n",
        "    test_x_onehot[i, j, intput_features_possibilities_indices[test_x.iloc[i,j]]] = 1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqeph7TIXnCs",
        "colab_type": "text"
      },
      "source": [
        "### One-hot coding output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2VuMvmf3YAOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8414ab1-7001-4114-907a-614636693878"
      },
      "source": [
        "output_features = train_y.shape[1]\n",
        "output_features"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iODc0TjZv6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e339bd1-8a28-4b0a-b537-e4473816232b"
      },
      "source": [
        "np.unique(train_y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nvgCj8GZYAOM",
        "colab": {}
      },
      "source": [
        "output_features_possibilities = list(np.unique(train_y))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gTxmCOeJYAOS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ecd92a6-32a4-4e4f-8246-479f5ec8d633"
      },
      "source": [
        "output_features_possibilities_indices = dict((feature, output_features_possibilities.index(feature)) for feature in output_features_possibilities)\n",
        "output_features_possibilities_indices"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0, 1: 1, 2: 2, 3: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ij-LF08GYAOV",
        "colab": {}
      },
      "source": [
        "train_y_onehot = np.zeros((train_y.shape[0], train_y.shape[1], len(output_features_possibilities)), dtype=np.bool)\n",
        "test_y_onehot = np.zeros((test_y.shape[0], test_y.shape[1], len(output_features_possibilities)), dtype=np.bool)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JfrgnzEsYAOY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0aab7c3f-2213-49aa-db42-491a594b8d4e"
      },
      "source": [
        "train_y_onehot.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 220, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtawtHl3YAOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "562e0cb8-da6f-4339-8ffd-87dc2f032083"
      },
      "source": [
        "test_y_onehot.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUQGuinFYAOd",
        "colab": {}
      },
      "source": [
        "for i in range(train_y.shape[0]):\n",
        "  for j in range(train_y.shape[1]):\n",
        "    train_y_onehot[i, j, output_features_possibilities_indices[train_y[i,j]]] = 1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4jPn0svkYAOg",
        "colab": {}
      },
      "source": [
        "for i in range(test_y.shape[0]):\n",
        "  for j in range(test_y.shape[1]):\n",
        "    test_y_onehot[i, j, output_features_possibilities_indices[test_y[i,j]]] = 1"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgooluCFZCTO",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Model (Softmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4vD9oqmRaz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "fd93a746-feeb-4114-fb9c-16f664be792d"
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(layers.LSTM(256, input_shape=(intput_features, len(intput_features_possibilities)))) \n",
        "model.add(layers.RepeatVector(output_features))\n",
        "for _ in range(3):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(output_features_possibilities), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 256)               270336    \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 220, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 220, 128)          197120    \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 220, 128)          131584    \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 220, 128)          131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 220, 4)            516       \n",
            "=================================================================\n",
            "Total params: 731,140\n",
            "Trainable params: 731,140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqcI2GXY_Iv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84017
        },
        "outputId": "f3432299-f81c-4689-f975-329e1de8aac3"
      },
      "source": [
        "\n",
        "history = model.fit(train_x_onehot, train_y_onehot,\n",
        "          epochs=3000,\n",
        "          batch_size=32,\n",
        "          #validation_data = (x_test, y_test)\n",
        "          validation_split = 0.2,\n",
        "          )"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1055 - accuracy: 0.4783 - val_loss: 1.6322 - val_accuracy: 0.3314\n",
            "Epoch 502/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1182 - accuracy: 0.4723 - val_loss: 1.6130 - val_accuracy: 0.3275\n",
            "Epoch 503/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.1123 - accuracy: 0.4748 - val_loss: 1.6242 - val_accuracy: 0.3294\n",
            "Epoch 504/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1033 - accuracy: 0.4800 - val_loss: 1.6319 - val_accuracy: 0.3266\n",
            "Epoch 505/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0972 - accuracy: 0.4837 - val_loss: 1.6358 - val_accuracy: 0.3308\n",
            "Epoch 506/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0992 - accuracy: 0.4833 - val_loss: 1.6396 - val_accuracy: 0.3311\n",
            "Epoch 507/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1014 - accuracy: 0.4834 - val_loss: 1.6426 - val_accuracy: 0.3334\n",
            "Epoch 508/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0990 - accuracy: 0.4829 - val_loss: 1.6415 - val_accuracy: 0.3299\n",
            "Epoch 509/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0926 - accuracy: 0.4867 - val_loss: 1.6396 - val_accuracy: 0.3233\n",
            "Epoch 510/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0870 - accuracy: 0.4901 - val_loss: 1.6613 - val_accuracy: 0.3283\n",
            "Epoch 511/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0840 - accuracy: 0.4896 - val_loss: 1.6559 - val_accuracy: 0.3293\n",
            "Epoch 512/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0822 - accuracy: 0.4929 - val_loss: 1.6594 - val_accuracy: 0.3285\n",
            "Epoch 513/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0882 - accuracy: 0.4882 - val_loss: 1.6566 - val_accuracy: 0.3250\n",
            "Epoch 514/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0924 - accuracy: 0.4859 - val_loss: 1.6615 - val_accuracy: 0.3325\n",
            "Epoch 515/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0961 - accuracy: 0.4848 - val_loss: 1.6569 - val_accuracy: 0.3294\n",
            "Epoch 516/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0977 - accuracy: 0.4820 - val_loss: 1.6605 - val_accuracy: 0.3286\n",
            "Epoch 517/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1038 - accuracy: 0.4803 - val_loss: 1.6535 - val_accuracy: 0.3278\n",
            "Epoch 518/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1071 - accuracy: 0.4773 - val_loss: 1.6571 - val_accuracy: 0.3296\n",
            "Epoch 519/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0982 - accuracy: 0.4827 - val_loss: 1.6472 - val_accuracy: 0.3284\n",
            "Epoch 520/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0969 - accuracy: 0.4837 - val_loss: 1.6695 - val_accuracy: 0.3243\n",
            "Epoch 521/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0881 - accuracy: 0.4888 - val_loss: 1.6676 - val_accuracy: 0.3286\n",
            "Epoch 522/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0887 - accuracy: 0.4880 - val_loss: 1.6664 - val_accuracy: 0.3225\n",
            "Epoch 523/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0884 - accuracy: 0.4873 - val_loss: 1.6757 - val_accuracy: 0.3252\n",
            "Epoch 524/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0858 - accuracy: 0.4900 - val_loss: 1.6760 - val_accuracy: 0.3258\n",
            "Epoch 525/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0869 - accuracy: 0.4897 - val_loss: 1.6898 - val_accuracy: 0.3250\n",
            "Epoch 526/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0927 - accuracy: 0.4859 - val_loss: 1.6663 - val_accuracy: 0.3290\n",
            "Epoch 527/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0900 - accuracy: 0.4867 - val_loss: 1.6756 - val_accuracy: 0.3253\n",
            "Epoch 528/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0858 - accuracy: 0.4883 - val_loss: 1.6824 - val_accuracy: 0.3260\n",
            "Epoch 529/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0853 - accuracy: 0.4906 - val_loss: 1.6746 - val_accuracy: 0.3255\n",
            "Epoch 530/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0848 - accuracy: 0.4903 - val_loss: 1.6777 - val_accuracy: 0.3254\n",
            "Epoch 531/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0846 - accuracy: 0.4904 - val_loss: 1.6676 - val_accuracy: 0.3271\n",
            "Epoch 532/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0871 - accuracy: 0.4879 - val_loss: 1.6842 - val_accuracy: 0.3282\n",
            "Epoch 533/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0913 - accuracy: 0.4860 - val_loss: 1.6761 - val_accuracy: 0.3277\n",
            "Epoch 534/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0939 - accuracy: 0.4847 - val_loss: 1.6717 - val_accuracy: 0.3241\n",
            "Epoch 535/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0916 - accuracy: 0.4865 - val_loss: 1.6708 - val_accuracy: 0.3293\n",
            "Epoch 536/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0868 - accuracy: 0.4884 - val_loss: 1.6813 - val_accuracy: 0.3266\n",
            "Epoch 537/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0932 - accuracy: 0.4853 - val_loss: 1.6655 - val_accuracy: 0.3266\n",
            "Epoch 538/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1020 - accuracy: 0.4805 - val_loss: 1.6675 - val_accuracy: 0.3248\n",
            "Epoch 539/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1090 - accuracy: 0.4770 - val_loss: 1.6597 - val_accuracy: 0.3288\n",
            "Epoch 540/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0904 - accuracy: 0.4860 - val_loss: 1.6806 - val_accuracy: 0.3258\n",
            "Epoch 541/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0896 - accuracy: 0.4863 - val_loss: 1.6619 - val_accuracy: 0.3295\n",
            "Epoch 542/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0870 - accuracy: 0.4881 - val_loss: 1.6764 - val_accuracy: 0.3245\n",
            "Epoch 543/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0859 - accuracy: 0.4897 - val_loss: 1.6836 - val_accuracy: 0.3247\n",
            "Epoch 544/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0882 - accuracy: 0.4903 - val_loss: 1.6597 - val_accuracy: 0.3274\n",
            "Epoch 545/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0979 - accuracy: 0.4827 - val_loss: 1.6772 - val_accuracy: 0.3260\n",
            "Epoch 546/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1023 - accuracy: 0.4806 - val_loss: 1.6548 - val_accuracy: 0.3273\n",
            "Epoch 547/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0967 - accuracy: 0.4849 - val_loss: 1.6756 - val_accuracy: 0.3282\n",
            "Epoch 548/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0928 - accuracy: 0.4857 - val_loss: 1.6760 - val_accuracy: 0.3279\n",
            "Epoch 549/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0912 - accuracy: 0.4863 - val_loss: 1.6677 - val_accuracy: 0.3255\n",
            "Epoch 550/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0944 - accuracy: 0.4861 - val_loss: 1.6786 - val_accuracy: 0.3225\n",
            "Epoch 551/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0834 - accuracy: 0.4908 - val_loss: 1.6718 - val_accuracy: 0.3254\n",
            "Epoch 552/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0862 - accuracy: 0.4901 - val_loss: 1.6910 - val_accuracy: 0.3257\n",
            "Epoch 553/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0881 - accuracy: 0.4899 - val_loss: 1.6788 - val_accuracy: 0.3289\n",
            "Epoch 554/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0878 - accuracy: 0.4875 - val_loss: 1.6907 - val_accuracy: 0.3273\n",
            "Epoch 555/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0885 - accuracy: 0.4884 - val_loss: 1.6778 - val_accuracy: 0.3229\n",
            "Epoch 556/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0865 - accuracy: 0.4895 - val_loss: 1.6883 - val_accuracy: 0.3257\n",
            "Epoch 557/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0819 - accuracy: 0.4911 - val_loss: 1.6836 - val_accuracy: 0.3242\n",
            "Epoch 558/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0882 - accuracy: 0.4879 - val_loss: 1.6867 - val_accuracy: 0.3264\n",
            "Epoch 559/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0886 - accuracy: 0.4876 - val_loss: 1.6789 - val_accuracy: 0.3281\n",
            "Epoch 560/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0822 - accuracy: 0.4907 - val_loss: 1.6920 - val_accuracy: 0.3273\n",
            "Epoch 561/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0761 - accuracy: 0.4929 - val_loss: 1.7007 - val_accuracy: 0.3248\n",
            "Epoch 562/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0813 - accuracy: 0.4908 - val_loss: 1.6968 - val_accuracy: 0.3238\n",
            "Epoch 563/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0813 - accuracy: 0.4922 - val_loss: 1.6966 - val_accuracy: 0.3264\n",
            "Epoch 564/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0756 - accuracy: 0.4944 - val_loss: 1.7013 - val_accuracy: 0.3225\n",
            "Epoch 565/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0675 - accuracy: 0.4988 - val_loss: 1.7132 - val_accuracy: 0.3287\n",
            "Epoch 566/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0946 - accuracy: 0.4862 - val_loss: 1.6909 - val_accuracy: 0.3232\n",
            "Epoch 567/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0990 - accuracy: 0.4836 - val_loss: 1.7080 - val_accuracy: 0.3240\n",
            "Epoch 568/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0882 - accuracy: 0.4882 - val_loss: 1.7009 - val_accuracy: 0.3250\n",
            "Epoch 569/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0777 - accuracy: 0.4935 - val_loss: 1.7035 - val_accuracy: 0.3266\n",
            "Epoch 570/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0794 - accuracy: 0.4940 - val_loss: 1.7021 - val_accuracy: 0.3260\n",
            "Epoch 571/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0751 - accuracy: 0.4950 - val_loss: 1.7109 - val_accuracy: 0.3257\n",
            "Epoch 572/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0811 - accuracy: 0.4908 - val_loss: 1.7079 - val_accuracy: 0.3282\n",
            "Epoch 573/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0778 - accuracy: 0.4957 - val_loss: 1.7067 - val_accuracy: 0.3244\n",
            "Epoch 574/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0756 - accuracy: 0.4949 - val_loss: 1.7137 - val_accuracy: 0.3239\n",
            "Epoch 575/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0807 - accuracy: 0.4917 - val_loss: 1.6948 - val_accuracy: 0.3264\n",
            "Epoch 576/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0835 - accuracy: 0.4894 - val_loss: 1.7059 - val_accuracy: 0.3273\n",
            "Epoch 577/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0809 - accuracy: 0.4914 - val_loss: 1.7150 - val_accuracy: 0.3216\n",
            "Epoch 578/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0716 - accuracy: 0.4964 - val_loss: 1.7108 - val_accuracy: 0.3268\n",
            "Epoch 579/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0672 - accuracy: 0.5001 - val_loss: 1.7229 - val_accuracy: 0.3255\n",
            "Epoch 580/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0748 - accuracy: 0.4958 - val_loss: 1.7107 - val_accuracy: 0.3263\n",
            "Epoch 581/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0753 - accuracy: 0.4955 - val_loss: 1.7153 - val_accuracy: 0.3264\n",
            "Epoch 582/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0750 - accuracy: 0.4964 - val_loss: 1.7189 - val_accuracy: 0.3258\n",
            "Epoch 583/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0730 - accuracy: 0.4958 - val_loss: 1.7131 - val_accuracy: 0.3240\n",
            "Epoch 584/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0748 - accuracy: 0.4962 - val_loss: 1.7152 - val_accuracy: 0.3271\n",
            "Epoch 585/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0789 - accuracy: 0.4925 - val_loss: 1.7098 - val_accuracy: 0.3256\n",
            "Epoch 586/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0801 - accuracy: 0.4910 - val_loss: 1.7188 - val_accuracy: 0.3207\n",
            "Epoch 587/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0791 - accuracy: 0.4932 - val_loss: 1.7100 - val_accuracy: 0.3233\n",
            "Epoch 588/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0737 - accuracy: 0.4956 - val_loss: 1.7205 - val_accuracy: 0.3251\n",
            "Epoch 589/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0762 - accuracy: 0.4948 - val_loss: 1.7184 - val_accuracy: 0.3255\n",
            "Epoch 590/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0766 - accuracy: 0.4952 - val_loss: 1.7101 - val_accuracy: 0.3284\n",
            "Epoch 591/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0780 - accuracy: 0.4945 - val_loss: 1.7210 - val_accuracy: 0.3261\n",
            "Epoch 592/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0877 - accuracy: 0.4875 - val_loss: 1.7070 - val_accuracy: 0.3258\n",
            "Epoch 593/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0878 - accuracy: 0.4891 - val_loss: 1.7257 - val_accuracy: 0.3252\n",
            "Epoch 594/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0819 - accuracy: 0.4911 - val_loss: 1.7273 - val_accuracy: 0.3237\n",
            "Epoch 595/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0883 - accuracy: 0.4893 - val_loss: 1.7168 - val_accuracy: 0.3266\n",
            "Epoch 596/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0815 - accuracy: 0.4912 - val_loss: 1.7252 - val_accuracy: 0.3258\n",
            "Epoch 597/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0877 - accuracy: 0.4879 - val_loss: 1.7207 - val_accuracy: 0.3240\n",
            "Epoch 598/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0906 - accuracy: 0.4873 - val_loss: 1.7048 - val_accuracy: 0.3236\n",
            "Epoch 599/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0866 - accuracy: 0.4895 - val_loss: 1.7229 - val_accuracy: 0.3235\n",
            "Epoch 600/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0779 - accuracy: 0.4949 - val_loss: 1.7188 - val_accuracy: 0.3204\n",
            "Epoch 601/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0707 - accuracy: 0.4991 - val_loss: 1.7264 - val_accuracy: 0.3257\n",
            "Epoch 602/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0687 - accuracy: 0.4999 - val_loss: 1.7292 - val_accuracy: 0.3188\n",
            "Epoch 603/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0750 - accuracy: 0.4951 - val_loss: 1.7318 - val_accuracy: 0.3241\n",
            "Epoch 604/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0663 - accuracy: 0.5007 - val_loss: 1.7420 - val_accuracy: 0.3225\n",
            "Epoch 605/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0627 - accuracy: 0.5027 - val_loss: 1.7407 - val_accuracy: 0.3235\n",
            "Epoch 606/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0638 - accuracy: 0.5003 - val_loss: 1.7417 - val_accuracy: 0.3201\n",
            "Epoch 607/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0696 - accuracy: 0.4978 - val_loss: 1.7371 - val_accuracy: 0.3216\n",
            "Epoch 608/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0735 - accuracy: 0.4952 - val_loss: 1.7252 - val_accuracy: 0.3266\n",
            "Epoch 609/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0884 - accuracy: 0.4886 - val_loss: 1.7252 - val_accuracy: 0.3225\n",
            "Epoch 610/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0873 - accuracy: 0.4890 - val_loss: 1.7162 - val_accuracy: 0.3231\n",
            "Epoch 611/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0817 - accuracy: 0.4924 - val_loss: 1.7240 - val_accuracy: 0.3203\n",
            "Epoch 612/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0776 - accuracy: 0.4922 - val_loss: 1.7292 - val_accuracy: 0.3221\n",
            "Epoch 613/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0773 - accuracy: 0.4955 - val_loss: 1.7277 - val_accuracy: 0.3255\n",
            "Epoch 614/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0750 - accuracy: 0.4951 - val_loss: 1.7287 - val_accuracy: 0.3210\n",
            "Epoch 615/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0691 - accuracy: 0.4976 - val_loss: 1.7329 - val_accuracy: 0.3218\n",
            "Epoch 616/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0648 - accuracy: 0.5004 - val_loss: 1.7494 - val_accuracy: 0.3213\n",
            "Epoch 617/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0661 - accuracy: 0.4992 - val_loss: 1.7463 - val_accuracy: 0.3230\n",
            "Epoch 618/3000\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 1.0679 - accuracy: 0.4984 - val_loss: 1.7462 - val_accuracy: 0.3212\n",
            "Epoch 619/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0661 - accuracy: 0.4991 - val_loss: 1.7467 - val_accuracy: 0.3221\n",
            "Epoch 620/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0650 - accuracy: 0.4996 - val_loss: 1.7506 - val_accuracy: 0.3245\n",
            "Epoch 621/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0591 - accuracy: 0.5051 - val_loss: 1.7451 - val_accuracy: 0.3221\n",
            "Epoch 622/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0650 - accuracy: 0.5006 - val_loss: 1.7520 - val_accuracy: 0.3190\n",
            "Epoch 623/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0577 - accuracy: 0.5056 - val_loss: 1.7539 - val_accuracy: 0.3234\n",
            "Epoch 624/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0546 - accuracy: 0.5059 - val_loss: 1.7655 - val_accuracy: 0.3200\n",
            "Epoch 625/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0540 - accuracy: 0.5073 - val_loss: 1.7580 - val_accuracy: 0.3221\n",
            "Epoch 626/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0549 - accuracy: 0.5058 - val_loss: 1.7600 - val_accuracy: 0.3197\n",
            "Epoch 627/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0660 - accuracy: 0.4995 - val_loss: 1.7512 - val_accuracy: 0.3217\n",
            "Epoch 628/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0731 - accuracy: 0.4966 - val_loss: 1.7417 - val_accuracy: 0.3215\n",
            "Epoch 629/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0675 - accuracy: 0.4992 - val_loss: 1.7659 - val_accuracy: 0.3232\n",
            "Epoch 630/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0593 - accuracy: 0.5040 - val_loss: 1.7474 - val_accuracy: 0.3204\n",
            "Epoch 631/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0652 - accuracy: 0.5006 - val_loss: 1.7623 - val_accuracy: 0.3183\n",
            "Epoch 632/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0854 - accuracy: 0.4909 - val_loss: 1.7464 - val_accuracy: 0.3215\n",
            "Epoch 633/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1011 - accuracy: 0.4821 - val_loss: 1.7318 - val_accuracy: 0.3219\n",
            "Epoch 634/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0997 - accuracy: 0.4823 - val_loss: 1.7371 - val_accuracy: 0.3194\n",
            "Epoch 635/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0800 - accuracy: 0.4930 - val_loss: 1.7377 - val_accuracy: 0.3249\n",
            "Epoch 636/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0672 - accuracy: 0.5004 - val_loss: 1.7355 - val_accuracy: 0.3215\n",
            "Epoch 637/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0566 - accuracy: 0.5051 - val_loss: 1.7568 - val_accuracy: 0.3222\n",
            "Epoch 638/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0500 - accuracy: 0.5094 - val_loss: 1.7589 - val_accuracy: 0.3273\n",
            "Epoch 639/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0518 - accuracy: 0.5081 - val_loss: 1.7549 - val_accuracy: 0.3241\n",
            "Epoch 640/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0549 - accuracy: 0.5059 - val_loss: 1.7658 - val_accuracy: 0.3224\n",
            "Epoch 641/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0516 - accuracy: 0.5077 - val_loss: 1.7660 - val_accuracy: 0.3211\n",
            "Epoch 642/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0602 - accuracy: 0.5022 - val_loss: 1.7702 - val_accuracy: 0.3178\n",
            "Epoch 643/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0753 - accuracy: 0.4949 - val_loss: 1.7520 - val_accuracy: 0.3227\n",
            "Epoch 644/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0705 - accuracy: 0.4982 - val_loss: 1.7530 - val_accuracy: 0.3228\n",
            "Epoch 645/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0649 - accuracy: 0.5026 - val_loss: 1.7538 - val_accuracy: 0.3227\n",
            "Epoch 646/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0554 - accuracy: 0.5061 - val_loss: 1.7623 - val_accuracy: 0.3270\n",
            "Epoch 647/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0592 - accuracy: 0.5062 - val_loss: 1.7461 - val_accuracy: 0.3218\n",
            "Epoch 648/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0698 - accuracy: 0.4974 - val_loss: 1.7578 - val_accuracy: 0.3241\n",
            "Epoch 649/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0784 - accuracy: 0.4943 - val_loss: 1.7490 - val_accuracy: 0.3198\n",
            "Epoch 650/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0831 - accuracy: 0.4915 - val_loss: 1.7493 - val_accuracy: 0.3258\n",
            "Epoch 651/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0725 - accuracy: 0.4963 - val_loss: 1.7474 - val_accuracy: 0.3210\n",
            "Epoch 652/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0643 - accuracy: 0.5012 - val_loss: 1.7510 - val_accuracy: 0.3235\n",
            "Epoch 653/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0602 - accuracy: 0.5045 - val_loss: 1.7574 - val_accuracy: 0.3237\n",
            "Epoch 654/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0554 - accuracy: 0.5060 - val_loss: 1.7565 - val_accuracy: 0.3223\n",
            "Epoch 655/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0560 - accuracy: 0.5052 - val_loss: 1.7606 - val_accuracy: 0.3196\n",
            "Epoch 656/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0505 - accuracy: 0.5069 - val_loss: 1.7628 - val_accuracy: 0.3227\n",
            "Epoch 657/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0570 - accuracy: 0.5055 - val_loss: 1.7578 - val_accuracy: 0.3251\n",
            "Epoch 658/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0513 - accuracy: 0.5070 - val_loss: 1.7615 - val_accuracy: 0.3222\n",
            "Epoch 659/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0518 - accuracy: 0.5071 - val_loss: 1.7699 - val_accuracy: 0.3204\n",
            "Epoch 660/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0459 - accuracy: 0.5097 - val_loss: 1.7564 - val_accuracy: 0.3216\n",
            "Epoch 661/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0608 - accuracy: 0.5020 - val_loss: 1.7734 - val_accuracy: 0.3190\n",
            "Epoch 662/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0601 - accuracy: 0.5031 - val_loss: 1.7577 - val_accuracy: 0.3243\n",
            "Epoch 663/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0585 - accuracy: 0.5043 - val_loss: 1.7658 - val_accuracy: 0.3246\n",
            "Epoch 664/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0593 - accuracy: 0.5025 - val_loss: 1.7666 - val_accuracy: 0.3275\n",
            "Epoch 665/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0583 - accuracy: 0.5041 - val_loss: 1.7702 - val_accuracy: 0.3264\n",
            "Epoch 666/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0550 - accuracy: 0.5049 - val_loss: 1.7668 - val_accuracy: 0.3231\n",
            "Epoch 667/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0632 - accuracy: 0.5009 - val_loss: 1.7513 - val_accuracy: 0.3267\n",
            "Epoch 668/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0708 - accuracy: 0.4987 - val_loss: 1.7598 - val_accuracy: 0.3271\n",
            "Epoch 669/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0648 - accuracy: 0.5000 - val_loss: 1.7683 - val_accuracy: 0.3223\n",
            "Epoch 670/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0613 - accuracy: 0.5022 - val_loss: 1.7679 - val_accuracy: 0.3244\n",
            "Epoch 671/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0599 - accuracy: 0.5033 - val_loss: 1.7682 - val_accuracy: 0.3233\n",
            "Epoch 672/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0609 - accuracy: 0.5034 - val_loss: 1.7807 - val_accuracy: 0.3250\n",
            "Epoch 673/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0448 - accuracy: 0.5129 - val_loss: 1.7783 - val_accuracy: 0.3238\n",
            "Epoch 674/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0370 - accuracy: 0.5167 - val_loss: 1.7742 - val_accuracy: 0.3242\n",
            "Epoch 675/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0302 - accuracy: 0.5199 - val_loss: 1.7850 - val_accuracy: 0.3226\n",
            "Epoch 676/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0426 - accuracy: 0.5127 - val_loss: 1.7878 - val_accuracy: 0.3225\n",
            "Epoch 677/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0518 - accuracy: 0.5075 - val_loss: 1.7780 - val_accuracy: 0.3246\n",
            "Epoch 678/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0622 - accuracy: 0.5025 - val_loss: 1.7735 - val_accuracy: 0.3240\n",
            "Epoch 679/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0608 - accuracy: 0.5035 - val_loss: 1.7800 - val_accuracy: 0.3271\n",
            "Epoch 680/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0619 - accuracy: 0.5031 - val_loss: 1.7908 - val_accuracy: 0.3209\n",
            "Epoch 681/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0616 - accuracy: 0.5027 - val_loss: 1.7773 - val_accuracy: 0.3210\n",
            "Epoch 682/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0607 - accuracy: 0.5021 - val_loss: 1.7697 - val_accuracy: 0.3223\n",
            "Epoch 683/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0598 - accuracy: 0.5020 - val_loss: 1.7891 - val_accuracy: 0.3238\n",
            "Epoch 684/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0543 - accuracy: 0.5061 - val_loss: 1.7719 - val_accuracy: 0.3229\n",
            "Epoch 685/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0608 - accuracy: 0.5025 - val_loss: 1.7698 - val_accuracy: 0.3230\n",
            "Epoch 686/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0603 - accuracy: 0.5043 - val_loss: 1.7916 - val_accuracy: 0.3218\n",
            "Epoch 687/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0560 - accuracy: 0.5044 - val_loss: 1.7695 - val_accuracy: 0.3230\n",
            "Epoch 688/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0611 - accuracy: 0.5028 - val_loss: 1.7898 - val_accuracy: 0.3205\n",
            "Epoch 689/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0540 - accuracy: 0.5069 - val_loss: 1.7811 - val_accuracy: 0.3221\n",
            "Epoch 690/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0506 - accuracy: 0.5088 - val_loss: 1.7852 - val_accuracy: 0.3218\n",
            "Epoch 691/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0439 - accuracy: 0.5120 - val_loss: 1.7818 - val_accuracy: 0.3198\n",
            "Epoch 692/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0496 - accuracy: 0.5089 - val_loss: 1.8027 - val_accuracy: 0.3190\n",
            "Epoch 693/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0485 - accuracy: 0.5109 - val_loss: 1.7882 - val_accuracy: 0.3227\n",
            "Epoch 694/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0553 - accuracy: 0.5063 - val_loss: 1.7918 - val_accuracy: 0.3218\n",
            "Epoch 695/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0500 - accuracy: 0.5102 - val_loss: 1.7738 - val_accuracy: 0.3213\n",
            "Epoch 696/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0495 - accuracy: 0.5082 - val_loss: 1.7880 - val_accuracy: 0.3192\n",
            "Epoch 697/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0481 - accuracy: 0.5110 - val_loss: 1.7882 - val_accuracy: 0.3237\n",
            "Epoch 698/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0493 - accuracy: 0.5094 - val_loss: 1.7778 - val_accuracy: 0.3245\n",
            "Epoch 699/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0496 - accuracy: 0.5099 - val_loss: 1.7847 - val_accuracy: 0.3253\n",
            "Epoch 700/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0462 - accuracy: 0.5112 - val_loss: 1.7935 - val_accuracy: 0.3207\n",
            "Epoch 701/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0511 - accuracy: 0.5085 - val_loss: 1.7910 - val_accuracy: 0.3219\n",
            "Epoch 702/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0536 - accuracy: 0.5060 - val_loss: 1.8006 - val_accuracy: 0.3202\n",
            "Epoch 703/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0540 - accuracy: 0.5074 - val_loss: 1.7849 - val_accuracy: 0.3243\n",
            "Epoch 704/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0500 - accuracy: 0.5089 - val_loss: 1.7930 - val_accuracy: 0.3230\n",
            "Epoch 705/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0517 - accuracy: 0.5074 - val_loss: 1.7851 - val_accuracy: 0.3230\n",
            "Epoch 706/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0437 - accuracy: 0.5121 - val_loss: 1.8060 - val_accuracy: 0.3231\n",
            "Epoch 707/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0388 - accuracy: 0.5146 - val_loss: 1.8000 - val_accuracy: 0.3209\n",
            "Epoch 708/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0482 - accuracy: 0.5125 - val_loss: 1.8090 - val_accuracy: 0.3221\n",
            "Epoch 709/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0605 - accuracy: 0.5030 - val_loss: 1.7919 - val_accuracy: 0.3228\n",
            "Epoch 710/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0584 - accuracy: 0.5050 - val_loss: 1.7968 - val_accuracy: 0.3201\n",
            "Epoch 711/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0590 - accuracy: 0.5039 - val_loss: 1.7885 - val_accuracy: 0.3245\n",
            "Epoch 712/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0724 - accuracy: 0.4971 - val_loss: 1.7873 - val_accuracy: 0.3212\n",
            "Epoch 713/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0741 - accuracy: 0.4962 - val_loss: 1.7962 - val_accuracy: 0.3227\n",
            "Epoch 714/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1033 - accuracy: 0.4865 - val_loss: 1.7592 - val_accuracy: 0.3241\n",
            "Epoch 715/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1060 - accuracy: 0.4845 - val_loss: 1.7540 - val_accuracy: 0.3237\n",
            "Epoch 716/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0787 - accuracy: 0.4951 - val_loss: 1.7461 - val_accuracy: 0.3248\n",
            "Epoch 717/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0600 - accuracy: 0.5040 - val_loss: 1.7801 - val_accuracy: 0.3255\n",
            "Epoch 718/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0491 - accuracy: 0.5110 - val_loss: 1.7802 - val_accuracy: 0.3218\n",
            "Epoch 719/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0414 - accuracy: 0.5129 - val_loss: 1.7782 - val_accuracy: 0.3269\n",
            "Epoch 720/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0386 - accuracy: 0.5149 - val_loss: 1.8043 - val_accuracy: 0.3228\n",
            "Epoch 721/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0494 - accuracy: 0.5102 - val_loss: 1.7767 - val_accuracy: 0.3197\n",
            "Epoch 722/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0561 - accuracy: 0.5051 - val_loss: 1.7868 - val_accuracy: 0.3178\n",
            "Epoch 723/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0576 - accuracy: 0.5055 - val_loss: 1.7779 - val_accuracy: 0.3244\n",
            "Epoch 724/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0553 - accuracy: 0.5058 - val_loss: 1.8119 - val_accuracy: 0.3195\n",
            "Epoch 725/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0508 - accuracy: 0.5077 - val_loss: 1.7776 - val_accuracy: 0.3245\n",
            "Epoch 726/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0411 - accuracy: 0.5132 - val_loss: 1.7986 - val_accuracy: 0.3204\n",
            "Epoch 727/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0357 - accuracy: 0.5160 - val_loss: 1.8111 - val_accuracy: 0.3254\n",
            "Epoch 728/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0361 - accuracy: 0.5170 - val_loss: 1.8106 - val_accuracy: 0.3190\n",
            "Epoch 729/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0368 - accuracy: 0.5145 - val_loss: 1.8167 - val_accuracy: 0.3187\n",
            "Epoch 730/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0344 - accuracy: 0.5159 - val_loss: 1.8050 - val_accuracy: 0.3251\n",
            "Epoch 731/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0468 - accuracy: 0.5116 - val_loss: 1.8173 - val_accuracy: 0.3256\n",
            "Epoch 732/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0446 - accuracy: 0.5106 - val_loss: 1.8164 - val_accuracy: 0.3230\n",
            "Epoch 733/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0535 - accuracy: 0.5078 - val_loss: 1.7915 - val_accuracy: 0.3240\n",
            "Epoch 734/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0561 - accuracy: 0.5052 - val_loss: 1.8240 - val_accuracy: 0.3215\n",
            "Epoch 735/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0479 - accuracy: 0.5096 - val_loss: 1.7992 - val_accuracy: 0.3193\n",
            "Epoch 736/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0447 - accuracy: 0.5113 - val_loss: 1.8094 - val_accuracy: 0.3218\n",
            "Epoch 737/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0529 - accuracy: 0.5055 - val_loss: 1.8028 - val_accuracy: 0.3195\n",
            "Epoch 738/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0577 - accuracy: 0.5052 - val_loss: 1.8142 - val_accuracy: 0.3227\n",
            "Epoch 739/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0562 - accuracy: 0.5085 - val_loss: 1.8002 - val_accuracy: 0.3197\n",
            "Epoch 740/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0458 - accuracy: 0.5122 - val_loss: 1.8124 - val_accuracy: 0.3205\n",
            "Epoch 741/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0368 - accuracy: 0.5151 - val_loss: 1.8167 - val_accuracy: 0.3196\n",
            "Epoch 742/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0454 - accuracy: 0.5120 - val_loss: 1.8122 - val_accuracy: 0.3233\n",
            "Epoch 743/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0588 - accuracy: 0.5054 - val_loss: 1.7967 - val_accuracy: 0.3261\n",
            "Epoch 744/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0534 - accuracy: 0.5070 - val_loss: 1.8045 - val_accuracy: 0.3222\n",
            "Epoch 745/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0427 - accuracy: 0.5134 - val_loss: 1.7983 - val_accuracy: 0.3263\n",
            "Epoch 746/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0358 - accuracy: 0.5163 - val_loss: 1.8169 - val_accuracy: 0.3245\n",
            "Epoch 747/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0411 - accuracy: 0.5145 - val_loss: 1.8010 - val_accuracy: 0.3246\n",
            "Epoch 748/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0436 - accuracy: 0.5121 - val_loss: 1.8112 - val_accuracy: 0.3255\n",
            "Epoch 749/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0434 - accuracy: 0.5118 - val_loss: 1.7938 - val_accuracy: 0.3204\n",
            "Epoch 750/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0450 - accuracy: 0.5119 - val_loss: 1.8201 - val_accuracy: 0.3212\n",
            "Epoch 751/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0438 - accuracy: 0.5138 - val_loss: 1.7932 - val_accuracy: 0.3239\n",
            "Epoch 752/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0403 - accuracy: 0.5136 - val_loss: 1.8232 - val_accuracy: 0.3221\n",
            "Epoch 753/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0520 - accuracy: 0.5100 - val_loss: 1.8106 - val_accuracy: 0.3240\n",
            "Epoch 754/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0547 - accuracy: 0.5072 - val_loss: 1.8094 - val_accuracy: 0.3259\n",
            "Epoch 755/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0561 - accuracy: 0.5045 - val_loss: 1.8129 - val_accuracy: 0.3228\n",
            "Epoch 756/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0415 - accuracy: 0.5141 - val_loss: 1.8177 - val_accuracy: 0.3234\n",
            "Epoch 757/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0385 - accuracy: 0.5161 - val_loss: 1.8199 - val_accuracy: 0.3221\n",
            "Epoch 758/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0424 - accuracy: 0.5134 - val_loss: 1.8190 - val_accuracy: 0.3210\n",
            "Epoch 759/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0442 - accuracy: 0.5118 - val_loss: 1.8059 - val_accuracy: 0.3272\n",
            "Epoch 760/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0527 - accuracy: 0.5082 - val_loss: 1.8071 - val_accuracy: 0.3219\n",
            "Epoch 761/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0502 - accuracy: 0.5109 - val_loss: 1.8114 - val_accuracy: 0.3230\n",
            "Epoch 762/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0434 - accuracy: 0.5138 - val_loss: 1.8099 - val_accuracy: 0.3200\n",
            "Epoch 763/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0397 - accuracy: 0.5154 - val_loss: 1.8071 - val_accuracy: 0.3203\n",
            "Epoch 764/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0335 - accuracy: 0.5186 - val_loss: 1.8250 - val_accuracy: 0.3208\n",
            "Epoch 765/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0313 - accuracy: 0.5192 - val_loss: 1.8266 - val_accuracy: 0.3171\n",
            "Epoch 766/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0296 - accuracy: 0.5184 - val_loss: 1.8236 - val_accuracy: 0.3178\n",
            "Epoch 767/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0283 - accuracy: 0.5210 - val_loss: 1.8392 - val_accuracy: 0.3210\n",
            "Epoch 768/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0363 - accuracy: 0.5159 - val_loss: 1.8263 - val_accuracy: 0.3220\n",
            "Epoch 769/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0366 - accuracy: 0.5165 - val_loss: 1.8566 - val_accuracy: 0.3172\n",
            "Epoch 770/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0337 - accuracy: 0.5171 - val_loss: 1.8320 - val_accuracy: 0.3213\n",
            "Epoch 771/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0477 - accuracy: 0.5086 - val_loss: 1.8180 - val_accuracy: 0.3211\n",
            "Epoch 772/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0502 - accuracy: 0.5096 - val_loss: 1.8526 - val_accuracy: 0.3197\n",
            "Epoch 773/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0544 - accuracy: 0.5063 - val_loss: 1.8159 - val_accuracy: 0.3229\n",
            "Epoch 774/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0771 - accuracy: 0.4975 - val_loss: 1.8284 - val_accuracy: 0.3219\n",
            "Epoch 775/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0690 - accuracy: 0.4983 - val_loss: 1.8197 - val_accuracy: 0.3240\n",
            "Epoch 776/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0571 - accuracy: 0.5054 - val_loss: 1.8304 - val_accuracy: 0.3218\n",
            "Epoch 777/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0492 - accuracy: 0.5095 - val_loss: 1.8141 - val_accuracy: 0.3235\n",
            "Epoch 778/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0525 - accuracy: 0.5068 - val_loss: 1.8204 - val_accuracy: 0.3217\n",
            "Epoch 779/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0476 - accuracy: 0.5107 - val_loss: 1.8176 - val_accuracy: 0.3191\n",
            "Epoch 780/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0404 - accuracy: 0.5145 - val_loss: 1.8276 - val_accuracy: 0.3248\n",
            "Epoch 781/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0414 - accuracy: 0.5137 - val_loss: 1.8303 - val_accuracy: 0.3231\n",
            "Epoch 782/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0544 - accuracy: 0.5068 - val_loss: 1.8306 - val_accuracy: 0.3234\n",
            "Epoch 783/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0471 - accuracy: 0.5118 - val_loss: 1.8240 - val_accuracy: 0.3218\n",
            "Epoch 784/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0486 - accuracy: 0.5115 - val_loss: 1.8357 - val_accuracy: 0.3218\n",
            "Epoch 785/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0396 - accuracy: 0.5156 - val_loss: 1.8249 - val_accuracy: 0.3261\n",
            "Epoch 786/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0320 - accuracy: 0.5199 - val_loss: 1.8317 - val_accuracy: 0.3230\n",
            "Epoch 787/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0245 - accuracy: 0.5243 - val_loss: 1.8557 - val_accuracy: 0.3195\n",
            "Epoch 788/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0197 - accuracy: 0.5266 - val_loss: 1.8435 - val_accuracy: 0.3206\n",
            "Epoch 789/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0220 - accuracy: 0.5244 - val_loss: 1.8437 - val_accuracy: 0.3219\n",
            "Epoch 790/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0320 - accuracy: 0.5190 - val_loss: 1.8406 - val_accuracy: 0.3213\n",
            "Epoch 791/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0351 - accuracy: 0.5167 - val_loss: 1.8523 - val_accuracy: 0.3222\n",
            "Epoch 792/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0367 - accuracy: 0.5167 - val_loss: 1.8460 - val_accuracy: 0.3196\n",
            "Epoch 793/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0382 - accuracy: 0.5180 - val_loss: 1.8627 - val_accuracy: 0.3193\n",
            "Epoch 794/3000\n",
            "16/16 [==============================] - 1s 31ms/step - loss: 1.0317 - accuracy: 0.5200 - val_loss: 1.8416 - val_accuracy: 0.3189\n",
            "Epoch 795/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0356 - accuracy: 0.5160 - val_loss: 1.8545 - val_accuracy: 0.3222\n",
            "Epoch 796/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0309 - accuracy: 0.5187 - val_loss: 1.8400 - val_accuracy: 0.3171\n",
            "Epoch 797/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0320 - accuracy: 0.5197 - val_loss: 1.8644 - val_accuracy: 0.3217\n",
            "Epoch 798/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0452 - accuracy: 0.5135 - val_loss: 1.8416 - val_accuracy: 0.3208\n",
            "Epoch 799/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0455 - accuracy: 0.5119 - val_loss: 1.8363 - val_accuracy: 0.3179\n",
            "Epoch 800/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0543 - accuracy: 0.5093 - val_loss: 1.8388 - val_accuracy: 0.3242\n",
            "Epoch 801/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0509 - accuracy: 0.5102 - val_loss: 1.8580 - val_accuracy: 0.3201\n",
            "Epoch 802/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0536 - accuracy: 0.5085 - val_loss: 1.8262 - val_accuracy: 0.3191\n",
            "Epoch 803/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0442 - accuracy: 0.5126 - val_loss: 1.8576 - val_accuracy: 0.3254\n",
            "Epoch 804/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0597 - accuracy: 0.5055 - val_loss: 1.8240 - val_accuracy: 0.3219\n",
            "Epoch 805/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0650 - accuracy: 0.5039 - val_loss: 1.8306 - val_accuracy: 0.3171\n",
            "Epoch 806/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0527 - accuracy: 0.5083 - val_loss: 1.8371 - val_accuracy: 0.3216\n",
            "Epoch 807/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0460 - accuracy: 0.5124 - val_loss: 1.8227 - val_accuracy: 0.3218\n",
            "Epoch 808/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0507 - accuracy: 0.5107 - val_loss: 1.8379 - val_accuracy: 0.3187\n",
            "Epoch 809/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0394 - accuracy: 0.5161 - val_loss: 1.8320 - val_accuracy: 0.3186\n",
            "Epoch 810/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0359 - accuracy: 0.5173 - val_loss: 1.8354 - val_accuracy: 0.3201\n",
            "Epoch 811/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0297 - accuracy: 0.5193 - val_loss: 1.8369 - val_accuracy: 0.3188\n",
            "Epoch 812/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0246 - accuracy: 0.5229 - val_loss: 1.8478 - val_accuracy: 0.3196\n",
            "Epoch 813/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0241 - accuracy: 0.5238 - val_loss: 1.8399 - val_accuracy: 0.3192\n",
            "Epoch 814/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0293 - accuracy: 0.5202 - val_loss: 1.8413 - val_accuracy: 0.3177\n",
            "Epoch 815/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0420 - accuracy: 0.5138 - val_loss: 1.8426 - val_accuracy: 0.3199\n",
            "Epoch 816/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0509 - accuracy: 0.5095 - val_loss: 1.8433 - val_accuracy: 0.3169\n",
            "Epoch 817/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0524 - accuracy: 0.5089 - val_loss: 1.8319 - val_accuracy: 0.3200\n",
            "Epoch 818/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0549 - accuracy: 0.5075 - val_loss: 1.8307 - val_accuracy: 0.3239\n",
            "Epoch 819/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0429 - accuracy: 0.5128 - val_loss: 1.8360 - val_accuracy: 0.3190\n",
            "Epoch 820/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0369 - accuracy: 0.5156 - val_loss: 1.8368 - val_accuracy: 0.3233\n",
            "Epoch 821/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0345 - accuracy: 0.5187 - val_loss: 1.8349 - val_accuracy: 0.3210\n",
            "Epoch 822/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0323 - accuracy: 0.5180 - val_loss: 1.8446 - val_accuracy: 0.3211\n",
            "Epoch 823/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0347 - accuracy: 0.5187 - val_loss: 1.8371 - val_accuracy: 0.3189\n",
            "Epoch 824/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0389 - accuracy: 0.5139 - val_loss: 1.8442 - val_accuracy: 0.3169\n",
            "Epoch 825/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0359 - accuracy: 0.5167 - val_loss: 1.8531 - val_accuracy: 0.3208\n",
            "Epoch 826/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0451 - accuracy: 0.5120 - val_loss: 1.8384 - val_accuracy: 0.3187\n",
            "Epoch 827/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0501 - accuracy: 0.5091 - val_loss: 1.8418 - val_accuracy: 0.3199\n",
            "Epoch 828/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0505 - accuracy: 0.5097 - val_loss: 1.8321 - val_accuracy: 0.3187\n",
            "Epoch 829/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0441 - accuracy: 0.5138 - val_loss: 1.8430 - val_accuracy: 0.3218\n",
            "Epoch 830/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0401 - accuracy: 0.5153 - val_loss: 1.8404 - val_accuracy: 0.3148\n",
            "Epoch 831/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0364 - accuracy: 0.5160 - val_loss: 1.8422 - val_accuracy: 0.3211\n",
            "Epoch 832/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0230 - accuracy: 0.5242 - val_loss: 1.8495 - val_accuracy: 0.3219\n",
            "Epoch 833/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0276 - accuracy: 0.5217 - val_loss: 1.8690 - val_accuracy: 0.3196\n",
            "Epoch 834/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0292 - accuracy: 0.5218 - val_loss: 1.8324 - val_accuracy: 0.3184\n",
            "Epoch 835/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0301 - accuracy: 0.5187 - val_loss: 1.8719 - val_accuracy: 0.3187\n",
            "Epoch 836/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0337 - accuracy: 0.5189 - val_loss: 1.8555 - val_accuracy: 0.3211\n",
            "Epoch 837/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0318 - accuracy: 0.5191 - val_loss: 1.8621 - val_accuracy: 0.3214\n",
            "Epoch 838/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0325 - accuracy: 0.5190 - val_loss: 1.8580 - val_accuracy: 0.3175\n",
            "Epoch 839/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0355 - accuracy: 0.5168 - val_loss: 1.8462 - val_accuracy: 0.3190\n",
            "Epoch 840/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0420 - accuracy: 0.5147 - val_loss: 1.8545 - val_accuracy: 0.3225\n",
            "Epoch 841/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0344 - accuracy: 0.5183 - val_loss: 1.8443 - val_accuracy: 0.3228\n",
            "Epoch 842/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0393 - accuracy: 0.5153 - val_loss: 1.8482 - val_accuracy: 0.3230\n",
            "Epoch 843/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0406 - accuracy: 0.5149 - val_loss: 1.8516 - val_accuracy: 0.3218\n",
            "Epoch 844/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0298 - accuracy: 0.5189 - val_loss: 1.8524 - val_accuracy: 0.3212\n",
            "Epoch 845/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0269 - accuracy: 0.5211 - val_loss: 1.8509 - val_accuracy: 0.3167\n",
            "Epoch 846/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0399 - accuracy: 0.5156 - val_loss: 1.8422 - val_accuracy: 0.3219\n",
            "Epoch 847/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0321 - accuracy: 0.5170 - val_loss: 1.8489 - val_accuracy: 0.3232\n",
            "Epoch 848/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0279 - accuracy: 0.5211 - val_loss: 1.8506 - val_accuracy: 0.3236\n",
            "Epoch 849/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0290 - accuracy: 0.5210 - val_loss: 1.8559 - val_accuracy: 0.3246\n",
            "Epoch 850/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0285 - accuracy: 0.5190 - val_loss: 1.8524 - val_accuracy: 0.3210\n",
            "Epoch 851/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0331 - accuracy: 0.5181 - val_loss: 1.8549 - val_accuracy: 0.3211\n",
            "Epoch 852/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0411 - accuracy: 0.5134 - val_loss: 1.8486 - val_accuracy: 0.3233\n",
            "Epoch 853/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0564 - accuracy: 0.5063 - val_loss: 1.8488 - val_accuracy: 0.3237\n",
            "Epoch 854/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0477 - accuracy: 0.5103 - val_loss: 1.8555 - val_accuracy: 0.3204\n",
            "Epoch 855/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0349 - accuracy: 0.5171 - val_loss: 1.8702 - val_accuracy: 0.3218\n",
            "Epoch 856/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0283 - accuracy: 0.5208 - val_loss: 1.8669 - val_accuracy: 0.3175\n",
            "Epoch 857/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0310 - accuracy: 0.5197 - val_loss: 1.8664 - val_accuracy: 0.3189\n",
            "Epoch 858/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0237 - accuracy: 0.5228 - val_loss: 1.8678 - val_accuracy: 0.3200\n",
            "Epoch 859/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0317 - accuracy: 0.5178 - val_loss: 1.8583 - val_accuracy: 0.3201\n",
            "Epoch 860/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0390 - accuracy: 0.5144 - val_loss: 1.8629 - val_accuracy: 0.3201\n",
            "Epoch 861/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0408 - accuracy: 0.5143 - val_loss: 1.8579 - val_accuracy: 0.3186\n",
            "Epoch 862/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0416 - accuracy: 0.5130 - val_loss: 1.8567 - val_accuracy: 0.3212\n",
            "Epoch 863/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0338 - accuracy: 0.5175 - val_loss: 1.8635 - val_accuracy: 0.3159\n",
            "Epoch 864/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0318 - accuracy: 0.5190 - val_loss: 1.8742 - val_accuracy: 0.3178\n",
            "Epoch 865/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0416 - accuracy: 0.5140 - val_loss: 1.8594 - val_accuracy: 0.3166\n",
            "Epoch 866/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0518 - accuracy: 0.5090 - val_loss: 1.8636 - val_accuracy: 0.3189\n",
            "Epoch 867/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0322 - accuracy: 0.5185 - val_loss: 1.8506 - val_accuracy: 0.3191\n",
            "Epoch 868/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0189 - accuracy: 0.5255 - val_loss: 1.8776 - val_accuracy: 0.3183\n",
            "Epoch 869/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0118 - accuracy: 0.5298 - val_loss: 1.8784 - val_accuracy: 0.3188\n",
            "Epoch 870/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0157 - accuracy: 0.5271 - val_loss: 1.8846 - val_accuracy: 0.3176\n",
            "Epoch 871/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0236 - accuracy: 0.5233 - val_loss: 1.8788 - val_accuracy: 0.3178\n",
            "Epoch 872/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0303 - accuracy: 0.5198 - val_loss: 1.8660 - val_accuracy: 0.3175\n",
            "Epoch 873/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0367 - accuracy: 0.5174 - val_loss: 1.8707 - val_accuracy: 0.3202\n",
            "Epoch 874/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0345 - accuracy: 0.5183 - val_loss: 1.8759 - val_accuracy: 0.3224\n",
            "Epoch 875/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0330 - accuracy: 0.5186 - val_loss: 1.8760 - val_accuracy: 0.3186\n",
            "Epoch 876/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0372 - accuracy: 0.5162 - val_loss: 1.8668 - val_accuracy: 0.3171\n",
            "Epoch 877/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0372 - accuracy: 0.5170 - val_loss: 1.8777 - val_accuracy: 0.3183\n",
            "Epoch 878/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0270 - accuracy: 0.5219 - val_loss: 1.8708 - val_accuracy: 0.3170\n",
            "Epoch 879/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0288 - accuracy: 0.5207 - val_loss: 1.8758 - val_accuracy: 0.3180\n",
            "Epoch 880/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0297 - accuracy: 0.5211 - val_loss: 1.8705 - val_accuracy: 0.3170\n",
            "Epoch 881/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0377 - accuracy: 0.5152 - val_loss: 1.8604 - val_accuracy: 0.3185\n",
            "Epoch 882/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0279 - accuracy: 0.5205 - val_loss: 1.8739 - val_accuracy: 0.3171\n",
            "Epoch 883/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0181 - accuracy: 0.5259 - val_loss: 1.8877 - val_accuracy: 0.3159\n",
            "Epoch 884/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0180 - accuracy: 0.5264 - val_loss: 1.8807 - val_accuracy: 0.3156\n",
            "Epoch 885/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0208 - accuracy: 0.5244 - val_loss: 1.8880 - val_accuracy: 0.3179\n",
            "Epoch 886/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0356 - accuracy: 0.5169 - val_loss: 1.8787 - val_accuracy: 0.3160\n",
            "Epoch 887/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0395 - accuracy: 0.5141 - val_loss: 1.8871 - val_accuracy: 0.3204\n",
            "Epoch 888/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0371 - accuracy: 0.5151 - val_loss: 1.8639 - val_accuracy: 0.3208\n",
            "Epoch 889/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0438 - accuracy: 0.5134 - val_loss: 1.8587 - val_accuracy: 0.3175\n",
            "Epoch 890/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0664 - accuracy: 0.5020 - val_loss: 1.8721 - val_accuracy: 0.3143\n",
            "Epoch 891/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0678 - accuracy: 0.5022 - val_loss: 1.8649 - val_accuracy: 0.3157\n",
            "Epoch 892/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0499 - accuracy: 0.5085 - val_loss: 1.8688 - val_accuracy: 0.3199\n",
            "Epoch 893/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0409 - accuracy: 0.5139 - val_loss: 1.8691 - val_accuracy: 0.3189\n",
            "Epoch 894/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0366 - accuracy: 0.5171 - val_loss: 1.8678 - val_accuracy: 0.3165\n",
            "Epoch 895/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0244 - accuracy: 0.5241 - val_loss: 1.8660 - val_accuracy: 0.3199\n",
            "Epoch 896/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0246 - accuracy: 0.5238 - val_loss: 1.8807 - val_accuracy: 0.3158\n",
            "Epoch 897/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0227 - accuracy: 0.5222 - val_loss: 1.8862 - val_accuracy: 0.3170\n",
            "Epoch 898/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0172 - accuracy: 0.5256 - val_loss: 1.8731 - val_accuracy: 0.3181\n",
            "Epoch 899/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0122 - accuracy: 0.5287 - val_loss: 1.8913 - val_accuracy: 0.3161\n",
            "Epoch 900/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0145 - accuracy: 0.5275 - val_loss: 1.8941 - val_accuracy: 0.3174\n",
            "Epoch 901/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0143 - accuracy: 0.5287 - val_loss: 1.8915 - val_accuracy: 0.3154\n",
            "Epoch 902/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0096 - accuracy: 0.5307 - val_loss: 1.9023 - val_accuracy: 0.3222\n",
            "Epoch 903/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0139 - accuracy: 0.5284 - val_loss: 1.8971 - val_accuracy: 0.3134\n",
            "Epoch 904/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0089 - accuracy: 0.5307 - val_loss: 1.8995 - val_accuracy: 0.3170\n",
            "Epoch 905/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0047 - accuracy: 0.5330 - val_loss: 1.9176 - val_accuracy: 0.3160\n",
            "Epoch 906/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0066 - accuracy: 0.5305 - val_loss: 1.9272 - val_accuracy: 0.3202\n",
            "Epoch 907/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0197 - accuracy: 0.5259 - val_loss: 1.8846 - val_accuracy: 0.3162\n",
            "Epoch 908/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0288 - accuracy: 0.5206 - val_loss: 1.9048 - val_accuracy: 0.3167\n",
            "Epoch 909/3000\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 1.0287 - accuracy: 0.5201 - val_loss: 1.8979 - val_accuracy: 0.3168\n",
            "Epoch 910/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0295 - accuracy: 0.5196 - val_loss: 1.9009 - val_accuracy: 0.3180\n",
            "Epoch 911/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0351 - accuracy: 0.5182 - val_loss: 1.8940 - val_accuracy: 0.3174\n",
            "Epoch 912/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0381 - accuracy: 0.5143 - val_loss: 1.8907 - val_accuracy: 0.3153\n",
            "Epoch 913/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0388 - accuracy: 0.5159 - val_loss: 1.8949 - val_accuracy: 0.3162\n",
            "Epoch 914/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0464 - accuracy: 0.5131 - val_loss: 1.8867 - val_accuracy: 0.3189\n",
            "Epoch 915/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0355 - accuracy: 0.5161 - val_loss: 1.8906 - val_accuracy: 0.3186\n",
            "Epoch 916/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0234 - accuracy: 0.5229 - val_loss: 1.8856 - val_accuracy: 0.3176\n",
            "Epoch 917/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0239 - accuracy: 0.5237 - val_loss: 1.8947 - val_accuracy: 0.3160\n",
            "Epoch 918/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0189 - accuracy: 0.5250 - val_loss: 1.9036 - val_accuracy: 0.3201\n",
            "Epoch 919/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0179 - accuracy: 0.5254 - val_loss: 1.8927 - val_accuracy: 0.3192\n",
            "Epoch 920/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0153 - accuracy: 0.5283 - val_loss: 1.9036 - val_accuracy: 0.3203\n",
            "Epoch 921/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0201 - accuracy: 0.5260 - val_loss: 1.8925 - val_accuracy: 0.3156\n",
            "Epoch 922/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0208 - accuracy: 0.5256 - val_loss: 1.9030 - val_accuracy: 0.3172\n",
            "Epoch 923/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0248 - accuracy: 0.5235 - val_loss: 1.8817 - val_accuracy: 0.3176\n",
            "Epoch 924/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0242 - accuracy: 0.5227 - val_loss: 1.9091 - val_accuracy: 0.3188\n",
            "Epoch 925/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0616 - accuracy: 0.5088 - val_loss: 1.8751 - val_accuracy: 0.3171\n",
            "Epoch 926/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0663 - accuracy: 0.5026 - val_loss: 1.9016 - val_accuracy: 0.3177\n",
            "Epoch 927/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0685 - accuracy: 0.5004 - val_loss: 1.8735 - val_accuracy: 0.3186\n",
            "Epoch 928/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0516 - accuracy: 0.5100 - val_loss: 1.8920 - val_accuracy: 0.3188\n",
            "Epoch 929/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0434 - accuracy: 0.5138 - val_loss: 1.8835 - val_accuracy: 0.3205\n",
            "Epoch 930/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0287 - accuracy: 0.5196 - val_loss: 1.8783 - val_accuracy: 0.3199\n",
            "Epoch 931/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0153 - accuracy: 0.5282 - val_loss: 1.8907 - val_accuracy: 0.3166\n",
            "Epoch 932/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0106 - accuracy: 0.5306 - val_loss: 1.8932 - val_accuracy: 0.3202\n",
            "Epoch 933/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0096 - accuracy: 0.5310 - val_loss: 1.9061 - val_accuracy: 0.3236\n",
            "Epoch 934/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0154 - accuracy: 0.5271 - val_loss: 1.8857 - val_accuracy: 0.3183\n",
            "Epoch 935/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0232 - accuracy: 0.5230 - val_loss: 1.8886 - val_accuracy: 0.3198\n",
            "Epoch 936/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0260 - accuracy: 0.5218 - val_loss: 1.8931 - val_accuracy: 0.3162\n",
            "Epoch 937/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0176 - accuracy: 0.5255 - val_loss: 1.9078 - val_accuracy: 0.3172\n",
            "Epoch 938/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0178 - accuracy: 0.5278 - val_loss: 1.9142 - val_accuracy: 0.3160\n",
            "Epoch 939/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0176 - accuracy: 0.5261 - val_loss: 1.9114 - val_accuracy: 0.3197\n",
            "Epoch 940/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0196 - accuracy: 0.5261 - val_loss: 1.9058 - val_accuracy: 0.3212\n",
            "Epoch 941/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0265 - accuracy: 0.5210 - val_loss: 1.9145 - val_accuracy: 0.3181\n",
            "Epoch 942/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0202 - accuracy: 0.5247 - val_loss: 1.9145 - val_accuracy: 0.3153\n",
            "Epoch 943/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0169 - accuracy: 0.5272 - val_loss: 1.9134 - val_accuracy: 0.3147\n",
            "Epoch 944/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0155 - accuracy: 0.5267 - val_loss: 1.9074 - val_accuracy: 0.3176\n",
            "Epoch 945/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0169 - accuracy: 0.5277 - val_loss: 1.9122 - val_accuracy: 0.3179\n",
            "Epoch 946/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0158 - accuracy: 0.5281 - val_loss: 1.9033 - val_accuracy: 0.3171\n",
            "Epoch 947/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0157 - accuracy: 0.5274 - val_loss: 1.9113 - val_accuracy: 0.3188\n",
            "Epoch 948/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0133 - accuracy: 0.5274 - val_loss: 1.9095 - val_accuracy: 0.3191\n",
            "Epoch 949/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0119 - accuracy: 0.5282 - val_loss: 1.9100 - val_accuracy: 0.3162\n",
            "Epoch 950/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0181 - accuracy: 0.5256 - val_loss: 1.9089 - val_accuracy: 0.3152\n",
            "Epoch 951/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0212 - accuracy: 0.5247 - val_loss: 1.9100 - val_accuracy: 0.3206\n",
            "Epoch 952/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0195 - accuracy: 0.5238 - val_loss: 1.9138 - val_accuracy: 0.3217\n",
            "Epoch 953/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0178 - accuracy: 0.5247 - val_loss: 1.8963 - val_accuracy: 0.3225\n",
            "Epoch 954/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0171 - accuracy: 0.5266 - val_loss: 1.9268 - val_accuracy: 0.3179\n",
            "Epoch 955/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0114 - accuracy: 0.5299 - val_loss: 1.9281 - val_accuracy: 0.3178\n",
            "Epoch 956/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0251 - accuracy: 0.5229 - val_loss: 1.9032 - val_accuracy: 0.3203\n",
            "Epoch 957/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0335 - accuracy: 0.5164 - val_loss: 1.9147 - val_accuracy: 0.3202\n",
            "Epoch 958/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0248 - accuracy: 0.5217 - val_loss: 1.9233 - val_accuracy: 0.3179\n",
            "Epoch 959/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0239 - accuracy: 0.5216 - val_loss: 1.9174 - val_accuracy: 0.3147\n",
            "Epoch 960/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0229 - accuracy: 0.5233 - val_loss: 1.9259 - val_accuracy: 0.3189\n",
            "Epoch 961/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0158 - accuracy: 0.5278 - val_loss: 1.9081 - val_accuracy: 0.3209\n",
            "Epoch 962/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0091 - accuracy: 0.5319 - val_loss: 1.9356 - val_accuracy: 0.3175\n",
            "Epoch 963/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0059 - accuracy: 0.5335 - val_loss: 1.9093 - val_accuracy: 0.3199\n",
            "Epoch 964/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0072 - accuracy: 0.5312 - val_loss: 1.9165 - val_accuracy: 0.3193\n",
            "Epoch 965/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0100 - accuracy: 0.5315 - val_loss: 1.9213 - val_accuracy: 0.3177\n",
            "Epoch 966/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0136 - accuracy: 0.5277 - val_loss: 1.9227 - val_accuracy: 0.3221\n",
            "Epoch 967/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0115 - accuracy: 0.5286 - val_loss: 1.9238 - val_accuracy: 0.3219\n",
            "Epoch 968/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0097 - accuracy: 0.5298 - val_loss: 1.9088 - val_accuracy: 0.3213\n",
            "Epoch 969/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0208 - accuracy: 0.5261 - val_loss: 1.9122 - val_accuracy: 0.3184\n",
            "Epoch 970/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0275 - accuracy: 0.5214 - val_loss: 1.9185 - val_accuracy: 0.3200\n",
            "Epoch 971/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0216 - accuracy: 0.5256 - val_loss: 1.9302 - val_accuracy: 0.3180\n",
            "Epoch 972/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0235 - accuracy: 0.5228 - val_loss: 1.9009 - val_accuracy: 0.3185\n",
            "Epoch 973/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0244 - accuracy: 0.5221 - val_loss: 1.9267 - val_accuracy: 0.3215\n",
            "Epoch 974/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0162 - accuracy: 0.5268 - val_loss: 1.9218 - val_accuracy: 0.3186\n",
            "Epoch 975/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0192 - accuracy: 0.5261 - val_loss: 1.9102 - val_accuracy: 0.3211\n",
            "Epoch 976/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0170 - accuracy: 0.5277 - val_loss: 1.9335 - val_accuracy: 0.3171\n",
            "Epoch 977/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0184 - accuracy: 0.5262 - val_loss: 1.9167 - val_accuracy: 0.3169\n",
            "Epoch 978/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0246 - accuracy: 0.5220 - val_loss: 1.9222 - val_accuracy: 0.3169\n",
            "Epoch 979/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0163 - accuracy: 0.5276 - val_loss: 1.9350 - val_accuracy: 0.3181\n",
            "Epoch 980/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0183 - accuracy: 0.5251 - val_loss: 1.9076 - val_accuracy: 0.3179\n",
            "Epoch 981/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0286 - accuracy: 0.5189 - val_loss: 1.9215 - val_accuracy: 0.3118\n",
            "Epoch 982/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0324 - accuracy: 0.5184 - val_loss: 1.9182 - val_accuracy: 0.3161\n",
            "Epoch 983/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0165 - accuracy: 0.5254 - val_loss: 1.9242 - val_accuracy: 0.3179\n",
            "Epoch 984/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0112 - accuracy: 0.5293 - val_loss: 1.9197 - val_accuracy: 0.3156\n",
            "Epoch 985/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0084 - accuracy: 0.5311 - val_loss: 1.9233 - val_accuracy: 0.3159\n",
            "Epoch 986/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0045 - accuracy: 0.5327 - val_loss: 1.9305 - val_accuracy: 0.3142\n",
            "Epoch 987/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0006 - accuracy: 0.5355 - val_loss: 1.9428 - val_accuracy: 0.3147\n",
            "Epoch 988/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9984 - accuracy: 0.5372 - val_loss: 1.9363 - val_accuracy: 0.3173\n",
            "Epoch 989/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0016 - accuracy: 0.5348 - val_loss: 1.9356 - val_accuracy: 0.3163\n",
            "Epoch 990/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9975 - accuracy: 0.5363 - val_loss: 1.9339 - val_accuracy: 0.3175\n",
            "Epoch 991/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9999 - accuracy: 0.5346 - val_loss: 1.9425 - val_accuracy: 0.3174\n",
            "Epoch 992/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0118 - accuracy: 0.5296 - val_loss: 1.9365 - val_accuracy: 0.3163\n",
            "Epoch 993/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0273 - accuracy: 0.5212 - val_loss: 1.9360 - val_accuracy: 0.3170\n",
            "Epoch 994/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0193 - accuracy: 0.5239 - val_loss: 1.9279 - val_accuracy: 0.3201\n",
            "Epoch 995/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0290 - accuracy: 0.5221 - val_loss: 1.9387 - val_accuracy: 0.3184\n",
            "Epoch 996/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0209 - accuracy: 0.5250 - val_loss: 1.9356 - val_accuracy: 0.3151\n",
            "Epoch 997/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0161 - accuracy: 0.5287 - val_loss: 1.9277 - val_accuracy: 0.3156\n",
            "Epoch 998/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0223 - accuracy: 0.5227 - val_loss: 1.9445 - val_accuracy: 0.3178\n",
            "Epoch 999/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0289 - accuracy: 0.5230 - val_loss: 1.8974 - val_accuracy: 0.3185\n",
            "Epoch 1000/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0370 - accuracy: 0.5153 - val_loss: 1.9263 - val_accuracy: 0.3159\n",
            "Epoch 1001/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0277 - accuracy: 0.5206 - val_loss: 1.9192 - val_accuracy: 0.3141\n",
            "Epoch 1002/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0323 - accuracy: 0.5180 - val_loss: 1.9230 - val_accuracy: 0.3157\n",
            "Epoch 1003/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0265 - accuracy: 0.5229 - val_loss: 1.9138 - val_accuracy: 0.3159\n",
            "Epoch 1004/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0241 - accuracy: 0.5255 - val_loss: 1.9388 - val_accuracy: 0.3137\n",
            "Epoch 1005/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0277 - accuracy: 0.5206 - val_loss: 1.9261 - val_accuracy: 0.3097\n",
            "Epoch 1006/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0257 - accuracy: 0.5227 - val_loss: 1.9361 - val_accuracy: 0.3134\n",
            "Epoch 1007/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0241 - accuracy: 0.5236 - val_loss: 1.9276 - val_accuracy: 0.3166\n",
            "Epoch 1008/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0286 - accuracy: 0.5220 - val_loss: 1.9283 - val_accuracy: 0.3144\n",
            "Epoch 1009/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0293 - accuracy: 0.5202 - val_loss: 1.9166 - val_accuracy: 0.3145\n",
            "Epoch 1010/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0258 - accuracy: 0.5221 - val_loss: 1.9232 - val_accuracy: 0.3175\n",
            "Epoch 1011/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0171 - accuracy: 0.5266 - val_loss: 1.9221 - val_accuracy: 0.3208\n",
            "Epoch 1012/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0159 - accuracy: 0.5285 - val_loss: 1.9287 - val_accuracy: 0.3251\n",
            "Epoch 1013/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0151 - accuracy: 0.5270 - val_loss: 1.9355 - val_accuracy: 0.3143\n",
            "Epoch 1014/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0149 - accuracy: 0.5283 - val_loss: 1.9311 - val_accuracy: 0.3220\n",
            "Epoch 1015/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0115 - accuracy: 0.5282 - val_loss: 1.9452 - val_accuracy: 0.3209\n",
            "Epoch 1016/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0073 - accuracy: 0.5318 - val_loss: 1.9367 - val_accuracy: 0.3184\n",
            "Epoch 1017/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0085 - accuracy: 0.5304 - val_loss: 1.9486 - val_accuracy: 0.3132\n",
            "Epoch 1018/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0084 - accuracy: 0.5306 - val_loss: 1.9417 - val_accuracy: 0.3208\n",
            "Epoch 1019/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0192 - accuracy: 0.5258 - val_loss: 1.9367 - val_accuracy: 0.3168\n",
            "Epoch 1020/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0163 - accuracy: 0.5285 - val_loss: 1.9512 - val_accuracy: 0.3159\n",
            "Epoch 1021/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0312 - accuracy: 0.5218 - val_loss: 1.9290 - val_accuracy: 0.3206\n",
            "Epoch 1022/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0390 - accuracy: 0.5158 - val_loss: 1.9314 - val_accuracy: 0.3166\n",
            "Epoch 1023/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0375 - accuracy: 0.5171 - val_loss: 1.9131 - val_accuracy: 0.3147\n",
            "Epoch 1024/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0443 - accuracy: 0.5149 - val_loss: 1.9367 - val_accuracy: 0.3192\n",
            "Epoch 1025/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0694 - accuracy: 0.5062 - val_loss: 1.9145 - val_accuracy: 0.3156\n",
            "Epoch 1026/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0657 - accuracy: 0.5068 - val_loss: 1.9296 - val_accuracy: 0.3151\n",
            "Epoch 1027/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0512 - accuracy: 0.5124 - val_loss: 1.9153 - val_accuracy: 0.3154\n",
            "Epoch 1028/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0396 - accuracy: 0.5181 - val_loss: 1.9183 - val_accuracy: 0.3153\n",
            "Epoch 1029/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0323 - accuracy: 0.5199 - val_loss: 1.9140 - val_accuracy: 0.3163\n",
            "Epoch 1030/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0259 - accuracy: 0.5238 - val_loss: 1.9269 - val_accuracy: 0.3145\n",
            "Epoch 1031/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0256 - accuracy: 0.5232 - val_loss: 1.9235 - val_accuracy: 0.3205\n",
            "Epoch 1032/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0159 - accuracy: 0.5274 - val_loss: 1.9308 - val_accuracy: 0.3128\n",
            "Epoch 1033/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0088 - accuracy: 0.5306 - val_loss: 1.9374 - val_accuracy: 0.3177\n",
            "Epoch 1034/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0121 - accuracy: 0.5290 - val_loss: 1.9419 - val_accuracy: 0.3125\n",
            "Epoch 1035/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0061 - accuracy: 0.5324 - val_loss: 1.9399 - val_accuracy: 0.3172\n",
            "Epoch 1036/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0029 - accuracy: 0.5346 - val_loss: 1.9494 - val_accuracy: 0.3166\n",
            "Epoch 1037/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9976 - accuracy: 0.5389 - val_loss: 1.9433 - val_accuracy: 0.3169\n",
            "Epoch 1038/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9962 - accuracy: 0.5378 - val_loss: 1.9494 - val_accuracy: 0.3138\n",
            "Epoch 1039/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9930 - accuracy: 0.5393 - val_loss: 1.9488 - val_accuracy: 0.3146\n",
            "Epoch 1040/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9938 - accuracy: 0.5387 - val_loss: 1.9497 - val_accuracy: 0.3134\n",
            "Epoch 1041/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9936 - accuracy: 0.5404 - val_loss: 1.9541 - val_accuracy: 0.3148\n",
            "Epoch 1042/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9958 - accuracy: 0.5379 - val_loss: 1.9418 - val_accuracy: 0.3135\n",
            "Epoch 1043/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9983 - accuracy: 0.5350 - val_loss: 1.9612 - val_accuracy: 0.3128\n",
            "Epoch 1044/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0035 - accuracy: 0.5328 - val_loss: 1.9460 - val_accuracy: 0.3148\n",
            "Epoch 1045/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0076 - accuracy: 0.5303 - val_loss: 1.9564 - val_accuracy: 0.3167\n",
            "Epoch 1046/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0106 - accuracy: 0.5280 - val_loss: 1.9566 - val_accuracy: 0.3140\n",
            "Epoch 1047/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0032 - accuracy: 0.5329 - val_loss: 1.9550 - val_accuracy: 0.3113\n",
            "Epoch 1048/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9989 - accuracy: 0.5375 - val_loss: 1.9641 - val_accuracy: 0.3140\n",
            "Epoch 1049/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0090 - accuracy: 0.5317 - val_loss: 1.9543 - val_accuracy: 0.3136\n",
            "Epoch 1050/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0167 - accuracy: 0.5277 - val_loss: 1.9725 - val_accuracy: 0.3127\n",
            "Epoch 1051/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0098 - accuracy: 0.5299 - val_loss: 1.9406 - val_accuracy: 0.3156\n",
            "Epoch 1052/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0097 - accuracy: 0.5314 - val_loss: 1.9601 - val_accuracy: 0.3121\n",
            "Epoch 1053/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0046 - accuracy: 0.5316 - val_loss: 1.9645 - val_accuracy: 0.3152\n",
            "Epoch 1054/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9994 - accuracy: 0.5365 - val_loss: 1.9603 - val_accuracy: 0.3150\n",
            "Epoch 1055/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9962 - accuracy: 0.5370 - val_loss: 1.9595 - val_accuracy: 0.3157\n",
            "Epoch 1056/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0046 - accuracy: 0.5345 - val_loss: 1.9655 - val_accuracy: 0.3164\n",
            "Epoch 1057/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9944 - accuracy: 0.5377 - val_loss: 1.9664 - val_accuracy: 0.3152\n",
            "Epoch 1058/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0087 - accuracy: 0.5292 - val_loss: 1.9520 - val_accuracy: 0.3145\n",
            "Epoch 1059/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0114 - accuracy: 0.5276 - val_loss: 1.9452 - val_accuracy: 0.3159\n",
            "Epoch 1060/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0100 - accuracy: 0.5292 - val_loss: 1.9319 - val_accuracy: 0.3153\n",
            "Epoch 1061/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0144 - accuracy: 0.5291 - val_loss: 1.9644 - val_accuracy: 0.3168\n",
            "Epoch 1062/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0223 - accuracy: 0.5232 - val_loss: 1.9283 - val_accuracy: 0.3151\n",
            "Epoch 1063/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0280 - accuracy: 0.5216 - val_loss: 1.9574 - val_accuracy: 0.3135\n",
            "Epoch 1064/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0252 - accuracy: 0.5233 - val_loss: 1.9408 - val_accuracy: 0.3166\n",
            "Epoch 1065/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0098 - accuracy: 0.5307 - val_loss: 1.9486 - val_accuracy: 0.3211\n",
            "Epoch 1066/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0114 - accuracy: 0.5295 - val_loss: 1.9599 - val_accuracy: 0.3155\n",
            "Epoch 1067/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0115 - accuracy: 0.5301 - val_loss: 1.9534 - val_accuracy: 0.3160\n",
            "Epoch 1068/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0105 - accuracy: 0.5300 - val_loss: 1.9582 - val_accuracy: 0.3146\n",
            "Epoch 1069/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0075 - accuracy: 0.5309 - val_loss: 1.9534 - val_accuracy: 0.3163\n",
            "Epoch 1070/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0094 - accuracy: 0.5291 - val_loss: 1.9597 - val_accuracy: 0.3177\n",
            "Epoch 1071/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0126 - accuracy: 0.5284 - val_loss: 1.9551 - val_accuracy: 0.3156\n",
            "Epoch 1072/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0150 - accuracy: 0.5273 - val_loss: 1.9548 - val_accuracy: 0.3156\n",
            "Epoch 1073/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0102 - accuracy: 0.5306 - val_loss: 1.9625 - val_accuracy: 0.3133\n",
            "Epoch 1074/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0306 - accuracy: 0.5216 - val_loss: 1.9525 - val_accuracy: 0.3125\n",
            "Epoch 1075/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0356 - accuracy: 0.5176 - val_loss: 1.9386 - val_accuracy: 0.3169\n",
            "Epoch 1076/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0248 - accuracy: 0.5232 - val_loss: 1.9336 - val_accuracy: 0.3153\n",
            "Epoch 1077/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0209 - accuracy: 0.5235 - val_loss: 1.9409 - val_accuracy: 0.3187\n",
            "Epoch 1078/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0264 - accuracy: 0.5229 - val_loss: 1.9428 - val_accuracy: 0.3165\n",
            "Epoch 1079/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0107 - accuracy: 0.5297 - val_loss: 1.9611 - val_accuracy: 0.3140\n",
            "Epoch 1080/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9946 - accuracy: 0.5390 - val_loss: 1.9643 - val_accuracy: 0.3157\n",
            "Epoch 1081/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9962 - accuracy: 0.5359 - val_loss: 1.9612 - val_accuracy: 0.3142\n",
            "Epoch 1082/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9986 - accuracy: 0.5341 - val_loss: 1.9794 - val_accuracy: 0.3136\n",
            "Epoch 1083/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9996 - accuracy: 0.5347 - val_loss: 1.9677 - val_accuracy: 0.3122\n",
            "Epoch 1084/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0227 - accuracy: 0.5223 - val_loss: 1.9719 - val_accuracy: 0.3150\n",
            "Epoch 1085/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0430 - accuracy: 0.5133 - val_loss: 1.9346 - val_accuracy: 0.3156\n",
            "Epoch 1086/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0549 - accuracy: 0.5107 - val_loss: 1.9517 - val_accuracy: 0.3131\n",
            "Epoch 1087/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0464 - accuracy: 0.5128 - val_loss: 1.9590 - val_accuracy: 0.3177\n",
            "Epoch 1088/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0235 - accuracy: 0.5228 - val_loss: 1.9713 - val_accuracy: 0.3157\n",
            "Epoch 1089/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0137 - accuracy: 0.5285 - val_loss: 1.9583 - val_accuracy: 0.3143\n",
            "Epoch 1090/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0035 - accuracy: 0.5337 - val_loss: 1.9635 - val_accuracy: 0.3147\n",
            "Epoch 1091/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9937 - accuracy: 0.5398 - val_loss: 1.9745 - val_accuracy: 0.3163\n",
            "Epoch 1092/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9902 - accuracy: 0.5412 - val_loss: 1.9666 - val_accuracy: 0.3152\n",
            "Epoch 1093/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9894 - accuracy: 0.5407 - val_loss: 1.9789 - val_accuracy: 0.3192\n",
            "Epoch 1094/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0018 - accuracy: 0.5350 - val_loss: 1.9763 - val_accuracy: 0.3126\n",
            "Epoch 1095/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0078 - accuracy: 0.5312 - val_loss: 1.9629 - val_accuracy: 0.3141\n",
            "Epoch 1096/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0146 - accuracy: 0.5283 - val_loss: 1.9823 - val_accuracy: 0.3147\n",
            "Epoch 1097/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0109 - accuracy: 0.5294 - val_loss: 1.9570 - val_accuracy: 0.3133\n",
            "Epoch 1098/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0085 - accuracy: 0.5314 - val_loss: 1.9818 - val_accuracy: 0.3115\n",
            "Epoch 1099/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0025 - accuracy: 0.5338 - val_loss: 1.9716 - val_accuracy: 0.3150\n",
            "Epoch 1100/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9977 - accuracy: 0.5375 - val_loss: 1.9882 - val_accuracy: 0.3109\n",
            "Epoch 1101/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9946 - accuracy: 0.5384 - val_loss: 1.9826 - val_accuracy: 0.3117\n",
            "Epoch 1102/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9890 - accuracy: 0.5419 - val_loss: 1.9904 - val_accuracy: 0.3153\n",
            "Epoch 1103/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9895 - accuracy: 0.5401 - val_loss: 1.9809 - val_accuracy: 0.3175\n",
            "Epoch 1104/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9926 - accuracy: 0.5412 - val_loss: 1.9855 - val_accuracy: 0.3156\n",
            "Epoch 1105/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0024 - accuracy: 0.5340 - val_loss: 1.9859 - val_accuracy: 0.3168\n",
            "Epoch 1106/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0061 - accuracy: 0.5321 - val_loss: 1.9960 - val_accuracy: 0.3168\n",
            "Epoch 1107/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0040 - accuracy: 0.5336 - val_loss: 1.9715 - val_accuracy: 0.3154\n",
            "Epoch 1108/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0126 - accuracy: 0.5279 - val_loss: 2.0000 - val_accuracy: 0.3143\n",
            "Epoch 1109/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0155 - accuracy: 0.5261 - val_loss: 1.9727 - val_accuracy: 0.3162\n",
            "Epoch 1110/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0086 - accuracy: 0.5314 - val_loss: 1.9901 - val_accuracy: 0.3190\n",
            "Epoch 1111/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9907 - accuracy: 0.5410 - val_loss: 1.9819 - val_accuracy: 0.3134\n",
            "Epoch 1112/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9868 - accuracy: 0.5430 - val_loss: 2.0000 - val_accuracy: 0.3190\n",
            "Epoch 1113/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9874 - accuracy: 0.5417 - val_loss: 1.9940 - val_accuracy: 0.3142\n",
            "Epoch 1114/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9867 - accuracy: 0.5406 - val_loss: 2.0023 - val_accuracy: 0.3142\n",
            "Epoch 1115/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9972 - accuracy: 0.5350 - val_loss: 1.9842 - val_accuracy: 0.3142\n",
            "Epoch 1116/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9987 - accuracy: 0.5354 - val_loss: 2.0015 - val_accuracy: 0.3166\n",
            "Epoch 1117/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0045 - accuracy: 0.5326 - val_loss: 1.9799 - val_accuracy: 0.3166\n",
            "Epoch 1118/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0201 - accuracy: 0.5245 - val_loss: 1.9794 - val_accuracy: 0.3196\n",
            "Epoch 1119/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0142 - accuracy: 0.5286 - val_loss: 1.9831 - val_accuracy: 0.3186\n",
            "Epoch 1120/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0053 - accuracy: 0.5320 - val_loss: 1.9907 - val_accuracy: 0.3178\n",
            "Epoch 1121/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0022 - accuracy: 0.5340 - val_loss: 1.9922 - val_accuracy: 0.3127\n",
            "Epoch 1122/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0101 - accuracy: 0.5315 - val_loss: 2.0030 - val_accuracy: 0.3130\n",
            "Epoch 1123/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0076 - accuracy: 0.5319 - val_loss: 1.9790 - val_accuracy: 0.3215\n",
            "Epoch 1124/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0156 - accuracy: 0.5299 - val_loss: 1.9824 - val_accuracy: 0.3119\n",
            "Epoch 1125/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0042 - accuracy: 0.5330 - val_loss: 1.9950 - val_accuracy: 0.3151\n",
            "Epoch 1126/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9983 - accuracy: 0.5367 - val_loss: 1.9849 - val_accuracy: 0.3208\n",
            "Epoch 1127/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9913 - accuracy: 0.5388 - val_loss: 1.9961 - val_accuracy: 0.3167\n",
            "Epoch 1128/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9880 - accuracy: 0.5417 - val_loss: 2.0043 - val_accuracy: 0.3111\n",
            "Epoch 1129/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9996 - accuracy: 0.5354 - val_loss: 2.0088 - val_accuracy: 0.3185\n",
            "Epoch 1130/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0025 - accuracy: 0.5336 - val_loss: 1.9824 - val_accuracy: 0.3169\n",
            "Epoch 1131/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0230 - accuracy: 0.5249 - val_loss: 1.9912 - val_accuracy: 0.3133\n",
            "Epoch 1132/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0353 - accuracy: 0.5183 - val_loss: 1.9649 - val_accuracy: 0.3162\n",
            "Epoch 1133/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0206 - accuracy: 0.5253 - val_loss: 1.9888 - val_accuracy: 0.3196\n",
            "Epoch 1134/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0092 - accuracy: 0.5312 - val_loss: 1.9869 - val_accuracy: 0.3192\n",
            "Epoch 1135/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0273 - accuracy: 0.5215 - val_loss: 1.9885 - val_accuracy: 0.3148\n",
            "Epoch 1136/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0588 - accuracy: 0.5078 - val_loss: 1.9537 - val_accuracy: 0.3163\n",
            "Epoch 1137/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0810 - accuracy: 0.5000 - val_loss: 1.9329 - val_accuracy: 0.3157\n",
            "Epoch 1138/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0532 - accuracy: 0.5113 - val_loss: 1.9646 - val_accuracy: 0.3159\n",
            "Epoch 1139/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0253 - accuracy: 0.5235 - val_loss: 1.9591 - val_accuracy: 0.3150\n",
            "Epoch 1140/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0099 - accuracy: 0.5338 - val_loss: 1.9819 - val_accuracy: 0.3142\n",
            "Epoch 1141/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0160 - accuracy: 0.5277 - val_loss: 1.9780 - val_accuracy: 0.3128\n",
            "Epoch 1142/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0103 - accuracy: 0.5306 - val_loss: 1.9621 - val_accuracy: 0.3141\n",
            "Epoch 1143/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9976 - accuracy: 0.5388 - val_loss: 1.9822 - val_accuracy: 0.3138\n",
            "Epoch 1144/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9863 - accuracy: 0.5436 - val_loss: 1.9867 - val_accuracy: 0.3137\n",
            "Epoch 1145/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9793 - accuracy: 0.5472 - val_loss: 1.9972 - val_accuracy: 0.3097\n",
            "Epoch 1146/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9748 - accuracy: 0.5483 - val_loss: 1.9974 - val_accuracy: 0.3172\n",
            "Epoch 1147/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9709 - accuracy: 0.5512 - val_loss: 1.9977 - val_accuracy: 0.3141\n",
            "Epoch 1148/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9722 - accuracy: 0.5495 - val_loss: 1.9977 - val_accuracy: 0.3142\n",
            "Epoch 1149/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9807 - accuracy: 0.5453 - val_loss: 1.9977 - val_accuracy: 0.3145\n",
            "Epoch 1150/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9901 - accuracy: 0.5400 - val_loss: 1.9963 - val_accuracy: 0.3179\n",
            "Epoch 1151/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0056 - accuracy: 0.5309 - val_loss: 2.0014 - val_accuracy: 0.3110\n",
            "Epoch 1152/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0107 - accuracy: 0.5298 - val_loss: 2.0026 - val_accuracy: 0.3104\n",
            "Epoch 1153/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0155 - accuracy: 0.5283 - val_loss: 1.9853 - val_accuracy: 0.3121\n",
            "Epoch 1154/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0152 - accuracy: 0.5284 - val_loss: 1.9982 - val_accuracy: 0.3115\n",
            "Epoch 1155/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0145 - accuracy: 0.5286 - val_loss: 2.0030 - val_accuracy: 0.3090\n",
            "Epoch 1156/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0025 - accuracy: 0.5341 - val_loss: 1.9847 - val_accuracy: 0.3124\n",
            "Epoch 1157/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0009 - accuracy: 0.5361 - val_loss: 2.0081 - val_accuracy: 0.3091\n",
            "Epoch 1158/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0028 - accuracy: 0.5340 - val_loss: 2.0143 - val_accuracy: 0.3113\n",
            "Epoch 1159/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0067 - accuracy: 0.5328 - val_loss: 1.9902 - val_accuracy: 0.3106\n",
            "Epoch 1160/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0053 - accuracy: 0.5330 - val_loss: 1.9976 - val_accuracy: 0.3133\n",
            "Epoch 1161/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0198 - accuracy: 0.5256 - val_loss: 1.9871 - val_accuracy: 0.3140\n",
            "Epoch 1162/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0193 - accuracy: 0.5255 - val_loss: 1.9884 - val_accuracy: 0.3118\n",
            "Epoch 1163/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9972 - accuracy: 0.5379 - val_loss: 2.0032 - val_accuracy: 0.3113\n",
            "Epoch 1164/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9934 - accuracy: 0.5395 - val_loss: 2.0072 - val_accuracy: 0.3106\n",
            "Epoch 1165/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0085 - accuracy: 0.5326 - val_loss: 1.9941 - val_accuracy: 0.3132\n",
            "Epoch 1166/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0081 - accuracy: 0.5303 - val_loss: 1.9962 - val_accuracy: 0.3163\n",
            "Epoch 1167/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0081 - accuracy: 0.5330 - val_loss: 1.9979 - val_accuracy: 0.3133\n",
            "Epoch 1168/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0049 - accuracy: 0.5342 - val_loss: 1.9963 - val_accuracy: 0.3096\n",
            "Epoch 1169/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9957 - accuracy: 0.5389 - val_loss: 1.9964 - val_accuracy: 0.3099\n",
            "Epoch 1170/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9887 - accuracy: 0.5420 - val_loss: 2.0015 - val_accuracy: 0.3128\n",
            "Epoch 1171/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9842 - accuracy: 0.5421 - val_loss: 2.0032 - val_accuracy: 0.3111\n",
            "Epoch 1172/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9900 - accuracy: 0.5406 - val_loss: 2.0155 - val_accuracy: 0.3126\n",
            "Epoch 1173/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9878 - accuracy: 0.5418 - val_loss: 2.0073 - val_accuracy: 0.3122\n",
            "Epoch 1174/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9950 - accuracy: 0.5391 - val_loss: 2.0210 - val_accuracy: 0.3129\n",
            "Epoch 1175/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9920 - accuracy: 0.5390 - val_loss: 2.0089 - val_accuracy: 0.3146\n",
            "Epoch 1176/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9870 - accuracy: 0.5437 - val_loss: 2.0293 - val_accuracy: 0.3135\n",
            "Epoch 1177/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9844 - accuracy: 0.5427 - val_loss: 2.0144 - val_accuracy: 0.3136\n",
            "Epoch 1178/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9997 - accuracy: 0.5357 - val_loss: 2.0100 - val_accuracy: 0.3177\n",
            "Epoch 1179/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0117 - accuracy: 0.5311 - val_loss: 2.0087 - val_accuracy: 0.3162\n",
            "Epoch 1180/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0104 - accuracy: 0.5333 - val_loss: 2.0092 - val_accuracy: 0.3148\n",
            "Epoch 1181/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0016 - accuracy: 0.5342 - val_loss: 2.0151 - val_accuracy: 0.3184\n",
            "Epoch 1182/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9944 - accuracy: 0.5386 - val_loss: 2.0078 - val_accuracy: 0.3152\n",
            "Epoch 1183/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9954 - accuracy: 0.5395 - val_loss: 2.0003 - val_accuracy: 0.3169\n",
            "Epoch 1184/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0046 - accuracy: 0.5328 - val_loss: 2.0065 - val_accuracy: 0.3161\n",
            "Epoch 1185/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0019 - accuracy: 0.5354 - val_loss: 2.0063 - val_accuracy: 0.3138\n",
            "Epoch 1186/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9925 - accuracy: 0.5398 - val_loss: 2.0184 - val_accuracy: 0.3147\n",
            "Epoch 1187/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9951 - accuracy: 0.5391 - val_loss: 2.0044 - val_accuracy: 0.3161\n",
            "Epoch 1188/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0097 - accuracy: 0.5334 - val_loss: 2.0142 - val_accuracy: 0.3146\n",
            "Epoch 1189/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0154 - accuracy: 0.5301 - val_loss: 1.9906 - val_accuracy: 0.3157\n",
            "Epoch 1190/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0108 - accuracy: 0.5308 - val_loss: 1.9961 - val_accuracy: 0.3182\n",
            "Epoch 1191/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0042 - accuracy: 0.5350 - val_loss: 1.9769 - val_accuracy: 0.3187\n",
            "Epoch 1192/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9998 - accuracy: 0.5366 - val_loss: 2.0027 - val_accuracy: 0.3144\n",
            "Epoch 1193/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9943 - accuracy: 0.5388 - val_loss: 2.0022 - val_accuracy: 0.3134\n",
            "Epoch 1194/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9996 - accuracy: 0.5362 - val_loss: 2.0018 - val_accuracy: 0.3168\n",
            "Epoch 1195/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0022 - accuracy: 0.5343 - val_loss: 2.0148 - val_accuracy: 0.3144\n",
            "Epoch 1196/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9974 - accuracy: 0.5364 - val_loss: 1.9967 - val_accuracy: 0.3139\n",
            "Epoch 1197/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9999 - accuracy: 0.5351 - val_loss: 2.0000 - val_accuracy: 0.3118\n",
            "Epoch 1198/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0038 - accuracy: 0.5324 - val_loss: 1.9931 - val_accuracy: 0.3134\n",
            "Epoch 1199/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0174 - accuracy: 0.5269 - val_loss: 1.9851 - val_accuracy: 0.3127\n",
            "Epoch 1200/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0143 - accuracy: 0.5299 - val_loss: 1.9987 - val_accuracy: 0.3155\n",
            "Epoch 1201/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0054 - accuracy: 0.5347 - val_loss: 1.9953 - val_accuracy: 0.3156\n",
            "Epoch 1202/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9955 - accuracy: 0.5380 - val_loss: 1.9883 - val_accuracy: 0.3175\n",
            "Epoch 1203/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9985 - accuracy: 0.5375 - val_loss: 1.9990 - val_accuracy: 0.3172\n",
            "Epoch 1204/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9918 - accuracy: 0.5394 - val_loss: 2.0078 - val_accuracy: 0.3171\n",
            "Epoch 1205/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9940 - accuracy: 0.5393 - val_loss: 2.0225 - val_accuracy: 0.3144\n",
            "Epoch 1206/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9916 - accuracy: 0.5391 - val_loss: 2.0053 - val_accuracy: 0.3148\n",
            "Epoch 1207/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0024 - accuracy: 0.5349 - val_loss: 1.9944 - val_accuracy: 0.3159\n",
            "Epoch 1208/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0228 - accuracy: 0.5268 - val_loss: 2.0073 - val_accuracy: 0.3116\n",
            "Epoch 1209/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0240 - accuracy: 0.5260 - val_loss: 1.9921 - val_accuracy: 0.3152\n",
            "Epoch 1210/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0007 - accuracy: 0.5354 - val_loss: 1.9924 - val_accuracy: 0.3098\n",
            "Epoch 1211/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9971 - accuracy: 0.5385 - val_loss: 2.0047 - val_accuracy: 0.3110\n",
            "Epoch 1212/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9981 - accuracy: 0.5372 - val_loss: 2.0187 - val_accuracy: 0.3105\n",
            "Epoch 1213/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0154 - accuracy: 0.5302 - val_loss: 2.0040 - val_accuracy: 0.3147\n",
            "Epoch 1214/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0434 - accuracy: 0.5204 - val_loss: 1.9939 - val_accuracy: 0.3112\n",
            "Epoch 1215/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0502 - accuracy: 0.5164 - val_loss: 1.9940 - val_accuracy: 0.3153\n",
            "Epoch 1216/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0398 - accuracy: 0.5195 - val_loss: 2.0002 - val_accuracy: 0.3128\n",
            "Epoch 1217/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0226 - accuracy: 0.5268 - val_loss: 2.0005 - val_accuracy: 0.3122\n",
            "Epoch 1218/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0199 - accuracy: 0.5282 - val_loss: 1.9883 - val_accuracy: 0.3151\n",
            "Epoch 1219/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0149 - accuracy: 0.5322 - val_loss: 1.9771 - val_accuracy: 0.3180\n",
            "Epoch 1220/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0092 - accuracy: 0.5337 - val_loss: 2.0033 - val_accuracy: 0.3139\n",
            "Epoch 1221/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0028 - accuracy: 0.5351 - val_loss: 1.9876 - val_accuracy: 0.3111\n",
            "Epoch 1222/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0030 - accuracy: 0.5355 - val_loss: 2.0032 - val_accuracy: 0.3099\n",
            "Epoch 1223/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9945 - accuracy: 0.5389 - val_loss: 1.9961 - val_accuracy: 0.3165\n",
            "Epoch 1224/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9985 - accuracy: 0.5382 - val_loss: 1.9998 - val_accuracy: 0.3168\n",
            "Epoch 1225/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9961 - accuracy: 0.5389 - val_loss: 2.0039 - val_accuracy: 0.3157\n",
            "Epoch 1226/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0008 - accuracy: 0.5339 - val_loss: 2.0023 - val_accuracy: 0.3115\n",
            "Epoch 1227/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9991 - accuracy: 0.5374 - val_loss: 2.0062 - val_accuracy: 0.3134\n",
            "Epoch 1228/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9990 - accuracy: 0.5359 - val_loss: 2.0069 - val_accuracy: 0.3094\n",
            "Epoch 1229/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9919 - accuracy: 0.5396 - val_loss: 1.9924 - val_accuracy: 0.3092\n",
            "Epoch 1230/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9933 - accuracy: 0.5406 - val_loss: 2.0198 - val_accuracy: 0.3094\n",
            "Epoch 1231/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0001 - accuracy: 0.5349 - val_loss: 1.9942 - val_accuracy: 0.3197\n",
            "Epoch 1232/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9980 - accuracy: 0.5357 - val_loss: 2.0053 - val_accuracy: 0.3131\n",
            "Epoch 1233/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9998 - accuracy: 0.5369 - val_loss: 2.0100 - val_accuracy: 0.3140\n",
            "Epoch 1234/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9973 - accuracy: 0.5352 - val_loss: 2.0064 - val_accuracy: 0.3144\n",
            "Epoch 1235/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0015 - accuracy: 0.5352 - val_loss: 2.0085 - val_accuracy: 0.3135\n",
            "Epoch 1236/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0016 - accuracy: 0.5365 - val_loss: 1.9946 - val_accuracy: 0.3137\n",
            "Epoch 1237/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9976 - accuracy: 0.5380 - val_loss: 2.0069 - val_accuracy: 0.3128\n",
            "Epoch 1238/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9897 - accuracy: 0.5409 - val_loss: 2.0177 - val_accuracy: 0.3152\n",
            "Epoch 1239/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9864 - accuracy: 0.5425 - val_loss: 2.0132 - val_accuracy: 0.3123\n",
            "Epoch 1240/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9823 - accuracy: 0.5435 - val_loss: 2.0204 - val_accuracy: 0.3145\n",
            "Epoch 1241/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9834 - accuracy: 0.5429 - val_loss: 2.0067 - val_accuracy: 0.3167\n",
            "Epoch 1242/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9822 - accuracy: 0.5445 - val_loss: 2.0283 - val_accuracy: 0.3115\n",
            "Epoch 1243/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9860 - accuracy: 0.5434 - val_loss: 2.0348 - val_accuracy: 0.3128\n",
            "Epoch 1244/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9907 - accuracy: 0.5406 - val_loss: 2.0243 - val_accuracy: 0.3140\n",
            "Epoch 1245/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0045 - accuracy: 0.5341 - val_loss: 2.0110 - val_accuracy: 0.3157\n",
            "Epoch 1246/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9992 - accuracy: 0.5375 - val_loss: 2.0283 - val_accuracy: 0.3157\n",
            "Epoch 1247/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9883 - accuracy: 0.5429 - val_loss: 2.0090 - val_accuracy: 0.3225\n",
            "Epoch 1248/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9803 - accuracy: 0.5466 - val_loss: 2.0285 - val_accuracy: 0.3156\n",
            "Epoch 1249/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9773 - accuracy: 0.5468 - val_loss: 2.0329 - val_accuracy: 0.3182\n",
            "Epoch 1250/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9746 - accuracy: 0.5488 - val_loss: 2.0206 - val_accuracy: 0.3162\n",
            "Epoch 1251/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9785 - accuracy: 0.5460 - val_loss: 2.0290 - val_accuracy: 0.3132\n",
            "Epoch 1252/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9806 - accuracy: 0.5442 - val_loss: 2.0347 - val_accuracy: 0.3125\n",
            "Epoch 1253/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9839 - accuracy: 0.5422 - val_loss: 2.0224 - val_accuracy: 0.3150\n",
            "Epoch 1254/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9890 - accuracy: 0.5410 - val_loss: 2.0257 - val_accuracy: 0.3151\n",
            "Epoch 1255/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9968 - accuracy: 0.5375 - val_loss: 2.0154 - val_accuracy: 0.3158\n",
            "Epoch 1256/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0086 - accuracy: 0.5317 - val_loss: 2.0321 - val_accuracy: 0.3162\n",
            "Epoch 1257/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0025 - accuracy: 0.5345 - val_loss: 2.0229 - val_accuracy: 0.3134\n",
            "Epoch 1258/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0112 - accuracy: 0.5309 - val_loss: 2.0109 - val_accuracy: 0.3135\n",
            "Epoch 1259/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0273 - accuracy: 0.5249 - val_loss: 2.0201 - val_accuracy: 0.3174\n",
            "Epoch 1260/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0312 - accuracy: 0.5231 - val_loss: 2.0044 - val_accuracy: 0.3171\n",
            "Epoch 1261/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0178 - accuracy: 0.5298 - val_loss: 2.0077 - val_accuracy: 0.3177\n",
            "Epoch 1262/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0276 - accuracy: 0.5264 - val_loss: 2.0173 - val_accuracy: 0.3143\n",
            "Epoch 1263/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0134 - accuracy: 0.5302 - val_loss: 2.0232 - val_accuracy: 0.3148\n",
            "Epoch 1264/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0014 - accuracy: 0.5345 - val_loss: 2.0201 - val_accuracy: 0.3128\n",
            "Epoch 1265/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9964 - accuracy: 0.5394 - val_loss: 2.0243 - val_accuracy: 0.3104\n",
            "Epoch 1266/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9868 - accuracy: 0.5433 - val_loss: 2.0225 - val_accuracy: 0.3153\n",
            "Epoch 1267/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9833 - accuracy: 0.5450 - val_loss: 2.0376 - val_accuracy: 0.3121\n",
            "Epoch 1268/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9842 - accuracy: 0.5442 - val_loss: 2.0212 - val_accuracy: 0.3151\n",
            "Epoch 1269/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0116 - accuracy: 0.5295 - val_loss: 2.0378 - val_accuracy: 0.3117\n",
            "Epoch 1270/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0079 - accuracy: 0.5315 - val_loss: 2.0355 - val_accuracy: 0.3123\n",
            "Epoch 1271/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9970 - accuracy: 0.5374 - val_loss: 2.0262 - val_accuracy: 0.3161\n",
            "Epoch 1272/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9889 - accuracy: 0.5412 - val_loss: 2.0440 - val_accuracy: 0.3116\n",
            "Epoch 1273/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9806 - accuracy: 0.5470 - val_loss: 2.0488 - val_accuracy: 0.3128\n",
            "Epoch 1274/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9809 - accuracy: 0.5448 - val_loss: 2.0370 - val_accuracy: 0.3118\n",
            "Epoch 1275/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9849 - accuracy: 0.5431 - val_loss: 2.0230 - val_accuracy: 0.3122\n",
            "Epoch 1276/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9883 - accuracy: 0.5406 - val_loss: 2.0337 - val_accuracy: 0.3109\n",
            "Epoch 1277/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9875 - accuracy: 0.5401 - val_loss: 2.0336 - val_accuracy: 0.3160\n",
            "Epoch 1278/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9889 - accuracy: 0.5422 - val_loss: 2.0359 - val_accuracy: 0.3100\n",
            "Epoch 1279/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9916 - accuracy: 0.5386 - val_loss: 2.0243 - val_accuracy: 0.3125\n",
            "Epoch 1280/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9978 - accuracy: 0.5377 - val_loss: 2.0293 - val_accuracy: 0.3112\n",
            "Epoch 1281/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9904 - accuracy: 0.5386 - val_loss: 2.0403 - val_accuracy: 0.3110\n",
            "Epoch 1282/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9967 - accuracy: 0.5367 - val_loss: 2.0217 - val_accuracy: 0.3153\n",
            "Epoch 1283/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9972 - accuracy: 0.5375 - val_loss: 2.0251 - val_accuracy: 0.3089\n",
            "Epoch 1284/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0449 - accuracy: 0.5146 - val_loss: 1.9893 - val_accuracy: 0.3159\n",
            "Epoch 1285/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0525 - accuracy: 0.5113 - val_loss: 1.9867 - val_accuracy: 0.3127\n",
            "Epoch 1286/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0501 - accuracy: 0.5103 - val_loss: 1.9840 - val_accuracy: 0.3206\n",
            "Epoch 1287/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0275 - accuracy: 0.5231 - val_loss: 2.0038 - val_accuracy: 0.3174\n",
            "Epoch 1288/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0155 - accuracy: 0.5274 - val_loss: 1.9950 - val_accuracy: 0.3174\n",
            "Epoch 1289/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9992 - accuracy: 0.5361 - val_loss: 2.0106 - val_accuracy: 0.3211\n",
            "Epoch 1290/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9965 - accuracy: 0.5399 - val_loss: 2.0267 - val_accuracy: 0.3128\n",
            "Epoch 1291/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0013 - accuracy: 0.5365 - val_loss: 2.0160 - val_accuracy: 0.3162\n",
            "Epoch 1292/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0078 - accuracy: 0.5318 - val_loss: 2.0154 - val_accuracy: 0.3125\n",
            "Epoch 1293/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0038 - accuracy: 0.5334 - val_loss: 2.0151 - val_accuracy: 0.3135\n",
            "Epoch 1294/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0036 - accuracy: 0.5353 - val_loss: 2.0172 - val_accuracy: 0.3144\n",
            "Epoch 1295/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0012 - accuracy: 0.5355 - val_loss: 2.0199 - val_accuracy: 0.3123\n",
            "Epoch 1296/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0151 - accuracy: 0.5298 - val_loss: 2.0171 - val_accuracy: 0.3171\n",
            "Epoch 1297/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0040 - accuracy: 0.5355 - val_loss: 2.0219 - val_accuracy: 0.3126\n",
            "Epoch 1298/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9961 - accuracy: 0.5408 - val_loss: 2.0193 - val_accuracy: 0.3169\n",
            "Epoch 1299/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9914 - accuracy: 0.5422 - val_loss: 2.0319 - val_accuracy: 0.3142\n",
            "Epoch 1300/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9946 - accuracy: 0.5386 - val_loss: 2.0197 - val_accuracy: 0.3151\n",
            "Epoch 1301/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9932 - accuracy: 0.5399 - val_loss: 2.0135 - val_accuracy: 0.3154\n",
            "Epoch 1302/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9943 - accuracy: 0.5388 - val_loss: 2.0432 - val_accuracy: 0.3143\n",
            "Epoch 1303/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9838 - accuracy: 0.5437 - val_loss: 2.0282 - val_accuracy: 0.3183\n",
            "Epoch 1304/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9849 - accuracy: 0.5436 - val_loss: 2.0326 - val_accuracy: 0.3144\n",
            "Epoch 1305/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9797 - accuracy: 0.5454 - val_loss: 2.0361 - val_accuracy: 0.3111\n",
            "Epoch 1306/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9751 - accuracy: 0.5487 - val_loss: 2.0530 - val_accuracy: 0.3121\n",
            "Epoch 1307/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9694 - accuracy: 0.5510 - val_loss: 2.0548 - val_accuracy: 0.3127\n",
            "Epoch 1308/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9695 - accuracy: 0.5506 - val_loss: 2.0470 - val_accuracy: 0.3167\n",
            "Epoch 1309/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9760 - accuracy: 0.5485 - val_loss: 2.0392 - val_accuracy: 0.3174\n",
            "Epoch 1310/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9936 - accuracy: 0.5371 - val_loss: 2.0455 - val_accuracy: 0.3191\n",
            "Epoch 1311/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9946 - accuracy: 0.5387 - val_loss: 2.0419 - val_accuracy: 0.3116\n",
            "Epoch 1312/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9897 - accuracy: 0.5410 - val_loss: 2.0393 - val_accuracy: 0.3102\n",
            "Epoch 1313/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0231 - accuracy: 0.5270 - val_loss: 2.0422 - val_accuracy: 0.3100\n",
            "Epoch 1314/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0243 - accuracy: 0.5261 - val_loss: 2.0222 - val_accuracy: 0.3084\n",
            "Epoch 1315/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0052 - accuracy: 0.5348 - val_loss: 2.0313 - val_accuracy: 0.3151\n",
            "Epoch 1316/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0130 - accuracy: 0.5295 - val_loss: 2.0099 - val_accuracy: 0.3167\n",
            "Epoch 1317/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0278 - accuracy: 0.5226 - val_loss: 2.0171 - val_accuracy: 0.3162\n",
            "Epoch 1318/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0195 - accuracy: 0.5272 - val_loss: 2.0022 - val_accuracy: 0.3161\n",
            "Epoch 1319/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0117 - accuracy: 0.5325 - val_loss: 2.0197 - val_accuracy: 0.3175\n",
            "Epoch 1320/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9941 - accuracy: 0.5383 - val_loss: 2.0363 - val_accuracy: 0.3139\n",
            "Epoch 1321/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9829 - accuracy: 0.5449 - val_loss: 2.0320 - val_accuracy: 0.3120\n",
            "Epoch 1322/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9836 - accuracy: 0.5446 - val_loss: 2.0187 - val_accuracy: 0.3145\n",
            "Epoch 1323/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9844 - accuracy: 0.5430 - val_loss: 2.0329 - val_accuracy: 0.3116\n",
            "Epoch 1324/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9884 - accuracy: 0.5424 - val_loss: 2.0335 - val_accuracy: 0.3168\n",
            "Epoch 1325/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9827 - accuracy: 0.5436 - val_loss: 2.0400 - val_accuracy: 0.3156\n",
            "Epoch 1326/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9779 - accuracy: 0.5474 - val_loss: 2.0356 - val_accuracy: 0.3149\n",
            "Epoch 1327/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9767 - accuracy: 0.5458 - val_loss: 2.0514 - val_accuracy: 0.3151\n",
            "Epoch 1328/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9750 - accuracy: 0.5473 - val_loss: 2.0354 - val_accuracy: 0.3131\n",
            "Epoch 1329/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9800 - accuracy: 0.5448 - val_loss: 2.0410 - val_accuracy: 0.3144\n",
            "Epoch 1330/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9809 - accuracy: 0.5446 - val_loss: 2.0483 - val_accuracy: 0.3138\n",
            "Epoch 1331/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9881 - accuracy: 0.5409 - val_loss: 2.0517 - val_accuracy: 0.3097\n",
            "Epoch 1332/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9925 - accuracy: 0.5381 - val_loss: 2.0496 - val_accuracy: 0.3145\n",
            "Epoch 1333/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0009 - accuracy: 0.5381 - val_loss: 2.0519 - val_accuracy: 0.3116\n",
            "Epoch 1334/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9930 - accuracy: 0.5400 - val_loss: 2.0359 - val_accuracy: 0.3189\n",
            "Epoch 1335/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0025 - accuracy: 0.5340 - val_loss: 2.0437 - val_accuracy: 0.3107\n",
            "Epoch 1336/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0102 - accuracy: 0.5306 - val_loss: 2.0144 - val_accuracy: 0.3130\n",
            "Epoch 1337/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0296 - accuracy: 0.5231 - val_loss: 2.0189 - val_accuracy: 0.3162\n",
            "Epoch 1338/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0205 - accuracy: 0.5268 - val_loss: 2.0167 - val_accuracy: 0.3127\n",
            "Epoch 1339/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0010 - accuracy: 0.5354 - val_loss: 2.0306 - val_accuracy: 0.3197\n",
            "Epoch 1340/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9993 - accuracy: 0.5365 - val_loss: 2.0245 - val_accuracy: 0.3174\n",
            "Epoch 1341/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9866 - accuracy: 0.5444 - val_loss: 2.0421 - val_accuracy: 0.3180\n",
            "Epoch 1342/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9767 - accuracy: 0.5484 - val_loss: 2.0407 - val_accuracy: 0.3167\n",
            "Epoch 1343/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9724 - accuracy: 0.5497 - val_loss: 2.0518 - val_accuracy: 0.3159\n",
            "Epoch 1344/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9786 - accuracy: 0.5463 - val_loss: 2.0440 - val_accuracy: 0.3143\n",
            "Epoch 1345/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9868 - accuracy: 0.5433 - val_loss: 2.0334 - val_accuracy: 0.3151\n",
            "Epoch 1346/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9910 - accuracy: 0.5398 - val_loss: 2.0485 - val_accuracy: 0.3125\n",
            "Epoch 1347/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9848 - accuracy: 0.5433 - val_loss: 2.0560 - val_accuracy: 0.3146\n",
            "Epoch 1348/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9812 - accuracy: 0.5463 - val_loss: 2.0552 - val_accuracy: 0.3089\n",
            "Epoch 1349/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9810 - accuracy: 0.5452 - val_loss: 2.0454 - val_accuracy: 0.3151\n",
            "Epoch 1350/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9767 - accuracy: 0.5470 - val_loss: 2.0455 - val_accuracy: 0.3165\n",
            "Epoch 1351/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9773 - accuracy: 0.5471 - val_loss: 2.0662 - val_accuracy: 0.3149\n",
            "Epoch 1352/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9743 - accuracy: 0.5480 - val_loss: 2.0535 - val_accuracy: 0.3177\n",
            "Epoch 1353/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9700 - accuracy: 0.5492 - val_loss: 2.0709 - val_accuracy: 0.3182\n",
            "Epoch 1354/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9664 - accuracy: 0.5523 - val_loss: 2.0683 - val_accuracy: 0.3126\n",
            "Epoch 1355/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9703 - accuracy: 0.5520 - val_loss: 2.0761 - val_accuracy: 0.3133\n",
            "Epoch 1356/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9747 - accuracy: 0.5490 - val_loss: 2.0652 - val_accuracy: 0.3118\n",
            "Epoch 1357/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9807 - accuracy: 0.5459 - val_loss: 2.0720 - val_accuracy: 0.3142\n",
            "Epoch 1358/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0108 - accuracy: 0.5311 - val_loss: 2.0391 - val_accuracy: 0.3175\n",
            "Epoch 1359/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0158 - accuracy: 0.5286 - val_loss: 2.0494 - val_accuracy: 0.3160\n",
            "Epoch 1360/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9976 - accuracy: 0.5378 - val_loss: 2.0472 - val_accuracy: 0.3169\n",
            "Epoch 1361/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9877 - accuracy: 0.5430 - val_loss: 2.0296 - val_accuracy: 0.3140\n",
            "Epoch 1362/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9847 - accuracy: 0.5451 - val_loss: 2.0609 - val_accuracy: 0.3134\n",
            "Epoch 1363/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9812 - accuracy: 0.5466 - val_loss: 2.0498 - val_accuracy: 0.3151\n",
            "Epoch 1364/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9803 - accuracy: 0.5460 - val_loss: 2.0504 - val_accuracy: 0.3114\n",
            "Epoch 1365/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9771 - accuracy: 0.5484 - val_loss: 2.0638 - val_accuracy: 0.3139\n",
            "Epoch 1366/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9760 - accuracy: 0.5491 - val_loss: 2.0555 - val_accuracy: 0.3149\n",
            "Epoch 1367/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9728 - accuracy: 0.5495 - val_loss: 2.0722 - val_accuracy: 0.3105\n",
            "Epoch 1368/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9737 - accuracy: 0.5484 - val_loss: 2.0476 - val_accuracy: 0.3147\n",
            "Epoch 1369/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9837 - accuracy: 0.5441 - val_loss: 2.0697 - val_accuracy: 0.3118\n",
            "Epoch 1370/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9831 - accuracy: 0.5439 - val_loss: 2.0337 - val_accuracy: 0.3139\n",
            "Epoch 1371/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9832 - accuracy: 0.5452 - val_loss: 2.0574 - val_accuracy: 0.3127\n",
            "Epoch 1372/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9869 - accuracy: 0.5426 - val_loss: 2.0473 - val_accuracy: 0.3146\n",
            "Epoch 1373/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9848 - accuracy: 0.5428 - val_loss: 2.0507 - val_accuracy: 0.3127\n",
            "Epoch 1374/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9833 - accuracy: 0.5430 - val_loss: 2.0589 - val_accuracy: 0.3147\n",
            "Epoch 1375/3000\n",
            "16/16 [==============================] - 1s 31ms/step - loss: 0.9774 - accuracy: 0.5462 - val_loss: 2.0520 - val_accuracy: 0.3143\n",
            "Epoch 1376/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9795 - accuracy: 0.5456 - val_loss: 2.0582 - val_accuracy: 0.3149\n",
            "Epoch 1377/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9804 - accuracy: 0.5450 - val_loss: 2.0633 - val_accuracy: 0.3139\n",
            "Epoch 1378/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9849 - accuracy: 0.5423 - val_loss: 2.0574 - val_accuracy: 0.3146\n",
            "Epoch 1379/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9878 - accuracy: 0.5419 - val_loss: 2.0476 - val_accuracy: 0.3130\n",
            "Epoch 1380/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9829 - accuracy: 0.5445 - val_loss: 2.0651 - val_accuracy: 0.3125\n",
            "Epoch 1381/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9841 - accuracy: 0.5438 - val_loss: 2.0619 - val_accuracy: 0.3095\n",
            "Epoch 1382/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9878 - accuracy: 0.5433 - val_loss: 2.0716 - val_accuracy: 0.3109\n",
            "Epoch 1383/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9807 - accuracy: 0.5461 - val_loss: 2.0568 - val_accuracy: 0.3121\n",
            "Epoch 1384/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9799 - accuracy: 0.5475 - val_loss: 2.0501 - val_accuracy: 0.3138\n",
            "Epoch 1385/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9858 - accuracy: 0.5438 - val_loss: 2.0627 - val_accuracy: 0.3121\n",
            "Epoch 1386/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0172 - accuracy: 0.5323 - val_loss: 2.0633 - val_accuracy: 0.3080\n",
            "Epoch 1387/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1708 - accuracy: 0.4762 - val_loss: 1.9715 - val_accuracy: 0.3164\n",
            "Epoch 1388/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.1677 - accuracy: 0.4728 - val_loss: 1.9297 - val_accuracy: 0.3208\n",
            "Epoch 1389/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1230 - accuracy: 0.4834 - val_loss: 1.9413 - val_accuracy: 0.3213\n",
            "Epoch 1390/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1164 - accuracy: 0.4876 - val_loss: 1.9264 - val_accuracy: 0.3202\n",
            "Epoch 1391/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.1285 - accuracy: 0.4831 - val_loss: 1.9185 - val_accuracy: 0.3196\n",
            "Epoch 1392/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0918 - accuracy: 0.4948 - val_loss: 1.9232 - val_accuracy: 0.3142\n",
            "Epoch 1393/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0570 - accuracy: 0.5082 - val_loss: 1.9348 - val_accuracy: 0.3112\n",
            "Epoch 1394/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0410 - accuracy: 0.5167 - val_loss: 1.9417 - val_accuracy: 0.3151\n",
            "Epoch 1395/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0936 - accuracy: 0.4956 - val_loss: 1.9356 - val_accuracy: 0.3154\n",
            "Epoch 1396/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0957 - accuracy: 0.4954 - val_loss: 1.9317 - val_accuracy: 0.3163\n",
            "Epoch 1397/3000\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 1.0619 - accuracy: 0.5074 - val_loss: 1.9423 - val_accuracy: 0.3195\n",
            "Epoch 1398/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0473 - accuracy: 0.5115 - val_loss: 1.9450 - val_accuracy: 0.3195\n",
            "Epoch 1399/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0286 - accuracy: 0.5216 - val_loss: 1.9490 - val_accuracy: 0.3169\n",
            "Epoch 1400/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0142 - accuracy: 0.5284 - val_loss: 1.9524 - val_accuracy: 0.3200\n",
            "Epoch 1401/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0045 - accuracy: 0.5342 - val_loss: 1.9711 - val_accuracy: 0.3170\n",
            "Epoch 1402/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9985 - accuracy: 0.5367 - val_loss: 1.9754 - val_accuracy: 0.3159\n",
            "Epoch 1403/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9968 - accuracy: 0.5378 - val_loss: 1.9733 - val_accuracy: 0.3202\n",
            "Epoch 1404/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0043 - accuracy: 0.5334 - val_loss: 1.9802 - val_accuracy: 0.3146\n",
            "Epoch 1405/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0001 - accuracy: 0.5353 - val_loss: 1.9801 - val_accuracy: 0.3118\n",
            "Epoch 1406/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0019 - accuracy: 0.5347 - val_loss: 1.9864 - val_accuracy: 0.3161\n",
            "Epoch 1407/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0064 - accuracy: 0.5307 - val_loss: 1.9861 - val_accuracy: 0.3148\n",
            "Epoch 1408/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9924 - accuracy: 0.5385 - val_loss: 1.9744 - val_accuracy: 0.3208\n",
            "Epoch 1409/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9869 - accuracy: 0.5404 - val_loss: 1.9861 - val_accuracy: 0.3194\n",
            "Epoch 1410/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9877 - accuracy: 0.5422 - val_loss: 1.9866 - val_accuracy: 0.3187\n",
            "Epoch 1411/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9988 - accuracy: 0.5364 - val_loss: 1.9893 - val_accuracy: 0.3199\n",
            "Epoch 1412/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9986 - accuracy: 0.5350 - val_loss: 1.9833 - val_accuracy: 0.3181\n",
            "Epoch 1413/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9890 - accuracy: 0.5406 - val_loss: 1.9968 - val_accuracy: 0.3171\n",
            "Epoch 1414/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9823 - accuracy: 0.5443 - val_loss: 2.0063 - val_accuracy: 0.3191\n",
            "Epoch 1415/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9855 - accuracy: 0.5412 - val_loss: 2.0143 - val_accuracy: 0.3169\n",
            "Epoch 1416/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9998 - accuracy: 0.5351 - val_loss: 1.9991 - val_accuracy: 0.3173\n",
            "Epoch 1417/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0100 - accuracy: 0.5307 - val_loss: 2.0003 - val_accuracy: 0.3151\n",
            "Epoch 1418/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0123 - accuracy: 0.5301 - val_loss: 1.9801 - val_accuracy: 0.3134\n",
            "Epoch 1419/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9978 - accuracy: 0.5362 - val_loss: 2.0060 - val_accuracy: 0.3126\n",
            "Epoch 1420/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9889 - accuracy: 0.5405 - val_loss: 2.0014 - val_accuracy: 0.3102\n",
            "Epoch 1421/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9792 - accuracy: 0.5464 - val_loss: 2.0052 - val_accuracy: 0.3090\n",
            "Epoch 1422/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9783 - accuracy: 0.5468 - val_loss: 2.0190 - val_accuracy: 0.3155\n",
            "Epoch 1423/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9753 - accuracy: 0.5491 - val_loss: 2.0198 - val_accuracy: 0.3116\n",
            "Epoch 1424/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9812 - accuracy: 0.5458 - val_loss: 2.0111 - val_accuracy: 0.3138\n",
            "Epoch 1425/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9828 - accuracy: 0.5435 - val_loss: 2.0171 - val_accuracy: 0.3134\n",
            "Epoch 1426/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9788 - accuracy: 0.5458 - val_loss: 2.0212 - val_accuracy: 0.3114\n",
            "Epoch 1427/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9820 - accuracy: 0.5457 - val_loss: 2.0062 - val_accuracy: 0.3148\n",
            "Epoch 1428/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9841 - accuracy: 0.5435 - val_loss: 2.0267 - val_accuracy: 0.3107\n",
            "Epoch 1429/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9801 - accuracy: 0.5453 - val_loss: 2.0262 - val_accuracy: 0.3120\n",
            "Epoch 1430/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9797 - accuracy: 0.5467 - val_loss: 2.0174 - val_accuracy: 0.3124\n",
            "Epoch 1431/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9774 - accuracy: 0.5473 - val_loss: 2.0319 - val_accuracy: 0.3157\n",
            "Epoch 1432/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9889 - accuracy: 0.5420 - val_loss: 2.0136 - val_accuracy: 0.3171\n",
            "Epoch 1433/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9895 - accuracy: 0.5399 - val_loss: 2.0369 - val_accuracy: 0.3135\n",
            "Epoch 1434/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9851 - accuracy: 0.5426 - val_loss: 2.0110 - val_accuracy: 0.3144\n",
            "Epoch 1435/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9898 - accuracy: 0.5403 - val_loss: 2.0350 - val_accuracy: 0.3122\n",
            "Epoch 1436/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9882 - accuracy: 0.5413 - val_loss: 2.0149 - val_accuracy: 0.3158\n",
            "Epoch 1437/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9912 - accuracy: 0.5396 - val_loss: 2.0267 - val_accuracy: 0.3138\n",
            "Epoch 1438/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9928 - accuracy: 0.5404 - val_loss: 2.0027 - val_accuracy: 0.3160\n",
            "Epoch 1439/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9888 - accuracy: 0.5422 - val_loss: 2.0208 - val_accuracy: 0.3104\n",
            "Epoch 1440/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9855 - accuracy: 0.5436 - val_loss: 2.0118 - val_accuracy: 0.3132\n",
            "Epoch 1441/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9932 - accuracy: 0.5381 - val_loss: 2.0264 - val_accuracy: 0.3152\n",
            "Epoch 1442/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9985 - accuracy: 0.5358 - val_loss: 2.0313 - val_accuracy: 0.3135\n",
            "Epoch 1443/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0072 - accuracy: 0.5318 - val_loss: 2.0129 - val_accuracy: 0.3139\n",
            "Epoch 1444/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0089 - accuracy: 0.5316 - val_loss: 2.0214 - val_accuracy: 0.3144\n",
            "Epoch 1445/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0027 - accuracy: 0.5335 - val_loss: 2.0108 - val_accuracy: 0.3127\n",
            "Epoch 1446/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0171 - accuracy: 0.5294 - val_loss: 2.0074 - val_accuracy: 0.3101\n",
            "Epoch 1447/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0173 - accuracy: 0.5277 - val_loss: 2.0130 - val_accuracy: 0.3122\n",
            "Epoch 1448/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0018 - accuracy: 0.5350 - val_loss: 2.0079 - val_accuracy: 0.3135\n",
            "Epoch 1449/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9920 - accuracy: 0.5413 - val_loss: 2.0253 - val_accuracy: 0.3127\n",
            "Epoch 1450/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9895 - accuracy: 0.5426 - val_loss: 2.0241 - val_accuracy: 0.3129\n",
            "Epoch 1451/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9861 - accuracy: 0.5437 - val_loss: 2.0322 - val_accuracy: 0.3088\n",
            "Epoch 1452/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9771 - accuracy: 0.5468 - val_loss: 2.0314 - val_accuracy: 0.3079\n",
            "Epoch 1453/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9707 - accuracy: 0.5507 - val_loss: 2.0440 - val_accuracy: 0.3086\n",
            "Epoch 1454/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9768 - accuracy: 0.5479 - val_loss: 2.0355 - val_accuracy: 0.3099\n",
            "Epoch 1455/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9965 - accuracy: 0.5369 - val_loss: 2.0275 - val_accuracy: 0.3144\n",
            "Epoch 1456/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9970 - accuracy: 0.5384 - val_loss: 2.0311 - val_accuracy: 0.3143\n",
            "Epoch 1457/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0055 - accuracy: 0.5338 - val_loss: 2.0190 - val_accuracy: 0.3127\n",
            "Epoch 1458/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0054 - accuracy: 0.5338 - val_loss: 2.0385 - val_accuracy: 0.3121\n",
            "Epoch 1459/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9886 - accuracy: 0.5424 - val_loss: 2.0280 - val_accuracy: 0.3134\n",
            "Epoch 1460/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9882 - accuracy: 0.5433 - val_loss: 2.0257 - val_accuracy: 0.3156\n",
            "Epoch 1461/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0023 - accuracy: 0.5343 - val_loss: 2.0317 - val_accuracy: 0.3104\n",
            "Epoch 1462/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0069 - accuracy: 0.5328 - val_loss: 2.0193 - val_accuracy: 0.3122\n",
            "Epoch 1463/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9911 - accuracy: 0.5405 - val_loss: 2.0389 - val_accuracy: 0.3086\n",
            "Epoch 1464/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9842 - accuracy: 0.5443 - val_loss: 2.0300 - val_accuracy: 0.3116\n",
            "Epoch 1465/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9747 - accuracy: 0.5498 - val_loss: 2.0410 - val_accuracy: 0.3127\n",
            "Epoch 1466/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9765 - accuracy: 0.5481 - val_loss: 2.0382 - val_accuracy: 0.3146\n",
            "Epoch 1467/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9784 - accuracy: 0.5484 - val_loss: 2.0651 - val_accuracy: 0.3120\n",
            "Epoch 1468/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9791 - accuracy: 0.5474 - val_loss: 2.0387 - val_accuracy: 0.3132\n",
            "Epoch 1469/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9832 - accuracy: 0.5438 - val_loss: 2.0459 - val_accuracy: 0.3110\n",
            "Epoch 1470/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9802 - accuracy: 0.5467 - val_loss: 2.0451 - val_accuracy: 0.3101\n",
            "Epoch 1471/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9833 - accuracy: 0.5446 - val_loss: 2.0406 - val_accuracy: 0.3139\n",
            "Epoch 1472/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9801 - accuracy: 0.5458 - val_loss: 2.0451 - val_accuracy: 0.3134\n",
            "Epoch 1473/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9763 - accuracy: 0.5466 - val_loss: 2.0416 - val_accuracy: 0.3114\n",
            "Epoch 1474/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9806 - accuracy: 0.5446 - val_loss: 2.0469 - val_accuracy: 0.3136\n",
            "Epoch 1475/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0091 - accuracy: 0.5333 - val_loss: 2.0336 - val_accuracy: 0.3130\n",
            "Epoch 1476/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0146 - accuracy: 0.5313 - val_loss: 2.0379 - val_accuracy: 0.3159\n",
            "Epoch 1477/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0299 - accuracy: 0.5247 - val_loss: 2.0254 - val_accuracy: 0.3154\n",
            "Epoch 1478/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0222 - accuracy: 0.5265 - val_loss: 2.0334 - val_accuracy: 0.3163\n",
            "Epoch 1479/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0053 - accuracy: 0.5361 - val_loss: 2.0246 - val_accuracy: 0.3160\n",
            "Epoch 1480/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9872 - accuracy: 0.5426 - val_loss: 2.0351 - val_accuracy: 0.3171\n",
            "Epoch 1481/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9817 - accuracy: 0.5460 - val_loss: 2.0340 - val_accuracy: 0.3164\n",
            "Epoch 1482/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9853 - accuracy: 0.5439 - val_loss: 2.0406 - val_accuracy: 0.3132\n",
            "Epoch 1483/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9820 - accuracy: 0.5459 - val_loss: 2.0477 - val_accuracy: 0.3131\n",
            "Epoch 1484/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9798 - accuracy: 0.5469 - val_loss: 2.0444 - val_accuracy: 0.3133\n",
            "Epoch 1485/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9873 - accuracy: 0.5435 - val_loss: 2.0188 - val_accuracy: 0.3143\n",
            "Epoch 1486/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9814 - accuracy: 0.5437 - val_loss: 2.0489 - val_accuracy: 0.3130\n",
            "Epoch 1487/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9877 - accuracy: 0.5435 - val_loss: 2.0289 - val_accuracy: 0.3172\n",
            "Epoch 1488/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9791 - accuracy: 0.5479 - val_loss: 2.0474 - val_accuracy: 0.3169\n",
            "Epoch 1489/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9652 - accuracy: 0.5551 - val_loss: 2.0514 - val_accuracy: 0.3095\n",
            "Epoch 1490/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9727 - accuracy: 0.5499 - val_loss: 2.0498 - val_accuracy: 0.3092\n",
            "Epoch 1491/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9796 - accuracy: 0.5466 - val_loss: 2.0491 - val_accuracy: 0.3137\n",
            "Epoch 1492/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9759 - accuracy: 0.5479 - val_loss: 2.0422 - val_accuracy: 0.3172\n",
            "Epoch 1493/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9756 - accuracy: 0.5477 - val_loss: 2.0452 - val_accuracy: 0.3157\n",
            "Epoch 1494/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9720 - accuracy: 0.5507 - val_loss: 2.0608 - val_accuracy: 0.3174\n",
            "Epoch 1495/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9642 - accuracy: 0.5535 - val_loss: 2.0601 - val_accuracy: 0.3136\n",
            "Epoch 1496/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9569 - accuracy: 0.5573 - val_loss: 2.0735 - val_accuracy: 0.3110\n",
            "Epoch 1497/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9563 - accuracy: 0.5568 - val_loss: 2.0726 - val_accuracy: 0.3136\n",
            "Epoch 1498/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9692 - accuracy: 0.5510 - val_loss: 2.0456 - val_accuracy: 0.3109\n",
            "Epoch 1499/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9843 - accuracy: 0.5435 - val_loss: 2.0581 - val_accuracy: 0.3130\n",
            "Epoch 1500/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9814 - accuracy: 0.5443 - val_loss: 2.0396 - val_accuracy: 0.3136\n",
            "Epoch 1501/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9800 - accuracy: 0.5441 - val_loss: 2.0668 - val_accuracy: 0.3096\n",
            "Epoch 1502/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9767 - accuracy: 0.5469 - val_loss: 2.0459 - val_accuracy: 0.3168\n",
            "Epoch 1503/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9831 - accuracy: 0.5432 - val_loss: 2.0533 - val_accuracy: 0.3129\n",
            "Epoch 1504/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9822 - accuracy: 0.5443 - val_loss: 2.0489 - val_accuracy: 0.3160\n",
            "Epoch 1505/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9862 - accuracy: 0.5432 - val_loss: 2.0763 - val_accuracy: 0.3140\n",
            "Epoch 1506/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9875 - accuracy: 0.5432 - val_loss: 2.0672 - val_accuracy: 0.3145\n",
            "Epoch 1507/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9836 - accuracy: 0.5435 - val_loss: 2.0621 - val_accuracy: 0.3104\n",
            "Epoch 1508/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9883 - accuracy: 0.5422 - val_loss: 2.0530 - val_accuracy: 0.3183\n",
            "Epoch 1509/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9932 - accuracy: 0.5383 - val_loss: 2.0609 - val_accuracy: 0.3176\n",
            "Epoch 1510/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9957 - accuracy: 0.5383 - val_loss: 2.0407 - val_accuracy: 0.3199\n",
            "Epoch 1511/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9880 - accuracy: 0.5417 - val_loss: 2.0631 - val_accuracy: 0.3170\n",
            "Epoch 1512/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9787 - accuracy: 0.5465 - val_loss: 2.0612 - val_accuracy: 0.3133\n",
            "Epoch 1513/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9820 - accuracy: 0.5453 - val_loss: 2.0610 - val_accuracy: 0.3166\n",
            "Epoch 1514/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9853 - accuracy: 0.5439 - val_loss: 2.0393 - val_accuracy: 0.3215\n",
            "Epoch 1515/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9894 - accuracy: 0.5401 - val_loss: 2.0481 - val_accuracy: 0.3193\n",
            "Epoch 1516/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9902 - accuracy: 0.5403 - val_loss: 2.0442 - val_accuracy: 0.3151\n",
            "Epoch 1517/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0009 - accuracy: 0.5359 - val_loss: 2.0490 - val_accuracy: 0.3197\n",
            "Epoch 1518/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9975 - accuracy: 0.5364 - val_loss: 2.0487 - val_accuracy: 0.3198\n",
            "Epoch 1519/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9909 - accuracy: 0.5426 - val_loss: 2.0423 - val_accuracy: 0.3147\n",
            "Epoch 1520/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9948 - accuracy: 0.5399 - val_loss: 2.0547 - val_accuracy: 0.3153\n",
            "Epoch 1521/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9993 - accuracy: 0.5376 - val_loss: 2.0449 - val_accuracy: 0.3135\n",
            "Epoch 1522/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9933 - accuracy: 0.5388 - val_loss: 2.0718 - val_accuracy: 0.3120\n",
            "Epoch 1523/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9925 - accuracy: 0.5400 - val_loss: 2.0461 - val_accuracy: 0.3145\n",
            "Epoch 1524/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9914 - accuracy: 0.5421 - val_loss: 2.0557 - val_accuracy: 0.3141\n",
            "Epoch 1525/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9922 - accuracy: 0.5407 - val_loss: 2.0484 - val_accuracy: 0.3163\n",
            "Epoch 1526/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9954 - accuracy: 0.5399 - val_loss: 2.0599 - val_accuracy: 0.3104\n",
            "Epoch 1527/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9951 - accuracy: 0.5395 - val_loss: 2.0496 - val_accuracy: 0.3141\n",
            "Epoch 1528/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9847 - accuracy: 0.5448 - val_loss: 2.0531 - val_accuracy: 0.3128\n",
            "Epoch 1529/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9803 - accuracy: 0.5473 - val_loss: 2.0424 - val_accuracy: 0.3097\n",
            "Epoch 1530/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9838 - accuracy: 0.5452 - val_loss: 2.0644 - val_accuracy: 0.3193\n",
            "Epoch 1531/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9823 - accuracy: 0.5442 - val_loss: 2.0585 - val_accuracy: 0.3167\n",
            "Epoch 1532/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9775 - accuracy: 0.5481 - val_loss: 2.0574 - val_accuracy: 0.3157\n",
            "Epoch 1533/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9852 - accuracy: 0.5444 - val_loss: 2.0525 - val_accuracy: 0.3112\n",
            "Epoch 1534/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9750 - accuracy: 0.5485 - val_loss: 2.0581 - val_accuracy: 0.3151\n",
            "Epoch 1535/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9713 - accuracy: 0.5502 - val_loss: 2.0646 - val_accuracy: 0.3102\n",
            "Epoch 1536/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9717 - accuracy: 0.5490 - val_loss: 2.0449 - val_accuracy: 0.3180\n",
            "Epoch 1537/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9705 - accuracy: 0.5494 - val_loss: 2.0616 - val_accuracy: 0.3144\n",
            "Epoch 1538/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9744 - accuracy: 0.5478 - val_loss: 2.0564 - val_accuracy: 0.3160\n",
            "Epoch 1539/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9753 - accuracy: 0.5474 - val_loss: 2.0538 - val_accuracy: 0.3189\n",
            "Epoch 1540/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0043 - accuracy: 0.5341 - val_loss: 2.0456 - val_accuracy: 0.3153\n",
            "Epoch 1541/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0053 - accuracy: 0.5351 - val_loss: 2.0494 - val_accuracy: 0.3192\n",
            "Epoch 1542/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.0063 - accuracy: 0.5335 - val_loss: 2.0656 - val_accuracy: 0.3160\n",
            "Epoch 1543/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9987 - accuracy: 0.5346 - val_loss: 2.0567 - val_accuracy: 0.3147\n",
            "Epoch 1544/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9969 - accuracy: 0.5377 - val_loss: 2.0556 - val_accuracy: 0.3190\n",
            "Epoch 1545/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0085 - accuracy: 0.5318 - val_loss: 2.0707 - val_accuracy: 0.3128\n",
            "Epoch 1546/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0233 - accuracy: 0.5281 - val_loss: 2.0491 - val_accuracy: 0.3154\n",
            "Epoch 1547/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0060 - accuracy: 0.5363 - val_loss: 2.0553 - val_accuracy: 0.3148\n",
            "Epoch 1548/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9946 - accuracy: 0.5400 - val_loss: 2.0686 - val_accuracy: 0.3151\n",
            "Epoch 1549/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9902 - accuracy: 0.5427 - val_loss: 2.0604 - val_accuracy: 0.3152\n",
            "Epoch 1550/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9819 - accuracy: 0.5453 - val_loss: 2.0705 - val_accuracy: 0.3128\n",
            "Epoch 1551/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9785 - accuracy: 0.5478 - val_loss: 2.0484 - val_accuracy: 0.3165\n",
            "Epoch 1552/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9790 - accuracy: 0.5466 - val_loss: 2.0589 - val_accuracy: 0.3159\n",
            "Epoch 1553/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9726 - accuracy: 0.5503 - val_loss: 2.0697 - val_accuracy: 0.3115\n",
            "Epoch 1554/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9672 - accuracy: 0.5521 - val_loss: 2.0592 - val_accuracy: 0.3161\n",
            "Epoch 1555/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9875 - accuracy: 0.5428 - val_loss: 2.0421 - val_accuracy: 0.3136\n",
            "Epoch 1556/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9835 - accuracy: 0.5444 - val_loss: 2.0671 - val_accuracy: 0.3105\n",
            "Epoch 1557/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9753 - accuracy: 0.5481 - val_loss: 2.0762 - val_accuracy: 0.3127\n",
            "Epoch 1558/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9727 - accuracy: 0.5502 - val_loss: 2.0904 - val_accuracy: 0.3124\n",
            "Epoch 1559/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9747 - accuracy: 0.5481 - val_loss: 2.0793 - val_accuracy: 0.3119\n",
            "Epoch 1560/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9779 - accuracy: 0.5485 - val_loss: 2.0810 - val_accuracy: 0.3095\n",
            "Epoch 1561/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9773 - accuracy: 0.5465 - val_loss: 2.0773 - val_accuracy: 0.3151\n",
            "Epoch 1562/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0005 - accuracy: 0.5382 - val_loss: 2.0633 - val_accuracy: 0.3128\n",
            "Epoch 1563/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0155 - accuracy: 0.5313 - val_loss: 2.0565 - val_accuracy: 0.3177\n",
            "Epoch 1564/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0120 - accuracy: 0.5321 - val_loss: 2.0796 - val_accuracy: 0.3129\n",
            "Epoch 1565/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0040 - accuracy: 0.5349 - val_loss: 2.0602 - val_accuracy: 0.3126\n",
            "Epoch 1566/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9916 - accuracy: 0.5420 - val_loss: 2.0678 - val_accuracy: 0.3089\n",
            "Epoch 1567/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9868 - accuracy: 0.5443 - val_loss: 2.0651 - val_accuracy: 0.3151\n",
            "Epoch 1568/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9822 - accuracy: 0.5450 - val_loss: 2.0705 - val_accuracy: 0.3131\n",
            "Epoch 1569/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9867 - accuracy: 0.5442 - val_loss: 2.0728 - val_accuracy: 0.3156\n",
            "Epoch 1570/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9926 - accuracy: 0.5396 - val_loss: 2.0648 - val_accuracy: 0.3154\n",
            "Epoch 1571/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0097 - accuracy: 0.5330 - val_loss: 2.0676 - val_accuracy: 0.3146\n",
            "Epoch 1572/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0146 - accuracy: 0.5311 - val_loss: 2.0565 - val_accuracy: 0.3157\n",
            "Epoch 1573/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0101 - accuracy: 0.5327 - val_loss: 2.0540 - val_accuracy: 0.3138\n",
            "Epoch 1574/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9984 - accuracy: 0.5378 - val_loss: 2.0593 - val_accuracy: 0.3159\n",
            "Epoch 1575/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9868 - accuracy: 0.5438 - val_loss: 2.0492 - val_accuracy: 0.3183\n",
            "Epoch 1576/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9794 - accuracy: 0.5460 - val_loss: 2.0682 - val_accuracy: 0.3131\n",
            "Epoch 1577/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9802 - accuracy: 0.5450 - val_loss: 2.0618 - val_accuracy: 0.3147\n",
            "Epoch 1578/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9884 - accuracy: 0.5440 - val_loss: 2.0737 - val_accuracy: 0.3123\n",
            "Epoch 1579/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9913 - accuracy: 0.5410 - val_loss: 2.0606 - val_accuracy: 0.3197\n",
            "Epoch 1580/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9928 - accuracy: 0.5420 - val_loss: 2.0592 - val_accuracy: 0.3137\n",
            "Epoch 1581/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9835 - accuracy: 0.5466 - val_loss: 2.0688 - val_accuracy: 0.3154\n",
            "Epoch 1582/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9778 - accuracy: 0.5482 - val_loss: 2.0636 - val_accuracy: 0.3160\n",
            "Epoch 1583/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9827 - accuracy: 0.5472 - val_loss: 2.0844 - val_accuracy: 0.3144\n",
            "Epoch 1584/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9803 - accuracy: 0.5468 - val_loss: 2.0558 - val_accuracy: 0.3182\n",
            "Epoch 1585/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9803 - accuracy: 0.5456 - val_loss: 2.0685 - val_accuracy: 0.3130\n",
            "Epoch 1586/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9829 - accuracy: 0.5448 - val_loss: 2.0471 - val_accuracy: 0.3175\n",
            "Epoch 1587/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9937 - accuracy: 0.5396 - val_loss: 2.0794 - val_accuracy: 0.3181\n",
            "Epoch 1588/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0085 - accuracy: 0.5340 - val_loss: 2.0707 - val_accuracy: 0.3118\n",
            "Epoch 1589/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0070 - accuracy: 0.5347 - val_loss: 2.0682 - val_accuracy: 0.3122\n",
            "Epoch 1590/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9932 - accuracy: 0.5418 - val_loss: 2.0788 - val_accuracy: 0.3132\n",
            "Epoch 1591/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9857 - accuracy: 0.5435 - val_loss: 2.0648 - val_accuracy: 0.3162\n",
            "Epoch 1592/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9795 - accuracy: 0.5466 - val_loss: 2.0554 - val_accuracy: 0.3144\n",
            "Epoch 1593/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9738 - accuracy: 0.5483 - val_loss: 2.0742 - val_accuracy: 0.3142\n",
            "Epoch 1594/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9731 - accuracy: 0.5479 - val_loss: 2.0741 - val_accuracy: 0.3160\n",
            "Epoch 1595/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9687 - accuracy: 0.5515 - val_loss: 2.0656 - val_accuracy: 0.3148\n",
            "Epoch 1596/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9642 - accuracy: 0.5530 - val_loss: 2.0884 - val_accuracy: 0.3105\n",
            "Epoch 1597/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9721 - accuracy: 0.5512 - val_loss: 2.0887 - val_accuracy: 0.3125\n",
            "Epoch 1598/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9720 - accuracy: 0.5514 - val_loss: 2.0738 - val_accuracy: 0.3172\n",
            "Epoch 1599/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9701 - accuracy: 0.5504 - val_loss: 2.0879 - val_accuracy: 0.3140\n",
            "Epoch 1600/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9765 - accuracy: 0.5477 - val_loss: 2.0836 - val_accuracy: 0.3136\n",
            "Epoch 1601/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9760 - accuracy: 0.5483 - val_loss: 2.0760 - val_accuracy: 0.3117\n",
            "Epoch 1602/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9696 - accuracy: 0.5500 - val_loss: 2.0742 - val_accuracy: 0.3113\n",
            "Epoch 1603/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9804 - accuracy: 0.5466 - val_loss: 2.0643 - val_accuracy: 0.3163\n",
            "Epoch 1604/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9905 - accuracy: 0.5421 - val_loss: 2.0845 - val_accuracy: 0.3167\n",
            "Epoch 1605/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9873 - accuracy: 0.5439 - val_loss: 2.0794 - val_accuracy: 0.3142\n",
            "Epoch 1606/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9844 - accuracy: 0.5450 - val_loss: 2.0806 - val_accuracy: 0.3148\n",
            "Epoch 1607/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9966 - accuracy: 0.5386 - val_loss: 2.0844 - val_accuracy: 0.3154\n",
            "Epoch 1608/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9914 - accuracy: 0.5415 - val_loss: 2.0557 - val_accuracy: 0.3187\n",
            "Epoch 1609/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9832 - accuracy: 0.5451 - val_loss: 2.0848 - val_accuracy: 0.3187\n",
            "Epoch 1610/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9793 - accuracy: 0.5454 - val_loss: 2.0723 - val_accuracy: 0.3123\n",
            "Epoch 1611/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9780 - accuracy: 0.5473 - val_loss: 2.0626 - val_accuracy: 0.3146\n",
            "Epoch 1612/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9751 - accuracy: 0.5477 - val_loss: 2.0691 - val_accuracy: 0.3165\n",
            "Epoch 1613/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9733 - accuracy: 0.5492 - val_loss: 2.0719 - val_accuracy: 0.3176\n",
            "Epoch 1614/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9684 - accuracy: 0.5505 - val_loss: 2.0840 - val_accuracy: 0.3133\n",
            "Epoch 1615/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9902 - accuracy: 0.5413 - val_loss: 2.0622 - val_accuracy: 0.3155\n",
            "Epoch 1616/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9854 - accuracy: 0.5436 - val_loss: 2.0639 - val_accuracy: 0.3158\n",
            "Epoch 1617/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9822 - accuracy: 0.5455 - val_loss: 2.0789 - val_accuracy: 0.3134\n",
            "Epoch 1618/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9737 - accuracy: 0.5485 - val_loss: 2.0553 - val_accuracy: 0.3133\n",
            "Epoch 1619/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9815 - accuracy: 0.5450 - val_loss: 2.0718 - val_accuracy: 0.3129\n",
            "Epoch 1620/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9894 - accuracy: 0.5420 - val_loss: 2.0636 - val_accuracy: 0.3146\n",
            "Epoch 1621/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9942 - accuracy: 0.5392 - val_loss: 2.0625 - val_accuracy: 0.3172\n",
            "Epoch 1622/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9886 - accuracy: 0.5413 - val_loss: 2.0649 - val_accuracy: 0.3171\n",
            "Epoch 1623/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9797 - accuracy: 0.5473 - val_loss: 2.0877 - val_accuracy: 0.3151\n",
            "Epoch 1624/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9778 - accuracy: 0.5462 - val_loss: 2.0657 - val_accuracy: 0.3156\n",
            "Epoch 1625/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9721 - accuracy: 0.5497 - val_loss: 2.0665 - val_accuracy: 0.3173\n",
            "Epoch 1626/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9796 - accuracy: 0.5477 - val_loss: 2.0686 - val_accuracy: 0.3139\n",
            "Epoch 1627/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9793 - accuracy: 0.5454 - val_loss: 2.0697 - val_accuracy: 0.3143\n",
            "Epoch 1628/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9741 - accuracy: 0.5479 - val_loss: 2.0930 - val_accuracy: 0.3140\n",
            "Epoch 1629/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9688 - accuracy: 0.5530 - val_loss: 2.0936 - val_accuracy: 0.3147\n",
            "Epoch 1630/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9645 - accuracy: 0.5526 - val_loss: 2.0878 - val_accuracy: 0.3109\n",
            "Epoch 1631/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9718 - accuracy: 0.5503 - val_loss: 2.0881 - val_accuracy: 0.3110\n",
            "Epoch 1632/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9985 - accuracy: 0.5399 - val_loss: 2.0865 - val_accuracy: 0.3162\n",
            "Epoch 1633/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0098 - accuracy: 0.5330 - val_loss: 2.0748 - val_accuracy: 0.3151\n",
            "Epoch 1634/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0107 - accuracy: 0.5335 - val_loss: 2.0734 - val_accuracy: 0.3158\n",
            "Epoch 1635/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0143 - accuracy: 0.5316 - val_loss: 2.0730 - val_accuracy: 0.3134\n",
            "Epoch 1636/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0042 - accuracy: 0.5351 - val_loss: 2.0726 - val_accuracy: 0.3145\n",
            "Epoch 1637/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9990 - accuracy: 0.5380 - val_loss: 2.0627 - val_accuracy: 0.3167\n",
            "Epoch 1638/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9917 - accuracy: 0.5403 - val_loss: 2.0838 - val_accuracy: 0.3181\n",
            "Epoch 1639/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9791 - accuracy: 0.5464 - val_loss: 2.0647 - val_accuracy: 0.3162\n",
            "Epoch 1640/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9772 - accuracy: 0.5481 - val_loss: 2.0788 - val_accuracy: 0.3138\n",
            "Epoch 1641/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9784 - accuracy: 0.5481 - val_loss: 2.0667 - val_accuracy: 0.3134\n",
            "Epoch 1642/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9784 - accuracy: 0.5497 - val_loss: 2.0822 - val_accuracy: 0.3163\n",
            "Epoch 1643/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9865 - accuracy: 0.5451 - val_loss: 2.0621 - val_accuracy: 0.3134\n",
            "Epoch 1644/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9786 - accuracy: 0.5481 - val_loss: 2.0814 - val_accuracy: 0.3133\n",
            "Epoch 1645/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9709 - accuracy: 0.5509 - val_loss: 2.0791 - val_accuracy: 0.3120\n",
            "Epoch 1646/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9694 - accuracy: 0.5521 - val_loss: 2.0987 - val_accuracy: 0.3162\n",
            "Epoch 1647/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9670 - accuracy: 0.5525 - val_loss: 2.0938 - val_accuracy: 0.3108\n",
            "Epoch 1648/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9788 - accuracy: 0.5461 - val_loss: 2.0790 - val_accuracy: 0.3125\n",
            "Epoch 1649/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9745 - accuracy: 0.5482 - val_loss: 2.0821 - val_accuracy: 0.3094\n",
            "Epoch 1650/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9817 - accuracy: 0.5431 - val_loss: 2.1020 - val_accuracy: 0.3122\n",
            "Epoch 1651/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9843 - accuracy: 0.5420 - val_loss: 2.0676 - val_accuracy: 0.3154\n",
            "Epoch 1652/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9950 - accuracy: 0.5381 - val_loss: 2.0700 - val_accuracy: 0.3198\n",
            "Epoch 1653/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9839 - accuracy: 0.5458 - val_loss: 2.0721 - val_accuracy: 0.3145\n",
            "Epoch 1654/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9758 - accuracy: 0.5469 - val_loss: 2.0761 - val_accuracy: 0.3121\n",
            "Epoch 1655/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9740 - accuracy: 0.5486 - val_loss: 2.0647 - val_accuracy: 0.3150\n",
            "Epoch 1656/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9702 - accuracy: 0.5519 - val_loss: 2.0855 - val_accuracy: 0.3163\n",
            "Epoch 1657/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9680 - accuracy: 0.5523 - val_loss: 2.0698 - val_accuracy: 0.3186\n",
            "Epoch 1658/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9658 - accuracy: 0.5529 - val_loss: 2.0840 - val_accuracy: 0.3168\n",
            "Epoch 1659/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9643 - accuracy: 0.5550 - val_loss: 2.0752 - val_accuracy: 0.3168\n",
            "Epoch 1660/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9597 - accuracy: 0.5572 - val_loss: 2.0867 - val_accuracy: 0.3143\n",
            "Epoch 1661/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9617 - accuracy: 0.5550 - val_loss: 2.0831 - val_accuracy: 0.3158\n",
            "Epoch 1662/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9708 - accuracy: 0.5519 - val_loss: 2.0817 - val_accuracy: 0.3193\n",
            "Epoch 1663/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9737 - accuracy: 0.5487 - val_loss: 2.0897 - val_accuracy: 0.3156\n",
            "Epoch 1664/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9739 - accuracy: 0.5492 - val_loss: 2.0955 - val_accuracy: 0.3175\n",
            "Epoch 1665/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9727 - accuracy: 0.5498 - val_loss: 2.0826 - val_accuracy: 0.3131\n",
            "Epoch 1666/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9729 - accuracy: 0.5485 - val_loss: 2.0934 - val_accuracy: 0.3164\n",
            "Epoch 1667/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9982 - accuracy: 0.5383 - val_loss: 2.0688 - val_accuracy: 0.3182\n",
            "Epoch 1668/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0055 - accuracy: 0.5354 - val_loss: 2.0684 - val_accuracy: 0.3172\n",
            "Epoch 1669/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0015 - accuracy: 0.5364 - val_loss: 2.0579 - val_accuracy: 0.3177\n",
            "Epoch 1670/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0041 - accuracy: 0.5355 - val_loss: 2.0559 - val_accuracy: 0.3172\n",
            "Epoch 1671/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0014 - accuracy: 0.5368 - val_loss: 2.0536 - val_accuracy: 0.3158\n",
            "Epoch 1672/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9886 - accuracy: 0.5416 - val_loss: 2.0506 - val_accuracy: 0.3185\n",
            "Epoch 1673/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9815 - accuracy: 0.5455 - val_loss: 2.0672 - val_accuracy: 0.3145\n",
            "Epoch 1674/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9870 - accuracy: 0.5444 - val_loss: 2.0566 - val_accuracy: 0.3176\n",
            "Epoch 1675/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9772 - accuracy: 0.5473 - val_loss: 2.0753 - val_accuracy: 0.3151\n",
            "Epoch 1676/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9643 - accuracy: 0.5541 - val_loss: 2.0650 - val_accuracy: 0.3164\n",
            "Epoch 1677/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9621 - accuracy: 0.5546 - val_loss: 2.0660 - val_accuracy: 0.3163\n",
            "Epoch 1678/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9659 - accuracy: 0.5526 - val_loss: 2.0642 - val_accuracy: 0.3169\n",
            "Epoch 1679/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9694 - accuracy: 0.5532 - val_loss: 2.0775 - val_accuracy: 0.3152\n",
            "Epoch 1680/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9764 - accuracy: 0.5482 - val_loss: 2.0700 - val_accuracy: 0.3173\n",
            "Epoch 1681/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9856 - accuracy: 0.5418 - val_loss: 2.0610 - val_accuracy: 0.3199\n",
            "Epoch 1682/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9859 - accuracy: 0.5424 - val_loss: 2.0694 - val_accuracy: 0.3151\n",
            "Epoch 1683/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9821 - accuracy: 0.5454 - val_loss: 2.0710 - val_accuracy: 0.3191\n",
            "Epoch 1684/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9804 - accuracy: 0.5467 - val_loss: 2.0638 - val_accuracy: 0.3174\n",
            "Epoch 1685/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9867 - accuracy: 0.5431 - val_loss: 2.0756 - val_accuracy: 0.3138\n",
            "Epoch 1686/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9922 - accuracy: 0.5411 - val_loss: 2.0576 - val_accuracy: 0.3153\n",
            "Epoch 1687/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9948 - accuracy: 0.5400 - val_loss: 2.0533 - val_accuracy: 0.3129\n",
            "Epoch 1688/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0011 - accuracy: 0.5371 - val_loss: 2.0633 - val_accuracy: 0.3156\n",
            "Epoch 1689/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0075 - accuracy: 0.5349 - val_loss: 2.0518 - val_accuracy: 0.3113\n",
            "Epoch 1690/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0072 - accuracy: 0.5337 - val_loss: 2.0402 - val_accuracy: 0.3171\n",
            "Epoch 1691/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0139 - accuracy: 0.5328 - val_loss: 2.0569 - val_accuracy: 0.3179\n",
            "Epoch 1692/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0217 - accuracy: 0.5270 - val_loss: 2.0320 - val_accuracy: 0.3133\n",
            "Epoch 1693/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0077 - accuracy: 0.5339 - val_loss: 2.0614 - val_accuracy: 0.3141\n",
            "Epoch 1694/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9892 - accuracy: 0.5422 - val_loss: 2.0584 - val_accuracy: 0.3083\n",
            "Epoch 1695/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9809 - accuracy: 0.5469 - val_loss: 2.0496 - val_accuracy: 0.3136\n",
            "Epoch 1696/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9691 - accuracy: 0.5524 - val_loss: 2.0696 - val_accuracy: 0.3094\n",
            "Epoch 1697/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9765 - accuracy: 0.5483 - val_loss: 2.0619 - val_accuracy: 0.3156\n",
            "Epoch 1698/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9883 - accuracy: 0.5413 - val_loss: 2.0629 - val_accuracy: 0.3118\n",
            "Epoch 1699/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9832 - accuracy: 0.5448 - val_loss: 2.0641 - val_accuracy: 0.3085\n",
            "Epoch 1700/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9695 - accuracy: 0.5513 - val_loss: 2.0710 - val_accuracy: 0.3140\n",
            "Epoch 1701/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9705 - accuracy: 0.5510 - val_loss: 2.0441 - val_accuracy: 0.3151\n",
            "Epoch 1702/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9957 - accuracy: 0.5382 - val_loss: 2.0590 - val_accuracy: 0.3157\n",
            "Epoch 1703/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9886 - accuracy: 0.5415 - val_loss: 2.0495 - val_accuracy: 0.3128\n",
            "Epoch 1704/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9810 - accuracy: 0.5458 - val_loss: 2.0591 - val_accuracy: 0.3113\n",
            "Epoch 1705/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9695 - accuracy: 0.5509 - val_loss: 2.0685 - val_accuracy: 0.3147\n",
            "Epoch 1706/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9716 - accuracy: 0.5498 - val_loss: 2.0736 - val_accuracy: 0.3135\n",
            "Epoch 1707/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9699 - accuracy: 0.5525 - val_loss: 2.0708 - val_accuracy: 0.3145\n",
            "Epoch 1708/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9614 - accuracy: 0.5551 - val_loss: 2.0743 - val_accuracy: 0.3107\n",
            "Epoch 1709/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9698 - accuracy: 0.5498 - val_loss: 2.0759 - val_accuracy: 0.3092\n",
            "Epoch 1710/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9748 - accuracy: 0.5487 - val_loss: 2.0733 - val_accuracy: 0.3162\n",
            "Epoch 1711/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9652 - accuracy: 0.5538 - val_loss: 2.0731 - val_accuracy: 0.3174\n",
            "Epoch 1712/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9608 - accuracy: 0.5555 - val_loss: 2.0948 - val_accuracy: 0.3153\n",
            "Epoch 1713/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9582 - accuracy: 0.5556 - val_loss: 2.0893 - val_accuracy: 0.3169\n",
            "Epoch 1714/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9666 - accuracy: 0.5528 - val_loss: 2.0669 - val_accuracy: 0.3189\n",
            "Epoch 1715/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9670 - accuracy: 0.5512 - val_loss: 2.0873 - val_accuracy: 0.3154\n",
            "Epoch 1716/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9712 - accuracy: 0.5501 - val_loss: 2.0756 - val_accuracy: 0.3175\n",
            "Epoch 1717/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9810 - accuracy: 0.5458 - val_loss: 2.0739 - val_accuracy: 0.3134\n",
            "Epoch 1718/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9784 - accuracy: 0.5459 - val_loss: 2.0755 - val_accuracy: 0.3133\n",
            "Epoch 1719/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9727 - accuracy: 0.5495 - val_loss: 2.0905 - val_accuracy: 0.3181\n",
            "Epoch 1720/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9724 - accuracy: 0.5498 - val_loss: 2.0730 - val_accuracy: 0.3145\n",
            "Epoch 1721/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9795 - accuracy: 0.5456 - val_loss: 2.0944 - val_accuracy: 0.3147\n",
            "Epoch 1722/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9983 - accuracy: 0.5384 - val_loss: 2.0710 - val_accuracy: 0.3154\n",
            "Epoch 1723/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9908 - accuracy: 0.5414 - val_loss: 2.0649 - val_accuracy: 0.3161\n",
            "Epoch 1724/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9805 - accuracy: 0.5476 - val_loss: 2.0769 - val_accuracy: 0.3174\n",
            "Epoch 1725/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9762 - accuracy: 0.5471 - val_loss: 2.0717 - val_accuracy: 0.3156\n",
            "Epoch 1726/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9763 - accuracy: 0.5471 - val_loss: 2.0705 - val_accuracy: 0.3137\n",
            "Epoch 1727/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9759 - accuracy: 0.5483 - val_loss: 2.0755 - val_accuracy: 0.3175\n",
            "Epoch 1728/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9658 - accuracy: 0.5521 - val_loss: 2.0831 - val_accuracy: 0.3112\n",
            "Epoch 1729/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9643 - accuracy: 0.5540 - val_loss: 2.0778 - val_accuracy: 0.3159\n",
            "Epoch 1730/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9624 - accuracy: 0.5545 - val_loss: 2.0966 - val_accuracy: 0.3126\n",
            "Epoch 1731/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9587 - accuracy: 0.5542 - val_loss: 2.1032 - val_accuracy: 0.3093\n",
            "Epoch 1732/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9590 - accuracy: 0.5550 - val_loss: 2.0931 - val_accuracy: 0.3151\n",
            "Epoch 1733/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9634 - accuracy: 0.5505 - val_loss: 2.1011 - val_accuracy: 0.3143\n",
            "Epoch 1734/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9697 - accuracy: 0.5502 - val_loss: 2.0897 - val_accuracy: 0.3134\n",
            "Epoch 1735/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9687 - accuracy: 0.5503 - val_loss: 2.0954 - val_accuracy: 0.3149\n",
            "Epoch 1736/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9590 - accuracy: 0.5562 - val_loss: 2.1078 - val_accuracy: 0.3148\n",
            "Epoch 1737/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9698 - accuracy: 0.5510 - val_loss: 2.1021 - val_accuracy: 0.3151\n",
            "Epoch 1738/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9698 - accuracy: 0.5521 - val_loss: 2.0976 - val_accuracy: 0.3142\n",
            "Epoch 1739/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9808 - accuracy: 0.5469 - val_loss: 2.1066 - val_accuracy: 0.3127\n",
            "Epoch 1740/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9749 - accuracy: 0.5497 - val_loss: 2.0999 - val_accuracy: 0.3153\n",
            "Epoch 1741/3000\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.9668 - accuracy: 0.5534 - val_loss: 2.1036 - val_accuracy: 0.3120\n",
            "Epoch 1742/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9615 - accuracy: 0.5562 - val_loss: 2.0978 - val_accuracy: 0.3163\n",
            "Epoch 1743/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9693 - accuracy: 0.5513 - val_loss: 2.1101 - val_accuracy: 0.3098\n",
            "Epoch 1744/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9717 - accuracy: 0.5495 - val_loss: 2.1000 - val_accuracy: 0.3121\n",
            "Epoch 1745/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9694 - accuracy: 0.5512 - val_loss: 2.1110 - val_accuracy: 0.3079\n",
            "Epoch 1746/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9685 - accuracy: 0.5528 - val_loss: 2.1005 - val_accuracy: 0.3109\n",
            "Epoch 1747/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9655 - accuracy: 0.5515 - val_loss: 2.0988 - val_accuracy: 0.3119\n",
            "Epoch 1748/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9613 - accuracy: 0.5560 - val_loss: 2.1098 - val_accuracy: 0.3105\n",
            "Epoch 1749/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9557 - accuracy: 0.5575 - val_loss: 2.0999 - val_accuracy: 0.3092\n",
            "Epoch 1750/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9559 - accuracy: 0.5565 - val_loss: 2.1065 - val_accuracy: 0.3070\n",
            "Epoch 1751/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9631 - accuracy: 0.5542 - val_loss: 2.1008 - val_accuracy: 0.3147\n",
            "Epoch 1752/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9616 - accuracy: 0.5539 - val_loss: 2.1187 - val_accuracy: 0.3110\n",
            "Epoch 1753/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9587 - accuracy: 0.5557 - val_loss: 2.1064 - val_accuracy: 0.3141\n",
            "Epoch 1754/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9587 - accuracy: 0.5558 - val_loss: 2.1107 - val_accuracy: 0.3131\n",
            "Epoch 1755/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9632 - accuracy: 0.5538 - val_loss: 2.0977 - val_accuracy: 0.3130\n",
            "Epoch 1756/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9622 - accuracy: 0.5549 - val_loss: 2.1122 - val_accuracy: 0.3083\n",
            "Epoch 1757/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9587 - accuracy: 0.5557 - val_loss: 2.1050 - val_accuracy: 0.3142\n",
            "Epoch 1758/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9640 - accuracy: 0.5542 - val_loss: 2.0989 - val_accuracy: 0.3138\n",
            "Epoch 1759/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9757 - accuracy: 0.5489 - val_loss: 2.1091 - val_accuracy: 0.3110\n",
            "Epoch 1760/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9672 - accuracy: 0.5532 - val_loss: 2.1104 - val_accuracy: 0.3159\n",
            "Epoch 1761/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9709 - accuracy: 0.5518 - val_loss: 2.1077 - val_accuracy: 0.3168\n",
            "Epoch 1762/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0110 - accuracy: 0.5331 - val_loss: 2.0767 - val_accuracy: 0.3162\n",
            "Epoch 1763/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0103 - accuracy: 0.5321 - val_loss: 2.0665 - val_accuracy: 0.3141\n",
            "Epoch 1764/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9887 - accuracy: 0.5414 - val_loss: 2.0940 - val_accuracy: 0.3129\n",
            "Epoch 1765/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9815 - accuracy: 0.5447 - val_loss: 2.0873 - val_accuracy: 0.3107\n",
            "Epoch 1766/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9700 - accuracy: 0.5502 - val_loss: 2.0902 - val_accuracy: 0.3136\n",
            "Epoch 1767/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9742 - accuracy: 0.5478 - val_loss: 2.1181 - val_accuracy: 0.3141\n",
            "Epoch 1768/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9831 - accuracy: 0.5446 - val_loss: 2.0882 - val_accuracy: 0.3121\n",
            "Epoch 1769/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9798 - accuracy: 0.5454 - val_loss: 2.0987 - val_accuracy: 0.3134\n",
            "Epoch 1770/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9788 - accuracy: 0.5456 - val_loss: 2.0995 - val_accuracy: 0.3147\n",
            "Epoch 1771/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9787 - accuracy: 0.5463 - val_loss: 2.1046 - val_accuracy: 0.3142\n",
            "Epoch 1772/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9863 - accuracy: 0.5442 - val_loss: 2.0858 - val_accuracy: 0.3173\n",
            "Epoch 1773/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9827 - accuracy: 0.5453 - val_loss: 2.0896 - val_accuracy: 0.3148\n",
            "Epoch 1774/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9762 - accuracy: 0.5486 - val_loss: 2.0892 - val_accuracy: 0.3157\n",
            "Epoch 1775/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9677 - accuracy: 0.5534 - val_loss: 2.1080 - val_accuracy: 0.3088\n",
            "Epoch 1776/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9728 - accuracy: 0.5497 - val_loss: 2.0989 - val_accuracy: 0.3123\n",
            "Epoch 1777/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9758 - accuracy: 0.5475 - val_loss: 2.0958 - val_accuracy: 0.3151\n",
            "Epoch 1778/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9774 - accuracy: 0.5485 - val_loss: 2.0903 - val_accuracy: 0.3181\n",
            "Epoch 1779/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9782 - accuracy: 0.5480 - val_loss: 2.1144 - val_accuracy: 0.3178\n",
            "Epoch 1780/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9814 - accuracy: 0.5455 - val_loss: 2.1042 - val_accuracy: 0.3140\n",
            "Epoch 1781/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9756 - accuracy: 0.5456 - val_loss: 2.1157 - val_accuracy: 0.3141\n",
            "Epoch 1782/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9891 - accuracy: 0.5404 - val_loss: 2.0889 - val_accuracy: 0.3189\n",
            "Epoch 1783/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9760 - accuracy: 0.5480 - val_loss: 2.1149 - val_accuracy: 0.3150\n",
            "Epoch 1784/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9711 - accuracy: 0.5499 - val_loss: 2.1026 - val_accuracy: 0.3163\n",
            "Epoch 1785/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9685 - accuracy: 0.5510 - val_loss: 2.1175 - val_accuracy: 0.3180\n",
            "Epoch 1786/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9692 - accuracy: 0.5502 - val_loss: 2.1092 - val_accuracy: 0.3176\n",
            "Epoch 1787/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9667 - accuracy: 0.5528 - val_loss: 2.1162 - val_accuracy: 0.3164\n",
            "Epoch 1788/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9726 - accuracy: 0.5498 - val_loss: 2.0972 - val_accuracy: 0.3163\n",
            "Epoch 1789/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9870 - accuracy: 0.5425 - val_loss: 2.1146 - val_accuracy: 0.3136\n",
            "Epoch 1790/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9911 - accuracy: 0.5413 - val_loss: 2.0847 - val_accuracy: 0.3174\n",
            "Epoch 1791/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9764 - accuracy: 0.5482 - val_loss: 2.0980 - val_accuracy: 0.3127\n",
            "Epoch 1792/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9682 - accuracy: 0.5527 - val_loss: 2.1050 - val_accuracy: 0.3143\n",
            "Epoch 1793/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9562 - accuracy: 0.5577 - val_loss: 2.1175 - val_accuracy: 0.3142\n",
            "Epoch 1794/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9500 - accuracy: 0.5605 - val_loss: 2.1119 - val_accuracy: 0.3100\n",
            "Epoch 1795/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9455 - accuracy: 0.5634 - val_loss: 2.1105 - val_accuracy: 0.3115\n",
            "Epoch 1796/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9481 - accuracy: 0.5627 - val_loss: 2.1149 - val_accuracy: 0.3128\n",
            "Epoch 1797/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9456 - accuracy: 0.5631 - val_loss: 2.1193 - val_accuracy: 0.3143\n",
            "Epoch 1798/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9522 - accuracy: 0.5575 - val_loss: 2.1240 - val_accuracy: 0.3143\n",
            "Epoch 1799/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9589 - accuracy: 0.5568 - val_loss: 2.1227 - val_accuracy: 0.3119\n",
            "Epoch 1800/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9560 - accuracy: 0.5567 - val_loss: 2.1184 - val_accuracy: 0.3186\n",
            "Epoch 1801/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9689 - accuracy: 0.5509 - val_loss: 2.1112 - val_accuracy: 0.3150\n",
            "Epoch 1802/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9805 - accuracy: 0.5476 - val_loss: 2.1205 - val_accuracy: 0.3159\n",
            "Epoch 1803/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9862 - accuracy: 0.5440 - val_loss: 2.1075 - val_accuracy: 0.3136\n",
            "Epoch 1804/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9811 - accuracy: 0.5488 - val_loss: 2.1021 - val_accuracy: 0.3149\n",
            "Epoch 1805/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9911 - accuracy: 0.5418 - val_loss: 2.1050 - val_accuracy: 0.3179\n",
            "Epoch 1806/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9875 - accuracy: 0.5447 - val_loss: 2.0936 - val_accuracy: 0.3183\n",
            "Epoch 1807/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0248 - accuracy: 0.5302 - val_loss: 2.0711 - val_accuracy: 0.3134\n",
            "Epoch 1808/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0890 - accuracy: 0.5066 - val_loss: 2.0730 - val_accuracy: 0.3182\n",
            "Epoch 1809/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0751 - accuracy: 0.5120 - val_loss: 2.0738 - val_accuracy: 0.3205\n",
            "Epoch 1810/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0402 - accuracy: 0.5207 - val_loss: 2.0600 - val_accuracy: 0.3207\n",
            "Epoch 1811/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0163 - accuracy: 0.5319 - val_loss: 2.0769 - val_accuracy: 0.3192\n",
            "Epoch 1812/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9995 - accuracy: 0.5383 - val_loss: 2.0863 - val_accuracy: 0.3183\n",
            "Epoch 1813/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9939 - accuracy: 0.5417 - val_loss: 2.0700 - val_accuracy: 0.3197\n",
            "Epoch 1814/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0228 - accuracy: 0.5321 - val_loss: 2.0696 - val_accuracy: 0.3187\n",
            "Epoch 1815/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0093 - accuracy: 0.5357 - val_loss: 2.0707 - val_accuracy: 0.3186\n",
            "Epoch 1816/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0115 - accuracy: 0.5343 - val_loss: 2.0619 - val_accuracy: 0.3147\n",
            "Epoch 1817/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9998 - accuracy: 0.5400 - val_loss: 2.0680 - val_accuracy: 0.3154\n",
            "Epoch 1818/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9903 - accuracy: 0.5448 - val_loss: 2.0729 - val_accuracy: 0.3194\n",
            "Epoch 1819/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9752 - accuracy: 0.5488 - val_loss: 2.0893 - val_accuracy: 0.3162\n",
            "Epoch 1820/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9722 - accuracy: 0.5504 - val_loss: 2.0704 - val_accuracy: 0.3174\n",
            "Epoch 1821/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9647 - accuracy: 0.5537 - val_loss: 2.0908 - val_accuracy: 0.3170\n",
            "Epoch 1822/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9590 - accuracy: 0.5569 - val_loss: 2.0859 - val_accuracy: 0.3122\n",
            "Epoch 1823/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9524 - accuracy: 0.5588 - val_loss: 2.0932 - val_accuracy: 0.3218\n",
            "Epoch 1824/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9511 - accuracy: 0.5601 - val_loss: 2.0944 - val_accuracy: 0.3151\n",
            "Epoch 1825/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9487 - accuracy: 0.5617 - val_loss: 2.0959 - val_accuracy: 0.3184\n",
            "Epoch 1826/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9475 - accuracy: 0.5623 - val_loss: 2.1230 - val_accuracy: 0.3163\n",
            "Epoch 1827/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9494 - accuracy: 0.5599 - val_loss: 2.1111 - val_accuracy: 0.3158\n",
            "Epoch 1828/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9608 - accuracy: 0.5560 - val_loss: 2.1102 - val_accuracy: 0.3153\n",
            "Epoch 1829/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9672 - accuracy: 0.5514 - val_loss: 2.1029 - val_accuracy: 0.3151\n",
            "Epoch 1830/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9637 - accuracy: 0.5534 - val_loss: 2.1067 - val_accuracy: 0.3151\n",
            "Epoch 1831/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9669 - accuracy: 0.5534 - val_loss: 2.1082 - val_accuracy: 0.3155\n",
            "Epoch 1832/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9715 - accuracy: 0.5489 - val_loss: 2.1179 - val_accuracy: 0.3136\n",
            "Epoch 1833/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9669 - accuracy: 0.5541 - val_loss: 2.1083 - val_accuracy: 0.3140\n",
            "Epoch 1834/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9576 - accuracy: 0.5566 - val_loss: 2.1181 - val_accuracy: 0.3130\n",
            "Epoch 1835/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9573 - accuracy: 0.5571 - val_loss: 2.0912 - val_accuracy: 0.3171\n",
            "Epoch 1836/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9677 - accuracy: 0.5507 - val_loss: 2.1157 - val_accuracy: 0.3110\n",
            "Epoch 1837/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9792 - accuracy: 0.5449 - val_loss: 2.1145 - val_accuracy: 0.3116\n",
            "Epoch 1838/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9819 - accuracy: 0.5469 - val_loss: 2.0934 - val_accuracy: 0.3156\n",
            "Epoch 1839/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9903 - accuracy: 0.5445 - val_loss: 2.0886 - val_accuracy: 0.3161\n",
            "Epoch 1840/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9924 - accuracy: 0.5428 - val_loss: 2.0956 - val_accuracy: 0.3163\n",
            "Epoch 1841/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9803 - accuracy: 0.5475 - val_loss: 2.0923 - val_accuracy: 0.3181\n",
            "Epoch 1842/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9587 - accuracy: 0.5578 - val_loss: 2.1166 - val_accuracy: 0.3118\n",
            "Epoch 1843/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9538 - accuracy: 0.5596 - val_loss: 2.1214 - val_accuracy: 0.3101\n",
            "Epoch 1844/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9582 - accuracy: 0.5557 - val_loss: 2.1255 - val_accuracy: 0.3112\n",
            "Epoch 1845/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9637 - accuracy: 0.5537 - val_loss: 2.1276 - val_accuracy: 0.3150\n",
            "Epoch 1846/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9909 - accuracy: 0.5432 - val_loss: 2.1044 - val_accuracy: 0.3175\n",
            "Epoch 1847/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9906 - accuracy: 0.5457 - val_loss: 2.1218 - val_accuracy: 0.3154\n",
            "Epoch 1848/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9801 - accuracy: 0.5472 - val_loss: 2.1128 - val_accuracy: 0.3166\n",
            "Epoch 1849/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9696 - accuracy: 0.5494 - val_loss: 2.1111 - val_accuracy: 0.3166\n",
            "Epoch 1850/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9744 - accuracy: 0.5492 - val_loss: 2.1214 - val_accuracy: 0.3194\n",
            "Epoch 1851/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9696 - accuracy: 0.5524 - val_loss: 2.1004 - val_accuracy: 0.3162\n",
            "Epoch 1852/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9724 - accuracy: 0.5504 - val_loss: 2.0946 - val_accuracy: 0.3184\n",
            "Epoch 1853/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9698 - accuracy: 0.5511 - val_loss: 2.1079 - val_accuracy: 0.3160\n",
            "Epoch 1854/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9724 - accuracy: 0.5500 - val_loss: 2.0997 - val_accuracy: 0.3157\n",
            "Epoch 1855/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9647 - accuracy: 0.5538 - val_loss: 2.1087 - val_accuracy: 0.3194\n",
            "Epoch 1856/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9594 - accuracy: 0.5576 - val_loss: 2.1041 - val_accuracy: 0.3201\n",
            "Epoch 1857/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9504 - accuracy: 0.5604 - val_loss: 2.1169 - val_accuracy: 0.3177\n",
            "Epoch 1858/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9529 - accuracy: 0.5591 - val_loss: 2.1069 - val_accuracy: 0.3225\n",
            "Epoch 1859/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9533 - accuracy: 0.5594 - val_loss: 2.1163 - val_accuracy: 0.3183\n",
            "Epoch 1860/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9494 - accuracy: 0.5606 - val_loss: 2.1222 - val_accuracy: 0.3170\n",
            "Epoch 1861/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9444 - accuracy: 0.5633 - val_loss: 2.1016 - val_accuracy: 0.3201\n",
            "Epoch 1862/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9438 - accuracy: 0.5643 - val_loss: 2.1191 - val_accuracy: 0.3138\n",
            "Epoch 1863/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9482 - accuracy: 0.5623 - val_loss: 2.1297 - val_accuracy: 0.3166\n",
            "Epoch 1864/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9445 - accuracy: 0.5623 - val_loss: 2.1352 - val_accuracy: 0.3176\n",
            "Epoch 1865/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9511 - accuracy: 0.5590 - val_loss: 2.1310 - val_accuracy: 0.3151\n",
            "Epoch 1866/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9578 - accuracy: 0.5559 - val_loss: 2.1347 - val_accuracy: 0.3188\n",
            "Epoch 1867/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9621 - accuracy: 0.5545 - val_loss: 2.1167 - val_accuracy: 0.3167\n",
            "Epoch 1868/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9744 - accuracy: 0.5504 - val_loss: 2.1224 - val_accuracy: 0.3174\n",
            "Epoch 1869/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9714 - accuracy: 0.5506 - val_loss: 2.1181 - val_accuracy: 0.3184\n",
            "Epoch 1870/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9767 - accuracy: 0.5465 - val_loss: 2.1136 - val_accuracy: 0.3166\n",
            "Epoch 1871/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9873 - accuracy: 0.5412 - val_loss: 2.0951 - val_accuracy: 0.3174\n",
            "Epoch 1872/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9884 - accuracy: 0.5414 - val_loss: 2.0858 - val_accuracy: 0.3171\n",
            "Epoch 1873/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9747 - accuracy: 0.5510 - val_loss: 2.1099 - val_accuracy: 0.3201\n",
            "Epoch 1874/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9692 - accuracy: 0.5530 - val_loss: 2.1062 - val_accuracy: 0.3175\n",
            "Epoch 1875/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9717 - accuracy: 0.5535 - val_loss: 2.1066 - val_accuracy: 0.3177\n",
            "Epoch 1876/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9707 - accuracy: 0.5523 - val_loss: 2.1074 - val_accuracy: 0.3169\n",
            "Epoch 1877/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9609 - accuracy: 0.5546 - val_loss: 2.1136 - val_accuracy: 0.3181\n",
            "Epoch 1878/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9660 - accuracy: 0.5535 - val_loss: 2.1131 - val_accuracy: 0.3172\n",
            "Epoch 1879/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9578 - accuracy: 0.5568 - val_loss: 2.1018 - val_accuracy: 0.3163\n",
            "Epoch 1880/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9728 - accuracy: 0.5507 - val_loss: 2.1109 - val_accuracy: 0.3195\n",
            "Epoch 1881/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9742 - accuracy: 0.5503 - val_loss: 2.1011 - val_accuracy: 0.3204\n",
            "Epoch 1882/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9667 - accuracy: 0.5552 - val_loss: 2.1188 - val_accuracy: 0.3125\n",
            "Epoch 1883/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9614 - accuracy: 0.5567 - val_loss: 2.1275 - val_accuracy: 0.3169\n",
            "Epoch 1884/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9550 - accuracy: 0.5576 - val_loss: 2.1349 - val_accuracy: 0.3141\n",
            "Epoch 1885/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9679 - accuracy: 0.5523 - val_loss: 2.1253 - val_accuracy: 0.3132\n",
            "Epoch 1886/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9704 - accuracy: 0.5491 - val_loss: 2.1242 - val_accuracy: 0.3146\n",
            "Epoch 1887/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9812 - accuracy: 0.5461 - val_loss: 2.1028 - val_accuracy: 0.3186\n",
            "Epoch 1888/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9864 - accuracy: 0.5456 - val_loss: 2.1355 - val_accuracy: 0.3156\n",
            "Epoch 1889/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9788 - accuracy: 0.5488 - val_loss: 2.1114 - val_accuracy: 0.3172\n",
            "Epoch 1890/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9716 - accuracy: 0.5525 - val_loss: 2.1450 - val_accuracy: 0.3135\n",
            "Epoch 1891/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9815 - accuracy: 0.5497 - val_loss: 2.1204 - val_accuracy: 0.3125\n",
            "Epoch 1892/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9742 - accuracy: 0.5523 - val_loss: 2.1373 - val_accuracy: 0.3135\n",
            "Epoch 1893/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9688 - accuracy: 0.5529 - val_loss: 2.1257 - val_accuracy: 0.3140\n",
            "Epoch 1894/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9670 - accuracy: 0.5524 - val_loss: 2.1165 - val_accuracy: 0.3169\n",
            "Epoch 1895/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9739 - accuracy: 0.5496 - val_loss: 2.1201 - val_accuracy: 0.3169\n",
            "Epoch 1896/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9669 - accuracy: 0.5517 - val_loss: 2.1205 - val_accuracy: 0.3142\n",
            "Epoch 1897/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9611 - accuracy: 0.5568 - val_loss: 2.1212 - val_accuracy: 0.3147\n",
            "Epoch 1898/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9524 - accuracy: 0.5608 - val_loss: 2.1310 - val_accuracy: 0.3161\n",
            "Epoch 1899/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9535 - accuracy: 0.5586 - val_loss: 2.1262 - val_accuracy: 0.3177\n",
            "Epoch 1900/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9610 - accuracy: 0.5556 - val_loss: 2.1334 - val_accuracy: 0.3178\n",
            "Epoch 1901/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9593 - accuracy: 0.5564 - val_loss: 2.1299 - val_accuracy: 0.3200\n",
            "Epoch 1902/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9595 - accuracy: 0.5580 - val_loss: 2.1350 - val_accuracy: 0.3195\n",
            "Epoch 1903/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9674 - accuracy: 0.5532 - val_loss: 2.1254 - val_accuracy: 0.3140\n",
            "Epoch 1904/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9711 - accuracy: 0.5514 - val_loss: 2.1381 - val_accuracy: 0.3170\n",
            "Epoch 1905/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9758 - accuracy: 0.5495 - val_loss: 2.1229 - val_accuracy: 0.3164\n",
            "Epoch 1906/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9849 - accuracy: 0.5443 - val_loss: 2.1338 - val_accuracy: 0.3145\n",
            "Epoch 1907/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9715 - accuracy: 0.5517 - val_loss: 2.1311 - val_accuracy: 0.3153\n",
            "Epoch 1908/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9619 - accuracy: 0.5544 - val_loss: 2.1535 - val_accuracy: 0.3201\n",
            "Epoch 1909/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9587 - accuracy: 0.5574 - val_loss: 2.1415 - val_accuracy: 0.3115\n",
            "Epoch 1910/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9514 - accuracy: 0.5603 - val_loss: 2.1619 - val_accuracy: 0.3154\n",
            "Epoch 1911/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9637 - accuracy: 0.5554 - val_loss: 2.1169 - val_accuracy: 0.3179\n",
            "Epoch 1912/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9841 - accuracy: 0.5458 - val_loss: 2.1537 - val_accuracy: 0.3160\n",
            "Epoch 1913/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9870 - accuracy: 0.5439 - val_loss: 2.1254 - val_accuracy: 0.3133\n",
            "Epoch 1914/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9853 - accuracy: 0.5452 - val_loss: 2.1395 - val_accuracy: 0.3157\n",
            "Epoch 1915/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9825 - accuracy: 0.5473 - val_loss: 2.1343 - val_accuracy: 0.3113\n",
            "Epoch 1916/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9866 - accuracy: 0.5450 - val_loss: 2.1260 - val_accuracy: 0.3159\n",
            "Epoch 1917/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9895 - accuracy: 0.5434 - val_loss: 2.1258 - val_accuracy: 0.3127\n",
            "Epoch 1918/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9969 - accuracy: 0.5405 - val_loss: 2.1120 - val_accuracy: 0.3140\n",
            "Epoch 1919/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0020 - accuracy: 0.5385 - val_loss: 2.1000 - val_accuracy: 0.3159\n",
            "Epoch 1920/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0257 - accuracy: 0.5296 - val_loss: 2.1031 - val_accuracy: 0.3186\n",
            "Epoch 1921/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0141 - accuracy: 0.5334 - val_loss: 2.1006 - val_accuracy: 0.3134\n",
            "Epoch 1922/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0177 - accuracy: 0.5325 - val_loss: 2.1130 - val_accuracy: 0.3113\n",
            "Epoch 1923/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0143 - accuracy: 0.5338 - val_loss: 2.0801 - val_accuracy: 0.3198\n",
            "Epoch 1924/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9946 - accuracy: 0.5419 - val_loss: 2.0893 - val_accuracy: 0.3222\n",
            "Epoch 1925/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9737 - accuracy: 0.5504 - val_loss: 2.0962 - val_accuracy: 0.3170\n",
            "Epoch 1926/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9694 - accuracy: 0.5523 - val_loss: 2.0926 - val_accuracy: 0.3170\n",
            "Epoch 1927/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9568 - accuracy: 0.5576 - val_loss: 2.0918 - val_accuracy: 0.3146\n",
            "Epoch 1928/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9485 - accuracy: 0.5635 - val_loss: 2.1143 - val_accuracy: 0.3121\n",
            "Epoch 1929/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9719 - accuracy: 0.5518 - val_loss: 2.1073 - val_accuracy: 0.3182\n",
            "Epoch 1930/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9797 - accuracy: 0.5476 - val_loss: 2.0972 - val_accuracy: 0.3189\n",
            "Epoch 1931/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9695 - accuracy: 0.5501 - val_loss: 2.1083 - val_accuracy: 0.3150\n",
            "Epoch 1932/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9621 - accuracy: 0.5549 - val_loss: 2.1012 - val_accuracy: 0.3183\n",
            "Epoch 1933/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9555 - accuracy: 0.5580 - val_loss: 2.1115 - val_accuracy: 0.3166\n",
            "Epoch 1934/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9504 - accuracy: 0.5607 - val_loss: 2.1230 - val_accuracy: 0.3186\n",
            "Epoch 1935/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9582 - accuracy: 0.5565 - val_loss: 2.1219 - val_accuracy: 0.3165\n",
            "Epoch 1936/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9647 - accuracy: 0.5546 - val_loss: 2.1158 - val_accuracy: 0.3177\n",
            "Epoch 1937/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9629 - accuracy: 0.5541 - val_loss: 2.1103 - val_accuracy: 0.3150\n",
            "Epoch 1938/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9587 - accuracy: 0.5570 - val_loss: 2.1138 - val_accuracy: 0.3175\n",
            "Epoch 1939/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9539 - accuracy: 0.5601 - val_loss: 2.1045 - val_accuracy: 0.3196\n",
            "Epoch 1940/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9467 - accuracy: 0.5617 - val_loss: 2.1307 - val_accuracy: 0.3140\n",
            "Epoch 1941/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9488 - accuracy: 0.5609 - val_loss: 2.1126 - val_accuracy: 0.3123\n",
            "Epoch 1942/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9525 - accuracy: 0.5585 - val_loss: 2.1298 - val_accuracy: 0.3145\n",
            "Epoch 1943/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9468 - accuracy: 0.5614 - val_loss: 2.1141 - val_accuracy: 0.3151\n",
            "Epoch 1944/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9450 - accuracy: 0.5631 - val_loss: 2.1377 - val_accuracy: 0.3143\n",
            "Epoch 1945/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9408 - accuracy: 0.5640 - val_loss: 2.1317 - val_accuracy: 0.3173\n",
            "Epoch 1946/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9431 - accuracy: 0.5640 - val_loss: 2.1513 - val_accuracy: 0.3134\n",
            "Epoch 1947/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9512 - accuracy: 0.5592 - val_loss: 2.1323 - val_accuracy: 0.3153\n",
            "Epoch 1948/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9532 - accuracy: 0.5586 - val_loss: 2.1446 - val_accuracy: 0.3151\n",
            "Epoch 1949/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9507 - accuracy: 0.5608 - val_loss: 2.1514 - val_accuracy: 0.3129\n",
            "Epoch 1950/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9454 - accuracy: 0.5626 - val_loss: 2.1286 - val_accuracy: 0.3164\n",
            "Epoch 1951/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9509 - accuracy: 0.5603 - val_loss: 2.1418 - val_accuracy: 0.3161\n",
            "Epoch 1952/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9545 - accuracy: 0.5595 - val_loss: 2.1319 - val_accuracy: 0.3170\n",
            "Epoch 1953/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9552 - accuracy: 0.5574 - val_loss: 2.1367 - val_accuracy: 0.3153\n",
            "Epoch 1954/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9549 - accuracy: 0.5594 - val_loss: 2.1390 - val_accuracy: 0.3140\n",
            "Epoch 1955/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9552 - accuracy: 0.5580 - val_loss: 2.1398 - val_accuracy: 0.3190\n",
            "Epoch 1956/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9542 - accuracy: 0.5592 - val_loss: 2.1463 - val_accuracy: 0.3142\n",
            "Epoch 1957/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9479 - accuracy: 0.5621 - val_loss: 2.1329 - val_accuracy: 0.3146\n",
            "Epoch 1958/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9551 - accuracy: 0.5572 - val_loss: 2.1325 - val_accuracy: 0.3170\n",
            "Epoch 1959/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9671 - accuracy: 0.5522 - val_loss: 2.1389 - val_accuracy: 0.3164\n",
            "Epoch 1960/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9642 - accuracy: 0.5529 - val_loss: 2.1442 - val_accuracy: 0.3172\n",
            "Epoch 1961/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9682 - accuracy: 0.5540 - val_loss: 2.1606 - val_accuracy: 0.3144\n",
            "Epoch 1962/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9597 - accuracy: 0.5575 - val_loss: 2.1404 - val_accuracy: 0.3103\n",
            "Epoch 1963/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9680 - accuracy: 0.5540 - val_loss: 2.1556 - val_accuracy: 0.3101\n",
            "Epoch 1964/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9633 - accuracy: 0.5565 - val_loss: 2.1404 - val_accuracy: 0.3184\n",
            "Epoch 1965/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9641 - accuracy: 0.5567 - val_loss: 2.1360 - val_accuracy: 0.3145\n",
            "Epoch 1966/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9596 - accuracy: 0.5570 - val_loss: 2.1525 - val_accuracy: 0.3121\n",
            "Epoch 1967/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9602 - accuracy: 0.5572 - val_loss: 2.1338 - val_accuracy: 0.3133\n",
            "Epoch 1968/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9664 - accuracy: 0.5552 - val_loss: 2.1375 - val_accuracy: 0.3108\n",
            "Epoch 1969/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9765 - accuracy: 0.5481 - val_loss: 2.1202 - val_accuracy: 0.3178\n",
            "Epoch 1970/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9847 - accuracy: 0.5454 - val_loss: 2.1250 - val_accuracy: 0.3148\n",
            "Epoch 1971/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9895 - accuracy: 0.5451 - val_loss: 2.1141 - val_accuracy: 0.3107\n",
            "Epoch 1972/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9786 - accuracy: 0.5489 - val_loss: 2.1117 - val_accuracy: 0.3187\n",
            "Epoch 1973/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9770 - accuracy: 0.5500 - val_loss: 2.1344 - val_accuracy: 0.3125\n",
            "Epoch 1974/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9671 - accuracy: 0.5547 - val_loss: 2.1282 - val_accuracy: 0.3148\n",
            "Epoch 1975/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9572 - accuracy: 0.5591 - val_loss: 2.1458 - val_accuracy: 0.3112\n",
            "Epoch 1976/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9647 - accuracy: 0.5549 - val_loss: 2.1319 - val_accuracy: 0.3173\n",
            "Epoch 1977/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9707 - accuracy: 0.5527 - val_loss: 2.1378 - val_accuracy: 0.3174\n",
            "Epoch 1978/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9773 - accuracy: 0.5497 - val_loss: 2.1378 - val_accuracy: 0.3166\n",
            "Epoch 1979/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9727 - accuracy: 0.5512 - val_loss: 2.1332 - val_accuracy: 0.3113\n",
            "Epoch 1980/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9641 - accuracy: 0.5558 - val_loss: 2.1285 - val_accuracy: 0.3135\n",
            "Epoch 1981/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9625 - accuracy: 0.5560 - val_loss: 2.1473 - val_accuracy: 0.3104\n",
            "Epoch 1982/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9704 - accuracy: 0.5526 - val_loss: 2.1346 - val_accuracy: 0.3131\n",
            "Epoch 1983/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9695 - accuracy: 0.5549 - val_loss: 2.1671 - val_accuracy: 0.3121\n",
            "Epoch 1984/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9642 - accuracy: 0.5547 - val_loss: 2.1470 - val_accuracy: 0.3140\n",
            "Epoch 1985/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9640 - accuracy: 0.5543 - val_loss: 2.1452 - val_accuracy: 0.3146\n",
            "Epoch 1986/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9582 - accuracy: 0.5593 - val_loss: 2.1329 - val_accuracy: 0.3136\n",
            "Epoch 1987/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9794 - accuracy: 0.5485 - val_loss: 2.1373 - val_accuracy: 0.3130\n",
            "Epoch 1988/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9921 - accuracy: 0.5420 - val_loss: 2.1290 - val_accuracy: 0.3130\n",
            "Epoch 1989/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9746 - accuracy: 0.5491 - val_loss: 2.1308 - val_accuracy: 0.3127\n",
            "Epoch 1990/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9738 - accuracy: 0.5493 - val_loss: 2.1143 - val_accuracy: 0.3156\n",
            "Epoch 1991/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9748 - accuracy: 0.5489 - val_loss: 2.1191 - val_accuracy: 0.3172\n",
            "Epoch 1992/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9677 - accuracy: 0.5526 - val_loss: 2.1335 - val_accuracy: 0.3086\n",
            "Epoch 1993/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9569 - accuracy: 0.5578 - val_loss: 2.1158 - val_accuracy: 0.3165\n",
            "Epoch 1994/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9596 - accuracy: 0.5572 - val_loss: 2.1258 - val_accuracy: 0.3166\n",
            "Epoch 1995/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9604 - accuracy: 0.5542 - val_loss: 2.1268 - val_accuracy: 0.3153\n",
            "Epoch 1996/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9598 - accuracy: 0.5551 - val_loss: 2.1316 - val_accuracy: 0.3133\n",
            "Epoch 1997/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9680 - accuracy: 0.5510 - val_loss: 2.1221 - val_accuracy: 0.3131\n",
            "Epoch 1998/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9593 - accuracy: 0.5570 - val_loss: 2.1285 - val_accuracy: 0.3092\n",
            "Epoch 1999/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9642 - accuracy: 0.5542 - val_loss: 2.1411 - val_accuracy: 0.3150\n",
            "Epoch 2000/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9547 - accuracy: 0.5594 - val_loss: 2.1502 - val_accuracy: 0.3119\n",
            "Epoch 2001/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9527 - accuracy: 0.5594 - val_loss: 2.1616 - val_accuracy: 0.3091\n",
            "Epoch 2002/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9623 - accuracy: 0.5545 - val_loss: 2.1487 - val_accuracy: 0.3147\n",
            "Epoch 2003/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9708 - accuracy: 0.5511 - val_loss: 2.1497 - val_accuracy: 0.3105\n",
            "Epoch 2004/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9888 - accuracy: 0.5446 - val_loss: 2.1389 - val_accuracy: 0.3117\n",
            "Epoch 2005/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9845 - accuracy: 0.5464 - val_loss: 2.1472 - val_accuracy: 0.3126\n",
            "Epoch 2006/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9808 - accuracy: 0.5494 - val_loss: 2.1267 - val_accuracy: 0.3109\n",
            "Epoch 2007/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9806 - accuracy: 0.5499 - val_loss: 2.1216 - val_accuracy: 0.3092\n",
            "Epoch 2008/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9622 - accuracy: 0.5577 - val_loss: 2.1392 - val_accuracy: 0.3131\n",
            "Epoch 2009/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9611 - accuracy: 0.5592 - val_loss: 2.1342 - val_accuracy: 0.3122\n",
            "Epoch 2010/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9640 - accuracy: 0.5561 - val_loss: 2.1335 - val_accuracy: 0.3073\n",
            "Epoch 2011/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9548 - accuracy: 0.5609 - val_loss: 2.1379 - val_accuracy: 0.3109\n",
            "Epoch 2012/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9523 - accuracy: 0.5627 - val_loss: 2.1599 - val_accuracy: 0.3113\n",
            "Epoch 2013/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9521 - accuracy: 0.5629 - val_loss: 2.1567 - val_accuracy: 0.3102\n",
            "Epoch 2014/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9512 - accuracy: 0.5610 - val_loss: 2.1499 - val_accuracy: 0.3072\n",
            "Epoch 2015/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9534 - accuracy: 0.5610 - val_loss: 2.1559 - val_accuracy: 0.3088\n",
            "Epoch 2016/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9491 - accuracy: 0.5625 - val_loss: 2.1467 - val_accuracy: 0.3086\n",
            "Epoch 2017/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9493 - accuracy: 0.5617 - val_loss: 2.1656 - val_accuracy: 0.3117\n",
            "Epoch 2018/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9503 - accuracy: 0.5628 - val_loss: 2.1611 - val_accuracy: 0.3089\n",
            "Epoch 2019/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9492 - accuracy: 0.5639 - val_loss: 2.1647 - val_accuracy: 0.3094\n",
            "Epoch 2020/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9448 - accuracy: 0.5657 - val_loss: 2.1613 - val_accuracy: 0.3091\n",
            "Epoch 2021/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9505 - accuracy: 0.5638 - val_loss: 2.1700 - val_accuracy: 0.3075\n",
            "Epoch 2022/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9757 - accuracy: 0.5512 - val_loss: 2.1435 - val_accuracy: 0.3133\n",
            "Epoch 2023/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9681 - accuracy: 0.5551 - val_loss: 2.1544 - val_accuracy: 0.3151\n",
            "Epoch 2024/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9590 - accuracy: 0.5599 - val_loss: 2.1394 - val_accuracy: 0.3148\n",
            "Epoch 2025/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9678 - accuracy: 0.5530 - val_loss: 2.1537 - val_accuracy: 0.3151\n",
            "Epoch 2026/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9731 - accuracy: 0.5526 - val_loss: 2.1688 - val_accuracy: 0.3110\n",
            "Epoch 2027/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9630 - accuracy: 0.5565 - val_loss: 2.1596 - val_accuracy: 0.3118\n",
            "Epoch 2028/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9654 - accuracy: 0.5548 - val_loss: 2.1597 - val_accuracy: 0.3103\n",
            "Epoch 2029/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9724 - accuracy: 0.5517 - val_loss: 2.1582 - val_accuracy: 0.3087\n",
            "Epoch 2030/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9641 - accuracy: 0.5557 - val_loss: 2.1512 - val_accuracy: 0.3115\n",
            "Epoch 2031/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9626 - accuracy: 0.5574 - val_loss: 2.1580 - val_accuracy: 0.3094\n",
            "Epoch 2032/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9633 - accuracy: 0.5575 - val_loss: 2.1771 - val_accuracy: 0.3110\n",
            "Epoch 2033/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9586 - accuracy: 0.5586 - val_loss: 2.1430 - val_accuracy: 0.3107\n",
            "Epoch 2034/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9583 - accuracy: 0.5586 - val_loss: 2.1786 - val_accuracy: 0.3086\n",
            "Epoch 2035/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9520 - accuracy: 0.5612 - val_loss: 2.1599 - val_accuracy: 0.3080\n",
            "Epoch 2036/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9432 - accuracy: 0.5680 - val_loss: 2.1757 - val_accuracy: 0.3089\n",
            "Epoch 2037/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9462 - accuracy: 0.5635 - val_loss: 2.1650 - val_accuracy: 0.3121\n",
            "Epoch 2038/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9474 - accuracy: 0.5632 - val_loss: 2.1673 - val_accuracy: 0.3125\n",
            "Epoch 2039/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9396 - accuracy: 0.5660 - val_loss: 2.1700 - val_accuracy: 0.3057\n",
            "Epoch 2040/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9381 - accuracy: 0.5678 - val_loss: 2.1645 - val_accuracy: 0.3098\n",
            "Epoch 2041/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9486 - accuracy: 0.5624 - val_loss: 2.1554 - val_accuracy: 0.3110\n",
            "Epoch 2042/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9507 - accuracy: 0.5613 - val_loss: 2.1779 - val_accuracy: 0.3084\n",
            "Epoch 2043/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9520 - accuracy: 0.5618 - val_loss: 2.1724 - val_accuracy: 0.3078\n",
            "Epoch 2044/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9503 - accuracy: 0.5617 - val_loss: 2.1658 - val_accuracy: 0.3085\n",
            "Epoch 2045/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9534 - accuracy: 0.5616 - val_loss: 2.1558 - val_accuracy: 0.3088\n",
            "Epoch 2046/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9528 - accuracy: 0.5614 - val_loss: 2.1699 - val_accuracy: 0.3044\n",
            "Epoch 2047/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9530 - accuracy: 0.5608 - val_loss: 2.1785 - val_accuracy: 0.3075\n",
            "Epoch 2048/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9543 - accuracy: 0.5595 - val_loss: 2.1533 - val_accuracy: 0.3136\n",
            "Epoch 2049/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9563 - accuracy: 0.5584 - val_loss: 2.1741 - val_accuracy: 0.3109\n",
            "Epoch 2050/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9562 - accuracy: 0.5583 - val_loss: 2.1697 - val_accuracy: 0.3094\n",
            "Epoch 2051/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9498 - accuracy: 0.5614 - val_loss: 2.1622 - val_accuracy: 0.3107\n",
            "Epoch 2052/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9394 - accuracy: 0.5665 - val_loss: 2.1638 - val_accuracy: 0.3118\n",
            "Epoch 2053/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9439 - accuracy: 0.5646 - val_loss: 2.1610 - val_accuracy: 0.3092\n",
            "Epoch 2054/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9516 - accuracy: 0.5611 - val_loss: 2.1614 - val_accuracy: 0.3136\n",
            "Epoch 2055/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0054 - accuracy: 0.5387 - val_loss: 2.1383 - val_accuracy: 0.3157\n",
            "Epoch 2056/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0514 - accuracy: 0.5206 - val_loss: 2.1218 - val_accuracy: 0.3150\n",
            "Epoch 2057/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0372 - accuracy: 0.5288 - val_loss: 2.1118 - val_accuracy: 0.3148\n",
            "Epoch 2058/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0686 - accuracy: 0.5173 - val_loss: 2.0786 - val_accuracy: 0.3152\n",
            "Epoch 2059/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0550 - accuracy: 0.5189 - val_loss: 2.1048 - val_accuracy: 0.3129\n",
            "Epoch 2060/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0564 - accuracy: 0.5175 - val_loss: 2.0843 - val_accuracy: 0.3160\n",
            "Epoch 2061/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0524 - accuracy: 0.5198 - val_loss: 2.0803 - val_accuracy: 0.3133\n",
            "Epoch 2062/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0303 - accuracy: 0.5265 - val_loss: 2.0929 - val_accuracy: 0.3140\n",
            "Epoch 2063/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9988 - accuracy: 0.5393 - val_loss: 2.0947 - val_accuracy: 0.3166\n",
            "Epoch 2064/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9906 - accuracy: 0.5438 - val_loss: 2.1063 - val_accuracy: 0.3122\n",
            "Epoch 2065/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9871 - accuracy: 0.5447 - val_loss: 2.1026 - val_accuracy: 0.3144\n",
            "Epoch 2066/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9846 - accuracy: 0.5475 - val_loss: 2.1029 - val_accuracy: 0.3155\n",
            "Epoch 2067/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9819 - accuracy: 0.5480 - val_loss: 2.1182 - val_accuracy: 0.3190\n",
            "Epoch 2068/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9877 - accuracy: 0.5446 - val_loss: 2.1159 - val_accuracy: 0.3144\n",
            "Epoch 2069/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0006 - accuracy: 0.5395 - val_loss: 2.1150 - val_accuracy: 0.3146\n",
            "Epoch 2070/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9858 - accuracy: 0.5468 - val_loss: 2.1303 - val_accuracy: 0.3087\n",
            "Epoch 2071/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9820 - accuracy: 0.5489 - val_loss: 2.1191 - val_accuracy: 0.3141\n",
            "Epoch 2072/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9859 - accuracy: 0.5466 - val_loss: 2.1188 - val_accuracy: 0.3095\n",
            "Epoch 2073/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9778 - accuracy: 0.5497 - val_loss: 2.1157 - val_accuracy: 0.3130\n",
            "Epoch 2074/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9665 - accuracy: 0.5556 - val_loss: 2.1144 - val_accuracy: 0.3100\n",
            "Epoch 2075/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9634 - accuracy: 0.5563 - val_loss: 2.1286 - val_accuracy: 0.3109\n",
            "Epoch 2076/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9663 - accuracy: 0.5557 - val_loss: 2.1253 - val_accuracy: 0.3098\n",
            "Epoch 2077/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9749 - accuracy: 0.5510 - val_loss: 2.1382 - val_accuracy: 0.3102\n",
            "Epoch 2078/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9743 - accuracy: 0.5505 - val_loss: 2.0930 - val_accuracy: 0.3168\n",
            "Epoch 2079/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9670 - accuracy: 0.5537 - val_loss: 2.1221 - val_accuracy: 0.3131\n",
            "Epoch 2080/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9681 - accuracy: 0.5546 - val_loss: 2.1088 - val_accuracy: 0.3100\n",
            "Epoch 2081/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9610 - accuracy: 0.5582 - val_loss: 2.1256 - val_accuracy: 0.3133\n",
            "Epoch 2082/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9569 - accuracy: 0.5598 - val_loss: 2.1349 - val_accuracy: 0.3150\n",
            "Epoch 2083/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9552 - accuracy: 0.5599 - val_loss: 2.1377 - val_accuracy: 0.3135\n",
            "Epoch 2084/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9783 - accuracy: 0.5514 - val_loss: 2.1173 - val_accuracy: 0.3106\n",
            "Epoch 2085/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9740 - accuracy: 0.5514 - val_loss: 2.1454 - val_accuracy: 0.3079\n",
            "Epoch 2086/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9936 - accuracy: 0.5430 - val_loss: 2.1098 - val_accuracy: 0.3110\n",
            "Epoch 2087/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0026 - accuracy: 0.5391 - val_loss: 2.1446 - val_accuracy: 0.3131\n",
            "Epoch 2088/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9925 - accuracy: 0.5438 - val_loss: 2.1065 - val_accuracy: 0.3145\n",
            "Epoch 2089/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9747 - accuracy: 0.5506 - val_loss: 2.1188 - val_accuracy: 0.3138\n",
            "Epoch 2090/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9670 - accuracy: 0.5533 - val_loss: 2.1165 - val_accuracy: 0.3122\n",
            "Epoch 2091/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9735 - accuracy: 0.5514 - val_loss: 2.1246 - val_accuracy: 0.3103\n",
            "Epoch 2092/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9805 - accuracy: 0.5486 - val_loss: 2.1097 - val_accuracy: 0.3113\n",
            "Epoch 2093/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9723 - accuracy: 0.5533 - val_loss: 2.1366 - val_accuracy: 0.3121\n",
            "Epoch 2094/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9664 - accuracy: 0.5555 - val_loss: 2.1419 - val_accuracy: 0.3133\n",
            "Epoch 2095/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9659 - accuracy: 0.5558 - val_loss: 2.1406 - val_accuracy: 0.3146\n",
            "Epoch 2096/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9688 - accuracy: 0.5567 - val_loss: 2.1391 - val_accuracy: 0.3128\n",
            "Epoch 2097/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9595 - accuracy: 0.5603 - val_loss: 2.1420 - val_accuracy: 0.3091\n",
            "Epoch 2098/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9498 - accuracy: 0.5638 - val_loss: 2.1388 - val_accuracy: 0.3139\n",
            "Epoch 2099/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9399 - accuracy: 0.5675 - val_loss: 2.1517 - val_accuracy: 0.3112\n",
            "Epoch 2100/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9382 - accuracy: 0.5683 - val_loss: 2.1588 - val_accuracy: 0.3103\n",
            "Epoch 2101/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9358 - accuracy: 0.5691 - val_loss: 2.1622 - val_accuracy: 0.3129\n",
            "Epoch 2102/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9409 - accuracy: 0.5658 - val_loss: 2.1630 - val_accuracy: 0.3124\n",
            "Epoch 2103/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9440 - accuracy: 0.5643 - val_loss: 2.1518 - val_accuracy: 0.3139\n",
            "Epoch 2104/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9331 - accuracy: 0.5705 - val_loss: 2.1695 - val_accuracy: 0.3128\n",
            "Epoch 2105/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9323 - accuracy: 0.5708 - val_loss: 2.1530 - val_accuracy: 0.3112\n",
            "Epoch 2106/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9446 - accuracy: 0.5645 - val_loss: 2.1719 - val_accuracy: 0.3139\n",
            "Epoch 2107/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9616 - accuracy: 0.5551 - val_loss: 2.1699 - val_accuracy: 0.3157\n",
            "Epoch 2108/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9642 - accuracy: 0.5544 - val_loss: 2.1754 - val_accuracy: 0.3139\n",
            "Epoch 2109/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9540 - accuracy: 0.5599 - val_loss: 2.1585 - val_accuracy: 0.3120\n",
            "Epoch 2110/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9757 - accuracy: 0.5507 - val_loss: 2.1487 - val_accuracy: 0.3101\n",
            "Epoch 2111/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9791 - accuracy: 0.5496 - val_loss: 2.1420 - val_accuracy: 0.3133\n",
            "Epoch 2112/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9801 - accuracy: 0.5458 - val_loss: 2.1480 - val_accuracy: 0.3103\n",
            "Epoch 2113/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9863 - accuracy: 0.5455 - val_loss: 2.1308 - val_accuracy: 0.3131\n",
            "Epoch 2114/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9814 - accuracy: 0.5472 - val_loss: 2.1480 - val_accuracy: 0.3131\n",
            "Epoch 2115/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9779 - accuracy: 0.5480 - val_loss: 2.1555 - val_accuracy: 0.3157\n",
            "Epoch 2116/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9829 - accuracy: 0.5457 - val_loss: 2.1427 - val_accuracy: 0.3107\n",
            "Epoch 2117/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9777 - accuracy: 0.5498 - val_loss: 2.1327 - val_accuracy: 0.3100\n",
            "Epoch 2118/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9764 - accuracy: 0.5495 - val_loss: 2.1456 - val_accuracy: 0.3122\n",
            "Epoch 2119/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9787 - accuracy: 0.5492 - val_loss: 2.1205 - val_accuracy: 0.3124\n",
            "Epoch 2120/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9715 - accuracy: 0.5537 - val_loss: 2.1402 - val_accuracy: 0.3118\n",
            "Epoch 2121/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9805 - accuracy: 0.5480 - val_loss: 2.1333 - val_accuracy: 0.3093\n",
            "Epoch 2122/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9820 - accuracy: 0.5483 - val_loss: 2.1318 - val_accuracy: 0.3065\n",
            "Epoch 2123/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9694 - accuracy: 0.5520 - val_loss: 2.1327 - val_accuracy: 0.3116\n",
            "Epoch 2124/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9605 - accuracy: 0.5560 - val_loss: 2.1512 - val_accuracy: 0.3065\n",
            "Epoch 2125/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9545 - accuracy: 0.5602 - val_loss: 2.1379 - val_accuracy: 0.3082\n",
            "Epoch 2126/3000\n",
            "16/16 [==============================] - 1s 31ms/step - loss: 0.9510 - accuracy: 0.5621 - val_loss: 2.1403 - val_accuracy: 0.3121\n",
            "Epoch 2127/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9737 - accuracy: 0.5522 - val_loss: 2.1297 - val_accuracy: 0.3124\n",
            "Epoch 2128/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9950 - accuracy: 0.5423 - val_loss: 2.1359 - val_accuracy: 0.3124\n",
            "Epoch 2129/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9861 - accuracy: 0.5455 - val_loss: 2.1223 - val_accuracy: 0.3119\n",
            "Epoch 2130/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9631 - accuracy: 0.5570 - val_loss: 2.1514 - val_accuracy: 0.3118\n",
            "Epoch 2131/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9540 - accuracy: 0.5620 - val_loss: 2.1496 - val_accuracy: 0.3140\n",
            "Epoch 2132/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9475 - accuracy: 0.5641 - val_loss: 2.1549 - val_accuracy: 0.3098\n",
            "Epoch 2133/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9532 - accuracy: 0.5617 - val_loss: 2.1445 - val_accuracy: 0.3127\n",
            "Epoch 2134/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9513 - accuracy: 0.5614 - val_loss: 2.1622 - val_accuracy: 0.3073\n",
            "Epoch 2135/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9449 - accuracy: 0.5648 - val_loss: 2.1601 - val_accuracy: 0.3125\n",
            "Epoch 2136/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9464 - accuracy: 0.5647 - val_loss: 2.1625 - val_accuracy: 0.3084\n",
            "Epoch 2137/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9413 - accuracy: 0.5668 - val_loss: 2.1665 - val_accuracy: 0.3125\n",
            "Epoch 2138/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9532 - accuracy: 0.5602 - val_loss: 2.1560 - val_accuracy: 0.3103\n",
            "Epoch 2139/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9495 - accuracy: 0.5624 - val_loss: 2.1563 - val_accuracy: 0.3097\n",
            "Epoch 2140/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9440 - accuracy: 0.5649 - val_loss: 2.1610 - val_accuracy: 0.3104\n",
            "Epoch 2141/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9438 - accuracy: 0.5648 - val_loss: 2.1620 - val_accuracy: 0.3119\n",
            "Epoch 2142/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9425 - accuracy: 0.5674 - val_loss: 2.1770 - val_accuracy: 0.3092\n",
            "Epoch 2143/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9390 - accuracy: 0.5665 - val_loss: 2.1568 - val_accuracy: 0.3116\n",
            "Epoch 2144/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9400 - accuracy: 0.5671 - val_loss: 2.1739 - val_accuracy: 0.3123\n",
            "Epoch 2145/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9467 - accuracy: 0.5636 - val_loss: 2.1718 - val_accuracy: 0.3094\n",
            "Epoch 2146/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9472 - accuracy: 0.5632 - val_loss: 2.1644 - val_accuracy: 0.3060\n",
            "Epoch 2147/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9457 - accuracy: 0.5642 - val_loss: 2.1682 - val_accuracy: 0.3108\n",
            "Epoch 2148/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9471 - accuracy: 0.5633 - val_loss: 2.1789 - val_accuracy: 0.3077\n",
            "Epoch 2149/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9466 - accuracy: 0.5601 - val_loss: 2.1676 - val_accuracy: 0.3077\n",
            "Epoch 2150/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9473 - accuracy: 0.5630 - val_loss: 2.1745 - val_accuracy: 0.3074\n",
            "Epoch 2151/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9485 - accuracy: 0.5625 - val_loss: 2.1683 - val_accuracy: 0.3112\n",
            "Epoch 2152/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9466 - accuracy: 0.5634 - val_loss: 2.1673 - val_accuracy: 0.3116\n",
            "Epoch 2153/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9494 - accuracy: 0.5632 - val_loss: 2.1682 - val_accuracy: 0.3098\n",
            "Epoch 2154/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9625 - accuracy: 0.5557 - val_loss: 2.1588 - val_accuracy: 0.3103\n",
            "Epoch 2155/3000\n",
            "16/16 [==============================] - 1s 31ms/step - loss: 0.9762 - accuracy: 0.5515 - val_loss: 2.1723 - val_accuracy: 0.3108\n",
            "Epoch 2156/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9682 - accuracy: 0.5540 - val_loss: 2.1633 - val_accuracy: 0.3119\n",
            "Epoch 2157/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9597 - accuracy: 0.5568 - val_loss: 2.1756 - val_accuracy: 0.3122\n",
            "Epoch 2158/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9693 - accuracy: 0.5540 - val_loss: 2.1543 - val_accuracy: 0.3116\n",
            "Epoch 2159/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9865 - accuracy: 0.5472 - val_loss: 2.1653 - val_accuracy: 0.3153\n",
            "Epoch 2160/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0004 - accuracy: 0.5412 - val_loss: 2.1574 - val_accuracy: 0.3151\n",
            "Epoch 2161/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9928 - accuracy: 0.5431 - val_loss: 2.1465 - val_accuracy: 0.3102\n",
            "Epoch 2162/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9908 - accuracy: 0.5439 - val_loss: 2.1187 - val_accuracy: 0.3129\n",
            "Epoch 2163/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9796 - accuracy: 0.5482 - val_loss: 2.1311 - val_accuracy: 0.3121\n",
            "Epoch 2164/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9760 - accuracy: 0.5530 - val_loss: 2.1416 - val_accuracy: 0.3137\n",
            "Epoch 2165/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9726 - accuracy: 0.5546 - val_loss: 2.1523 - val_accuracy: 0.3095\n",
            "Epoch 2166/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9644 - accuracy: 0.5571 - val_loss: 2.1489 - val_accuracy: 0.3111\n",
            "Epoch 2167/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9699 - accuracy: 0.5545 - val_loss: 2.1394 - val_accuracy: 0.3097\n",
            "Epoch 2168/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9707 - accuracy: 0.5545 - val_loss: 2.1451 - val_accuracy: 0.3108\n",
            "Epoch 2169/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9630 - accuracy: 0.5574 - val_loss: 2.1645 - val_accuracy: 0.3083\n",
            "Epoch 2170/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9500 - accuracy: 0.5631 - val_loss: 2.1555 - val_accuracy: 0.3079\n",
            "Epoch 2171/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9432 - accuracy: 0.5647 - val_loss: 2.1755 - val_accuracy: 0.3080\n",
            "Epoch 2172/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9409 - accuracy: 0.5675 - val_loss: 2.1663 - val_accuracy: 0.3093\n",
            "Epoch 2173/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9454 - accuracy: 0.5647 - val_loss: 2.1626 - val_accuracy: 0.3136\n",
            "Epoch 2174/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9566 - accuracy: 0.5586 - val_loss: 2.1651 - val_accuracy: 0.3127\n",
            "Epoch 2175/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9500 - accuracy: 0.5608 - val_loss: 2.1529 - val_accuracy: 0.3127\n",
            "Epoch 2176/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9443 - accuracy: 0.5646 - val_loss: 2.1660 - val_accuracy: 0.3102\n",
            "Epoch 2177/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9522 - accuracy: 0.5626 - val_loss: 2.1430 - val_accuracy: 0.3119\n",
            "Epoch 2178/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9577 - accuracy: 0.5595 - val_loss: 2.1601 - val_accuracy: 0.3105\n",
            "Epoch 2179/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9521 - accuracy: 0.5617 - val_loss: 2.1691 - val_accuracy: 0.3102\n",
            "Epoch 2180/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9501 - accuracy: 0.5639 - val_loss: 2.1700 - val_accuracy: 0.3089\n",
            "Epoch 2181/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9527 - accuracy: 0.5612 - val_loss: 2.1560 - val_accuracy: 0.3099\n",
            "Epoch 2182/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9551 - accuracy: 0.5617 - val_loss: 2.1755 - val_accuracy: 0.3088\n",
            "Epoch 2183/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9576 - accuracy: 0.5592 - val_loss: 2.1612 - val_accuracy: 0.3106\n",
            "Epoch 2184/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9512 - accuracy: 0.5631 - val_loss: 2.1876 - val_accuracy: 0.3087\n",
            "Epoch 2185/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9483 - accuracy: 0.5630 - val_loss: 2.1806 - val_accuracy: 0.3093\n",
            "Epoch 2186/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9512 - accuracy: 0.5611 - val_loss: 2.1878 - val_accuracy: 0.3073\n",
            "Epoch 2187/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9514 - accuracy: 0.5619 - val_loss: 2.1822 - val_accuracy: 0.3096\n",
            "Epoch 2188/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9601 - accuracy: 0.5582 - val_loss: 2.1795 - val_accuracy: 0.3101\n",
            "Epoch 2189/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9487 - accuracy: 0.5640 - val_loss: 2.1897 - val_accuracy: 0.3080\n",
            "Epoch 2190/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9475 - accuracy: 0.5645 - val_loss: 2.1799 - val_accuracy: 0.3082\n",
            "Epoch 2191/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9462 - accuracy: 0.5641 - val_loss: 2.1826 - val_accuracy: 0.3069\n",
            "Epoch 2192/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9445 - accuracy: 0.5641 - val_loss: 2.1972 - val_accuracy: 0.3047\n",
            "Epoch 2193/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9561 - accuracy: 0.5595 - val_loss: 2.1770 - val_accuracy: 0.3119\n",
            "Epoch 2194/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9902 - accuracy: 0.5464 - val_loss: 2.1626 - val_accuracy: 0.3132\n",
            "Epoch 2195/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0026 - accuracy: 0.5417 - val_loss: 2.1512 - val_accuracy: 0.3114\n",
            "Epoch 2196/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9932 - accuracy: 0.5443 - val_loss: 2.1763 - val_accuracy: 0.3083\n",
            "Epoch 2197/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9865 - accuracy: 0.5458 - val_loss: 2.1425 - val_accuracy: 0.3108\n",
            "Epoch 2198/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9901 - accuracy: 0.5444 - val_loss: 2.1509 - val_accuracy: 0.3070\n",
            "Epoch 2199/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9746 - accuracy: 0.5494 - val_loss: 2.1774 - val_accuracy: 0.3102\n",
            "Epoch 2200/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9621 - accuracy: 0.5565 - val_loss: 2.1684 - val_accuracy: 0.3145\n",
            "Epoch 2201/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9629 - accuracy: 0.5580 - val_loss: 2.1767 - val_accuracy: 0.3056\n",
            "Epoch 2202/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9590 - accuracy: 0.5592 - val_loss: 2.1593 - val_accuracy: 0.3108\n",
            "Epoch 2203/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9573 - accuracy: 0.5597 - val_loss: 2.1597 - val_accuracy: 0.3118\n",
            "Epoch 2204/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9529 - accuracy: 0.5631 - val_loss: 2.1689 - val_accuracy: 0.3103\n",
            "Epoch 2205/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9546 - accuracy: 0.5594 - val_loss: 2.1748 - val_accuracy: 0.3065\n",
            "Epoch 2206/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9517 - accuracy: 0.5614 - val_loss: 2.1847 - val_accuracy: 0.3112\n",
            "Epoch 2207/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9570 - accuracy: 0.5591 - val_loss: 2.1681 - val_accuracy: 0.3077\n",
            "Epoch 2208/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9608 - accuracy: 0.5556 - val_loss: 2.1679 - val_accuracy: 0.3109\n",
            "Epoch 2209/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9612 - accuracy: 0.5579 - val_loss: 2.1717 - val_accuracy: 0.3107\n",
            "Epoch 2210/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9948 - accuracy: 0.5419 - val_loss: 2.1606 - val_accuracy: 0.3100\n",
            "Epoch 2211/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0150 - accuracy: 0.5335 - val_loss: 2.1628 - val_accuracy: 0.3130\n",
            "Epoch 2212/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9911 - accuracy: 0.5451 - val_loss: 2.1486 - val_accuracy: 0.3102\n",
            "Epoch 2213/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9895 - accuracy: 0.5469 - val_loss: 2.1513 - val_accuracy: 0.3085\n",
            "Epoch 2214/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9837 - accuracy: 0.5464 - val_loss: 2.1453 - val_accuracy: 0.3101\n",
            "Epoch 2215/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9830 - accuracy: 0.5487 - val_loss: 2.1589 - val_accuracy: 0.3118\n",
            "Epoch 2216/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9673 - accuracy: 0.5555 - val_loss: 2.1632 - val_accuracy: 0.3125\n",
            "Epoch 2217/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9578 - accuracy: 0.5617 - val_loss: 2.1454 - val_accuracy: 0.3091\n",
            "Epoch 2218/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9560 - accuracy: 0.5612 - val_loss: 2.1738 - val_accuracy: 0.3090\n",
            "Epoch 2219/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9534 - accuracy: 0.5602 - val_loss: 2.1605 - val_accuracy: 0.3098\n",
            "Epoch 2220/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9521 - accuracy: 0.5597 - val_loss: 2.1508 - val_accuracy: 0.3092\n",
            "Epoch 2221/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9560 - accuracy: 0.5606 - val_loss: 2.1693 - val_accuracy: 0.3134\n",
            "Epoch 2222/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9558 - accuracy: 0.5600 - val_loss: 2.1554 - val_accuracy: 0.3067\n",
            "Epoch 2223/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9623 - accuracy: 0.5563 - val_loss: 2.1969 - val_accuracy: 0.3088\n",
            "Epoch 2224/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9600 - accuracy: 0.5577 - val_loss: 2.1554 - val_accuracy: 0.3100\n",
            "Epoch 2225/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9931 - accuracy: 0.5470 - val_loss: 2.1613 - val_accuracy: 0.3155\n",
            "Epoch 2226/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9955 - accuracy: 0.5443 - val_loss: 2.1422 - val_accuracy: 0.3112\n",
            "Epoch 2227/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9818 - accuracy: 0.5483 - val_loss: 2.1435 - val_accuracy: 0.3086\n",
            "Epoch 2228/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9758 - accuracy: 0.5514 - val_loss: 2.1653 - val_accuracy: 0.3167\n",
            "Epoch 2229/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9679 - accuracy: 0.5542 - val_loss: 2.1477 - val_accuracy: 0.3168\n",
            "Epoch 2230/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9680 - accuracy: 0.5543 - val_loss: 2.1617 - val_accuracy: 0.3165\n",
            "Epoch 2231/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9687 - accuracy: 0.5553 - val_loss: 2.1577 - val_accuracy: 0.3139\n",
            "Epoch 2232/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9706 - accuracy: 0.5536 - val_loss: 2.1782 - val_accuracy: 0.3131\n",
            "Epoch 2233/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9604 - accuracy: 0.5598 - val_loss: 2.1594 - val_accuracy: 0.3107\n",
            "Epoch 2234/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9528 - accuracy: 0.5625 - val_loss: 2.1817 - val_accuracy: 0.3090\n",
            "Epoch 2235/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9576 - accuracy: 0.5598 - val_loss: 2.1637 - val_accuracy: 0.3119\n",
            "Epoch 2236/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9521 - accuracy: 0.5615 - val_loss: 2.1808 - val_accuracy: 0.3114\n",
            "Epoch 2237/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9532 - accuracy: 0.5608 - val_loss: 2.1917 - val_accuracy: 0.3062\n",
            "Epoch 2238/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9569 - accuracy: 0.5589 - val_loss: 2.1826 - val_accuracy: 0.3116\n",
            "Epoch 2239/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9537 - accuracy: 0.5609 - val_loss: 2.2100 - val_accuracy: 0.3097\n",
            "Epoch 2240/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9557 - accuracy: 0.5602 - val_loss: 2.1846 - val_accuracy: 0.3146\n",
            "Epoch 2241/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9533 - accuracy: 0.5626 - val_loss: 2.1988 - val_accuracy: 0.3142\n",
            "Epoch 2242/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9513 - accuracy: 0.5623 - val_loss: 2.1895 - val_accuracy: 0.3162\n",
            "Epoch 2243/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9628 - accuracy: 0.5552 - val_loss: 2.2121 - val_accuracy: 0.3115\n",
            "Epoch 2244/3000\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.9587 - accuracy: 0.5586 - val_loss: 2.1892 - val_accuracy: 0.3140\n",
            "Epoch 2245/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9568 - accuracy: 0.5605 - val_loss: 2.1915 - val_accuracy: 0.3119\n",
            "Epoch 2246/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9538 - accuracy: 0.5605 - val_loss: 2.1726 - val_accuracy: 0.3106\n",
            "Epoch 2247/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9597 - accuracy: 0.5592 - val_loss: 2.1857 - val_accuracy: 0.3125\n",
            "Epoch 2248/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9520 - accuracy: 0.5625 - val_loss: 2.1823 - val_accuracy: 0.3119\n",
            "Epoch 2249/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9643 - accuracy: 0.5582 - val_loss: 2.1835 - val_accuracy: 0.3124\n",
            "Epoch 2250/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9576 - accuracy: 0.5594 - val_loss: 2.1710 - val_accuracy: 0.3114\n",
            "Epoch 2251/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9554 - accuracy: 0.5593 - val_loss: 2.1623 - val_accuracy: 0.3136\n",
            "Epoch 2252/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9648 - accuracy: 0.5558 - val_loss: 2.1837 - val_accuracy: 0.3147\n",
            "Epoch 2253/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9632 - accuracy: 0.5561 - val_loss: 2.1657 - val_accuracy: 0.3091\n",
            "Epoch 2254/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0958 - accuracy: 0.5133 - val_loss: 2.1184 - val_accuracy: 0.3154\n",
            "Epoch 2255/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1599 - accuracy: 0.4894 - val_loss: 2.0919 - val_accuracy: 0.3130\n",
            "Epoch 2256/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1460 - accuracy: 0.4931 - val_loss: 2.0732 - val_accuracy: 0.3157\n",
            "Epoch 2257/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.1326 - accuracy: 0.4947 - val_loss: 2.0340 - val_accuracy: 0.3194\n",
            "Epoch 2258/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.1529 - accuracy: 0.4872 - val_loss: 2.0201 - val_accuracy: 0.3193\n",
            "Epoch 2259/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 1.1280 - accuracy: 0.4944 - val_loss: 2.0226 - val_accuracy: 0.3171\n",
            "Epoch 2260/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0840 - accuracy: 0.5100 - val_loss: 2.0428 - val_accuracy: 0.3178\n",
            "Epoch 2261/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0446 - accuracy: 0.5239 - val_loss: 2.0323 - val_accuracy: 0.3201\n",
            "Epoch 2262/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0171 - accuracy: 0.5359 - val_loss: 2.0569 - val_accuracy: 0.3161\n",
            "Epoch 2263/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9973 - accuracy: 0.5435 - val_loss: 2.0613 - val_accuracy: 0.3203\n",
            "Epoch 2264/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9858 - accuracy: 0.5493 - val_loss: 2.0873 - val_accuracy: 0.3178\n",
            "Epoch 2265/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9808 - accuracy: 0.5513 - val_loss: 2.0748 - val_accuracy: 0.3190\n",
            "Epoch 2266/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9819 - accuracy: 0.5511 - val_loss: 2.0763 - val_accuracy: 0.3204\n",
            "Epoch 2267/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9772 - accuracy: 0.5535 - val_loss: 2.0776 - val_accuracy: 0.3191\n",
            "Epoch 2268/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9778 - accuracy: 0.5510 - val_loss: 2.0802 - val_accuracy: 0.3182\n",
            "Epoch 2269/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9750 - accuracy: 0.5527 - val_loss: 2.0824 - val_accuracy: 0.3120\n",
            "Epoch 2270/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9734 - accuracy: 0.5529 - val_loss: 2.0807 - val_accuracy: 0.3154\n",
            "Epoch 2271/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9834 - accuracy: 0.5475 - val_loss: 2.0817 - val_accuracy: 0.3170\n",
            "Epoch 2272/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9870 - accuracy: 0.5457 - val_loss: 2.0796 - val_accuracy: 0.3143\n",
            "Epoch 2273/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9841 - accuracy: 0.5470 - val_loss: 2.0886 - val_accuracy: 0.3145\n",
            "Epoch 2274/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9751 - accuracy: 0.5525 - val_loss: 2.1034 - val_accuracy: 0.3109\n",
            "Epoch 2275/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9700 - accuracy: 0.5535 - val_loss: 2.1068 - val_accuracy: 0.3125\n",
            "Epoch 2276/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9669 - accuracy: 0.5562 - val_loss: 2.0948 - val_accuracy: 0.3131\n",
            "Epoch 2277/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9774 - accuracy: 0.5518 - val_loss: 2.0950 - val_accuracy: 0.3125\n",
            "Epoch 2278/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9768 - accuracy: 0.5514 - val_loss: 2.1037 - val_accuracy: 0.3154\n",
            "Epoch 2279/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9676 - accuracy: 0.5545 - val_loss: 2.0994 - val_accuracy: 0.3147\n",
            "Epoch 2280/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9682 - accuracy: 0.5559 - val_loss: 2.0953 - val_accuracy: 0.3157\n",
            "Epoch 2281/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9634 - accuracy: 0.5576 - val_loss: 2.1107 - val_accuracy: 0.3156\n",
            "Epoch 2282/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9612 - accuracy: 0.5595 - val_loss: 2.1013 - val_accuracy: 0.3165\n",
            "Epoch 2283/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9529 - accuracy: 0.5626 - val_loss: 2.1138 - val_accuracy: 0.3171\n",
            "Epoch 2284/3000\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.9507 - accuracy: 0.5634 - val_loss: 2.1166 - val_accuracy: 0.3169\n",
            "Epoch 2285/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9507 - accuracy: 0.5622 - val_loss: 2.1175 - val_accuracy: 0.3147\n",
            "Epoch 2286/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9592 - accuracy: 0.5609 - val_loss: 2.1254 - val_accuracy: 0.3147\n",
            "Epoch 2287/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9567 - accuracy: 0.5616 - val_loss: 2.1212 - val_accuracy: 0.3135\n",
            "Epoch 2288/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9594 - accuracy: 0.5607 - val_loss: 2.1056 - val_accuracy: 0.3171\n",
            "Epoch 2289/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9629 - accuracy: 0.5578 - val_loss: 2.1026 - val_accuracy: 0.3179\n",
            "Epoch 2290/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9605 - accuracy: 0.5586 - val_loss: 2.0971 - val_accuracy: 0.3172\n",
            "Epoch 2291/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9676 - accuracy: 0.5559 - val_loss: 2.1082 - val_accuracy: 0.3174\n",
            "Epoch 2292/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9619 - accuracy: 0.5583 - val_loss: 2.1040 - val_accuracy: 0.3166\n",
            "Epoch 2293/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9520 - accuracy: 0.5626 - val_loss: 2.1107 - val_accuracy: 0.3155\n",
            "Epoch 2294/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9461 - accuracy: 0.5653 - val_loss: 2.1085 - val_accuracy: 0.3194\n",
            "Epoch 2295/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9388 - accuracy: 0.5683 - val_loss: 2.1142 - val_accuracy: 0.3182\n",
            "Epoch 2296/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9457 - accuracy: 0.5656 - val_loss: 2.1190 - val_accuracy: 0.3176\n",
            "Epoch 2297/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9471 - accuracy: 0.5649 - val_loss: 2.1272 - val_accuracy: 0.3152\n",
            "Epoch 2298/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9459 - accuracy: 0.5652 - val_loss: 2.1206 - val_accuracy: 0.3169\n",
            "Epoch 2299/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9497 - accuracy: 0.5645 - val_loss: 2.1211 - val_accuracy: 0.3125\n",
            "Epoch 2300/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9548 - accuracy: 0.5599 - val_loss: 2.1246 - val_accuracy: 0.3140\n",
            "Epoch 2301/3000\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.9817 - accuracy: 0.5487 - val_loss: 2.1131 - val_accuracy: 0.3166\n",
            "Epoch 2302/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9724 - accuracy: 0.5520 - val_loss: 2.1172 - val_accuracy: 0.3134\n",
            "Epoch 2303/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9699 - accuracy: 0.5536 - val_loss: 2.1271 - val_accuracy: 0.3171\n",
            "Epoch 2304/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9591 - accuracy: 0.5596 - val_loss: 2.1205 - val_accuracy: 0.3121\n",
            "Epoch 2305/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9605 - accuracy: 0.5569 - val_loss: 2.1373 - val_accuracy: 0.3130\n",
            "Epoch 2306/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9548 - accuracy: 0.5591 - val_loss: 2.1336 - val_accuracy: 0.3154\n",
            "Epoch 2307/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9655 - accuracy: 0.5566 - val_loss: 2.1363 - val_accuracy: 0.3155\n",
            "Epoch 2308/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9714 - accuracy: 0.5531 - val_loss: 2.1268 - val_accuracy: 0.3152\n",
            "Epoch 2309/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9669 - accuracy: 0.5543 - val_loss: 2.1306 - val_accuracy: 0.3127\n",
            "Epoch 2310/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9645 - accuracy: 0.5565 - val_loss: 2.1520 - val_accuracy: 0.3136\n",
            "Epoch 2311/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9620 - accuracy: 0.5580 - val_loss: 2.1416 - val_accuracy: 0.3139\n",
            "Epoch 2312/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9753 - accuracy: 0.5530 - val_loss: 2.1312 - val_accuracy: 0.3141\n",
            "Epoch 2313/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9782 - accuracy: 0.5489 - val_loss: 2.1235 - val_accuracy: 0.3151\n",
            "Epoch 2314/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9829 - accuracy: 0.5474 - val_loss: 2.1097 - val_accuracy: 0.3132\n",
            "Epoch 2315/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9778 - accuracy: 0.5498 - val_loss: 2.1248 - val_accuracy: 0.3123\n",
            "Epoch 2316/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9768 - accuracy: 0.5515 - val_loss: 2.1172 - val_accuracy: 0.3143\n",
            "Epoch 2317/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9743 - accuracy: 0.5513 - val_loss: 2.1285 - val_accuracy: 0.3163\n",
            "Epoch 2318/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9697 - accuracy: 0.5554 - val_loss: 2.1112 - val_accuracy: 0.3183\n",
            "Epoch 2319/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9728 - accuracy: 0.5537 - val_loss: 2.1196 - val_accuracy: 0.3127\n",
            "Epoch 2320/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9642 - accuracy: 0.5585 - val_loss: 2.1201 - val_accuracy: 0.3097\n",
            "Epoch 2321/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9722 - accuracy: 0.5546 - val_loss: 2.1303 - val_accuracy: 0.3103\n",
            "Epoch 2322/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9708 - accuracy: 0.5525 - val_loss: 2.1191 - val_accuracy: 0.3158\n",
            "Epoch 2323/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9620 - accuracy: 0.5580 - val_loss: 2.1071 - val_accuracy: 0.3131\n",
            "Epoch 2324/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9587 - accuracy: 0.5591 - val_loss: 2.1290 - val_accuracy: 0.3157\n",
            "Epoch 2325/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9469 - accuracy: 0.5647 - val_loss: 2.1262 - val_accuracy: 0.3122\n",
            "Epoch 2326/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9405 - accuracy: 0.5662 - val_loss: 2.1371 - val_accuracy: 0.3107\n",
            "Epoch 2327/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9372 - accuracy: 0.5694 - val_loss: 2.1160 - val_accuracy: 0.3125\n",
            "Epoch 2328/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9360 - accuracy: 0.5703 - val_loss: 2.1521 - val_accuracy: 0.3158\n",
            "Epoch 2329/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9433 - accuracy: 0.5663 - val_loss: 2.1411 - val_accuracy: 0.3131\n",
            "Epoch 2330/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9606 - accuracy: 0.5580 - val_loss: 2.1307 - val_accuracy: 0.3117\n",
            "Epoch 2331/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9602 - accuracy: 0.5568 - val_loss: 2.1410 - val_accuracy: 0.3144\n",
            "Epoch 2332/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9577 - accuracy: 0.5577 - val_loss: 2.1370 - val_accuracy: 0.3115\n",
            "Epoch 2333/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9627 - accuracy: 0.5564 - val_loss: 2.1335 - val_accuracy: 0.3114\n",
            "Epoch 2334/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9604 - accuracy: 0.5581 - val_loss: 2.1525 - val_accuracy: 0.3163\n",
            "Epoch 2335/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9542 - accuracy: 0.5613 - val_loss: 2.1295 - val_accuracy: 0.3142\n",
            "Epoch 2336/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9515 - accuracy: 0.5617 - val_loss: 2.1380 - val_accuracy: 0.3173\n",
            "Epoch 2337/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9481 - accuracy: 0.5634 - val_loss: 2.1429 - val_accuracy: 0.3139\n",
            "Epoch 2338/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9535 - accuracy: 0.5613 - val_loss: 2.1435 - val_accuracy: 0.3180\n",
            "Epoch 2339/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9510 - accuracy: 0.5616 - val_loss: 2.1569 - val_accuracy: 0.3138\n",
            "Epoch 2340/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9489 - accuracy: 0.5646 - val_loss: 2.1554 - val_accuracy: 0.3130\n",
            "Epoch 2341/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9457 - accuracy: 0.5639 - val_loss: 2.1730 - val_accuracy: 0.3136\n",
            "Epoch 2342/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9491 - accuracy: 0.5631 - val_loss: 2.1551 - val_accuracy: 0.3149\n",
            "Epoch 2343/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9477 - accuracy: 0.5651 - val_loss: 2.1784 - val_accuracy: 0.3151\n",
            "Epoch 2344/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9519 - accuracy: 0.5614 - val_loss: 2.1417 - val_accuracy: 0.3141\n",
            "Epoch 2345/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9540 - accuracy: 0.5594 - val_loss: 2.1561 - val_accuracy: 0.3149\n",
            "Epoch 2346/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9646 - accuracy: 0.5553 - val_loss: 2.1309 - val_accuracy: 0.3156\n",
            "Epoch 2347/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9717 - accuracy: 0.5518 - val_loss: 2.1636 - val_accuracy: 0.3095\n",
            "Epoch 2348/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9613 - accuracy: 0.5562 - val_loss: 2.1385 - val_accuracy: 0.3162\n",
            "Epoch 2349/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9592 - accuracy: 0.5596 - val_loss: 2.1350 - val_accuracy: 0.3160\n",
            "Epoch 2350/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9620 - accuracy: 0.5574 - val_loss: 2.1521 - val_accuracy: 0.3162\n",
            "Epoch 2351/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9634 - accuracy: 0.5586 - val_loss: 2.1468 - val_accuracy: 0.3133\n",
            "Epoch 2352/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9664 - accuracy: 0.5551 - val_loss: 2.1447 - val_accuracy: 0.3134\n",
            "Epoch 2353/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9663 - accuracy: 0.5555 - val_loss: 2.1557 - val_accuracy: 0.3131\n",
            "Epoch 2354/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9736 - accuracy: 0.5527 - val_loss: 2.1539 - val_accuracy: 0.3116\n",
            "Epoch 2355/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9725 - accuracy: 0.5515 - val_loss: 2.1457 - val_accuracy: 0.3178\n",
            "Epoch 2356/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9691 - accuracy: 0.5554 - val_loss: 2.1474 - val_accuracy: 0.3154\n",
            "Epoch 2357/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9662 - accuracy: 0.5573 - val_loss: 2.1437 - val_accuracy: 0.3137\n",
            "Epoch 2358/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9516 - accuracy: 0.5610 - val_loss: 2.1438 - val_accuracy: 0.3126\n",
            "Epoch 2359/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9546 - accuracy: 0.5603 - val_loss: 2.1533 - val_accuracy: 0.3152\n",
            "Epoch 2360/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9559 - accuracy: 0.5604 - val_loss: 2.1527 - val_accuracy: 0.3137\n",
            "Epoch 2361/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9628 - accuracy: 0.5576 - val_loss: 2.1586 - val_accuracy: 0.3123\n",
            "Epoch 2362/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9627 - accuracy: 0.5572 - val_loss: 2.1488 - val_accuracy: 0.3138\n",
            "Epoch 2363/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9587 - accuracy: 0.5585 - val_loss: 2.1502 - val_accuracy: 0.3098\n",
            "Epoch 2364/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9606 - accuracy: 0.5587 - val_loss: 2.1556 - val_accuracy: 0.3144\n",
            "Epoch 2365/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9597 - accuracy: 0.5570 - val_loss: 2.1554 - val_accuracy: 0.3163\n",
            "Epoch 2366/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9579 - accuracy: 0.5591 - val_loss: 2.1460 - val_accuracy: 0.3153\n",
            "Epoch 2367/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9580 - accuracy: 0.5585 - val_loss: 2.1477 - val_accuracy: 0.3152\n",
            "Epoch 2368/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9570 - accuracy: 0.5590 - val_loss: 2.1494 - val_accuracy: 0.3128\n",
            "Epoch 2369/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9500 - accuracy: 0.5611 - val_loss: 2.1500 - val_accuracy: 0.3137\n",
            "Epoch 2370/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9574 - accuracy: 0.5578 - val_loss: 2.1537 - val_accuracy: 0.3139\n",
            "Epoch 2371/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9608 - accuracy: 0.5568 - val_loss: 2.1385 - val_accuracy: 0.3159\n",
            "Epoch 2372/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9618 - accuracy: 0.5560 - val_loss: 2.1435 - val_accuracy: 0.3177\n",
            "Epoch 2373/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9557 - accuracy: 0.5598 - val_loss: 2.1475 - val_accuracy: 0.3174\n",
            "Epoch 2374/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9525 - accuracy: 0.5622 - val_loss: 2.1550 - val_accuracy: 0.3117\n",
            "Epoch 2375/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9510 - accuracy: 0.5612 - val_loss: 2.1463 - val_accuracy: 0.3119\n",
            "Epoch 2376/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9425 - accuracy: 0.5663 - val_loss: 2.1604 - val_accuracy: 0.3118\n",
            "Epoch 2377/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9375 - accuracy: 0.5683 - val_loss: 2.1775 - val_accuracy: 0.3115\n",
            "Epoch 2378/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9317 - accuracy: 0.5698 - val_loss: 2.1669 - val_accuracy: 0.3139\n",
            "Epoch 2379/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9352 - accuracy: 0.5694 - val_loss: 2.1750 - val_accuracy: 0.3140\n",
            "Epoch 2380/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9310 - accuracy: 0.5714 - val_loss: 2.1756 - val_accuracy: 0.3115\n",
            "Epoch 2381/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9322 - accuracy: 0.5703 - val_loss: 2.1793 - val_accuracy: 0.3165\n",
            "Epoch 2382/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9404 - accuracy: 0.5645 - val_loss: 2.1811 - val_accuracy: 0.3152\n",
            "Epoch 2383/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9447 - accuracy: 0.5647 - val_loss: 2.1794 - val_accuracy: 0.3130\n",
            "Epoch 2384/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9441 - accuracy: 0.5636 - val_loss: 2.1874 - val_accuracy: 0.3125\n",
            "Epoch 2385/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9542 - accuracy: 0.5604 - val_loss: 2.1699 - val_accuracy: 0.3126\n",
            "Epoch 2386/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9548 - accuracy: 0.5579 - val_loss: 2.1815 - val_accuracy: 0.3130\n",
            "Epoch 2387/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9705 - accuracy: 0.5524 - val_loss: 2.1492 - val_accuracy: 0.3150\n",
            "Epoch 2388/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9772 - accuracy: 0.5509 - val_loss: 2.1627 - val_accuracy: 0.3121\n",
            "Epoch 2389/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9746 - accuracy: 0.5522 - val_loss: 2.1580 - val_accuracy: 0.3138\n",
            "Epoch 2390/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9763 - accuracy: 0.5514 - val_loss: 2.1470 - val_accuracy: 0.3134\n",
            "Epoch 2391/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9652 - accuracy: 0.5546 - val_loss: 2.1724 - val_accuracy: 0.3086\n",
            "Epoch 2392/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9583 - accuracy: 0.5583 - val_loss: 2.1789 - val_accuracy: 0.3131\n",
            "Epoch 2393/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9603 - accuracy: 0.5581 - val_loss: 2.1677 - val_accuracy: 0.3125\n",
            "Epoch 2394/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9532 - accuracy: 0.5608 - val_loss: 2.1807 - val_accuracy: 0.3134\n",
            "Epoch 2395/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9611 - accuracy: 0.5560 - val_loss: 2.1765 - val_accuracy: 0.3091\n",
            "Epoch 2396/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9567 - accuracy: 0.5601 - val_loss: 2.1770 - val_accuracy: 0.3131\n",
            "Epoch 2397/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9534 - accuracy: 0.5634 - val_loss: 2.1855 - val_accuracy: 0.3119\n",
            "Epoch 2398/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9697 - accuracy: 0.5550 - val_loss: 2.1757 - val_accuracy: 0.3124\n",
            "Epoch 2399/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9636 - accuracy: 0.5576 - val_loss: 2.1847 - val_accuracy: 0.3099\n",
            "Epoch 2400/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9544 - accuracy: 0.5621 - val_loss: 2.1996 - val_accuracy: 0.3091\n",
            "Epoch 2401/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9553 - accuracy: 0.5616 - val_loss: 2.1948 - val_accuracy: 0.3174\n",
            "Epoch 2402/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9487 - accuracy: 0.5643 - val_loss: 2.1932 - val_accuracy: 0.3098\n",
            "Epoch 2403/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9388 - accuracy: 0.5684 - val_loss: 2.2039 - val_accuracy: 0.3147\n",
            "Epoch 2404/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9467 - accuracy: 0.5627 - val_loss: 2.1952 - val_accuracy: 0.3156\n",
            "Epoch 2405/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5659 - val_loss: 2.2000 - val_accuracy: 0.3125\n",
            "Epoch 2406/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9432 - accuracy: 0.5645 - val_loss: 2.1797 - val_accuracy: 0.3120\n",
            "Epoch 2407/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9480 - accuracy: 0.5643 - val_loss: 2.1993 - val_accuracy: 0.3125\n",
            "Epoch 2408/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9503 - accuracy: 0.5614 - val_loss: 2.1848 - val_accuracy: 0.3101\n",
            "Epoch 2409/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9493 - accuracy: 0.5626 - val_loss: 2.1962 - val_accuracy: 0.3110\n",
            "Epoch 2410/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9422 - accuracy: 0.5660 - val_loss: 2.1914 - val_accuracy: 0.3136\n",
            "Epoch 2411/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9452 - accuracy: 0.5659 - val_loss: 2.2038 - val_accuracy: 0.3115\n",
            "Epoch 2412/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9479 - accuracy: 0.5644 - val_loss: 2.1885 - val_accuracy: 0.3126\n",
            "Epoch 2413/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9580 - accuracy: 0.5578 - val_loss: 2.2087 - val_accuracy: 0.3094\n",
            "Epoch 2414/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9716 - accuracy: 0.5532 - val_loss: 2.1822 - val_accuracy: 0.3085\n",
            "Epoch 2415/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9779 - accuracy: 0.5495 - val_loss: 2.1662 - val_accuracy: 0.3125\n",
            "Epoch 2416/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9725 - accuracy: 0.5524 - val_loss: 2.1952 - val_accuracy: 0.3079\n",
            "Epoch 2417/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9740 - accuracy: 0.5523 - val_loss: 2.1586 - val_accuracy: 0.3130\n",
            "Epoch 2418/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9754 - accuracy: 0.5514 - val_loss: 2.1652 - val_accuracy: 0.3142\n",
            "Epoch 2419/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9791 - accuracy: 0.5512 - val_loss: 2.1774 - val_accuracy: 0.3080\n",
            "Epoch 2420/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9640 - accuracy: 0.5573 - val_loss: 2.1669 - val_accuracy: 0.3140\n",
            "Epoch 2421/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9648 - accuracy: 0.5591 - val_loss: 2.1986 - val_accuracy: 0.3125\n",
            "Epoch 2422/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9777 - accuracy: 0.5511 - val_loss: 2.1774 - val_accuracy: 0.3106\n",
            "Epoch 2423/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9706 - accuracy: 0.5554 - val_loss: 2.1687 - val_accuracy: 0.3142\n",
            "Epoch 2424/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9619 - accuracy: 0.5584 - val_loss: 2.1856 - val_accuracy: 0.3116\n",
            "Epoch 2425/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9651 - accuracy: 0.5567 - val_loss: 2.1824 - val_accuracy: 0.3132\n",
            "Epoch 2426/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9622 - accuracy: 0.5569 - val_loss: 2.1810 - val_accuracy: 0.3115\n",
            "Epoch 2427/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9673 - accuracy: 0.5563 - val_loss: 2.2068 - val_accuracy: 0.3104\n",
            "Epoch 2428/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9767 - accuracy: 0.5519 - val_loss: 2.1847 - val_accuracy: 0.3118\n",
            "Epoch 2429/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9803 - accuracy: 0.5500 - val_loss: 2.1839 - val_accuracy: 0.3097\n",
            "Epoch 2430/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9681 - accuracy: 0.5549 - val_loss: 2.1763 - val_accuracy: 0.3083\n",
            "Epoch 2431/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9574 - accuracy: 0.5616 - val_loss: 2.1847 - val_accuracy: 0.3120\n",
            "Epoch 2432/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9584 - accuracy: 0.5601 - val_loss: 2.1921 - val_accuracy: 0.3116\n",
            "Epoch 2433/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9452 - accuracy: 0.5662 - val_loss: 2.1982 - val_accuracy: 0.3118\n",
            "Epoch 2434/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9439 - accuracy: 0.5665 - val_loss: 2.2045 - val_accuracy: 0.3121\n",
            "Epoch 2435/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9419 - accuracy: 0.5665 - val_loss: 2.2037 - val_accuracy: 0.3121\n",
            "Epoch 2436/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9518 - accuracy: 0.5606 - val_loss: 2.1986 - val_accuracy: 0.3079\n",
            "Epoch 2437/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9585 - accuracy: 0.5586 - val_loss: 2.1942 - val_accuracy: 0.3136\n",
            "Epoch 2438/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9457 - accuracy: 0.5649 - val_loss: 2.2021 - val_accuracy: 0.3089\n",
            "Epoch 2439/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9456 - accuracy: 0.5638 - val_loss: 2.2012 - val_accuracy: 0.3147\n",
            "Epoch 2440/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9477 - accuracy: 0.5639 - val_loss: 2.1975 - val_accuracy: 0.3128\n",
            "Epoch 2441/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9479 - accuracy: 0.5630 - val_loss: 2.1962 - val_accuracy: 0.3144\n",
            "Epoch 2442/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9508 - accuracy: 0.5612 - val_loss: 2.1890 - val_accuracy: 0.3125\n",
            "Epoch 2443/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9470 - accuracy: 0.5636 - val_loss: 2.2156 - val_accuracy: 0.3119\n",
            "Epoch 2444/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9567 - accuracy: 0.5595 - val_loss: 2.2052 - val_accuracy: 0.3105\n",
            "Epoch 2445/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9588 - accuracy: 0.5574 - val_loss: 2.2079 - val_accuracy: 0.3118\n",
            "Epoch 2446/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9555 - accuracy: 0.5617 - val_loss: 2.1932 - val_accuracy: 0.3132\n",
            "Epoch 2447/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9574 - accuracy: 0.5590 - val_loss: 2.1902 - val_accuracy: 0.3166\n",
            "Epoch 2448/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9486 - accuracy: 0.5623 - val_loss: 2.1998 - val_accuracy: 0.3131\n",
            "Epoch 2449/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9408 - accuracy: 0.5672 - val_loss: 2.1970 - val_accuracy: 0.3146\n",
            "Epoch 2450/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9443 - accuracy: 0.5665 - val_loss: 2.1902 - val_accuracy: 0.3136\n",
            "Epoch 2451/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9490 - accuracy: 0.5625 - val_loss: 2.2049 - val_accuracy: 0.3136\n",
            "Epoch 2452/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9444 - accuracy: 0.5648 - val_loss: 2.2199 - val_accuracy: 0.3112\n",
            "Epoch 2453/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9473 - accuracy: 0.5634 - val_loss: 2.1853 - val_accuracy: 0.3137\n",
            "Epoch 2454/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9483 - accuracy: 0.5633 - val_loss: 2.2034 - val_accuracy: 0.3104\n",
            "Epoch 2455/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9441 - accuracy: 0.5652 - val_loss: 2.1912 - val_accuracy: 0.3124\n",
            "Epoch 2456/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9494 - accuracy: 0.5639 - val_loss: 2.2147 - val_accuracy: 0.3088\n",
            "Epoch 2457/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9375 - accuracy: 0.5677 - val_loss: 2.2003 - val_accuracy: 0.3117\n",
            "Epoch 2458/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9358 - accuracy: 0.5701 - val_loss: 2.2014 - val_accuracy: 0.3128\n",
            "Epoch 2459/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9458 - accuracy: 0.5658 - val_loss: 2.2116 - val_accuracy: 0.3113\n",
            "Epoch 2460/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9461 - accuracy: 0.5654 - val_loss: 2.2106 - val_accuracy: 0.3130\n",
            "Epoch 2461/3000\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.9494 - accuracy: 0.5640 - val_loss: 2.2026 - val_accuracy: 0.3099\n",
            "Epoch 2462/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9452 - accuracy: 0.5650 - val_loss: 2.2168 - val_accuracy: 0.3098\n",
            "Epoch 2463/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9472 - accuracy: 0.5626 - val_loss: 2.2031 - val_accuracy: 0.3134\n",
            "Epoch 2464/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9503 - accuracy: 0.5628 - val_loss: 2.1993 - val_accuracy: 0.3144\n",
            "Epoch 2465/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9463 - accuracy: 0.5647 - val_loss: 2.1995 - val_accuracy: 0.3092\n",
            "Epoch 2466/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9564 - accuracy: 0.5607 - val_loss: 2.1936 - val_accuracy: 0.3103\n",
            "Epoch 2467/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9677 - accuracy: 0.5579 - val_loss: 2.1879 - val_accuracy: 0.3120\n",
            "Epoch 2468/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9702 - accuracy: 0.5567 - val_loss: 2.1994 - val_accuracy: 0.3092\n",
            "Epoch 2469/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9626 - accuracy: 0.5595 - val_loss: 2.1944 - val_accuracy: 0.3111\n",
            "Epoch 2470/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9606 - accuracy: 0.5607 - val_loss: 2.2020 - val_accuracy: 0.3116\n",
            "Epoch 2471/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9572 - accuracy: 0.5613 - val_loss: 2.1907 - val_accuracy: 0.3083\n",
            "Epoch 2472/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9709 - accuracy: 0.5552 - val_loss: 2.1844 - val_accuracy: 0.3116\n",
            "Epoch 2473/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9734 - accuracy: 0.5529 - val_loss: 2.1765 - val_accuracy: 0.3085\n",
            "Epoch 2474/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9633 - accuracy: 0.5584 - val_loss: 2.1914 - val_accuracy: 0.3135\n",
            "Epoch 2475/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9943 - accuracy: 0.5483 - val_loss: 2.1796 - val_accuracy: 0.3129\n",
            "Epoch 2476/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9790 - accuracy: 0.5523 - val_loss: 2.1806 - val_accuracy: 0.3150\n",
            "Epoch 2477/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9698 - accuracy: 0.5550 - val_loss: 2.1782 - val_accuracy: 0.3105\n",
            "Epoch 2478/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9647 - accuracy: 0.5586 - val_loss: 2.1866 - val_accuracy: 0.3076\n",
            "Epoch 2479/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9549 - accuracy: 0.5617 - val_loss: 2.1809 - val_accuracy: 0.3097\n",
            "Epoch 2480/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9530 - accuracy: 0.5627 - val_loss: 2.1879 - val_accuracy: 0.3095\n",
            "Epoch 2481/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9561 - accuracy: 0.5614 - val_loss: 2.1717 - val_accuracy: 0.3142\n",
            "Epoch 2482/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9598 - accuracy: 0.5602 - val_loss: 2.1866 - val_accuracy: 0.3093\n",
            "Epoch 2483/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9704 - accuracy: 0.5571 - val_loss: 2.1935 - val_accuracy: 0.3103\n",
            "Epoch 2484/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9760 - accuracy: 0.5527 - val_loss: 2.1877 - val_accuracy: 0.3118\n",
            "Epoch 2485/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9608 - accuracy: 0.5583 - val_loss: 2.1822 - val_accuracy: 0.3088\n",
            "Epoch 2486/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9591 - accuracy: 0.5585 - val_loss: 2.1842 - val_accuracy: 0.3106\n",
            "Epoch 2487/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9513 - accuracy: 0.5639 - val_loss: 2.1852 - val_accuracy: 0.3090\n",
            "Epoch 2488/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9584 - accuracy: 0.5598 - val_loss: 2.1795 - val_accuracy: 0.3095\n",
            "Epoch 2489/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9526 - accuracy: 0.5631 - val_loss: 2.1941 - val_accuracy: 0.3113\n",
            "Epoch 2490/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9466 - accuracy: 0.5656 - val_loss: 2.1897 - val_accuracy: 0.3124\n",
            "Epoch 2491/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9484 - accuracy: 0.5644 - val_loss: 2.1818 - val_accuracy: 0.3141\n",
            "Epoch 2492/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9503 - accuracy: 0.5638 - val_loss: 2.1982 - val_accuracy: 0.3105\n",
            "Epoch 2493/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9562 - accuracy: 0.5608 - val_loss: 2.1811 - val_accuracy: 0.3135\n",
            "Epoch 2494/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9529 - accuracy: 0.5604 - val_loss: 2.1846 - val_accuracy: 0.3130\n",
            "Epoch 2495/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9410 - accuracy: 0.5683 - val_loss: 2.1936 - val_accuracy: 0.3112\n",
            "Epoch 2496/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9390 - accuracy: 0.5679 - val_loss: 2.2011 - val_accuracy: 0.3082\n",
            "Epoch 2497/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9605 - accuracy: 0.5580 - val_loss: 2.1867 - val_accuracy: 0.3101\n",
            "Epoch 2498/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9640 - accuracy: 0.5571 - val_loss: 2.1756 - val_accuracy: 0.3100\n",
            "Epoch 2499/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9499 - accuracy: 0.5655 - val_loss: 2.1878 - val_accuracy: 0.3118\n",
            "Epoch 2500/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9434 - accuracy: 0.5681 - val_loss: 2.1927 - val_accuracy: 0.3103\n",
            "Epoch 2501/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9379 - accuracy: 0.5694 - val_loss: 2.2019 - val_accuracy: 0.3154\n",
            "Epoch 2502/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9332 - accuracy: 0.5712 - val_loss: 2.1934 - val_accuracy: 0.3142\n",
            "Epoch 2503/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9322 - accuracy: 0.5715 - val_loss: 2.2129 - val_accuracy: 0.3103\n",
            "Epoch 2504/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9351 - accuracy: 0.5704 - val_loss: 2.1934 - val_accuracy: 0.3098\n",
            "Epoch 2505/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9373 - accuracy: 0.5690 - val_loss: 2.1973 - val_accuracy: 0.3106\n",
            "Epoch 2506/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9390 - accuracy: 0.5675 - val_loss: 2.2048 - val_accuracy: 0.3109\n",
            "Epoch 2507/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9482 - accuracy: 0.5639 - val_loss: 2.1992 - val_accuracy: 0.3099\n",
            "Epoch 2508/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9454 - accuracy: 0.5657 - val_loss: 2.1958 - val_accuracy: 0.3096\n",
            "Epoch 2509/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9445 - accuracy: 0.5657 - val_loss: 2.2075 - val_accuracy: 0.3166\n",
            "Epoch 2510/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9435 - accuracy: 0.5661 - val_loss: 2.2014 - val_accuracy: 0.3116\n",
            "Epoch 2511/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9431 - accuracy: 0.5663 - val_loss: 2.2071 - val_accuracy: 0.3138\n",
            "Epoch 2512/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9541 - accuracy: 0.5636 - val_loss: 2.1967 - val_accuracy: 0.3137\n",
            "Epoch 2513/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9565 - accuracy: 0.5608 - val_loss: 2.2031 - val_accuracy: 0.3116\n",
            "Epoch 2514/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9668 - accuracy: 0.5559 - val_loss: 2.1793 - val_accuracy: 0.3132\n",
            "Epoch 2515/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9704 - accuracy: 0.5550 - val_loss: 2.2013 - val_accuracy: 0.3131\n",
            "Epoch 2516/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9717 - accuracy: 0.5528 - val_loss: 2.1784 - val_accuracy: 0.3127\n",
            "Epoch 2517/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9832 - accuracy: 0.5499 - val_loss: 2.1794 - val_accuracy: 0.3122\n",
            "Epoch 2518/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9693 - accuracy: 0.5544 - val_loss: 2.1795 - val_accuracy: 0.3129\n",
            "Epoch 2519/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9738 - accuracy: 0.5549 - val_loss: 2.1933 - val_accuracy: 0.3109\n",
            "Epoch 2520/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9694 - accuracy: 0.5578 - val_loss: 2.1779 - val_accuracy: 0.3106\n",
            "Epoch 2521/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9647 - accuracy: 0.5575 - val_loss: 2.1864 - val_accuracy: 0.3124\n",
            "Epoch 2522/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9639 - accuracy: 0.5580 - val_loss: 2.1903 - val_accuracy: 0.3071\n",
            "Epoch 2523/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9712 - accuracy: 0.5582 - val_loss: 2.1790 - val_accuracy: 0.3095\n",
            "Epoch 2524/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9725 - accuracy: 0.5551 - val_loss: 2.1681 - val_accuracy: 0.3036\n",
            "Epoch 2525/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9617 - accuracy: 0.5594 - val_loss: 2.1802 - val_accuracy: 0.3103\n",
            "Epoch 2526/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9433 - accuracy: 0.5684 - val_loss: 2.1979 - val_accuracy: 0.3091\n",
            "Epoch 2527/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9488 - accuracy: 0.5659 - val_loss: 2.1950 - val_accuracy: 0.3082\n",
            "Epoch 2528/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9549 - accuracy: 0.5632 - val_loss: 2.1938 - val_accuracy: 0.3106\n",
            "Epoch 2529/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9463 - accuracy: 0.5674 - val_loss: 2.1868 - val_accuracy: 0.3118\n",
            "Epoch 2530/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9440 - accuracy: 0.5668 - val_loss: 2.2087 - val_accuracy: 0.3096\n",
            "Epoch 2531/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9465 - accuracy: 0.5667 - val_loss: 2.2100 - val_accuracy: 0.3069\n",
            "Epoch 2532/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9550 - accuracy: 0.5604 - val_loss: 2.1894 - val_accuracy: 0.3100\n",
            "Epoch 2533/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9663 - accuracy: 0.5559 - val_loss: 2.1901 - val_accuracy: 0.3096\n",
            "Epoch 2534/3000\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.9642 - accuracy: 0.5557 - val_loss: 2.2025 - val_accuracy: 0.3084\n",
            "Epoch 2535/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9607 - accuracy: 0.5580 - val_loss: 2.1936 - val_accuracy: 0.3068\n",
            "Epoch 2536/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9446 - accuracy: 0.5677 - val_loss: 2.2003 - val_accuracy: 0.3087\n",
            "Epoch 2537/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9412 - accuracy: 0.5696 - val_loss: 2.2145 - val_accuracy: 0.3090\n",
            "Epoch 2538/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9439 - accuracy: 0.5672 - val_loss: 2.1984 - val_accuracy: 0.3088\n",
            "Epoch 2539/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9445 - accuracy: 0.5658 - val_loss: 2.2190 - val_accuracy: 0.3085\n",
            "Epoch 2540/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9677 - accuracy: 0.5544 - val_loss: 2.2040 - val_accuracy: 0.3073\n",
            "Epoch 2541/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9635 - accuracy: 0.5573 - val_loss: 2.1961 - val_accuracy: 0.3104\n",
            "Epoch 2542/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9687 - accuracy: 0.5561 - val_loss: 2.2118 - val_accuracy: 0.3095\n",
            "Epoch 2543/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9613 - accuracy: 0.5601 - val_loss: 2.2148 - val_accuracy: 0.3125\n",
            "Epoch 2544/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9754 - accuracy: 0.5552 - val_loss: 2.1861 - val_accuracy: 0.3077\n",
            "Epoch 2545/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9787 - accuracy: 0.5529 - val_loss: 2.2012 - val_accuracy: 0.3096\n",
            "Epoch 2546/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9900 - accuracy: 0.5488 - val_loss: 2.1931 - val_accuracy: 0.3102\n",
            "Epoch 2547/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9940 - accuracy: 0.5470 - val_loss: 2.1770 - val_accuracy: 0.3135\n",
            "Epoch 2548/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9846 - accuracy: 0.5524 - val_loss: 2.1666 - val_accuracy: 0.3116\n",
            "Epoch 2549/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9762 - accuracy: 0.5547 - val_loss: 2.1847 - val_accuracy: 0.3131\n",
            "Epoch 2550/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9732 - accuracy: 0.5581 - val_loss: 2.1751 - val_accuracy: 0.3085\n",
            "Epoch 2551/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9819 - accuracy: 0.5534 - val_loss: 2.1974 - val_accuracy: 0.3065\n",
            "Epoch 2552/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9732 - accuracy: 0.5570 - val_loss: 2.1748 - val_accuracy: 0.3116\n",
            "Epoch 2553/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9653 - accuracy: 0.5600 - val_loss: 2.1945 - val_accuracy: 0.3106\n",
            "Epoch 2554/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9638 - accuracy: 0.5583 - val_loss: 2.1863 - val_accuracy: 0.3100\n",
            "Epoch 2555/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9557 - accuracy: 0.5628 - val_loss: 2.1931 - val_accuracy: 0.3074\n",
            "Epoch 2556/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9503 - accuracy: 0.5651 - val_loss: 2.1832 - val_accuracy: 0.3134\n",
            "Epoch 2557/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9521 - accuracy: 0.5628 - val_loss: 2.1936 - val_accuracy: 0.3121\n",
            "Epoch 2558/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9522 - accuracy: 0.5629 - val_loss: 2.2023 - val_accuracy: 0.3066\n",
            "Epoch 2559/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9469 - accuracy: 0.5653 - val_loss: 2.1933 - val_accuracy: 0.3104\n",
            "Epoch 2560/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9394 - accuracy: 0.5702 - val_loss: 2.1948 - val_accuracy: 0.3101\n",
            "Epoch 2561/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9350 - accuracy: 0.5713 - val_loss: 2.1944 - val_accuracy: 0.3080\n",
            "Epoch 2562/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9333 - accuracy: 0.5721 - val_loss: 2.1999 - val_accuracy: 0.3100\n",
            "Epoch 2563/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9309 - accuracy: 0.5756 - val_loss: 2.1922 - val_accuracy: 0.3106\n",
            "Epoch 2564/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9289 - accuracy: 0.5729 - val_loss: 2.2100 - val_accuracy: 0.3109\n",
            "Epoch 2565/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9289 - accuracy: 0.5740 - val_loss: 2.1923 - val_accuracy: 0.3112\n",
            "Epoch 2566/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9255 - accuracy: 0.5761 - val_loss: 2.2134 - val_accuracy: 0.3110\n",
            "Epoch 2567/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9310 - accuracy: 0.5738 - val_loss: 2.2035 - val_accuracy: 0.3085\n",
            "Epoch 2568/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9358 - accuracy: 0.5712 - val_loss: 2.2079 - val_accuracy: 0.3072\n",
            "Epoch 2569/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9478 - accuracy: 0.5645 - val_loss: 2.1816 - val_accuracy: 0.3120\n",
            "Epoch 2570/3000\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.9508 - accuracy: 0.5617 - val_loss: 2.2082 - val_accuracy: 0.3068\n",
            "Epoch 2571/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9569 - accuracy: 0.5591 - val_loss: 2.2050 - val_accuracy: 0.3112\n",
            "Epoch 2572/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9626 - accuracy: 0.5579 - val_loss: 2.1988 - val_accuracy: 0.3136\n",
            "Epoch 2573/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9543 - accuracy: 0.5637 - val_loss: 2.1943 - val_accuracy: 0.3089\n",
            "Epoch 2574/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9593 - accuracy: 0.5615 - val_loss: 2.1901 - val_accuracy: 0.3105\n",
            "Epoch 2575/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9615 - accuracy: 0.5576 - val_loss: 2.1741 - val_accuracy: 0.3128\n",
            "Epoch 2576/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9709 - accuracy: 0.5522 - val_loss: 2.1860 - val_accuracy: 0.3110\n",
            "Epoch 2577/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9691 - accuracy: 0.5545 - val_loss: 2.1939 - val_accuracy: 0.3094\n",
            "Epoch 2578/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9678 - accuracy: 0.5568 - val_loss: 2.1996 - val_accuracy: 0.3095\n",
            "Epoch 2579/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9661 - accuracy: 0.5575 - val_loss: 2.1651 - val_accuracy: 0.3149\n",
            "Epoch 2580/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9558 - accuracy: 0.5615 - val_loss: 2.1889 - val_accuracy: 0.3086\n",
            "Epoch 2581/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9653 - accuracy: 0.5577 - val_loss: 2.1772 - val_accuracy: 0.3097\n",
            "Epoch 2582/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9626 - accuracy: 0.5581 - val_loss: 2.1934 - val_accuracy: 0.3110\n",
            "Epoch 2583/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9593 - accuracy: 0.5600 - val_loss: 2.1959 - val_accuracy: 0.3106\n",
            "Epoch 2584/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9651 - accuracy: 0.5570 - val_loss: 2.1811 - val_accuracy: 0.3110\n",
            "Epoch 2585/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9513 - accuracy: 0.5648 - val_loss: 2.2019 - val_accuracy: 0.3097\n",
            "Epoch 2586/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9414 - accuracy: 0.5680 - val_loss: 2.1782 - val_accuracy: 0.3088\n",
            "Epoch 2587/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9375 - accuracy: 0.5702 - val_loss: 2.1964 - val_accuracy: 0.3099\n",
            "Epoch 2588/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9563 - accuracy: 0.5597 - val_loss: 2.1895 - val_accuracy: 0.3079\n",
            "Epoch 2589/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9670 - accuracy: 0.5557 - val_loss: 2.1933 - val_accuracy: 0.3091\n",
            "Epoch 2590/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9573 - accuracy: 0.5609 - val_loss: 2.1877 - val_accuracy: 0.3138\n",
            "Epoch 2591/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9576 - accuracy: 0.5616 - val_loss: 2.1846 - val_accuracy: 0.3130\n",
            "Epoch 2592/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9541 - accuracy: 0.5632 - val_loss: 2.1878 - val_accuracy: 0.3133\n",
            "Epoch 2593/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9423 - accuracy: 0.5674 - val_loss: 2.1881 - val_accuracy: 0.3090\n",
            "Epoch 2594/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9372 - accuracy: 0.5704 - val_loss: 2.2045 - val_accuracy: 0.3050\n",
            "Epoch 2595/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9352 - accuracy: 0.5714 - val_loss: 2.1933 - val_accuracy: 0.3093\n",
            "Epoch 2596/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9357 - accuracy: 0.5720 - val_loss: 2.1976 - val_accuracy: 0.3133\n",
            "Epoch 2597/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9346 - accuracy: 0.5693 - val_loss: 2.1958 - val_accuracy: 0.3099\n",
            "Epoch 2598/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9367 - accuracy: 0.5690 - val_loss: 2.2141 - val_accuracy: 0.3104\n",
            "Epoch 2599/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9248 - accuracy: 0.5741 - val_loss: 2.2075 - val_accuracy: 0.3129\n",
            "Epoch 2600/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9285 - accuracy: 0.5719 - val_loss: 2.2215 - val_accuracy: 0.3082\n",
            "Epoch 2601/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9355 - accuracy: 0.5697 - val_loss: 2.2111 - val_accuracy: 0.3104\n",
            "Epoch 2602/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9381 - accuracy: 0.5695 - val_loss: 2.2176 - val_accuracy: 0.3082\n",
            "Epoch 2603/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9364 - accuracy: 0.5695 - val_loss: 2.2016 - val_accuracy: 0.3121\n",
            "Epoch 2604/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9492 - accuracy: 0.5612 - val_loss: 2.2172 - val_accuracy: 0.3121\n",
            "Epoch 2605/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9577 - accuracy: 0.5603 - val_loss: 2.2175 - val_accuracy: 0.3098\n",
            "Epoch 2606/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9867 - accuracy: 0.5502 - val_loss: 2.1867 - val_accuracy: 0.3129\n",
            "Epoch 2607/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9866 - accuracy: 0.5468 - val_loss: 2.1883 - val_accuracy: 0.3104\n",
            "Epoch 2608/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9750 - accuracy: 0.5526 - val_loss: 2.1754 - val_accuracy: 0.3105\n",
            "Epoch 2609/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9773 - accuracy: 0.5514 - val_loss: 2.1768 - val_accuracy: 0.3098\n",
            "Epoch 2610/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9613 - accuracy: 0.5580 - val_loss: 2.1867 - val_accuracy: 0.3107\n",
            "Epoch 2611/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9537 - accuracy: 0.5625 - val_loss: 2.1923 - val_accuracy: 0.3107\n",
            "Epoch 2612/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9510 - accuracy: 0.5632 - val_loss: 2.1843 - val_accuracy: 0.3121\n",
            "Epoch 2613/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9437 - accuracy: 0.5665 - val_loss: 2.1893 - val_accuracy: 0.3095\n",
            "Epoch 2614/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9521 - accuracy: 0.5615 - val_loss: 2.1744 - val_accuracy: 0.3098\n",
            "Epoch 2615/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9465 - accuracy: 0.5631 - val_loss: 2.1746 - val_accuracy: 0.3140\n",
            "Epoch 2616/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9390 - accuracy: 0.5689 - val_loss: 2.2052 - val_accuracy: 0.3110\n",
            "Epoch 2617/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9330 - accuracy: 0.5714 - val_loss: 2.1860 - val_accuracy: 0.3114\n",
            "Epoch 2618/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9407 - accuracy: 0.5686 - val_loss: 2.2105 - val_accuracy: 0.3104\n",
            "Epoch 2619/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9397 - accuracy: 0.5683 - val_loss: 2.1801 - val_accuracy: 0.3119\n",
            "Epoch 2620/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9621 - accuracy: 0.5607 - val_loss: 2.1686 - val_accuracy: 0.3168\n",
            "Epoch 2621/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9548 - accuracy: 0.5603 - val_loss: 2.1754 - val_accuracy: 0.3124\n",
            "Epoch 2622/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9691 - accuracy: 0.5560 - val_loss: 2.1958 - val_accuracy: 0.3112\n",
            "Epoch 2623/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9835 - accuracy: 0.5501 - val_loss: 2.1670 - val_accuracy: 0.3085\n",
            "Epoch 2624/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9913 - accuracy: 0.5486 - val_loss: 2.1883 - val_accuracy: 0.3107\n",
            "Epoch 2625/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9866 - accuracy: 0.5486 - val_loss: 2.1894 - val_accuracy: 0.3114\n",
            "Epoch 2626/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9768 - accuracy: 0.5534 - val_loss: 2.1792 - val_accuracy: 0.3127\n",
            "Epoch 2627/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9861 - accuracy: 0.5497 - val_loss: 2.1928 - val_accuracy: 0.3124\n",
            "Epoch 2628/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9792 - accuracy: 0.5511 - val_loss: 2.1783 - val_accuracy: 0.3178\n",
            "Epoch 2629/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9840 - accuracy: 0.5489 - val_loss: 2.1722 - val_accuracy: 0.3111\n",
            "Epoch 2630/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9798 - accuracy: 0.5527 - val_loss: 2.1783 - val_accuracy: 0.3119\n",
            "Epoch 2631/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9786 - accuracy: 0.5537 - val_loss: 2.1747 - val_accuracy: 0.3136\n",
            "Epoch 2632/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9773 - accuracy: 0.5532 - val_loss: 2.1810 - val_accuracy: 0.3092\n",
            "Epoch 2633/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9736 - accuracy: 0.5553 - val_loss: 2.1809 - val_accuracy: 0.3104\n",
            "Epoch 2634/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9640 - accuracy: 0.5588 - val_loss: 2.1726 - val_accuracy: 0.3124\n",
            "Epoch 2635/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9603 - accuracy: 0.5618 - val_loss: 2.1861 - val_accuracy: 0.3127\n",
            "Epoch 2636/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9521 - accuracy: 0.5645 - val_loss: 2.1718 - val_accuracy: 0.3128\n",
            "Epoch 2637/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9487 - accuracy: 0.5653 - val_loss: 2.1730 - val_accuracy: 0.3180\n",
            "Epoch 2638/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9503 - accuracy: 0.5652 - val_loss: 2.1752 - val_accuracy: 0.3137\n",
            "Epoch 2639/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9504 - accuracy: 0.5645 - val_loss: 2.1785 - val_accuracy: 0.3150\n",
            "Epoch 2640/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9472 - accuracy: 0.5662 - val_loss: 2.1765 - val_accuracy: 0.3121\n",
            "Epoch 2641/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9423 - accuracy: 0.5692 - val_loss: 2.1892 - val_accuracy: 0.3134\n",
            "Epoch 2642/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9360 - accuracy: 0.5707 - val_loss: 2.1991 - val_accuracy: 0.3126\n",
            "Epoch 2643/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9368 - accuracy: 0.5711 - val_loss: 2.2204 - val_accuracy: 0.3126\n",
            "Epoch 2644/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9463 - accuracy: 0.5655 - val_loss: 2.1793 - val_accuracy: 0.3098\n",
            "Epoch 2645/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9522 - accuracy: 0.5627 - val_loss: 2.1957 - val_accuracy: 0.3109\n",
            "Epoch 2646/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9446 - accuracy: 0.5659 - val_loss: 2.1846 - val_accuracy: 0.3131\n",
            "Epoch 2647/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9413 - accuracy: 0.5682 - val_loss: 2.1906 - val_accuracy: 0.3098\n",
            "Epoch 2648/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9538 - accuracy: 0.5625 - val_loss: 2.1802 - val_accuracy: 0.3147\n",
            "Epoch 2649/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9463 - accuracy: 0.5675 - val_loss: 2.1834 - val_accuracy: 0.3144\n",
            "Epoch 2650/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9374 - accuracy: 0.5687 - val_loss: 2.1994 - val_accuracy: 0.3124\n",
            "Epoch 2651/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9477 - accuracy: 0.5643 - val_loss: 2.1849 - val_accuracy: 0.3140\n",
            "Epoch 2652/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9577 - accuracy: 0.5594 - val_loss: 2.1821 - val_accuracy: 0.3129\n",
            "Epoch 2653/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9531 - accuracy: 0.5610 - val_loss: 2.1814 - val_accuracy: 0.3120\n",
            "Epoch 2654/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9410 - accuracy: 0.5679 - val_loss: 2.1832 - val_accuracy: 0.3134\n",
            "Epoch 2655/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9349 - accuracy: 0.5718 - val_loss: 2.1894 - val_accuracy: 0.3128\n",
            "Epoch 2656/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9321 - accuracy: 0.5718 - val_loss: 2.1972 - val_accuracy: 0.3098\n",
            "Epoch 2657/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9266 - accuracy: 0.5752 - val_loss: 2.1926 - val_accuracy: 0.3127\n",
            "Epoch 2658/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9359 - accuracy: 0.5687 - val_loss: 2.1935 - val_accuracy: 0.3145\n",
            "Epoch 2659/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9323 - accuracy: 0.5717 - val_loss: 2.1946 - val_accuracy: 0.3131\n",
            "Epoch 2660/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9306 - accuracy: 0.5733 - val_loss: 2.2064 - val_accuracy: 0.3130\n",
            "Epoch 2661/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9341 - accuracy: 0.5713 - val_loss: 2.1846 - val_accuracy: 0.3142\n",
            "Epoch 2662/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9431 - accuracy: 0.5664 - val_loss: 2.1824 - val_accuracy: 0.3180\n",
            "Epoch 2663/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9507 - accuracy: 0.5627 - val_loss: 2.1975 - val_accuracy: 0.3132\n",
            "Epoch 2664/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9487 - accuracy: 0.5647 - val_loss: 2.1997 - val_accuracy: 0.3133\n",
            "Epoch 2665/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9439 - accuracy: 0.5659 - val_loss: 2.1975 - val_accuracy: 0.3088\n",
            "Epoch 2666/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9355 - accuracy: 0.5703 - val_loss: 2.2032 - val_accuracy: 0.3130\n",
            "Epoch 2667/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9290 - accuracy: 0.5721 - val_loss: 2.2181 - val_accuracy: 0.3092\n",
            "Epoch 2668/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9355 - accuracy: 0.5677 - val_loss: 2.2076 - val_accuracy: 0.3101\n",
            "Epoch 2669/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9357 - accuracy: 0.5703 - val_loss: 2.2069 - val_accuracy: 0.3140\n",
            "Epoch 2670/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9337 - accuracy: 0.5719 - val_loss: 2.2104 - val_accuracy: 0.3143\n",
            "Epoch 2671/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9346 - accuracy: 0.5715 - val_loss: 2.2285 - val_accuracy: 0.3126\n",
            "Epoch 2672/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9488 - accuracy: 0.5642 - val_loss: 2.2097 - val_accuracy: 0.3149\n",
            "Epoch 2673/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9580 - accuracy: 0.5586 - val_loss: 2.2038 - val_accuracy: 0.3131\n",
            "Epoch 2674/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9580 - accuracy: 0.5595 - val_loss: 2.1912 - val_accuracy: 0.3164\n",
            "Epoch 2675/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9523 - accuracy: 0.5627 - val_loss: 2.1971 - val_accuracy: 0.3139\n",
            "Epoch 2676/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9475 - accuracy: 0.5642 - val_loss: 2.2018 - val_accuracy: 0.3154\n",
            "Epoch 2677/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9463 - accuracy: 0.5661 - val_loss: 2.2160 - val_accuracy: 0.3130\n",
            "Epoch 2678/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9485 - accuracy: 0.5644 - val_loss: 2.2078 - val_accuracy: 0.3097\n",
            "Epoch 2679/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9456 - accuracy: 0.5656 - val_loss: 2.2064 - val_accuracy: 0.3109\n",
            "Epoch 2680/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9244 - accuracy: 0.5751 - val_loss: 2.2233 - val_accuracy: 0.3102\n",
            "Epoch 2681/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9248 - accuracy: 0.5744 - val_loss: 2.2283 - val_accuracy: 0.3115\n",
            "Epoch 2682/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9220 - accuracy: 0.5767 - val_loss: 2.2417 - val_accuracy: 0.3150\n",
            "Epoch 2683/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9275 - accuracy: 0.5750 - val_loss: 2.2174 - val_accuracy: 0.3149\n",
            "Epoch 2684/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9303 - accuracy: 0.5737 - val_loss: 2.2344 - val_accuracy: 0.3108\n",
            "Epoch 2685/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9335 - accuracy: 0.5718 - val_loss: 2.2246 - val_accuracy: 0.3142\n",
            "Epoch 2686/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9329 - accuracy: 0.5718 - val_loss: 2.2051 - val_accuracy: 0.3108\n",
            "Epoch 2687/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9383 - accuracy: 0.5690 - val_loss: 2.2178 - val_accuracy: 0.3111\n",
            "Epoch 2688/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9348 - accuracy: 0.5708 - val_loss: 2.2218 - val_accuracy: 0.3098\n",
            "Epoch 2689/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9350 - accuracy: 0.5699 - val_loss: 2.2097 - val_accuracy: 0.3148\n",
            "Epoch 2690/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9453 - accuracy: 0.5652 - val_loss: 2.2079 - val_accuracy: 0.3095\n",
            "Epoch 2691/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9649 - accuracy: 0.5565 - val_loss: 2.2289 - val_accuracy: 0.3121\n",
            "Epoch 2692/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9713 - accuracy: 0.5536 - val_loss: 2.2112 - val_accuracy: 0.3123\n",
            "Epoch 2693/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9793 - accuracy: 0.5524 - val_loss: 2.2162 - val_accuracy: 0.3126\n",
            "Epoch 2694/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9716 - accuracy: 0.5550 - val_loss: 2.2128 - val_accuracy: 0.3134\n",
            "Epoch 2695/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9765 - accuracy: 0.5536 - val_loss: 2.2340 - val_accuracy: 0.3124\n",
            "Epoch 2696/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9925 - accuracy: 0.5464 - val_loss: 2.1778 - val_accuracy: 0.3141\n",
            "Epoch 2697/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0022 - accuracy: 0.5432 - val_loss: 2.2120 - val_accuracy: 0.3109\n",
            "Epoch 2698/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0036 - accuracy: 0.5411 - val_loss: 2.1807 - val_accuracy: 0.3122\n",
            "Epoch 2699/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0201 - accuracy: 0.5368 - val_loss: 2.1782 - val_accuracy: 0.3121\n",
            "Epoch 2700/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0001 - accuracy: 0.5424 - val_loss: 2.1789 - val_accuracy: 0.3119\n",
            "Epoch 2701/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 1.0071 - accuracy: 0.5433 - val_loss: 2.1879 - val_accuracy: 0.3131\n",
            "Epoch 2702/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0246 - accuracy: 0.5368 - val_loss: 2.1755 - val_accuracy: 0.3117\n",
            "Epoch 2703/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0139 - accuracy: 0.5388 - val_loss: 2.1721 - val_accuracy: 0.3106\n",
            "Epoch 2704/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0046 - accuracy: 0.5425 - val_loss: 2.1916 - val_accuracy: 0.3082\n",
            "Epoch 2705/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9950 - accuracy: 0.5456 - val_loss: 2.1777 - val_accuracy: 0.3128\n",
            "Epoch 2706/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9788 - accuracy: 0.5519 - val_loss: 2.1863 - val_accuracy: 0.3157\n",
            "Epoch 2707/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9695 - accuracy: 0.5551 - val_loss: 2.1959 - val_accuracy: 0.3117\n",
            "Epoch 2708/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9563 - accuracy: 0.5637 - val_loss: 2.1960 - val_accuracy: 0.3150\n",
            "Epoch 2709/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9547 - accuracy: 0.5633 - val_loss: 2.2106 - val_accuracy: 0.3099\n",
            "Epoch 2710/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9566 - accuracy: 0.5620 - val_loss: 2.2186 - val_accuracy: 0.3109\n",
            "Epoch 2711/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9493 - accuracy: 0.5646 - val_loss: 2.2220 - val_accuracy: 0.3099\n",
            "Epoch 2712/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9424 - accuracy: 0.5681 - val_loss: 2.2134 - val_accuracy: 0.3110\n",
            "Epoch 2713/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9436 - accuracy: 0.5679 - val_loss: 2.2204 - val_accuracy: 0.3131\n",
            "Epoch 2714/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9441 - accuracy: 0.5674 - val_loss: 2.2197 - val_accuracy: 0.3114\n",
            "Epoch 2715/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9451 - accuracy: 0.5670 - val_loss: 2.2291 - val_accuracy: 0.3074\n",
            "Epoch 2716/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9485 - accuracy: 0.5655 - val_loss: 2.2291 - val_accuracy: 0.3100\n",
            "Epoch 2717/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9498 - accuracy: 0.5657 - val_loss: 2.2073 - val_accuracy: 0.3077\n",
            "Epoch 2718/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9494 - accuracy: 0.5653 - val_loss: 2.2114 - val_accuracy: 0.3089\n",
            "Epoch 2719/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9465 - accuracy: 0.5675 - val_loss: 2.1993 - val_accuracy: 0.3148\n",
            "Epoch 2720/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9403 - accuracy: 0.5687 - val_loss: 2.2204 - val_accuracy: 0.3092\n",
            "Epoch 2721/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9373 - accuracy: 0.5691 - val_loss: 2.2044 - val_accuracy: 0.3113\n",
            "Epoch 2722/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9406 - accuracy: 0.5688 - val_loss: 2.2105 - val_accuracy: 0.3082\n",
            "Epoch 2723/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9398 - accuracy: 0.5688 - val_loss: 2.2130 - val_accuracy: 0.3107\n",
            "Epoch 2724/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9405 - accuracy: 0.5684 - val_loss: 2.2001 - val_accuracy: 0.3132\n",
            "Epoch 2725/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9490 - accuracy: 0.5644 - val_loss: 2.2151 - val_accuracy: 0.3131\n",
            "Epoch 2726/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9420 - accuracy: 0.5673 - val_loss: 2.2022 - val_accuracy: 0.3122\n",
            "Epoch 2727/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9349 - accuracy: 0.5713 - val_loss: 2.2257 - val_accuracy: 0.3104\n",
            "Epoch 2728/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9289 - accuracy: 0.5741 - val_loss: 2.2230 - val_accuracy: 0.3100\n",
            "Epoch 2729/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9273 - accuracy: 0.5745 - val_loss: 2.2203 - val_accuracy: 0.3126\n",
            "Epoch 2730/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9294 - accuracy: 0.5719 - val_loss: 2.2156 - val_accuracy: 0.3102\n",
            "Epoch 2731/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9307 - accuracy: 0.5728 - val_loss: 2.2291 - val_accuracy: 0.3097\n",
            "Epoch 2732/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9304 - accuracy: 0.5725 - val_loss: 2.2407 - val_accuracy: 0.3062\n",
            "Epoch 2733/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9346 - accuracy: 0.5697 - val_loss: 2.2236 - val_accuracy: 0.3109\n",
            "Epoch 2734/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9358 - accuracy: 0.5704 - val_loss: 2.2191 - val_accuracy: 0.3073\n",
            "Epoch 2735/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9343 - accuracy: 0.5712 - val_loss: 2.2445 - val_accuracy: 0.3091\n",
            "Epoch 2736/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9442 - accuracy: 0.5661 - val_loss: 2.2223 - val_accuracy: 0.3094\n",
            "Epoch 2737/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9588 - accuracy: 0.5602 - val_loss: 2.2409 - val_accuracy: 0.3086\n",
            "Epoch 2738/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9712 - accuracy: 0.5546 - val_loss: 2.2254 - val_accuracy: 0.3123\n",
            "Epoch 2739/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9702 - accuracy: 0.5548 - val_loss: 2.2206 - val_accuracy: 0.3142\n",
            "Epoch 2740/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9750 - accuracy: 0.5527 - val_loss: 2.2197 - val_accuracy: 0.3097\n",
            "Epoch 2741/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9680 - accuracy: 0.5552 - val_loss: 2.1961 - val_accuracy: 0.3172\n",
            "Epoch 2742/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9675 - accuracy: 0.5550 - val_loss: 2.2184 - val_accuracy: 0.3098\n",
            "Epoch 2743/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9639 - accuracy: 0.5588 - val_loss: 2.2133 - val_accuracy: 0.3082\n",
            "Epoch 2744/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9526 - accuracy: 0.5639 - val_loss: 2.2086 - val_accuracy: 0.3111\n",
            "Epoch 2745/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9521 - accuracy: 0.5626 - val_loss: 2.2265 - val_accuracy: 0.3086\n",
            "Epoch 2746/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9553 - accuracy: 0.5618 - val_loss: 2.2016 - val_accuracy: 0.3078\n",
            "Epoch 2747/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9534 - accuracy: 0.5604 - val_loss: 2.2117 - val_accuracy: 0.3094\n",
            "Epoch 2748/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9574 - accuracy: 0.5598 - val_loss: 2.1977 - val_accuracy: 0.3061\n",
            "Epoch 2749/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9524 - accuracy: 0.5639 - val_loss: 2.2035 - val_accuracy: 0.3125\n",
            "Epoch 2750/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9474 - accuracy: 0.5668 - val_loss: 2.2196 - val_accuracy: 0.3133\n",
            "Epoch 2751/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9430 - accuracy: 0.5688 - val_loss: 2.2139 - val_accuracy: 0.3076\n",
            "Epoch 2752/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9314 - accuracy: 0.5730 - val_loss: 2.2183 - val_accuracy: 0.3098\n",
            "Epoch 2753/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9344 - accuracy: 0.5720 - val_loss: 2.2090 - val_accuracy: 0.3077\n",
            "Epoch 2754/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9268 - accuracy: 0.5753 - val_loss: 2.2269 - val_accuracy: 0.3065\n",
            "Epoch 2755/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9241 - accuracy: 0.5773 - val_loss: 2.2135 - val_accuracy: 0.3102\n",
            "Epoch 2756/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9234 - accuracy: 0.5762 - val_loss: 2.2392 - val_accuracy: 0.3026\n",
            "Epoch 2757/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9256 - accuracy: 0.5747 - val_loss: 2.2217 - val_accuracy: 0.3098\n",
            "Epoch 2758/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9326 - accuracy: 0.5701 - val_loss: 2.2187 - val_accuracy: 0.3085\n",
            "Epoch 2759/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9327 - accuracy: 0.5723 - val_loss: 2.2252 - val_accuracy: 0.3068\n",
            "Epoch 2760/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9366 - accuracy: 0.5694 - val_loss: 2.2209 - val_accuracy: 0.3072\n",
            "Epoch 2761/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9304 - accuracy: 0.5730 - val_loss: 2.2195 - val_accuracy: 0.3116\n",
            "Epoch 2762/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9366 - accuracy: 0.5688 - val_loss: 2.2353 - val_accuracy: 0.3124\n",
            "Epoch 2763/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9297 - accuracy: 0.5718 - val_loss: 2.2157 - val_accuracy: 0.3107\n",
            "Epoch 2764/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9226 - accuracy: 0.5760 - val_loss: 2.2316 - val_accuracy: 0.3114\n",
            "Epoch 2765/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9190 - accuracy: 0.5778 - val_loss: 2.2229 - val_accuracy: 0.3092\n",
            "Epoch 2766/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9284 - accuracy: 0.5742 - val_loss: 2.2343 - val_accuracy: 0.3109\n",
            "Epoch 2767/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9296 - accuracy: 0.5744 - val_loss: 2.2576 - val_accuracy: 0.3094\n",
            "Epoch 2768/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9256 - accuracy: 0.5750 - val_loss: 2.2321 - val_accuracy: 0.3080\n",
            "Epoch 2769/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9199 - accuracy: 0.5785 - val_loss: 2.2428 - val_accuracy: 0.3062\n",
            "Epoch 2770/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9219 - accuracy: 0.5756 - val_loss: 2.2431 - val_accuracy: 0.3092\n",
            "Epoch 2771/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9250 - accuracy: 0.5756 - val_loss: 2.2471 - val_accuracy: 0.3039\n",
            "Epoch 2772/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9369 - accuracy: 0.5710 - val_loss: 2.2237 - val_accuracy: 0.3056\n",
            "Epoch 2773/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9357 - accuracy: 0.5694 - val_loss: 2.2475 - val_accuracy: 0.3045\n",
            "Epoch 2774/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9375 - accuracy: 0.5697 - val_loss: 2.2278 - val_accuracy: 0.3130\n",
            "Epoch 2775/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9459 - accuracy: 0.5648 - val_loss: 2.2401 - val_accuracy: 0.3099\n",
            "Epoch 2776/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9555 - accuracy: 0.5629 - val_loss: 2.2356 - val_accuracy: 0.3116\n",
            "Epoch 2777/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9552 - accuracy: 0.5627 - val_loss: 2.2174 - val_accuracy: 0.3117\n",
            "Epoch 2778/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9656 - accuracy: 0.5578 - val_loss: 2.2203 - val_accuracy: 0.3108\n",
            "Epoch 2779/3000\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.9655 - accuracy: 0.5581 - val_loss: 2.2313 - val_accuracy: 0.3119\n",
            "Epoch 2780/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9764 - accuracy: 0.5520 - val_loss: 2.2343 - val_accuracy: 0.3113\n",
            "Epoch 2781/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9671 - accuracy: 0.5559 - val_loss: 2.2284 - val_accuracy: 0.3074\n",
            "Epoch 2782/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9650 - accuracy: 0.5596 - val_loss: 2.2348 - val_accuracy: 0.3080\n",
            "Epoch 2783/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9661 - accuracy: 0.5560 - val_loss: 2.2286 - val_accuracy: 0.3086\n",
            "Epoch 2784/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9775 - accuracy: 0.5536 - val_loss: 2.2361 - val_accuracy: 0.3100\n",
            "Epoch 2785/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9741 - accuracy: 0.5548 - val_loss: 2.2201 - val_accuracy: 0.3065\n",
            "Epoch 2786/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 1.0322 - accuracy: 0.5377 - val_loss: 2.1915 - val_accuracy: 0.3085\n",
            "Epoch 2787/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0141 - accuracy: 0.5413 - val_loss: 2.2043 - val_accuracy: 0.3094\n",
            "Epoch 2788/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9949 - accuracy: 0.5466 - val_loss: 2.1864 - val_accuracy: 0.3149\n",
            "Epoch 2789/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9824 - accuracy: 0.5522 - val_loss: 2.1818 - val_accuracy: 0.3103\n",
            "Epoch 2790/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9830 - accuracy: 0.5528 - val_loss: 2.1958 - val_accuracy: 0.3159\n",
            "Epoch 2791/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9757 - accuracy: 0.5534 - val_loss: 2.1891 - val_accuracy: 0.3117\n",
            "Epoch 2792/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9815 - accuracy: 0.5533 - val_loss: 2.1913 - val_accuracy: 0.3120\n",
            "Epoch 2793/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9709 - accuracy: 0.5585 - val_loss: 2.1771 - val_accuracy: 0.3138\n",
            "Epoch 2794/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9805 - accuracy: 0.5533 - val_loss: 2.1689 - val_accuracy: 0.3128\n",
            "Epoch 2795/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9733 - accuracy: 0.5542 - val_loss: 2.1743 - val_accuracy: 0.3147\n",
            "Epoch 2796/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9674 - accuracy: 0.5554 - val_loss: 2.1742 - val_accuracy: 0.3133\n",
            "Epoch 2797/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9562 - accuracy: 0.5624 - val_loss: 2.1888 - val_accuracy: 0.3069\n",
            "Epoch 2798/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9470 - accuracy: 0.5664 - val_loss: 2.2100 - val_accuracy: 0.3090\n",
            "Epoch 2799/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9397 - accuracy: 0.5710 - val_loss: 2.2030 - val_accuracy: 0.3059\n",
            "Epoch 2800/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9371 - accuracy: 0.5706 - val_loss: 2.2105 - val_accuracy: 0.3086\n",
            "Epoch 2801/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9411 - accuracy: 0.5689 - val_loss: 2.2162 - val_accuracy: 0.3079\n",
            "Epoch 2802/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9378 - accuracy: 0.5716 - val_loss: 2.2118 - val_accuracy: 0.3097\n",
            "Epoch 2803/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9393 - accuracy: 0.5695 - val_loss: 2.2204 - val_accuracy: 0.3093\n",
            "Epoch 2804/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9424 - accuracy: 0.5675 - val_loss: 2.2023 - val_accuracy: 0.3127\n",
            "Epoch 2805/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9417 - accuracy: 0.5679 - val_loss: 2.2292 - val_accuracy: 0.3077\n",
            "Epoch 2806/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9455 - accuracy: 0.5666 - val_loss: 2.1991 - val_accuracy: 0.3142\n",
            "Epoch 2807/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9454 - accuracy: 0.5653 - val_loss: 2.1991 - val_accuracy: 0.3120\n",
            "Epoch 2808/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9377 - accuracy: 0.5710 - val_loss: 2.1921 - val_accuracy: 0.3089\n",
            "Epoch 2809/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9473 - accuracy: 0.5661 - val_loss: 2.1977 - val_accuracy: 0.3082\n",
            "Epoch 2810/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9606 - accuracy: 0.5592 - val_loss: 2.2110 - val_accuracy: 0.3085\n",
            "Epoch 2811/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9593 - accuracy: 0.5598 - val_loss: 2.2104 - val_accuracy: 0.3106\n",
            "Epoch 2812/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9596 - accuracy: 0.5595 - val_loss: 2.2128 - val_accuracy: 0.3110\n",
            "Epoch 2813/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9515 - accuracy: 0.5633 - val_loss: 2.2255 - val_accuracy: 0.3104\n",
            "Epoch 2814/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9837 - accuracy: 0.5502 - val_loss: 2.1776 - val_accuracy: 0.3160\n",
            "Epoch 2815/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9924 - accuracy: 0.5485 - val_loss: 2.2080 - val_accuracy: 0.3120\n",
            "Epoch 2816/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9802 - accuracy: 0.5529 - val_loss: 2.1883 - val_accuracy: 0.3137\n",
            "Epoch 2817/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9776 - accuracy: 0.5547 - val_loss: 2.1995 - val_accuracy: 0.3083\n",
            "Epoch 2818/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9631 - accuracy: 0.5618 - val_loss: 2.1881 - val_accuracy: 0.3126\n",
            "Epoch 2819/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9668 - accuracy: 0.5600 - val_loss: 2.1878 - val_accuracy: 0.3094\n",
            "Epoch 2820/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9634 - accuracy: 0.5594 - val_loss: 2.1679 - val_accuracy: 0.3123\n",
            "Epoch 2821/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9460 - accuracy: 0.5655 - val_loss: 2.2004 - val_accuracy: 0.3090\n",
            "Epoch 2822/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9524 - accuracy: 0.5640 - val_loss: 2.1869 - val_accuracy: 0.3067\n",
            "Epoch 2823/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9488 - accuracy: 0.5663 - val_loss: 2.1850 - val_accuracy: 0.3144\n",
            "Epoch 2824/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9339 - accuracy: 0.5723 - val_loss: 2.1964 - val_accuracy: 0.3121\n",
            "Epoch 2825/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9287 - accuracy: 0.5738 - val_loss: 2.2115 - val_accuracy: 0.3077\n",
            "Epoch 2826/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9274 - accuracy: 0.5765 - val_loss: 2.2000 - val_accuracy: 0.3100\n",
            "Epoch 2827/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9350 - accuracy: 0.5710 - val_loss: 2.2063 - val_accuracy: 0.3094\n",
            "Epoch 2828/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9577 - accuracy: 0.5614 - val_loss: 2.1962 - val_accuracy: 0.3071\n",
            "Epoch 2829/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9580 - accuracy: 0.5606 - val_loss: 2.1840 - val_accuracy: 0.3081\n",
            "Epoch 2830/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9457 - accuracy: 0.5671 - val_loss: 2.1839 - val_accuracy: 0.3144\n",
            "Epoch 2831/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9490 - accuracy: 0.5663 - val_loss: 2.1813 - val_accuracy: 0.3160\n",
            "Epoch 2832/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9688 - accuracy: 0.5569 - val_loss: 2.1691 - val_accuracy: 0.3123\n",
            "Epoch 2833/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9606 - accuracy: 0.5604 - val_loss: 2.1827 - val_accuracy: 0.3128\n",
            "Epoch 2834/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9552 - accuracy: 0.5616 - val_loss: 2.1909 - val_accuracy: 0.3125\n",
            "Epoch 2835/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9519 - accuracy: 0.5656 - val_loss: 2.1766 - val_accuracy: 0.3152\n",
            "Epoch 2836/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9426 - accuracy: 0.5679 - val_loss: 2.1936 - val_accuracy: 0.3160\n",
            "Epoch 2837/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9350 - accuracy: 0.5702 - val_loss: 2.1835 - val_accuracy: 0.3154\n",
            "Epoch 2838/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9333 - accuracy: 0.5715 - val_loss: 2.1872 - val_accuracy: 0.3166\n",
            "Epoch 2839/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9315 - accuracy: 0.5727 - val_loss: 2.2019 - val_accuracy: 0.3135\n",
            "Epoch 2840/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9317 - accuracy: 0.5727 - val_loss: 2.2003 - val_accuracy: 0.3120\n",
            "Epoch 2841/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9332 - accuracy: 0.5715 - val_loss: 2.1872 - val_accuracy: 0.3149\n",
            "Epoch 2842/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9342 - accuracy: 0.5719 - val_loss: 2.2069 - val_accuracy: 0.3123\n",
            "Epoch 2843/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9273 - accuracy: 0.5753 - val_loss: 2.1934 - val_accuracy: 0.3171\n",
            "Epoch 2844/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9371 - accuracy: 0.5718 - val_loss: 2.2093 - val_accuracy: 0.3115\n",
            "Epoch 2845/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9342 - accuracy: 0.5729 - val_loss: 2.2080 - val_accuracy: 0.3118\n",
            "Epoch 2846/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9324 - accuracy: 0.5720 - val_loss: 2.2037 - val_accuracy: 0.3113\n",
            "Epoch 2847/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9447 - accuracy: 0.5686 - val_loss: 2.2016 - val_accuracy: 0.3172\n",
            "Epoch 2848/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9656 - accuracy: 0.5572 - val_loss: 2.1779 - val_accuracy: 0.3119\n",
            "Epoch 2849/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9555 - accuracy: 0.5606 - val_loss: 2.2013 - val_accuracy: 0.3144\n",
            "Epoch 2850/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9449 - accuracy: 0.5679 - val_loss: 2.1814 - val_accuracy: 0.3153\n",
            "Epoch 2851/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9567 - accuracy: 0.5626 - val_loss: 2.1928 - val_accuracy: 0.3084\n",
            "Epoch 2852/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9579 - accuracy: 0.5600 - val_loss: 2.1952 - val_accuracy: 0.3157\n",
            "Epoch 2853/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9568 - accuracy: 0.5605 - val_loss: 2.1992 - val_accuracy: 0.3148\n",
            "Epoch 2854/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9526 - accuracy: 0.5628 - val_loss: 2.1902 - val_accuracy: 0.3134\n",
            "Epoch 2855/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9435 - accuracy: 0.5677 - val_loss: 2.1917 - val_accuracy: 0.3132\n",
            "Epoch 2856/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9394 - accuracy: 0.5693 - val_loss: 2.1937 - val_accuracy: 0.3115\n",
            "Epoch 2857/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9530 - accuracy: 0.5608 - val_loss: 2.1970 - val_accuracy: 0.3151\n",
            "Epoch 2858/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9484 - accuracy: 0.5638 - val_loss: 2.1891 - val_accuracy: 0.3162\n",
            "Epoch 2859/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9491 - accuracy: 0.5624 - val_loss: 2.1867 - val_accuracy: 0.3103\n",
            "Epoch 2860/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9361 - accuracy: 0.5702 - val_loss: 2.2128 - val_accuracy: 0.3074\n",
            "Epoch 2861/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9354 - accuracy: 0.5716 - val_loss: 2.2024 - val_accuracy: 0.3127\n",
            "Epoch 2862/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9372 - accuracy: 0.5692 - val_loss: 2.2098 - val_accuracy: 0.3115\n",
            "Epoch 2863/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9349 - accuracy: 0.5703 - val_loss: 2.1982 - val_accuracy: 0.3139\n",
            "Epoch 2864/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9272 - accuracy: 0.5732 - val_loss: 2.2090 - val_accuracy: 0.3162\n",
            "Epoch 2865/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9228 - accuracy: 0.5754 - val_loss: 2.1993 - val_accuracy: 0.3156\n",
            "Epoch 2866/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9331 - accuracy: 0.5690 - val_loss: 2.2122 - val_accuracy: 0.3159\n",
            "Epoch 2867/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9343 - accuracy: 0.5707 - val_loss: 2.1999 - val_accuracy: 0.3159\n",
            "Epoch 2868/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9330 - accuracy: 0.5712 - val_loss: 2.1996 - val_accuracy: 0.3186\n",
            "Epoch 2869/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9315 - accuracy: 0.5716 - val_loss: 2.2083 - val_accuracy: 0.3128\n",
            "Epoch 2870/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9291 - accuracy: 0.5718 - val_loss: 2.2178 - val_accuracy: 0.3144\n",
            "Epoch 2871/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9275 - accuracy: 0.5726 - val_loss: 2.2023 - val_accuracy: 0.3169\n",
            "Epoch 2872/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9281 - accuracy: 0.5731 - val_loss: 2.2147 - val_accuracy: 0.3137\n",
            "Epoch 2873/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9350 - accuracy: 0.5707 - val_loss: 2.2253 - val_accuracy: 0.3149\n",
            "Epoch 2874/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9347 - accuracy: 0.5709 - val_loss: 2.2214 - val_accuracy: 0.3118\n",
            "Epoch 2875/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9445 - accuracy: 0.5657 - val_loss: 2.2348 - val_accuracy: 0.3151\n",
            "Epoch 2876/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9425 - accuracy: 0.5687 - val_loss: 2.2233 - val_accuracy: 0.3144\n",
            "Epoch 2877/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9435 - accuracy: 0.5682 - val_loss: 2.2249 - val_accuracy: 0.3150\n",
            "Epoch 2878/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9590 - accuracy: 0.5627 - val_loss: 2.2338 - val_accuracy: 0.3107\n",
            "Epoch 2879/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9849 - accuracy: 0.5509 - val_loss: 2.2189 - val_accuracy: 0.3153\n",
            "Epoch 2880/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9930 - accuracy: 0.5486 - val_loss: 2.1970 - val_accuracy: 0.3100\n",
            "Epoch 2881/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9876 - accuracy: 0.5517 - val_loss: 2.1943 - val_accuracy: 0.3132\n",
            "Epoch 2882/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9659 - accuracy: 0.5601 - val_loss: 2.1921 - val_accuracy: 0.3138\n",
            "Epoch 2883/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9545 - accuracy: 0.5629 - val_loss: 2.2011 - val_accuracy: 0.3140\n",
            "Epoch 2884/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9428 - accuracy: 0.5687 - val_loss: 2.1975 - val_accuracy: 0.3136\n",
            "Epoch 2885/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9442 - accuracy: 0.5654 - val_loss: 2.2128 - val_accuracy: 0.3125\n",
            "Epoch 2886/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9416 - accuracy: 0.5679 - val_loss: 2.2103 - val_accuracy: 0.3125\n",
            "Epoch 2887/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9328 - accuracy: 0.5714 - val_loss: 2.2086 - val_accuracy: 0.3142\n",
            "Epoch 2888/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9295 - accuracy: 0.5727 - val_loss: 2.2183 - val_accuracy: 0.3113\n",
            "Epoch 2889/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9298 - accuracy: 0.5726 - val_loss: 2.2247 - val_accuracy: 0.3101\n",
            "Epoch 2890/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9301 - accuracy: 0.5712 - val_loss: 2.2220 - val_accuracy: 0.3113\n",
            "Epoch 2891/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9321 - accuracy: 0.5718 - val_loss: 2.2253 - val_accuracy: 0.3123\n",
            "Epoch 2892/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9361 - accuracy: 0.5676 - val_loss: 2.2292 - val_accuracy: 0.3105\n",
            "Epoch 2893/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9404 - accuracy: 0.5677 - val_loss: 2.2354 - val_accuracy: 0.3125\n",
            "Epoch 2894/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9325 - accuracy: 0.5705 - val_loss: 2.2270 - val_accuracy: 0.3131\n",
            "Epoch 2895/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9296 - accuracy: 0.5751 - val_loss: 2.2336 - val_accuracy: 0.3172\n",
            "Epoch 2896/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9232 - accuracy: 0.5764 - val_loss: 2.2432 - val_accuracy: 0.3123\n",
            "Epoch 2897/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9237 - accuracy: 0.5765 - val_loss: 2.2315 - val_accuracy: 0.3107\n",
            "Epoch 2898/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9309 - accuracy: 0.5712 - val_loss: 2.2355 - val_accuracy: 0.3122\n",
            "Epoch 2899/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9345 - accuracy: 0.5714 - val_loss: 2.2315 - val_accuracy: 0.3160\n",
            "Epoch 2900/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9317 - accuracy: 0.5714 - val_loss: 2.2441 - val_accuracy: 0.3123\n",
            "Epoch 2901/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9331 - accuracy: 0.5718 - val_loss: 2.2282 - val_accuracy: 0.3136\n",
            "Epoch 2902/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9434 - accuracy: 0.5661 - val_loss: 2.2301 - val_accuracy: 0.3124\n",
            "Epoch 2903/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9395 - accuracy: 0.5691 - val_loss: 2.2424 - val_accuracy: 0.3138\n",
            "Epoch 2904/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9366 - accuracy: 0.5701 - val_loss: 2.2287 - val_accuracy: 0.3151\n",
            "Epoch 2905/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9318 - accuracy: 0.5715 - val_loss: 2.2237 - val_accuracy: 0.3171\n",
            "Epoch 2906/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9426 - accuracy: 0.5670 - val_loss: 2.2312 - val_accuracy: 0.3139\n",
            "Epoch 2907/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9474 - accuracy: 0.5646 - val_loss: 2.2257 - val_accuracy: 0.3136\n",
            "Epoch 2908/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9433 - accuracy: 0.5651 - val_loss: 2.2363 - val_accuracy: 0.3121\n",
            "Epoch 2909/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9359 - accuracy: 0.5701 - val_loss: 2.2388 - val_accuracy: 0.3134\n",
            "Epoch 2910/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9304 - accuracy: 0.5709 - val_loss: 2.2383 - val_accuracy: 0.3139\n",
            "Epoch 2911/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9352 - accuracy: 0.5707 - val_loss: 2.2249 - val_accuracy: 0.3110\n",
            "Epoch 2912/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9317 - accuracy: 0.5714 - val_loss: 2.2475 - val_accuracy: 0.3086\n",
            "Epoch 2913/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9263 - accuracy: 0.5733 - val_loss: 2.2282 - val_accuracy: 0.3148\n",
            "Epoch 2914/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9255 - accuracy: 0.5732 - val_loss: 2.2367 - val_accuracy: 0.3127\n",
            "Epoch 2915/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9330 - accuracy: 0.5709 - val_loss: 2.2290 - val_accuracy: 0.3175\n",
            "Epoch 2916/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9489 - accuracy: 0.5631 - val_loss: 2.2337 - val_accuracy: 0.3127\n",
            "Epoch 2917/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9497 - accuracy: 0.5620 - val_loss: 2.2147 - val_accuracy: 0.3162\n",
            "Epoch 2918/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9485 - accuracy: 0.5627 - val_loss: 2.2153 - val_accuracy: 0.3151\n",
            "Epoch 2919/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9527 - accuracy: 0.5627 - val_loss: 2.2205 - val_accuracy: 0.3157\n",
            "Epoch 2920/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9555 - accuracy: 0.5632 - val_loss: 2.2182 - val_accuracy: 0.3146\n",
            "Epoch 2921/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9516 - accuracy: 0.5649 - val_loss: 2.2265 - val_accuracy: 0.3140\n",
            "Epoch 2922/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9447 - accuracy: 0.5677 - val_loss: 2.2475 - val_accuracy: 0.3091\n",
            "Epoch 2923/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9424 - accuracy: 0.5677 - val_loss: 2.2363 - val_accuracy: 0.3104\n",
            "Epoch 2924/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9429 - accuracy: 0.5691 - val_loss: 2.2463 - val_accuracy: 0.3140\n",
            "Epoch 2925/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9429 - accuracy: 0.5680 - val_loss: 2.2374 - val_accuracy: 0.3146\n",
            "Epoch 2926/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9473 - accuracy: 0.5651 - val_loss: 2.2518 - val_accuracy: 0.3133\n",
            "Epoch 2927/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9493 - accuracy: 0.5641 - val_loss: 2.2543 - val_accuracy: 0.3105\n",
            "Epoch 2928/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9428 - accuracy: 0.5655 - val_loss: 2.2314 - val_accuracy: 0.3100\n",
            "Epoch 2929/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9385 - accuracy: 0.5691 - val_loss: 2.2569 - val_accuracy: 0.3134\n",
            "Epoch 2930/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9340 - accuracy: 0.5717 - val_loss: 2.2486 - val_accuracy: 0.3115\n",
            "Epoch 2931/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9240 - accuracy: 0.5767 - val_loss: 2.2600 - val_accuracy: 0.3150\n",
            "Epoch 2932/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9556 - accuracy: 0.5634 - val_loss: 2.2534 - val_accuracy: 0.3117\n",
            "Epoch 2933/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9626 - accuracy: 0.5582 - val_loss: 2.2479 - val_accuracy: 0.3153\n",
            "Epoch 2934/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9684 - accuracy: 0.5542 - val_loss: 2.2282 - val_accuracy: 0.3137\n",
            "Epoch 2935/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9592 - accuracy: 0.5587 - val_loss: 2.2298 - val_accuracy: 0.3170\n",
            "Epoch 2936/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9941 - accuracy: 0.5461 - val_loss: 2.2306 - val_accuracy: 0.3114\n",
            "Epoch 2937/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 1.0053 - accuracy: 0.5411 - val_loss: 2.2185 - val_accuracy: 0.3173\n",
            "Epoch 2938/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0072 - accuracy: 0.5420 - val_loss: 2.2043 - val_accuracy: 0.3140\n",
            "Epoch 2939/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0063 - accuracy: 0.5457 - val_loss: 2.2057 - val_accuracy: 0.3095\n",
            "Epoch 2940/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9925 - accuracy: 0.5474 - val_loss: 2.1963 - val_accuracy: 0.3110\n",
            "Epoch 2941/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 1.0013 - accuracy: 0.5431 - val_loss: 2.2040 - val_accuracy: 0.3127\n",
            "Epoch 2942/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9937 - accuracy: 0.5490 - val_loss: 2.2079 - val_accuracy: 0.3143\n",
            "Epoch 2943/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9795 - accuracy: 0.5553 - val_loss: 2.2260 - val_accuracy: 0.3107\n",
            "Epoch 2944/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9758 - accuracy: 0.5574 - val_loss: 2.2066 - val_accuracy: 0.3111\n",
            "Epoch 2945/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9634 - accuracy: 0.5611 - val_loss: 2.2142 - val_accuracy: 0.3145\n",
            "Epoch 2946/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9541 - accuracy: 0.5640 - val_loss: 2.2250 - val_accuracy: 0.3101\n",
            "Epoch 2947/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9589 - accuracy: 0.5619 - val_loss: 2.2195 - val_accuracy: 0.3086\n",
            "Epoch 2948/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9526 - accuracy: 0.5642 - val_loss: 2.2250 - val_accuracy: 0.3097\n",
            "Epoch 2949/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9403 - accuracy: 0.5715 - val_loss: 2.2130 - val_accuracy: 0.3096\n",
            "Epoch 2950/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9359 - accuracy: 0.5738 - val_loss: 2.2388 - val_accuracy: 0.3086\n",
            "Epoch 2951/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9252 - accuracy: 0.5764 - val_loss: 2.2219 - val_accuracy: 0.3105\n",
            "Epoch 2952/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9221 - accuracy: 0.5802 - val_loss: 2.2533 - val_accuracy: 0.3067\n",
            "Epoch 2953/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9164 - accuracy: 0.5796 - val_loss: 2.2339 - val_accuracy: 0.3119\n",
            "Epoch 2954/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9223 - accuracy: 0.5779 - val_loss: 2.2490 - val_accuracy: 0.3075\n",
            "Epoch 2955/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9296 - accuracy: 0.5730 - val_loss: 2.2471 - val_accuracy: 0.3112\n",
            "Epoch 2956/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9311 - accuracy: 0.5740 - val_loss: 2.2393 - val_accuracy: 0.3131\n",
            "Epoch 2957/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9331 - accuracy: 0.5735 - val_loss: 2.2350 - val_accuracy: 0.3107\n",
            "Epoch 2958/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9294 - accuracy: 0.5756 - val_loss: 2.2470 - val_accuracy: 0.3119\n",
            "Epoch 2959/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9193 - accuracy: 0.5774 - val_loss: 2.2396 - val_accuracy: 0.3088\n",
            "Epoch 2960/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9204 - accuracy: 0.5778 - val_loss: 2.2517 - val_accuracy: 0.3089\n",
            "Epoch 2961/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9201 - accuracy: 0.5761 - val_loss: 2.2429 - val_accuracy: 0.3101\n",
            "Epoch 2962/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9245 - accuracy: 0.5766 - val_loss: 2.2501 - val_accuracy: 0.3102\n",
            "Epoch 2963/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9294 - accuracy: 0.5728 - val_loss: 2.2469 - val_accuracy: 0.3101\n",
            "Epoch 2964/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9275 - accuracy: 0.5737 - val_loss: 2.2558 - val_accuracy: 0.3098\n",
            "Epoch 2965/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9294 - accuracy: 0.5724 - val_loss: 2.2475 - val_accuracy: 0.3109\n",
            "Epoch 2966/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9199 - accuracy: 0.5787 - val_loss: 2.2562 - val_accuracy: 0.3112\n",
            "Epoch 2967/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9344 - accuracy: 0.5717 - val_loss: 2.2526 - val_accuracy: 0.3134\n",
            "Epoch 2968/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9319 - accuracy: 0.5736 - val_loss: 2.2434 - val_accuracy: 0.3137\n",
            "Epoch 2969/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9257 - accuracy: 0.5751 - val_loss: 2.2657 - val_accuracy: 0.3105\n",
            "Epoch 2970/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9228 - accuracy: 0.5771 - val_loss: 2.2671 - val_accuracy: 0.3121\n",
            "Epoch 2971/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9158 - accuracy: 0.5801 - val_loss: 2.2636 - val_accuracy: 0.3147\n",
            "Epoch 2972/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9122 - accuracy: 0.5827 - val_loss: 2.2785 - val_accuracy: 0.3124\n",
            "Epoch 2973/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9129 - accuracy: 0.5809 - val_loss: 2.2688 - val_accuracy: 0.3113\n",
            "Epoch 2974/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9215 - accuracy: 0.5770 - val_loss: 2.2647 - val_accuracy: 0.3140\n",
            "Epoch 2975/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9299 - accuracy: 0.5713 - val_loss: 2.2500 - val_accuracy: 0.3106\n",
            "Epoch 2976/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9338 - accuracy: 0.5704 - val_loss: 2.2492 - val_accuracy: 0.3112\n",
            "Epoch 2977/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9314 - accuracy: 0.5709 - val_loss: 2.2804 - val_accuracy: 0.3055\n",
            "Epoch 2978/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9335 - accuracy: 0.5699 - val_loss: 2.2547 - val_accuracy: 0.3109\n",
            "Epoch 2979/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9201 - accuracy: 0.5773 - val_loss: 2.2660 - val_accuracy: 0.3101\n",
            "Epoch 2980/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9183 - accuracy: 0.5794 - val_loss: 2.2719 - val_accuracy: 0.3109\n",
            "Epoch 2981/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9168 - accuracy: 0.5786 - val_loss: 2.2733 - val_accuracy: 0.3106\n",
            "Epoch 2982/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9173 - accuracy: 0.5790 - val_loss: 2.2592 - val_accuracy: 0.3150\n",
            "Epoch 2983/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9313 - accuracy: 0.5721 - val_loss: 2.2639 - val_accuracy: 0.3109\n",
            "Epoch 2984/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9362 - accuracy: 0.5687 - val_loss: 2.2468 - val_accuracy: 0.3171\n",
            "Epoch 2985/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9431 - accuracy: 0.5690 - val_loss: 2.2623 - val_accuracy: 0.3144\n",
            "Epoch 2986/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9399 - accuracy: 0.5674 - val_loss: 2.2445 - val_accuracy: 0.3136\n",
            "Epoch 2987/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9373 - accuracy: 0.5696 - val_loss: 2.2598 - val_accuracy: 0.3104\n",
            "Epoch 2988/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9382 - accuracy: 0.5710 - val_loss: 2.2480 - val_accuracy: 0.3122\n",
            "Epoch 2989/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9374 - accuracy: 0.5695 - val_loss: 2.2846 - val_accuracy: 0.3108\n",
            "Epoch 2990/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9339 - accuracy: 0.5712 - val_loss: 2.2499 - val_accuracy: 0.3138\n",
            "Epoch 2991/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9328 - accuracy: 0.5716 - val_loss: 2.2596 - val_accuracy: 0.3125\n",
            "Epoch 2992/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9285 - accuracy: 0.5723 - val_loss: 2.2752 - val_accuracy: 0.3083\n",
            "Epoch 2993/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9233 - accuracy: 0.5755 - val_loss: 2.2659 - val_accuracy: 0.3144\n",
            "Epoch 2994/3000\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.9215 - accuracy: 0.5768 - val_loss: 2.2631 - val_accuracy: 0.3131\n",
            "Epoch 2995/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9189 - accuracy: 0.5768 - val_loss: 2.2817 - val_accuracy: 0.3096\n",
            "Epoch 2996/3000\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.9261 - accuracy: 0.5717 - val_loss: 2.2559 - val_accuracy: 0.3101\n",
            "Epoch 2997/3000\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.9284 - accuracy: 0.5722 - val_loss: 2.2713 - val_accuracy: 0.3141\n",
            "Epoch 2998/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9205 - accuracy: 0.5754 - val_loss: 2.2626 - val_accuracy: 0.3148\n",
            "Epoch 2999/3000\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.9088 - accuracy: 0.5823 - val_loss: 2.2877 - val_accuracy: 0.3116\n",
            "Epoch 3000/3000\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.9108 - accuracy: 0.5821 - val_loss: 2.2729 - val_accuracy: 0.3139\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7mg0A_wlnif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_model_200921.h5')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu5-G0YkpJWX",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ2op0IDKtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict(test_x_onehot)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57FnCwYfu9ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba52dedf-7a84-430b-e8e9-22af4709e2b2"
      },
      "source": [
        "test_predictions.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ2w_yAoMSfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "2c0db3be-5e6e-413f-f0e2-73bcfb6c34bd"
      },
      "source": [
        "test_predictions"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[3.45610678e-01, 6.17646337e-01, 3.02663427e-02, 6.47670543e-03],\n",
              "        [2.95053795e-02, 9.70479548e-01, 1.05311146e-05, 4.55397731e-06],\n",
              "        [3.81466210e-01, 6.18533611e-01, 3.95798168e-08, 1.72015277e-07],\n",
              "        ...,\n",
              "        [1.03124917e-01, 5.02758443e-01, 3.24414492e-01, 6.97021857e-02],\n",
              "        [1.18633144e-01, 4.96468633e-01, 3.24393719e-01, 6.05044365e-02],\n",
              "        [1.38558790e-01, 4.87482131e-01, 3.21153879e-01, 5.28051555e-02]],\n",
              "\n",
              "       [[2.01613516e-01, 6.19823337e-02, 7.29102492e-01, 7.30163930e-03],\n",
              "        [5.76579608e-02, 6.59649432e-01, 2.82627523e-01, 6.50865841e-05],\n",
              "        [1.14854216e-03, 9.66243505e-01, 3.25940512e-02, 1.40067996e-05],\n",
              "        ...,\n",
              "        [2.23384157e-01, 3.61619443e-01, 2.97238439e-01, 1.17757894e-01],\n",
              "        [2.22773522e-01, 3.61638248e-01, 2.96851486e-01, 1.18736736e-01],\n",
              "        [2.21895903e-01, 3.61545235e-01, 2.96094269e-01, 1.20464645e-01]],\n",
              "\n",
              "       [[8.73730332e-03, 9.10957336e-01, 5.42959955e-04, 7.97624514e-02],\n",
              "        [1.36619862e-02, 9.76469457e-01, 5.30350907e-03, 4.56502475e-03],\n",
              "        [8.98587473e-07, 9.99484777e-01, 5.05827309e-04, 8.45368959e-06],\n",
              "        ...,\n",
              "        [2.18775287e-01, 4.24091130e-01, 2.28708982e-01, 1.28424555e-01],\n",
              "        [2.18443438e-01, 4.15325910e-01, 2.44697228e-01, 1.21533424e-01],\n",
              "        [2.17136517e-01, 4.06527430e-01, 2.62100667e-01, 1.14235386e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[4.21414077e-02, 6.61707640e-01, 2.94577450e-01, 1.57346658e-03],\n",
              "        [6.51419342e-01, 1.50756463e-02, 3.33496302e-01, 8.66744449e-06],\n",
              "        [3.47900973e-03, 1.66611462e-05, 9.96504068e-01, 1.84178106e-07],\n",
              "        ...,\n",
              "        [1.49711415e-01, 5.11480391e-01, 3.36230308e-01, 2.57787271e-03],\n",
              "        [1.84753433e-01, 4.42129970e-01, 3.69371504e-01, 3.74510791e-03],\n",
              "        [2.08444044e-01, 3.82685751e-01, 4.02896881e-01, 5.97336609e-03]],\n",
              "\n",
              "       [[3.37585479e-01, 4.09713715e-01, 2.33113870e-01, 1.95869263e-02],\n",
              "        [6.73339665e-01, 1.45147939e-03, 3.25195312e-01, 1.35349919e-05],\n",
              "        [9.54599798e-01, 3.97062166e-07, 4.52462807e-02, 1.53574540e-04],\n",
              "        ...,\n",
              "        [2.77582645e-01, 4.46234226e-01, 2.59484380e-01, 1.66987497e-02],\n",
              "        [2.72875607e-01, 5.47036350e-01, 1.66058153e-01, 1.40299285e-02],\n",
              "        [2.80990332e-01, 5.97913146e-01, 1.06688358e-01, 1.44081255e-02]],\n",
              "\n",
              "       [[2.05792040e-01, 6.76875353e-01, 9.18915644e-02, 2.54410654e-02],\n",
              "        [4.09661839e-03, 3.40576917e-01, 6.55326128e-01, 3.35089396e-07],\n",
              "        [9.96659160e-01, 1.13637710e-03, 2.20439420e-03, 4.67464012e-10],\n",
              "        ...,\n",
              "        [2.37787098e-01, 2.08621725e-01, 4.91749823e-01, 6.18413538e-02],\n",
              "        [2.43426055e-01, 2.07710028e-01, 4.87477869e-01, 6.13860525e-02],\n",
              "        [2.50284433e-01, 2.06731111e-01, 4.81690109e-01, 6.12944327e-02]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmc2VwJ-byp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = np.argmax(test_predictions,axis=-1)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBFLv8racBFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1025
        },
        "outputId": "120c83e3-463f-4114-dffe-872e0383563a"
      },
      "source": [
        "for i in range(10):\n",
        "  print(test_predictions[i])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 0 0 0 3 1 2 2 2 2 1 1 0 1 2 2 1 3 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 2\n",
            " 2 1 0 1 2 0 0 1 2 1 0 0 1 1 1 1 1 1 1 1 1 3 3 2 2 0 0 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 1 1 1 2 2 0 0 1 0 0 2 2 2 2 1 2 2 2 0 0 0 0 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
            " 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
            " 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[2 1 1 1 1 0 0 2 2 1 0 3 3 0 0 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 2 2 2 1 1 1 1 2 2 2 2 2 2 3 3 3 2 2 2 2 2 2 1 1 1 1 1 1 2 2\n",
            " 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 2 2 2 2 2 3 3\n",
            " 3 3 2 2 2 2 2 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 1 1 1 2 3 3 0 2 2 1 1 1 2 1 0 2 1 3 1 0 1 0 1 2 1 2 3 1 0 0 1 2 2 1 2\n",
            " 2 1 1 1 1 1 0 2 2 1 1 1 1 0 0 0 0 2 2 0 0 1 1 0 0 0 0 0 0 0 0 3 3 1 0 0 0\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 0 2 2 2 2 0 0 0 0 2 2 2 2 2 2 0 0 0 0 3 3 3 3 3\n",
            " 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 0 0 1 1 2 1 1 1 1 2 2 1 1 2 0 0 1 0 0 2 1 0 2 2 0 0 1 1 0 0 0 1 0 0 0 1\n",
            " 1 1 1 1 2 2 2 1 2 2 1 1 2 2 2 2 2 0 1 2 2 2 2 2 2 2 0 2 2 1 1 1 1 1 3 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 1 2 0 3 2 2 3 0 1 2 1 1 2 2 3 2 2 2 2 0 0 1 1 1 1 2 2 1 2 1 1 1 1 1 3 2\n",
            " 2 3 2 1 1 2 2 1 1 1 0 1 1 1 1 0 0 1 1 3 2 2 1 2 1 1 1 0 3 3 1 1 2 2 2 1 2\n",
            " 1 1 1 1 1 1 1 1 1 2 0 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 0 0 3 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 2 2 0 0 0 0 3\n",
            " 3 3 2 2 2 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 2 2 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "[2 0 3 3 3 1 0 0 2 0 2 1 2 1 1 1 2 2 0 0 1 1 0 2 1 0 1 1 2 1 1 2 2 3 1 1 0\n",
            " 2 0 0 0 3 1 0 0 1 1 1 1 0 3 1 1 2 2 1 1 1 2 1 2 2 2 1 1 1 1 1 1 2 1 1 1 1\n",
            " 2 2 2 2 2 1 1 1 1 1 3 0 1 1 1 1 3 3 2 2 2 2 1 1 1 1 0 0 0 2 1 3 3 2 2 2 2\n",
            " 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1\n",
            " 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2]\n",
            "[2 0 0 0 0 2 1 0 1 0 0 1 2 3 0 1 1 0 3 1 2 0 2 0 0 0 2 2 0 2 1 0 2 1 1 2 2\n",
            " 1 1 1 0 1 1 2 2 0 0 2 1 1 1 2 2 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 2 2 2 2\n",
            " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[1 0 2 2 1 1 1 2 1 1 1 1 0 0 2 2 1 1 1 2 2 2 2 3 0 2 1 0 0 1 1 0 0 2 1 1 2\n",
            " 2 1 1 2 1 1 1 0 0 1 1 0 1 1 2 2 2 2 2 2 0 2 2 1 1 1 1 1 1 1 1 1 0 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 3 2 2 2 2 2 2 2 2\n",
            " 2 2 0 0 2 2 3 3 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0 0 0 0 0 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 2 2 2 2 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2]\n",
            "[1 0 0 2 2 2 1 2 1 1 1 2 3 1 1 3 1 0 1 1 2 1 1 2 2 1 1 0 2 2 2 2 0 2 2 0 1\n",
            " 1 2 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 0 0 1 1 1 1 1 2 2\n",
            " 2 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 3 3\n",
            " 3 3 3 3 1 1 1 1 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 2 2 2 2 2 2 2 1\n",
            " 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 1]\n",
            "[1 2 0 0 2 0 1 3 0 1 0 3 2 3 1 1 2 2 2 3 2 2 0 1 2 2 1 1 1 2 0 1 0 0 0 0 3\n",
            " 1 2 1 1 2 2 1 3 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 0 0 0 0\n",
            " 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_tuXsq6Gv1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1025
        },
        "outputId": "d72c3412-f267-4bd4-ded2-0a4db41651f9"
      },
      "source": [
        "for i in range(10):\n",
        "  print(test_y[i])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 2 0 3 2 2 1 2 2 1 1 1 3 1 2 2 2 3 0 1 2 1 1 0 1 0 2 1 1 1 0 2 2 0 1 0\n",
            " 2 1 1 2 2 0 1 2 2 1 3 2 3 3 1 3 2 2 1 2 2 0 3 1 0 1 3 1 1 2 1 2 0 1 0 1 0\n",
            " 3 2 0 2 0 0 3 2 2 1 0 2 2 0 0 2 3 2 1 1 1 0 2 1 0 2 0 0 0 2 2 0 2 1 2 0 2\n",
            " 0 2 1 3 0 2 2 2 2 1 2 2 2 0 1 3 1 1 0 1 2 1 2 0 0 1 1 1 0 1 0 1 2 2 1 1 2\n",
            " 1 1 1 0 2 2 1 1 2 3 2 0 2 1 2 3 2 0 0 1 2 3 2 2 2 1 2 2 1 1 1 1 1 1 0 1 2\n",
            " 2 1 3 0 2 2 3 2 0 2 1 2 1 0 0 0 3 2 0 3 1 0 2 1 2 0 2 1 0 3 3 0 0 0 2]\n",
            "[1 1 1 1 2 0 1 2 3 3 2 2 2 1 0 3 2 1 2 0 1 1 0 1 2 2 1 2 1 2 3 1 1 0 3 0 2\n",
            " 1 0 1 2 1 0 0 2 0 0 1 1 1 2 1 1 1 1 1 1 0 1 1 2 1 2 1 3 2 0 2 3 1 2 2 0 0\n",
            " 3 0 2 2 2 1 1 2 2 2 1 1 0 2 2 0 0 1 0 3 0 0 1 1 0 1 2 2 1 1 2 2 2 0 0 1 2\n",
            " 0 2 1 3 2 2 3 3 1 3 1 0 2 2 0 2 0 3 0 0 0 1 1 2 1 1 1 2 2 2 0 1 0 1 1 1 2\n",
            " 1 2 1 2 1 3 0 0 1 0 2 0 3 2 1 2 3 0 0 0 1 1 0 1 1 0 1 2 1 1 2 2 2 1 1 1 1\n",
            " 1 1 3 0 1 1 2 3 2 2 1 2 2 0 2 2 2 0 0 2 1 2 2 1 1 0 2 1 2 0 2 0 1 1 1]\n",
            "[1 1 3 2 1 0 2 0 1 0 0 0 0 1 2 0 2 0 2 3 3 1 2 1 2 2 1 1 0 2 1 2 0 1 1 1 2\n",
            " 1 2 2 1 1 0 1 1 2 2 0 1 1 1 1 3 1 2 2 0 0 0 1 1 0 3 0 1 2 2 2 1 1 0 1 1 1\n",
            " 0 3 1 3 2 2 3 3 3 1 2 2 3 0 1 1 0 0 1 2 0 1 1 1 1 3 3 1 3 1 1 2 0 0 0 1 1\n",
            " 1 1 1 1 2 3 2 1 0 1 1 1 3 3 2 2 0 0 2 2 0 0 1 0 2 1 0 1 1 2 2 1 1 2 2 1 1\n",
            " 1 3 2 1 3 2 1 2 1 1 0 2 0 2 0 1 3 2 2 0 2 0 1 0 1 1 1 1 0 1 0 1 2 0 0 0 0\n",
            " 2 1 1 0 3 0 1 0 0 1 0 1 1 2 2 0 0 1 0 0 1 2 1 0 0 2 2 1 1 2 1 1 1 0 0]\n",
            "[3 1 1 2 0 1 2 1 1 2 1 2 1 1 1 0 2 3 1 2 1 2 1 2 1 1 2 2 0 1 0 2 0 1 1 0 1\n",
            " 2 2 2 1 2 1 1 3 2 0 2 3 0 1 3 0 1 0 1 2 2 2 0 0 0 3 0 2 1 1 2 2 1 0 3 2 1\n",
            " 0 1 2 2 1 2 1 2 3 1 2 2 1 1 2 3 2 1 1 2 3 1 0 2 2 1 1 3 1 1 0 2 2 2 1 2 1\n",
            " 2 0 2 1 1 0 1 3 2 1 1 1 3 2 0 3 1 1 1 0 0 2 0 1 1 1 0 0 0 0 3 0 1 1 2 1 1\n",
            " 0 2 2 0 2 2 1 1 1 1 1 1 2 3 1 1 1 2 2 1 2 1 2 0 1 1 2 0 3 2 0 1 1 0 1 2 1\n",
            " 0 3 2 2 2 1 1 1 1 3 1 2 2 1 0 2 1 1 1 3 1 1 1 1 0 1 1 2 0 2 1 1 3 3 0]\n",
            "[2 0 3 1 2 0 3 2 0 3 1 2 1 2 0 2 2 1 2 1 0 2 1 0 0 2 2 0 1 1 1 1 2 1 1 1 1\n",
            " 1 1 2 2 2 0 1 1 1 0 2 1 0 2 1 2 1 1 0 1 1 1 0 2 1 1 2 1 1 1 0 0 2 1 1 1 3\n",
            " 3 1 2 2 2 3 2 3 2 0 2 2 0 2 0 2 1 3 1 0 1 2 2 2 2 0 1 0 3 0 1 3 2 0 1 0 2\n",
            " 3 1 0 2 2 3 1 2 2 2 1 1 1 2 3 1 0 2 2 0 1 1 1 0 0 1 3 2 1 2 3 0 1 0 1 3 2\n",
            " 3 2 2 2 1 2 1 2 1 1 1 2 1 0 1 0 1 1 0 1 1 3 0 0 3 0 2 1 1 0 1 2 0 1 2 2 0\n",
            " 3 2 1 1 1 1 3 0 2 2 2 2 1 0 1 2 2 1 0 0 0 2 0 1 3 0 2 2 2 1 1 3 1 3 0]\n",
            "[0 1 0 0 3 2 2 0 1 2 3 1 2 0 1 0 1 1 2 3 1 1 2 0 1 2 1 0 2 2 2 0 2 1 0 1 2\n",
            " 2 2 2 2 1 1 2 1 0 1 2 1 1 1 2 2 1 1 0 0 2 3 0 1 3 3 1 1 2 3 0 1 1 1 0 1 0\n",
            " 2 1 2 0 2 2 1 1 3 2 2 2 0 0 0 1 2 3 1 1 1 1 1 1 1 0 2 2 1 1 2 2 2 1 2 2 2\n",
            " 1 2 2 3 2 2 2 1 2 0 3 0 0 3 0 0 1 1 0 1 2 1 2 2 1 0 2 0 1 2 2 3 2 2 1 1 0\n",
            " 1 1 2 0 2 0 1 1 3 1 3 0 1 2 3 2 3 1 1 2 1 1 2 0 0 3 0 0 3 1 0 2 0 0 1 0 0\n",
            " 1 0 0 3 2 0 2 1 0 1 2 3 0 1 3 1 1 1 2 1 1 1 1 1 1 2 3 2 0 1 0 2 2 2 0]\n",
            "[1 2 1 1 3 0 1 2 3 1 2 0 3 1 0 2 0 0 0 2 3 0 2 0 1 0 2 1 2 2 3 1 0 0 1 1 2\n",
            " 1 1 2 2 1 1 1 3 2 2 1 1 0 0 1 3 2 1 2 2 1 1 2 2 1 1 1 2 2 2 2 2 1 2 2 2 2\n",
            " 1 1 0 0 1 2 0 1 1 0 2 0 1 2 1 1 0 0 0 0 1 0 0 1 2 1 3 1 1 0 2 1 2 2 2 2 2\n",
            " 0 2 1 3 0 1 2 0 1 1 1 2 0 0 0 1 2 3 1 1 1 1 0 1 3 0 2 2 2 1 2 0 3 1 2 2 1\n",
            " 0 1 1 1 0 2 2 1 1 1 1 2 1 2 3 3 1 1 2 1 2 2 1 0 1 0 1 2 0 1 1 3 3 0 2 2 1\n",
            " 3 0 0 2 3 2 1 3 2 2 1 1 2 1 1 1 1 2 2 1 2 1 3 2 3 1 2 3 2 1 1 2 2 2 2]\n",
            "[2 0 1 1 2 2 0 1 1 1 0 1 0 0 1 3 3 3 3 0 0 3 2 3 1 2 1 1 1 0 2 1 1 3 3 0 2\n",
            " 0 3 3 2 2 2 0 1 3 2 0 1 1 2 1 1 1 0 0 2 1 1 1 0 2 3 2 3 0 0 2 1 0 1 0 1 1\n",
            " 1 2 0 1 2 1 0 0 0 0 1 0 1 2 2 0 1 1 2 1 3 1 1 1 1 1 2 0 1 0 0 3 0 2 0 2 0\n",
            " 3 1 1 0 0 0 1 0 2 1 1 0 0 1 2 2 0 3 1 1 2 2 2 1 2 1 2 2 0 1 2 2 2 1 1 1 2\n",
            " 1 0 1 1 1 2 0 1 1 1 3 2 3 0 2 3 0 1 2 0 1 2 3 2 1 2 1 2 1 1 0 1 1 3 1 0 0\n",
            " 0 1 1 0 1 2 3 1 2 3 0 2 2 1 2 0 1 1 0 1 0 1 2 3 2 1 1 1 0 1 1 3 2 0 2]\n",
            "[2 2 1 1 1 1 0 1 1 1 3 0 2 1 0 0 2 3 2 1 0 1 0 1 1 0 1 1 2 3 1 1 2 0 2 0 2\n",
            " 1 1 1 1 0 0 2 2 1 0 1 1 3 1 1 2 2 1 1 2 3 1 1 2 0 2 1 1 2 1 0 2 2 1 1 2 1\n",
            " 2 1 3 2 1 2 2 0 2 1 0 3 2 2 0 3 0 0 0 1 1 3 1 3 2 3 2 1 0 1 1 3 0 1 0 1 1\n",
            " 1 0 2 3 2 1 0 0 3 0 2 3 2 2 2 3 1 3 0 1 3 1 2 0 2 3 0 1 0 1 1 1 0 2 2 0 0\n",
            " 1 1 1 2 2 1 0 0 1 2 1 2 2 0 3 1 0 2 0 2 1 2 0 1 1 1 3 1 1 1 2 2 2 1 1 0 1\n",
            " 0 3 1 0 2 2 0 2 0 2 1 2 0 2 2 2 2 1 2 1 1 0 1 2 2 2 0 1 1 0 1 0 0 0 2]\n",
            "[0 1 2 0 0 0 3 2 1 0 0 2 2 2 1 0 2 2 0 0 2 3 0 0 3 2 1 1 2 2 3 2 1 1 2 2 1\n",
            " 3 0 1 1 0 1 2 2 2 2 1 0 1 0 3 1 0 1 1 2 1 2 1 1 2 2 2 2 1 0 1 2 0 3 2 0 1\n",
            " 1 2 1 1 2 2 0 0 1 0 3 0 1 3 1 1 1 0 1 1 2 1 2 1 2 1 2 3 0 2 2 1 3 0 2 3 1\n",
            " 1 3 1 1 2 2 2 1 1 1 1 2 2 1 2 2 2 2 1 2 2 2 1 0 1 0 2 0 2 1 1 2 0 2 2 2 1\n",
            " 2 1 2 1 0 1 2 1 2 2 0 2 2 2 1 0 2 1 1 3 2 2 2 1 3 0 0 1 3 2 2 0 1 1 0 1 0\n",
            " 0 0 3 0 0 1 2 1 1 2 1 1 0 1 3 0 1 2 0 3 1 2 1 3 1 1 2 3 1 1 2 2 2 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5heg7ZegYtWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "029eaefa-a454-44ba-b267-f82986321b9a"
      },
      "source": [
        "test_y_raw"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bar_orders</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.266980124286869, 0.730679958020752, 2.711269...</td>\n",
              "      <td>114.448665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.6958148032167406, 1.7591587138881446, 1.2060...</td>\n",
              "      <td>106.610619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.7085216320647125, 1.4621386406536667, 3.5362...</td>\n",
              "      <td>102.109287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.7551681342158973, 1.990770038662044, 1.80226...</td>\n",
              "      <td>110.346827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.214742624257507, 0.6186439869353193, 3.49283...</td>\n",
              "      <td>114.621284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.9234232113919192, 1.6482721066715125, 0.0, 0...</td>\n",
              "      <td>111.679542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.172564922379456, 2.2300877394955734, 1.70185...</td>\n",
              "      <td>114.881194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.076408619577882, 0.10647776266119709, 1.3806...</td>\n",
              "      <td>110.441386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.5462705110867003, 2.3184685520032353, 1.3827...</td>\n",
              "      <td>105.344714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.5705349047075131, 1.6914648742655225, 2.3156...</td>\n",
              "      <td>116.785690</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          bar_orders      weight\n",
              "0  1.266980124286869, 0.730679958020752, 2.711269...  114.448665\n",
              "1  1.6958148032167406, 1.7591587138881446, 1.2060...  106.610619\n",
              "2  1.7085216320647125, 1.4621386406536667, 3.5362...  102.109287\n",
              "3  3.7551681342158973, 1.990770038662044, 1.80226...  110.346827\n",
              "4  2.214742624257507, 0.6186439869353193, 3.49283...  114.621284\n",
              "5  0.9234232113919192, 1.6482721066715125, 0.0, 0...  111.679542\n",
              "6  1.172564922379456, 2.2300877394955734, 1.70185...  114.881194\n",
              "7  2.076408619577882, 0.10647776266119709, 1.3806...  110.441386\n",
              "8  2.5462705110867003, 2.3184685520032353, 1.3827...  105.344714\n",
              "9  0.5705349047075131, 1.6914648742655225, 2.3156...  116.785690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP0Af54XC8kV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "07851fb7-606b-43f6-b5a8-dcd2142e364b"
      },
      "source": [
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(weight_pred, test_weight_label)\n",
        "plt.xlabel('True Values [weight]')\n",
        "plt.ylabel('Predictions [weight]')\n",
        "lims = [30, 60]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UQRubkHJOCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "87cdd4fa-6d2f-4928-f803-beab9bd4b109"
      },
      "source": [
        "test_weight_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141     49.664072\n",
              "178     46.876165\n",
              "180     46.752680\n",
              "188     49.893984\n",
              "207     46.951447\n",
              "          ...    \n",
              "2527    34.756029\n",
              "2528    35.064065\n",
              "2536    36.279261\n",
              "2541    34.114205\n",
              "2547    38.539278\n",
              "Name: weight, Length: 420, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOweFgdsI-eO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "c6b9a8eb-6016-43a9-fc13-3915a62c32ae"
      },
      "source": [
        "error = weight_pred.flatten() - test_weight_label\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [weight]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOiBgu0TDBm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "37bb57de-3b3e-4dd3-c8fa-f491f1c0a1db"
      },
      "source": [
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(displacement_pred, test_displacement_label)\n",
        "plt.xlabel('True Values [displacement]')\n",
        "plt.ylabel('Predictions [displacement]')\n",
        "lims = [0.2, 0.8]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OXrKZjAJaQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "284d4e67-cbb7-4f82-f673-551e94f71f34"
      },
      "source": [
        "error = displacement_pred.flatten() - test_displacement_label\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [displacement]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvBfL7fiDEDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7db6daa2-2a89-4a1f-c91b-6f6fa14e6303"
      },
      "source": [
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(util_pred, test_util_label)\n",
        "plt.xlabel('True Values [util]')\n",
        "plt.ylabel('Predictions [util]')\n",
        "lims = [10, 35]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAEKCAYAAAAM4tCNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2df5xcdXnv389OJmQ2YCbU1MLKr6qXlAjJQmyx6bWQXqG3NNwFotFKqy0V7S3egjQvo9eaxLaX1Ki5rbcvLf4o2CIGCK4i2mhJqjVVMWETQoTUKpSyIMaSRZJdk83uc/8458yenTk/Z+bMnJl53q/Xkpkz58czw5zPfL/Pr6+oKoZhGGnpa7cBhmF0JiYehmHUhYmHYRh1YeJhGEZdmHgYhlEXJh6GYdRFZuIhIvNE5EER2SciB0Rko7v9NhF5XET2un/LsrLBMIzsmJPhuY8BK1X1iIgUgW+IyJfd19aq6j0ZXtswjIzJTDzUyT474j4tun+WkWYYXYJkmWEqIgVgD/By4K9V9V0ichvwapyRyQPAOlU9FnDs9cD1APPnz79o8eLFmdlpGL3KtCqP//goY08e/LGqLkpzbKbiUbmISBn4HPAO4D+BHwJzgVuB76vq+6OOX758ue7evTtzOw2jlzhy7ARv+dSDjPzHGD+45Yo9qro8zfEtibao6hiwE/h1VX1GHY4Bfwv8YitsMAxjBr9w/NUbBus6R5bRlkXuiAMRKQGvBR4TkdPcbQIMAY9kZYNhGLVUC8cVF5xW13myjLacBtzu+j36gLtU9YsiskNEFgEC7AXenqENhmH4aJZwQLbRloeBmvGQqq7M6pqGYYTTTOEAyzA1jJ6g2cIBJh6G0fVkIRxg4mEYXU1WwgEmHobRtWQpHGDiYRhdSdbCASYehtF1tEI4wMTDMLqKVgkHmHgYRtfQSuEAEw/D6ApaLRxg4mEYHU87hANMPAyjo2mXcICJh2F0LO0UDjDxMIyOpN3CASYehtFx5EE4wMTDMDqKvAgHmHgYRseQJ+EAEw/D6AjyJhxg4mEYuSePwgEmHoaRa/IqHGDiYRi5Jc/CASYehpFL8i4cYOJhGLmjE4QDTDwMI1d0inCAiYdh5IZOEg4w8TCMXNBpwgEmHobRdjpROMDEwzDaSqcKB5h4GEbb6GThABMPw2gLnS4cYOJhGC2nG4QDTDwMo6V0i3CAiYdhtIxuEg4w8TCMltBtwgEmHoaROd0oHGDiYRiZ0q3CARmKh4jME5EHRWSfiBwQkY3u9nNE5Nsi8m8islVE5mZlg2G0k24WDoA5GZ77GLBSVY+ISBH4hoh8GXgnsEVVPysiHwOuAz6aoR1GThkeGWXz9oM8PTbB6eUSay8/l6HBgdydsx66XTggQ/FQVQWOuE+L7p8CK4HfcrffDmzAxKPnGB4Z5d337mdicgqA0bEJ3n3vfoDUN7snGKNjEwjOl6zRczZCLwgHZOzzEJGCiOwFfgR8Ffg+MKaqJ9xdngIC/6+KyPUisltEdh86dChLM402sHn7wYpweExMTrF5+8FU5/FEaHRsApgRjkbO2Qi9IhyQ7bQFVZ0ClolIGfgcsDjFsbcCtwIsX768+jthdDhPuzd70PY0U48gEUp6rWbTS8IBGYuHh6qOichO4NVAWUTmuKOPlwKjrbChV8mLD6Ca08ulymjBz4JSMXQ6A9S8lyTCcHq51DzDQ+g14YBsoy2L3BEHIlICXgs8CuwEVru7vRn4fFY29Dr+Ib0ycyMOj7Rfr9defi6lYmHWtlKxgAiB05mN9x0IfC8LSsXI65SKBdZefm6zzZ9FLwoHZOvzOA3YKSIPA98BvqqqXwTeBbxTRP4N+Bngkxna0NM0y6+QBUODA9xy9fkMuKOCgggTk1McHp8M3P/w+GTgexGhRoTE/XegXOKWq8/PdKTVq8IB2UZbHgYGA7b/APjFrK5rzBDlVwijldMc77z+aUpaxsYn2bJmWVumZr0sHNAin4fRHsL8CmE+gKDw6U1b93Lj1r0M1HFTJhGiJA7PUrHASXP6GJuoHZWcXi4xNDjQcj9OrwsHWHp6VxPmVwjzAQTdyNU5E0n9JUn9LVGjIGFm6rHhyiWp3kuWmHA42Miji/F+jZMO6eMiF56/JMmvfJS/xX982OhooFxi17qVgedtZ+TIhGMGE48uJ82QPuxG9pM0ZyKpv2Xt5efW+DzCRhTtmJ74MeGYjU1bjApB05xqkuZMhO1Xvd0fdfFPU/KQi+LHhKMWG3kYFfzTnOo6EUjnY8jLiKIZ0SMTjmBMPIxZ+G/kRm68tP6WLGhG8Z0JRzjiFL/mm+XLl+vu3bvbbYbRJFqVS7Ji045Uzthqekk4RGSPqi5Pc4yNPIyW0sxS/DjqSZLz6CXhqBdzmBotpZUp80mdttWYcCTDxMNoKY2MBqoZHhllxaYdnLPuflZs2lGTgJY2SQ5MONJg0xajpSRNmY/ziySZ/qR12ppwpMPEw2gpSUK4SYQhaQZr0jCwCUd6LNqSQ5oRjchrEyCIt23Zxq8EFsEt7C/SP3cOT7v1MmEMlEup3rcJR33RFhOPnFH9qwvOL3OarMugcwCIgCp1Vci2iuGRUW7curfu44MS26I+OxMOBwvVdjD+DuDVpClIg/Ayd+93ol1dxYOoHoWMHz8Rf1AEYQ2Qg96nCUdjWLQlB1R3AA8iTTQiyb556CgWVLYf1kmsEYI+DxOOxrGRRw5I0hAnTRPfJNWxkE6QsvChJHnfzaD6szPhaA428sgBcTdx2qY3SapjIbkgZdVIuRVLIhT7ZNZnZ8LRPEw8ckDUTVxPibpX5l6O6CyeRpCyygoNe9+lYh99EvhSak6eN6fy2ZlwNJfIaYuIXJjgHJOquj9+NyOMsNyHRvpaePkNfkdsQYQp1dTRlmZmhfoJet/FPuH4lDLdpCDgmOtDMeFoPnE+j6/hLJsQ9TtwDnB2swzqRbIsX29Gr4xyfzHQkdnoYkpB73ts/DhHjzfPD3J6uWTCkRGReR4iskNVI2uXk+zTKL2U5xFHEsdlM52bwyOjrL17H5NVQ4E+cVZ3GxufrLlGI9c/e939oa8NlEscPXYiMIEsiFKxwPpV53HPnqdMOGJoep5HElHIWjiMGZKkbTe75H3z9oM1wgEwrVRGI9VLQtZ7/TgH7K51K2OTyPzZpe9Y+XITjgxpyOehqg8115zup5Ff5ST1HElrPpKS1K/hd6DWc31P9MLwnL9DgwO8+96HmZicrtlHhMrnaVOV7InzeXwo4jUFbNSRgkZHBUkcl812bibNGQESJbmFiWdUzkexT9hw5ZLK81uuviBwKqXqjHq++YMf87mHnub41DSn9s9lcqpWaIzGiZu2XNoqQ3qBRkcFScrZ064SF4T/Bi/3Fyn2yawbtbp+JAmnl0uR4hklbptft7SmUhbg5rv2MVXls5uYnGLrd56qPH9u/HhuUvG7jcg8DxFZ6f57ddBfa0zsHhodFVy6eFHs9noa4PipTgg7PD4J4kwbvKUR3nTxmYmS0KqvHyWeYeI24C4nWc3Q4ADTCYs685CK343ETVt+FdgBrAp4TYF7m25RF1PPqMA/CuiT4Ij5zscOVR43GvYNusEnp5T5J81h7/rLKtuWn3Vq5Rpx5fHe9W8KcXQ+PTbBljXLAnNdLl28iBWbdgS+lzRTqlZks/YacdOW9e7D96vq4/7XROSczKzqUtKsZQK1PpLqIbpH9Y3RSG5H0tGR/xpJu5RHiWeQ6F26eBHb9oyG+oiCPs8wGs1JMWpJmp6+LWDbPc00pBdIuzpa0sKxZt4Y9TQNTjpVittvaHCAXetW8vimK9i1biU7HzsUmRY/NDjA+lXnMbfgfI1P7Z/LtQFTqnYtiN3txIVqFwNLgAVVPo4XAfOyNKxbSTMqSDLUbvaNkXZ0BOFTJZgZlXip8eVSkXnFvsDksmriRkFHjp3gnj1PcWLaiaocHj/OzscOcc1FA+x87FAuu6h1E3E+j3OB3wTKzPZ7vAC8NSujDIewYX5BhGnVTG6Men0m1aIYNuUam5ikVCywZc2y2HNGTXO8PI6HnjzMnL4+nhs/DjhTm217RnO53m23kagNoYi8WlW/2QJ7AunV9PRmtCRsF2F+EI8kAhj2/v0p5wvmFSvC4SfpqnCGQ5ZtCK8XkZqRhqr+XoQxZwCfBl6CE5m5VVX/UkQ24IxavBDBe1T1S2mM7hWSjgLy2Ow4LgrijUSiEuWC3n91yvkNnwlOcrboSvYkFY8v+h7PA64Cno455gRws6o+JCKnAHtE5Kvua1tU9YPpTO1N4nwkrVy+MSnDI6OpEsmiEuX87z8o5fz/fKnxpDijPhKJh6rOiraIyJ3AN2KOeQZ4xn38gog8CuR7rN2BNJK1mtWIZfP2g6kzUONGCmG1KvU4eI3mUG8P01cAP5t0ZxE5GxgEvg2sAG4Qkd8BduOMTg4HHHM9cD3AmWeeWaeZ3U89WavDI6NsvO/ArB4dzRyxRF3bi7pUEzVSiCpyy7IXihFNIvEQkReYPQr9IfCuhMeejJMncqOq/kREPgr8qXu+P8UpvqvxnajqrcCt4DhMk1yrF0mbtRq2pgs4I5ab79oHNCYgYTZ52aZB1z967ATDI6M11w0SjqARkzlHW0/Sacsp9ZxcRIo4wnGHqt7rnutZ3+sfZ7Y/xUhJ3LC9+kY7euxEZOLZlGrDI5Aom7xzVo98xiYma65bLRyTU9M1q8nlwcfTq8QVxv1c3AnC9hERAT4JPKqqH/Zt9zdWuAp4JJmpRhBRWavDI6OsvWffrK7nSbpwNVpIFpdJOzQ4QP/c2t8t/3X9eRwL5hX5w888xE1b9wbab4Vv7SFu5PElIK4Jctg+K4DfBvaLiFcR9R7gjSKyDGfa8gTwtsTWGoGERWQ23neAyan6ZnyNhjrjokRRvpqwBLCod2Kh2dYTJx5LReQnEa8LEPi6qn6D4MbJltPRIhpZfS3rUGeYX+TnFsyrTFXKpbmBCWBh5zNaS+S0RVULqvqiiL9TVNUmmh2IN6VY6Db7qWb8+ImGF3WKIqhIbt6cPuYVCxUfx+GEwmGh2fZgy03mgKzyLcqlYqCPoFwqzopODI+MsuELB2bte3i81oHZTKpDrD+3YB7zigWefG48NgHMz8L+IutXLTFnaRuwFePajLe0gd+pufbufU351d9w5ZKaUUV1P1BwbuT5J0U7MLPAK8Hfv/FyBsqlWcIB8ctmlksmHO3ExKPNbPjCgZpGvpPTyoYvHGj43EODA2x+3dJZUY/qfqAeWa0KF0dcApg/alM9xfLCu1lOr4xwkiaJvQx4SlWPicglwAXAp1V1LEvjeoGw0GnShY3iSNo/pBmNk9OSZHmE6o5l1U7gRpaVMBojTSexKRF5OU7W5xnAZzKzymg5jTZOTks966q0a3RkBJPUYTqtqidE5CrgI6r6EREZydKwXmFhyDqwC/vDV7hvJn5n7YIUXb4aod4FmdoxOjLCSTrymBSRNwJvZiadvDXf7i5n/aolFAtVTs2CsH7VkpAjmkf1MgtjE5P8dHKaLWuWsWvdylwJB7R+dGREk1Q8fhd4NfDnqvq42zn977Izq3cYGhxgzavOoOAuq1AQYc2rzmjJHD6qnD8LGl0CMm0DaSNbkhbGfRf4X77njwN/kZVRvcTwyCjb9oxWytSnVNm2Z5TlZ52a+U3RSh9Cs9aObWRZCaO5JI22rAA2AGe5xwigqvrz2ZnWG4T9+m+870DmPSqy8iFUJ72lXa0+Lmkuj20Xe5GkDtNPAjcBe4D4hUSMRF/w4ZHR0AzKw+OTFUdqI2XnUXZk0YUrqC3iez7n2P6RN17I5NR0zQpwMJNpWu4vcuSnJyq5L9XvPY9tF3uVpOLxvKp+OVNLuogkX3Bvn6TUk88QZ0cWXbiCRlLTSmW1+mp71t69D4RK9W9Q5Mn/3htdLNxoHknFY6eIbMZZm/aYt1FVg1tX9yjer3zQaKL6C550NTg/aX0RSW60ZvsQwmw8PH48eB3c6WQtA7zzWq5HfkgqHr/k/utf10EB6/3mEtXez8P/Ba/ny57WF9GOGy3Kj9LIdb33brke+SFRqFZVLw34M+HwkWQk4f+CR33ZiwWpKWirxxcRdo1yhglo71j5cqor/D3b673B/e/dcj3yQyLxEJEFIvJhEdnt/n1IRBZkbVwnEferWv0FD6sYXdhfZPPqpTUFbfXkM6y9/NyaBDSA58cnMykm89aOBcfHUW37pYsXBR5XqK78LQjlUjG0haHleuSDpMtNbsPpNXq7u+m3gaWqenX4Uc2jE5abjFpecSAi2uLvo5FFb4pf+JMvMzE5XbO9XCqyd/1lFTsadZom6XI+fvxEoEO0XCoy/6Q5FpptI1kuN/kyVb3G93yjry+pQXjYM+5X8diJmRs7iwY8QcIBM1W7zQh9hglH9XnDeH5isiJk1aS1z4SmdSQVjwkR+RW3L6mXNGbubR/1hD3j0sO9yI23UFLYCKYRGg19hmWOpokmKc7ILei9pbHPckBaS1Lx+APgdtfPIcBzwFuyMqpTSRv2DPOTeF967yZIsih0GHFVu41EZKJSztNGVvzvDWZEOGxSHXR+ywFpLUlrW/bidFJ/kfs8qqO6kZCwsGNBJPRXO+06tEHC4a/arTf0GVerEnZez78Rlgtz09a9ida5DbLPckBaS9yiT9e6/75TRN4J/D7w+77nRgOERVyC1nL1E3cz+EvtPbx4xkC5xObVM60I6wl9JilyCzvvhiuXsGvdysA1OSB6bZY4+8IEz3JAsiFu5DHf/TdouUlbP7ZBvBu4unN5HNU3Q5IlJRVHOKrXdE3rq0laHRt33rCRSRTiHhdmXxa1OkY4keKhqn/jPvxHVd3lf811mhopCYoGzD9pTmLxqL4Z0kQ1wl6rvtE9h229i077czLCzhu24HUUb7r4TP5s6PzIfeYV+yrnLJeKbLjSuqtnRdJmQB9JuM2IoLpzl+ckTPoLLDg3x01b97Ji047KjZv0BhTXhqR2+feNCseGHRe1rISX7OU1QUrCHd96MjS5zbPF7+Pxh8GN5hPn83i1iNwMLPL8HO7fBiB8QQ0jkLBoQNIbSHFyQeoRHu/4oC5hcSHjNOFY/3Fxy0oMDQ4wnSBJMc7+JLYYzSfO5zEXONndz+/3+AmwOiujOpEkyUlhN/qUKqViIXWVrSc8cQ5WP0HO1iSLTqcJx46OTbBi045Ey0qk9X2kjahYpCU74taq/ZqqbgQuVtWNvr8Pq+r3WmRj7kky7B8eGQ2NMHj1GV69RrlUDKxJCcITHj+lYiG0+3pQ5GFBKXhf/6LTYeHYMJIKQlBUJuq9p42oWKQlO5L6PD4hImXviYgsFJHtGdnUcSQZMm/efjAwPCVQGaXsWreSxzddwd71l7F59ezCuPlzg2eJ1cLjPV+/akmiEOzwyChHj5+oOe8cYdai02Hh2OQeixn8whZU6LZ59VKuvfjMmnNHRU6s2rb1JM0wfbF/dThVPSwiP5uRTR1FVCvBJP07lJn2etXTHi+s+t7h/fz9t56sObbQJxXhCYsoxE2lNm8/WOniNcsukZq1Y6sZGhzgxq3pS5wOj0/OSkf32+//HMr9RVSd2peoEK3fcZxlKr8xm8SLPonImar6JICInIXlecS2EvQPmcshaeID5VJkTQY4UYYgpmK6cCVJlw/1w0wrf/1bF8Y2Kx6I8Vks7C/SP9fJKBVmvjRRrRm9z+Hw+CSlYoEta5aFvo/qY7xpnAlH9iSdtvxv4Bsi8nci8vfA14F3Z2dWZxAVJvUPmYdHRjny09qpQbHgjByiOqjHpWs3Ek2I8sOc2j830fIIUSvZl4oF1q9yMkoHyqWa9xE0tUsbMbEoS/tI2knsH4ALga3AZ4GLVLXnfR5Rnnx/Kf7m7QcDe3XOnzuHocGBiL6fk7HDu0aiCWF+GID3rTov0Tn8PgugEnaubtKTJBpST8TEoiztI3LaIiKLVfUxEbnQ3fS0+++Z7jSmpxsgh4UZB8qlWUPmsC/y8xNOR6++lOHWahuq/SWXLl7EzscOxaabR91gaYb8SaZHSQrw6inSs56m7SNu5HGz+++HAv4+GHWgiJwhIjtF5LsickBE/sjdfqqIfFVEvuf+u7DB99A2knr4o3qJvvve/XULh+D4Dm7aundWmPjvv/VkZNg4zq6BDG68JJ9VPRETi7K0j7g8j7e6/9bTAPkEcLOqngdcDPyhiJwHrAMeUNVXAA+4zzuSJP00h0dGGQ8IhZaKBVQJ9JkUxOnhGYXf+RgnPWE+gKBmxcWCcPTYCc5Zd38lBb4ZJPms6ulPaj1N20dkD1MRiexRqqr3Jr6QyOeB/+f+XaKqz4jIacA/qWrkz0Qn9DANImw5Bq9gK8wZKsCWNctYe/e+Gl9JsSCcfNKcwMhNFAI8vumKynMvc/ShJw9TLs3l8PjxmtXaIFkrxVZjrQabTz09TOOmLavcv+twlpx8k/v3CeD3Uhh2NjAIfBt4iao+4770Q+AlIcdc73VrP3ToUNJL5YqwaMz8kxxHadi0QWSmLsRf9uJ1Vh9LKRwwe4riTzn/yBsv5H2rzuP0conD45M1YpW3yEWSbF6jNcRNW35XVX8XKALnqeo1biPkJe62WETkZGAbcGN1BzJ1hj2BQx9VvVVVl6vq8kWLglv25524SEBYmHNaZ+o/VJ1f//+7Zhkj77ssUnTC8PsAqmtVvCUgo3I1wt7H8MgoKzbtaOoUJ+6cFprND0nzPM7wjRYAngXOjDtIRIo4wnGHb4rzrDtdwf33Ryns7Sji6i2SlqVX3xxRuRVBXHOREw0JKnJLu1iVRxYjgCTntNBsfkgqHg+IyHYReYuIvAW4H/jHqANERHCmOo+q6od9L30BeLP7+M3A59OZ3D6GR0YZfP9XOHvd/Zy97n6WbfxKZH+Jo8eCHaX+SEDSsnT/zeGJTrWzM4xte0b57INP1ow4otaaCbPXI4sRQJJzhglyn4hNXVpM0gbIN4jIVcBr3E23qurnYg5bgbM41H7fGi/vATYBd4nIdcC/A69Pb3brGR4ZZe09+2bVgYxNTDqrvDM7xTqqreBJc2r1OklZ+oJSkRWbdsxyEiaN8E5MTvG+zx9gSnXWVCVuxBFVHxJmb9rWgn6SjCrCOpBNqdoyCy0maW0LwEPAC6r6jyLSLyKnqOoLYTu7a7yE/Tb+Whoj80BYAdnktFa6mSdZ7HpsonZhp7iWfH0CR4+fqAiSN5wPq5cJ4vjUdKVWZcWmHZE2JomwhPURSdMZrJokCV+eTTffta/m+rbMQmtJulbtW4F7AK+n6QAwnJVReSSJQzFpS0D/UDxJK8FppUa4JianGBufTNz3w1+rEuUfKJeKiUKzYYlt9Sa8QfKEr6ipnvk+WkdSn8cf4kxDfgLgNgLqmZL8qAIymPllTPPFfXpsInCJhDQojqh4P/ZhNs4t9M2qVYmK1iTt+xmWhdpIdmqahC9r/tN+korHMVU97j0RkTn0UEl+VAFZ0e2pAeEduYJYUCqmal4chersjFM/fcAHVl8w6waMitYkdXpmlRbub4q0a93K0BGQpaW3n6Q+j6+JyHuAkoi8FvifwH3ZmZUvokYUm1+3tOLvCOrIFYbfh9EMwsRtmpmy/eolEcIa+SQZQdWzNm8zaff1jeTi8S6c1eL2A28DvoSTZdoTJKmeDXOohpFm30YJarwzNDhQWUi7mqRD/7Rr8xrdRax4iEgBOKCqi4GPZ29Svkiar5F3R11QJKKZK6y1ut4kqvuaCVpriPV5qOoUcFBEYjNKuw3vC1o9vVjYXxuRaLejri/GaQrBAjevOPMVSBppqaaZ2aZJU94tTb39JJ22LAQOiMiDwFFvo6pemYlVOSHKobl5+0Fu2rq30nwnqOy+lUwrFPpgKiJY4he4oJyUeldYi7qR0whRmtGEpam3n6Ti8SeZWpFTotoDeslZXvOdavqLfcydU+B5r8AtOzMBZwgZJRzV05Fm3fDQvBs5jU3WQaz9xC03OU9EbgReBywGdrkLQX1NVb/WEgvbSCNfxIXzT2Lv+svYsmYZcxImcjVC3JihejrSzPTyZuVcpBEhC9W2nzifx+3Acpwoy3/HaT/YM6StXvUzOjbBOevu56a79rY0shJEdU9VCE8jrye9vFk3choRsg5i7Sdu2nKeqp4PICKfBB7M3qT8EJRLcPRY8vwMrfwnW8ISxDwuXTzTD8WLijQzvbzenIugxs3b9owmjv5YqLi9xIlH5S5R1RPSQNFTp1L9BU1S/NZq4m73bXtGWX7WqQCxttebXp72Rg5yjm7bM8o1Fw0k6vxutJ+4HqZTzERXBCgB4+5jVdUXZW4h+ethGrXUQTsmKHEjD3CmI6fMm5N41LSwv8j6VUuacuMG5YCEJagNlEvsWrfS+pS2mHp6mEaKR17Im3hEkaTBTqdQLAibVy9t6KYNGqmVioXQ0Y/X/DnoGPNpZEcWDZB7mrQ9OsOWWcg7YU7SySltOOkqLPwads3TyyVLAOsQTDxCSJs1+d7h/dy0dW/qJRHaTalYiHSSNpp0FXa8tyB1tS1rLz/XEsA6hDSdxHqKuF8//3z87J8psev7z7XDzLoYKJcS+R+g8aSrqKJC79rVfo1GC/aM1mDiEULYr5w3AvFHCTrJxyEwy9EbJRzFgjScdBVVfBcWoWlmwZ6RHSYeIUQ1Jc5TmDYt3gQlLK3eo1nRlnpyQKxXR2dg0ZYQ8pjP0Qq8UKnRW9QTbbGRRwj+X79OmpY0Sqc4JS0PpP1YtCUCr59mPXTqB9sJTklbrzYfdOp3vGXEdU4PI/+TwVo6xSlpeSD5wMQjhqjO6VG0Qjy8RKu4Sliv8rRcKrKwv1ipQr324jMrtSwFkcoNmPdf8LBpZKdMuboF83nEkNcvZLVjMywtPs4B2mm9QL2RYJA4d8KUq5uwkUcMef1CVk8vLl28qGZ6lWQa0mlTgLCRoFD7mRjZYuIRw9rLz6WYdDn6NjE8Msq2PaOzbioBrrkovky+01LBw+xS8jlS6mZs2hLD0OAAG+87kLuaFX9fz6DRgwI7Hzs0a9vwyCgbvnCgUpa/sL/IglIxsEw/ryOuqHR3o7WYeITgzyPIY+TE/zmH2S0AAAw4SURBVAucxIE4PDLK2rv3MTk9824Oj09S6BOKfTJre56jLpa6nh9MPALohOxSb2SQ1IG4efvBWQLhMTWtvKi/SP/cOR2RcGWp6/nBxCOAZi1AnRX+X9qkDsQoH8bY+CQj77usyVZmh/UuzQfmMA0gr85CqO0SntSBGOXDyKt/w8g3Jh4B5PFmEgleSjLM1moHYljUqBll90Zvkpl4iMinRORHIvKIb9sGERkVkb3u329kdf1GWHv5uXWlpGeJKpU6jrV376tkgSZdM2VocIDNr1tKuVSsbFvYX2y4R6nRu2RWki8irwGOAJ9W1Ve62zYAR1T1g2nO1Y6S/PcO7+eObz3Z9kiLiCMc1ZRLRfaud/wUVmFqNEquSvJV9esicnZW58+aPxs6n+VnnVq5KcPyIbLAa8QDcOPWvYH7+G0xB6LRDtrh87hBRB52pzULw3YSketFZLeI7D506FDYbpnileRvWbOMoy3oii7AtRefWYl8eDUmhpFHWi0eHwVeBiwDniFi7VtVvVVVl6vq8kWLFoXt1hI23negJevNKs7qbt40JCpcvLC/GPqaYbSCluZ5qOqz3mMR+TjwxVZePw3tyjD1itKiwsXFglSmNYbRLloqHiJymqo+4z69Cngkav920e4MU8/xGZR2XpDZq7iZs9RoF1mGau8EvgmcKyJPich1wAdEZL+IPAxcCtyU1fUbod0Zpp4IBIVgP/T62cJh7fiMdpFltOWNAZs/mdX1mkk7M0y9tPIkNRxRvThs9GFkjdW2BBC1ZkvW+NPK40KwndaLw+guLD09gKApQ6PMn5vsfGn6UoSlpucxvd7oPkw8AhgaHOCWq88nTQOxQp/MSv2uptw/Nza8mrYvRdLUdMPIApu2hOBNF9besy82x6NP4OJzFvLEf06EZqHGTSUG6oiUWG8Lo52YeEQwNDjATyenWBeT6TmtsOv7z0Xu400lgnwp1U7StDaaWBjtwKYtERw5doJ79jzV8Hm8qURYta5CbruVG0YYJh4hHDl2grd86kEeevIwcwv1F+j7m/cMDQ6EZqtahMToNGzaEoBfOOb09XF8arqu8wQtuDQQEga2CInRadjIowpPOEb+Y4xyaW7dwhEW9bAIidEt2MjDh184/uoNg9zwmYdSHV8QYVq1EvUAZxnIoEiIRUiMTsfEw6VaOK644DTW3t3H+GSykUepWJjVmDhuDVgTC6PTsWkLwcIxPDKaWDigdmnHTlsD1jDS0vPiESQckD50Wr20o9WdGN1OT4tHmHBA+pu8OoJSDklFD9tuGJ1Gz4pHlHBA+tCpwKw+GmFN6TNqVm8YLacnxSNOOMBdJClFclh1lujzITUuYdsNo9PoOfFIIhzgLpK0emlNJexJc8I/Mv9Ux8rljW6np8QjqXB4DA0OsH7VklkjkGMnwiMwfmGwZDCj2+mZPI+0wuGRdNmFamGwZDCj2+kJ8ahXOAAOjyfzUfgTxDwsGczoZrp+2tKIcCRloFwykTB6jq4Wj2YIR1RrQTA/htG7dK14NGvEseHKJRRDmpn6e3UYRq/RlT6PZk5VzPFpGMF0nXhk4eMwx6dh1NJV4pGFcNhasIYRTNeIR1bCEdWTwzB6ma5wmGYVjrWeHIYRTseLR5Z5HNaTwzDC6WjxyDoBzIrbDCOcjhWPVmSOBhW3CXDp4kVNv5ZhdBodKR6tEA5wnKLXXDQwa5U3BbbtGZ3V+McwepGOE49WCYfHzscO1azyZk5Tw+gw8Wi1cIA5TQ0jjI4Rj3YIB5jT1DDCyEw8RORTIvIjEXnEt+1UEfmqiHzP/XdhknNNq7ZFOMA6ghlGGFmOPG4Dfr1q2zrgAVV9BfCA+zyWx398tC3CAY7T9Jarz2egXEKwSlrD8BDNcC0AETkb+KKqvtJ9fhC4RFWfEZHTgH9S1dif8JNOe4Xeu/3rLRcOw+gVRGSPqi5Pc0yra1teoqrPuI9/CLwkbEcRuR643n167DeXnv5I2L4548XAj9ttRAo6yd5OshU6y97U8/C2FcapqopI6LBHVW8FbgUQkd1pVbFddJKt0Fn2dpKt0Fn2isjutMe0OtryrDtdwf33Ry2+vmEYTaLV4vEF4M3u4zcDn2/x9Q3DaBJZhmrvBL4JnCsiT4nIdcAm4LUi8j3gv7nPk3BrRmZmQSfZCp1lbyfZCp1lb2pbM422GIbRvXRMhqlhGPnCxMMwjLrInXg0M609a0Js3SAioyKy1/37jXba6CEiZ4jIThH5rogcEJE/crfn9bMNszd3n6+IzBORB0Vkn2vrRnf7OSLybRH5NxHZKiJz220rRNp7m4g87vtsl0WeSFVz9Qe8BrgQeMS37QPAOvfxOuAv2m1nhK0bgD9ut20Btp4GXOg+PgX4V+C8HH+2Yfbm7vPF6RF1svu4CHwbuBi4C3iDu/1jwB+029YYe28DVic9T+5GHqr6deC5qs3/A7jdfXw7MNRSo0IIsTWXqOozqvqQ+/gF4FFggPx+tmH25g51OOI+Lbp/CqwE7nG35+mzDbM3FbkTjxASp7XnhBtE5GF3WpOLaYAft+ZoEOcXJ/efbZW9kMPPV0QKIrIXJ/Hxq8D3gTFVPeHu8hQ5Er9qe1XV+2z/3P1st4jISVHn6BTxqKDOWCvP8eWPAi8DlgHPAB9qrzmzEZGTgW3Ajar6E/9refxsA+zN5eerqlOqugx4KfCLwOI2mxRJtb0i8krg3Th2vwo4FXhX1Dk6RTw6Jq1dVZ91/8dMAx/H+SLlAhEp4tyId6jqve7m3H62Qfbm+fMFUNUxYCfwaqAsIl792EuB3DW+9dn76+5UUVX1GPC3xHy2nSIeHZPW7t2ILlcBuagGFhEBPgk8qqof9r2Uy882zN48fr4iskhEyu7jEvBaHB/NTmC1u1uePtsgex/z/YgIjn8m8rPNXYapm9Z+CU4587PAemAYx3N9JvDvwOtVte2OyhBbL8EZUivwBPA2n0+hbYjIrwD/DOwHpt3N78HxI+Txsw2z943k7PMVkQtwHKIFnB/ku1T1/SLy88BncaYAI8C17q96W4mwdwewCCcasxd4u8+xWnuevImHYRidQadMWwzDyBkmHoZh1IWJh2EYdWHiYRhGXZh4GIZRFyYehmHUhYlHhyEiP+Mrmf5hVXl6wyXfIrJeRG6p2rZMRB6NOGaDiPxxo9eOOP8TIrJfRCI7kYvIJSLyy77nbxeR33Ef3yYiq93Hd4jIc95zoz7atvSCUR+q+p84SVKIyAbgiKp+0HtdROb4irHq4U7gH3DqHDze4G5vJ5eqatwaKJcAR4B/AVDVjwXtpKpvEpHbmmpdD2Ijjy7A/VX9mIh8G/hA9UhARB5xK1MRkWvdRjB7ReRvRGTWQryq+q/AYRH5Jd/m1wN3ishbReQ7bhOZbSLSH2DLP3kjBBF5sYg84T4uiMhm9/iHReRt7vbTROTrrj2PiMh/TfB+nxCRF7uPl7vXPBt4O3CTe67/mvWIqNcx8egeXgr8sqq+M2wHEfkFYA2wwq2onALeFLDrnTijDUTkYuA5Vf0ecK+qvkpVl+LUblyXwr7rgOdV9VU4VZtvFZFzgN8Ctrv2LMVJi06Nqj6B03Bni6ouU9V/ruc8RnJs2tI93K2qUzH7/BpwEfAdp/aJEsFVtFuBfxGRm5k9ZXmliPwZUAZOBransO8y4AKfn2EB8ArgO8Cn3AraYVWtSzyM1mPi0T0c9T0+wexR5Tz3XwFuV1W/P6MGVf0PEXkc+FXgGpzycnDa1A2p6j4ReQuOj6Ea/7Xn+bYL8A5VrREcEXkNcAVwm4h8WFU/HWVfxDWMFmLTlu7kCZzeqojIhcA57vYHgNUi8rPua6eKyFkh57gT2AL8QFWfcredAjzjjhKCpjvetS9yH/ujGduBP3CPRUT+i4jMd6//rKp+HPiEZ3eC9+dd4xrf9hdcG40WYOLRnWwDThWRA8ANOM2DUdXvAu8FviIiD+O0yzst5Bx3A0uYHWX5E5wS/l3AYyHHfRBHJEZwWhV4fAL4LvCQON3m/wZn5HsJsM/dfw3wlwne30bgL8VZnNk/VbsPuMpzmCY4j9EAVpJv5B43YrM8Qag2zTlvA76oqvfE7WsEYyMPoxM4BDwQlySWFBG5A8ef89NmnK9XsZGHYRh1YSMPwzDqwsTDMIy6MPEwDKMuTDwMw6iL/w9obGm52Ud6NAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcsWbnXxJmmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "98436a81-f0f1-4a2d-e1c6-ebe3de01fa6e"
      },
      "source": [
        "error = util_pred.flatten() - test_util_label\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [util]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}