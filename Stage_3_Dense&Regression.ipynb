{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage_3_Dense&Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "g0w4MW9hpLhz",
        "AgooluCFZCTO"
      ],
      "authorship_tag": "ABX9TyMbHN9t7fDd34tT1q3/W1Ky",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XingxinHE/FinalThesis_DL-GA/blob/master/Stage_3_Dense%26Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTxgp4izTN0j",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxHz82xPo63m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "679989d9-ada8-411d-b57f-994e4e72a2ad"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV9asYKxyxN-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3234e8d8-c31d-436c-b547-144cb55e83b0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uisTtYdxS8h-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d887afb5-491d-4784-a496-6db5204b851a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3m1cig3TDmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/Final Thesis/data/stage3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80y1T2cGX5nD",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YG9VicuX5JS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = pd.read_csv('605_coord.csv', index_col=0)\n",
        "train_x.drop(columns=list('2568'), axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNZ6co9qZ2a_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6326ee3a-f44f-4183-8d0f-b0ad4b21644f"
      },
      "source": [
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h1O7ZjLBkio",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7f85e31b-9d70-423a-c80a-47f88b0165a4"
      },
      "source": [
        "train_x.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     3     4     7\n",
              "0  40.0  35.0  30.0  20.0  35.0\n",
              "1  40.0  40.0  40.0  15.0  35.0\n",
              "2  30.0  30.0  40.0  20.0  20.0\n",
              "3  10.0  40.0  40.0  20.0  25.0\n",
              "4  35.0  40.0  30.0  10.0  30.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecO6GbLJA2Nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x = pd.read_csv('10_coord.csv', index_col=0)\n",
        "test_x.drop(columns=list('2568'), axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1LYg1x9A_b3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a92a22f6-e78e-47e1-dc89-34eaea59fe06"
      },
      "source": [
        "test_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAeQFbp8BehP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "11248473-b9eb-478c-fb3d-76415571ad8c"
      },
      "source": [
        "test_x.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>25.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1     3     4     7\n",
              "5  30.0  40.0  15.0  10.0  20.0\n",
              "6  40.0  35.0  35.0  20.0  30.0\n",
              "7  35.0  40.0  25.0  15.0  20.0\n",
              "8  25.0  35.0  30.0  15.0  15.0\n",
              "9  20.0  40.0  10.0  10.0  35.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt6bDAU-BGHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "47f4c9a8-3e2d-4b13-9c3b-cb239642c27f"
      },
      "source": [
        "train_test = pd.concat([train_x, test_x])\n",
        "train_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>25.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>20.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>35.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>615 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0     1     3     4     7\n",
              "0   40.0  35.0  30.0  20.0  35.0\n",
              "1   40.0  40.0  40.0  15.0  35.0\n",
              "2   30.0  30.0  40.0  20.0  20.0\n",
              "3   10.0  40.0  40.0  20.0  25.0\n",
              "4   35.0  40.0  30.0  10.0  30.0\n",
              "..   ...   ...   ...   ...   ...\n",
              "5   30.0  40.0  15.0  10.0  20.0\n",
              "6   40.0  35.0  35.0  20.0  30.0\n",
              "7   35.0  40.0  25.0  15.0  20.0\n",
              "8   25.0  35.0  30.0  15.0  15.0\n",
              "9   20.0  40.0  10.0  10.0  35.0\n",
              "\n",
              "[615 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx3UTW27nJa4",
        "colab_type": "text"
      },
      "source": [
        "### Normalize train_x and test_x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l03YbVHhnHqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - x.describe().transpose()['mean']) / x.describe().transpose()['std']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ABl5Q7UBp6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cd4ec714-1943-4dd3-ef47-d3644cfb70b0"
      },
      "source": [
        "train_test = norm(train_test)\n",
        "train_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.535916</td>\n",
              "      <td>0.015960</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>1.351416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.535916</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>-0.019255</td>\n",
              "      <td>1.351416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.547853</td>\n",
              "      <td>-1.210941</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>-0.785142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.428273</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>-0.072956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.041884</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>0.639230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         3         4         7\n",
              "0  1.535916  0.015960  0.455173  1.164952  1.351416\n",
              "1  1.535916  1.242861  1.449600 -0.019255  1.351416\n",
              "2  0.547853 -1.210941  1.449600  1.164952 -0.785142\n",
              "3 -1.428273  1.242861  1.449600  1.164952 -0.072956\n",
              "4  1.041884  1.242861  0.455173 -1.203463  0.639230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhtXxVqnnfP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10c696c2-2390-46b2-cc6a-8638269fada9"
      },
      "source": [
        "train_x = train_test.iloc[:605, :]\n",
        "train_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AeTlMqWCc_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "d36b197c-61e4-4550-b1b7-564be4c6dd42"
      },
      "source": [
        "train_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.535916</td>\n",
              "      <td>0.015960</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>1.351416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.535916</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>-0.019255</td>\n",
              "      <td>1.351416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.547853</td>\n",
              "      <td>-1.210941</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>-0.785142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.428273</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>-0.072956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.041884</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>0.639230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>-0.934242</td>\n",
              "      <td>0.015960</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>-0.072956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>-0.934242</td>\n",
              "      <td>-1.210941</td>\n",
              "      <td>-1.533682</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>0.639230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>0.053821</td>\n",
              "      <td>-1.210941</td>\n",
              "      <td>0.952387</td>\n",
              "      <td>-0.019255</td>\n",
              "      <td>-0.785142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>603</th>\n",
              "      <td>-0.440210</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>0.639230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>0.053821</td>\n",
              "      <td>0.015960</td>\n",
              "      <td>-0.042041</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>0.639230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>605 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         3         4         7\n",
              "0    1.535916  0.015960  0.455173  1.164952  1.351416\n",
              "1    1.535916  1.242861  1.449600 -0.019255  1.351416\n",
              "2    0.547853 -1.210941  1.449600  1.164952 -0.785142\n",
              "3   -1.428273  1.242861  1.449600  1.164952 -0.072956\n",
              "4    1.041884  1.242861  0.455173 -1.203463  0.639230\n",
              "..        ...       ...       ...       ...       ...\n",
              "600 -0.934242  0.015960  0.455173 -1.203463 -0.072956\n",
              "601 -0.934242 -1.210941 -1.533682 -1.203463  0.639230\n",
              "602  0.053821 -1.210941  0.952387 -0.019255 -0.785142\n",
              "603 -0.440210  1.242861  0.455173  1.164952  0.639230\n",
              "604  0.053821  0.015960 -0.042041 -1.203463  0.639230\n",
              "\n",
              "[605 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTDrP9kBCNjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbdd2383-81fe-4765-e656-462c27ac5cd7"
      },
      "source": [
        "test_x = train_test.iloc[605:, :]\n",
        "test_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgSnYvZ1Cg1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "2569e7d6-b18f-46c2-da89-21fd2226d202"
      },
      "source": [
        "test_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.934242</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>-0.042041</td>\n",
              "      <td>-0.019255</td>\n",
              "      <td>-1.497328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.547853</td>\n",
              "      <td>-1.210941</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>-0.072956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.428273</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>1.449600</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>0.639230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.041884</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>1.351416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.440210</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>-0.042041</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>-0.785142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.547853</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>-1.036468</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>-0.785142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.535916</td>\n",
              "      <td>0.015960</td>\n",
              "      <td>0.952387</td>\n",
              "      <td>1.164952</td>\n",
              "      <td>0.639230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.041884</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>-0.042041</td>\n",
              "      <td>-0.019255</td>\n",
              "      <td>-0.785142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.053821</td>\n",
              "      <td>0.015960</td>\n",
              "      <td>0.455173</td>\n",
              "      <td>-0.019255</td>\n",
              "      <td>-1.497328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.440210</td>\n",
              "      <td>1.242861</td>\n",
              "      <td>-1.533682</td>\n",
              "      <td>-1.203463</td>\n",
              "      <td>1.351416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         3         4         7\n",
              "0 -0.934242  1.242861 -0.042041 -0.019255 -1.497328\n",
              "1  0.547853 -1.210941  1.449600 -1.203463 -0.072956\n",
              "2 -1.428273  1.242861  1.449600  1.164952  0.639230\n",
              "3  1.041884  1.242861  0.455173  1.164952  1.351416\n",
              "4 -0.440210  1.242861 -0.042041  1.164952 -0.785142\n",
              "5  0.547853  1.242861 -1.036468 -1.203463 -0.785142\n",
              "6  1.535916  0.015960  0.952387  1.164952  0.639230\n",
              "7  1.041884  1.242861 -0.042041 -0.019255 -0.785142\n",
              "8  0.053821  0.015960  0.455173 -0.019255 -1.497328\n",
              "9 -0.440210  1.242861 -1.533682 -1.203463  1.351416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pOk9oIYa92P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6a8544a-bf75-4385-b1b2-8e02ddec345a"
      },
      "source": [
        "train_y = pd.read_csv('optimal_605.csv', index_col=0)\n",
        "train_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAd58oRClUff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "49912986-1bfb-494d-b56b-22ded8a1991d"
      },
      "source": [
        "train_y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bar_orders</th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.83810870599491, 0.6358100457084843, 1.591918...</td>\n",
              "      <td>103.451705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.8345770523120521, 0.9756589343833298, 2.6056...</td>\n",
              "      <td>111.959005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.957788117293222, 2.724991772207066, 1.764825...</td>\n",
              "      <td>119.747432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.438750738336929, 0.0004908677138951938, 1.38...</td>\n",
              "      <td>101.092659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.2559104201266245, 1.5397079930733486, 1.6019...</td>\n",
              "      <td>111.386501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          bar_orders      weight\n",
              "0  2.83810870599491, 0.6358100457084843, 1.591918...  103.451705\n",
              "1  0.8345770523120521, 0.9756589343833298, 2.6056...  111.959005\n",
              "2  2.957788117293222, 2.724991772207066, 1.764825...  119.747432\n",
              "3  3.438750738336929, 0.0004908677138951938, 1.38...  101.092659\n",
              "4  0.2559104201266245, 1.5397079930733486, 1.6019...  111.386501"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DdbbqmGCp7-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b9c4411-a0ea-433e-ca80-4de950e6d78b"
      },
      "source": [
        "test_y = pd.read_csv('testing_10.csv', index_col=0)\n",
        "test_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmfYOE9pnceq",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Input and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76gM9IY9l7Z_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function convert np of object to np of float\n",
        "def f(x):\n",
        "    return np.array(x.replace('[', '').replace(']', '').replace(',', ' ').split()).astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5ZRNLSbqtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1efb0c2-e7d6-4a9a-d269-13f211f2e10c"
      },
      "source": [
        "train_y = np.array([f(t) for t in train_y['bar_orders']])\n",
        "train_y = np.floor(train_y)\n",
        "train_y = train_y.astype(int)\n",
        "train_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bawNEeUXlMs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "b8ad141a-a9dc-4777-a39f-ecf300f39361"
      },
      "source": [
        "train_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 1, ..., 0, 2, 1],\n",
              "       [0, 0, 2, ..., 2, 0, 1],\n",
              "       [2, 2, 1, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [0, 1, 3, ..., 0, 3, 1],\n",
              "       [1, 1, 2, ..., 0, 1, 2],\n",
              "       [2, 3, 2, ..., 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKNbyYvdGqZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c74426c-640e-451b-8aed-f26c94779927"
      },
      "source": [
        "test_y = np.array([f(t) for t in test_y['bar_orders']])\n",
        "test_y = np.floor(test_y)\n",
        "test_y = test_y.astype(int)\n",
        "test_y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMSdhe9RGzzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "8982eb89-51c2-4aad-9256-4e0d8d162ed9"
      },
      "source": [
        "test_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 2, ..., 0, 0, 2],\n",
              "       [1, 1, 1, ..., 1, 1, 1],\n",
              "       [1, 1, 3, ..., 1, 0, 0],\n",
              "       ...,\n",
              "       [2, 0, 1, ..., 2, 0, 2],\n",
              "       [2, 2, 1, ..., 0, 0, 2],\n",
              "       [0, 1, 2, ..., 2, 1, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN-8VXW6Hi6R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "dfaab66d-c3f5-4636-c03c-54e79c568e59"
      },
      "source": [
        "train_y_test_y = pd.concat([pd.DataFrame(train_y), pd.DataFrame(test_y)])\n",
        "train_y_test_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>615 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0    1    2    3    4    5    6    ...  213  214  215  216  217  218  219\n",
              "0     2    0    1    0    2    3    3  ...    1    0    2    1    0    2    1\n",
              "1     0    0    2    1    1    3    1  ...    1    0    1    3    2    0    1\n",
              "2     2    2    1    0    2    2    3  ...    2    0    2    1    1    1    1\n",
              "3     3    0    1    1    0    3    0  ...    1    0    1    0    0    1    0\n",
              "4     0    1    1    3    3    3    3  ...    0    2    3    1    2    2    1\n",
              "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "5     0    1    0    0    3    2    2  ...    0    1    0    2    2    2    0\n",
              "6     1    2    1    1    3    0    1  ...    2    1    1    2    2    2    2\n",
              "7     2    0    1    1    2    2    0  ...    0    1    1    3    2    0    2\n",
              "8     2    2    1    1    1    1    0  ...    1    0    1    0    0    0    2\n",
              "9     0    1    2    0    0    0    3  ...    1    1    2    2    2    1    2\n",
              "\n",
              "[615 rows x 220 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0zjeADJJWnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y_test_y_stats = train_y_test_y.describe()\n",
        "train_y_test_y_stats = train_y_test_y_stats.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMMTMG4GJerA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "5bf0e690-859c-4012-8ec1-b76a44c5965a"
      },
      "source": [
        "train_y_test_y_norm = (train_y_test_y - train_y_test_y_stats['mean']) / train_y_test_y_stats['std']\n",
        "train_y_test_y_norm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.637912</td>\n",
              "      <td>-1.349487</td>\n",
              "      <td>-0.256199</td>\n",
              "      <td>-1.379299</td>\n",
              "      <td>0.836795</td>\n",
              "      <td>1.844873</td>\n",
              "      <td>1.891552</td>\n",
              "      <td>-1.318091</td>\n",
              "      <td>1.701761</td>\n",
              "      <td>0.765689</td>\n",
              "      <td>-1.388060</td>\n",
              "      <td>-1.426462</td>\n",
              "      <td>-0.304781</td>\n",
              "      <td>1.810436</td>\n",
              "      <td>0.709804</td>\n",
              "      <td>0.713032</td>\n",
              "      <td>-0.301542</td>\n",
              "      <td>0.718276</td>\n",
              "      <td>0.797253</td>\n",
              "      <td>-0.259416</td>\n",
              "      <td>-0.343574</td>\n",
              "      <td>-1.396560</td>\n",
              "      <td>-1.292497</td>\n",
              "      <td>-0.288035</td>\n",
              "      <td>0.780531</td>\n",
              "      <td>-1.386420</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>0.798573</td>\n",
              "      <td>-0.360344</td>\n",
              "      <td>-1.460930</td>\n",
              "      <td>1.983074</td>\n",
              "      <td>-0.308396</td>\n",
              "      <td>-0.223730</td>\n",
              "      <td>0.954380</td>\n",
              "      <td>-0.323264</td>\n",
              "      <td>0.841739</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>0.746149</td>\n",
              "      <td>-0.328638</td>\n",
              "      <td>0.826867</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.394318</td>\n",
              "      <td>0.742745</td>\n",
              "      <td>-0.274467</td>\n",
              "      <td>-1.422518</td>\n",
              "      <td>0.749987</td>\n",
              "      <td>-0.361715</td>\n",
              "      <td>-0.295671</td>\n",
              "      <td>0.722112</td>\n",
              "      <td>-0.314141</td>\n",
              "      <td>0.753838</td>\n",
              "      <td>0.777771</td>\n",
              "      <td>-1.334180</td>\n",
              "      <td>-0.316996</td>\n",
              "      <td>1.866992</td>\n",
              "      <td>-0.273221</td>\n",
              "      <td>-0.235318</td>\n",
              "      <td>0.882719</td>\n",
              "      <td>0.902012</td>\n",
              "      <td>-0.240638</td>\n",
              "      <td>0.805439</td>\n",
              "      <td>-1.388863</td>\n",
              "      <td>-0.33512</td>\n",
              "      <td>-1.380492</td>\n",
              "      <td>-1.275218</td>\n",
              "      <td>0.749387</td>\n",
              "      <td>0.867023</td>\n",
              "      <td>-1.407922</td>\n",
              "      <td>-0.178607</td>\n",
              "      <td>1.808913</td>\n",
              "      <td>0.790308</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>-0.384042</td>\n",
              "      <td>0.687744</td>\n",
              "      <td>-0.274992</td>\n",
              "      <td>-1.358830</td>\n",
              "      <td>0.836463</td>\n",
              "      <td>-0.198348</td>\n",
              "      <td>-1.385978</td>\n",
              "      <td>0.765501</td>\n",
              "      <td>-0.332882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.389560</td>\n",
              "      <td>-1.349487</td>\n",
              "      <td>0.845636</td>\n",
              "      <td>-0.357288</td>\n",
              "      <td>-0.237587</td>\n",
              "      <td>1.844873</td>\n",
              "      <td>-0.212073</td>\n",
              "      <td>0.817946</td>\n",
              "      <td>-1.382472</td>\n",
              "      <td>-0.306973</td>\n",
              "      <td>-0.318315</td>\n",
              "      <td>0.672280</td>\n",
              "      <td>1.837393</td>\n",
              "      <td>-0.284424</td>\n",
              "      <td>-0.357505</td>\n",
              "      <td>-1.415681</td>\n",
              "      <td>0.770415</td>\n",
              "      <td>-1.415732</td>\n",
              "      <td>1.882011</td>\n",
              "      <td>-0.259416</td>\n",
              "      <td>-1.405372</td>\n",
              "      <td>-1.396560</td>\n",
              "      <td>-1.292497</td>\n",
              "      <td>1.846198</td>\n",
              "      <td>-0.288570</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>-0.295241</td>\n",
              "      <td>0.689947</td>\n",
              "      <td>-1.460930</td>\n",
              "      <td>1.983074</td>\n",
              "      <td>0.781625</td>\n",
              "      <td>0.851224</td>\n",
              "      <td>-0.180908</td>\n",
              "      <td>0.728626</td>\n",
              "      <td>-0.257347</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>0.746149</td>\n",
              "      <td>-0.328638</td>\n",
              "      <td>-0.248235</td>\n",
              "      <td>...</td>\n",
              "      <td>1.817314</td>\n",
              "      <td>0.742745</td>\n",
              "      <td>-1.356501</td>\n",
              "      <td>-1.422518</td>\n",
              "      <td>-0.335288</td>\n",
              "      <td>1.767037</td>\n",
              "      <td>-1.378036</td>\n",
              "      <td>-1.392645</td>\n",
              "      <td>0.802603</td>\n",
              "      <td>-0.326839</td>\n",
              "      <td>-0.316804</td>\n",
              "      <td>1.805567</td>\n",
              "      <td>0.742528</td>\n",
              "      <td>-1.391854</td>\n",
              "      <td>-1.378687</td>\n",
              "      <td>-1.340055</td>\n",
              "      <td>-0.227449</td>\n",
              "      <td>-0.179347</td>\n",
              "      <td>2.018789</td>\n",
              "      <td>-0.295328</td>\n",
              "      <td>-0.333052</td>\n",
              "      <td>-0.33512</td>\n",
              "      <td>-0.313906</td>\n",
              "      <td>-1.275218</td>\n",
              "      <td>0.749387</td>\n",
              "      <td>0.867023</td>\n",
              "      <td>0.714313</td>\n",
              "      <td>0.877578</td>\n",
              "      <td>-1.434473</td>\n",
              "      <td>-0.294602</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>-0.384042</td>\n",
              "      <td>-0.348929</td>\n",
              "      <td>-0.274992</td>\n",
              "      <td>-1.358830</td>\n",
              "      <td>-0.233027</td>\n",
              "      <td>1.979942</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>-1.369569</td>\n",
              "      <td>-0.332882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.637912</td>\n",
              "      <td>0.849015</td>\n",
              "      <td>-0.256199</td>\n",
              "      <td>-1.379299</td>\n",
              "      <td>0.836795</td>\n",
              "      <td>0.772475</td>\n",
              "      <td>1.891552</td>\n",
              "      <td>-0.250073</td>\n",
              "      <td>-1.382472</td>\n",
              "      <td>1.838351</td>\n",
              "      <td>-0.318315</td>\n",
              "      <td>0.672280</td>\n",
              "      <td>0.766306</td>\n",
              "      <td>-0.284424</td>\n",
              "      <td>-0.357505</td>\n",
              "      <td>0.713032</td>\n",
              "      <td>-0.301542</td>\n",
              "      <td>0.718276</td>\n",
              "      <td>-1.372263</td>\n",
              "      <td>-1.337393</td>\n",
              "      <td>-1.405372</td>\n",
              "      <td>-0.332267</td>\n",
              "      <td>0.894259</td>\n",
              "      <td>1.846198</td>\n",
              "      <td>-0.288570</td>\n",
              "      <td>1.939907</td>\n",
              "      <td>1.939907</td>\n",
              "      <td>0.798573</td>\n",
              "      <td>-1.410634</td>\n",
              "      <td>0.678289</td>\n",
              "      <td>-1.229192</td>\n",
              "      <td>-0.308396</td>\n",
              "      <td>-1.298685</td>\n",
              "      <td>-1.316195</td>\n",
              "      <td>0.728626</td>\n",
              "      <td>-1.356432</td>\n",
              "      <td>-1.504430</td>\n",
              "      <td>1.849229</td>\n",
              "      <td>0.740739</td>\n",
              "      <td>0.826867</td>\n",
              "      <td>...</td>\n",
              "      <td>1.817314</td>\n",
              "      <td>0.742745</td>\n",
              "      <td>0.807566</td>\n",
              "      <td>-0.346444</td>\n",
              "      <td>0.749987</td>\n",
              "      <td>1.767037</td>\n",
              "      <td>-0.295671</td>\n",
              "      <td>0.722112</td>\n",
              "      <td>-1.430886</td>\n",
              "      <td>-1.407516</td>\n",
              "      <td>0.777771</td>\n",
              "      <td>-0.287597</td>\n",
              "      <td>-0.316996</td>\n",
              "      <td>-0.305572</td>\n",
              "      <td>0.832245</td>\n",
              "      <td>0.869419</td>\n",
              "      <td>-0.227449</td>\n",
              "      <td>-0.179347</td>\n",
              "      <td>2.018789</td>\n",
              "      <td>0.805439</td>\n",
              "      <td>-1.388863</td>\n",
              "      <td>0.73275</td>\n",
              "      <td>-0.313906</td>\n",
              "      <td>0.897245</td>\n",
              "      <td>-1.424543</td>\n",
              "      <td>0.867023</td>\n",
              "      <td>-1.407922</td>\n",
              "      <td>1.933762</td>\n",
              "      <td>1.808913</td>\n",
              "      <td>-0.294602</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>-0.384042</td>\n",
              "      <td>0.687744</td>\n",
              "      <td>0.809111</td>\n",
              "      <td>-1.358830</td>\n",
              "      <td>0.836463</td>\n",
              "      <td>-0.198348</td>\n",
              "      <td>-0.249476</td>\n",
              "      <td>-0.302034</td>\n",
              "      <td>-0.332882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.651648</td>\n",
              "      <td>-1.349487</td>\n",
              "      <td>-0.256199</td>\n",
              "      <td>-0.357288</td>\n",
              "      <td>-1.311969</td>\n",
              "      <td>1.844873</td>\n",
              "      <td>-1.263885</td>\n",
              "      <td>0.817946</td>\n",
              "      <td>-0.354394</td>\n",
              "      <td>-1.379636</td>\n",
              "      <td>-1.388060</td>\n",
              "      <td>-1.426462</td>\n",
              "      <td>0.766306</td>\n",
              "      <td>-1.331854</td>\n",
              "      <td>-0.357505</td>\n",
              "      <td>-1.415681</td>\n",
              "      <td>-1.373499</td>\n",
              "      <td>-0.348728</td>\n",
              "      <td>-0.287505</td>\n",
              "      <td>-0.259416</td>\n",
              "      <td>1.780023</td>\n",
              "      <td>-1.396560</td>\n",
              "      <td>0.894259</td>\n",
              "      <td>0.779082</td>\n",
              "      <td>-1.357672</td>\n",
              "      <td>-1.386420</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>-0.295241</td>\n",
              "      <td>-1.410634</td>\n",
              "      <td>-0.391321</td>\n",
              "      <td>-0.158437</td>\n",
              "      <td>-1.398418</td>\n",
              "      <td>-1.298685</td>\n",
              "      <td>-0.180908</td>\n",
              "      <td>0.728626</td>\n",
              "      <td>-1.356432</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>1.849229</td>\n",
              "      <td>-1.398014</td>\n",
              "      <td>0.826867</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.394318</td>\n",
              "      <td>0.742745</td>\n",
              "      <td>1.889600</td>\n",
              "      <td>-0.346444</td>\n",
              "      <td>-0.335288</td>\n",
              "      <td>-0.361715</td>\n",
              "      <td>-0.295671</td>\n",
              "      <td>0.722112</td>\n",
              "      <td>-0.314141</td>\n",
              "      <td>0.753838</td>\n",
              "      <td>-1.411378</td>\n",
              "      <td>-1.334180</td>\n",
              "      <td>0.742528</td>\n",
              "      <td>0.780710</td>\n",
              "      <td>-0.273221</td>\n",
              "      <td>-0.235318</td>\n",
              "      <td>0.882719</td>\n",
              "      <td>-1.260707</td>\n",
              "      <td>-0.240638</td>\n",
              "      <td>-0.295328</td>\n",
              "      <td>-1.388863</td>\n",
              "      <td>-0.33512</td>\n",
              "      <td>0.752680</td>\n",
              "      <td>-1.275218</td>\n",
              "      <td>1.836353</td>\n",
              "      <td>-1.441284</td>\n",
              "      <td>-1.407922</td>\n",
              "      <td>-1.234791</td>\n",
              "      <td>-1.434473</td>\n",
              "      <td>0.790308</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>-0.384042</td>\n",
              "      <td>-1.385602</td>\n",
              "      <td>-0.274992</td>\n",
              "      <td>-1.358830</td>\n",
              "      <td>-0.233027</td>\n",
              "      <td>-1.287493</td>\n",
              "      <td>-1.385978</td>\n",
              "      <td>-0.302034</td>\n",
              "      <td>-1.399143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.389560</td>\n",
              "      <td>-0.250236</td>\n",
              "      <td>-0.256199</td>\n",
              "      <td>1.686734</td>\n",
              "      <td>1.911178</td>\n",
              "      <td>1.844873</td>\n",
              "      <td>1.891552</td>\n",
              "      <td>-0.250073</td>\n",
              "      <td>-0.354394</td>\n",
              "      <td>-0.306973</td>\n",
              "      <td>-1.388060</td>\n",
              "      <td>0.672280</td>\n",
              "      <td>-0.304781</td>\n",
              "      <td>-1.331854</td>\n",
              "      <td>-0.357505</td>\n",
              "      <td>1.777389</td>\n",
              "      <td>-0.301542</td>\n",
              "      <td>0.718276</td>\n",
              "      <td>0.797253</td>\n",
              "      <td>0.818561</td>\n",
              "      <td>-0.343574</td>\n",
              "      <td>0.732026</td>\n",
              "      <td>-0.199119</td>\n",
              "      <td>1.846198</td>\n",
              "      <td>1.849632</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>0.798573</td>\n",
              "      <td>-0.360344</td>\n",
              "      <td>-0.391321</td>\n",
              "      <td>-1.229192</td>\n",
              "      <td>-0.308396</td>\n",
              "      <td>-1.298685</td>\n",
              "      <td>0.954380</td>\n",
              "      <td>0.728626</td>\n",
              "      <td>0.841739</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>-0.356932</td>\n",
              "      <td>-0.328638</td>\n",
              "      <td>-0.248235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323774</td>\n",
              "      <td>-1.396779</td>\n",
              "      <td>-0.274467</td>\n",
              "      <td>0.729631</td>\n",
              "      <td>0.749987</td>\n",
              "      <td>-0.361715</td>\n",
              "      <td>0.786695</td>\n",
              "      <td>-0.335266</td>\n",
              "      <td>-0.314141</td>\n",
              "      <td>0.753838</td>\n",
              "      <td>0.777771</td>\n",
              "      <td>1.805567</td>\n",
              "      <td>0.742528</td>\n",
              "      <td>-0.305572</td>\n",
              "      <td>0.832245</td>\n",
              "      <td>-0.235318</td>\n",
              "      <td>-0.227449</td>\n",
              "      <td>-1.260707</td>\n",
              "      <td>-0.240638</td>\n",
              "      <td>-0.295328</td>\n",
              "      <td>-1.388863</td>\n",
              "      <td>0.73275</td>\n",
              "      <td>-0.313906</td>\n",
              "      <td>0.897245</td>\n",
              "      <td>-0.337578</td>\n",
              "      <td>0.867023</td>\n",
              "      <td>-1.407922</td>\n",
              "      <td>0.877578</td>\n",
              "      <td>0.727784</td>\n",
              "      <td>0.790308</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>-1.452755</td>\n",
              "      <td>1.724417</td>\n",
              "      <td>-1.359095</td>\n",
              "      <td>0.778460</td>\n",
              "      <td>1.905952</td>\n",
              "      <td>-0.198348</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>0.765501</td>\n",
              "      <td>-0.332882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-1.389560</td>\n",
              "      <td>-0.250236</td>\n",
              "      <td>-1.358034</td>\n",
              "      <td>-1.379299</td>\n",
              "      <td>1.911178</td>\n",
              "      <td>0.772475</td>\n",
              "      <td>0.839740</td>\n",
              "      <td>-1.318091</td>\n",
              "      <td>-0.354394</td>\n",
              "      <td>0.765689</td>\n",
              "      <td>1.821177</td>\n",
              "      <td>-0.377091</td>\n",
              "      <td>0.766306</td>\n",
              "      <td>-1.331854</td>\n",
              "      <td>-0.357505</td>\n",
              "      <td>-1.415681</td>\n",
              "      <td>-0.301542</td>\n",
              "      <td>-0.348728</td>\n",
              "      <td>0.797253</td>\n",
              "      <td>1.896538</td>\n",
              "      <td>-0.343574</td>\n",
              "      <td>-0.332267</td>\n",
              "      <td>0.894259</td>\n",
              "      <td>-1.355151</td>\n",
              "      <td>-0.288570</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>-1.389055</td>\n",
              "      <td>0.689947</td>\n",
              "      <td>0.678289</td>\n",
              "      <td>0.912318</td>\n",
              "      <td>-1.398418</td>\n",
              "      <td>0.851224</td>\n",
              "      <td>-0.180908</td>\n",
              "      <td>-1.375153</td>\n",
              "      <td>-0.257347</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>0.746149</td>\n",
              "      <td>0.740739</td>\n",
              "      <td>0.826867</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.394318</td>\n",
              "      <td>-1.396779</td>\n",
              "      <td>-0.274467</td>\n",
              "      <td>-1.422518</td>\n",
              "      <td>-1.420564</td>\n",
              "      <td>-0.361715</td>\n",
              "      <td>-1.378036</td>\n",
              "      <td>-1.392645</td>\n",
              "      <td>1.919348</td>\n",
              "      <td>0.753838</td>\n",
              "      <td>-1.411378</td>\n",
              "      <td>0.758985</td>\n",
              "      <td>-0.316996</td>\n",
              "      <td>-1.391854</td>\n",
              "      <td>-0.273221</td>\n",
              "      <td>0.869419</td>\n",
              "      <td>1.992887</td>\n",
              "      <td>-1.260707</td>\n",
              "      <td>-0.240638</td>\n",
              "      <td>1.906205</td>\n",
              "      <td>-0.333052</td>\n",
              "      <td>-0.33512</td>\n",
              "      <td>-0.313906</td>\n",
              "      <td>0.897245</td>\n",
              "      <td>-0.337578</td>\n",
              "      <td>-0.287131</td>\n",
              "      <td>-0.346804</td>\n",
              "      <td>-0.178607</td>\n",
              "      <td>-0.353345</td>\n",
              "      <td>-0.294602</td>\n",
              "      <td>0.674459</td>\n",
              "      <td>1.753385</td>\n",
              "      <td>0.687744</td>\n",
              "      <td>-1.359095</td>\n",
              "      <td>-0.290185</td>\n",
              "      <td>-1.302517</td>\n",
              "      <td>0.890797</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>0.765501</td>\n",
              "      <td>-1.399143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.375824</td>\n",
              "      <td>0.849015</td>\n",
              "      <td>-0.256199</td>\n",
              "      <td>-0.357288</td>\n",
              "      <td>1.911178</td>\n",
              "      <td>-1.372320</td>\n",
              "      <td>-0.212073</td>\n",
              "      <td>0.817946</td>\n",
              "      <td>1.701761</td>\n",
              "      <td>-0.306973</td>\n",
              "      <td>0.751431</td>\n",
              "      <td>-1.426462</td>\n",
              "      <td>1.837393</td>\n",
              "      <td>-0.284424</td>\n",
              "      <td>-1.424815</td>\n",
              "      <td>0.713032</td>\n",
              "      <td>-1.373499</td>\n",
              "      <td>-1.415732</td>\n",
              "      <td>-1.372263</td>\n",
              "      <td>0.818561</td>\n",
              "      <td>1.780023</td>\n",
              "      <td>-1.396560</td>\n",
              "      <td>0.894259</td>\n",
              "      <td>-1.355151</td>\n",
              "      <td>-0.288570</td>\n",
              "      <td>-1.386420</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>-0.295241</td>\n",
              "      <td>0.689947</td>\n",
              "      <td>0.678289</td>\n",
              "      <td>1.983074</td>\n",
              "      <td>-0.308396</td>\n",
              "      <td>-1.298685</td>\n",
              "      <td>-1.316195</td>\n",
              "      <td>-0.323264</td>\n",
              "      <td>-0.257347</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>-0.356932</td>\n",
              "      <td>-0.328638</td>\n",
              "      <td>0.826867</td>\n",
              "      <td>...</td>\n",
              "      <td>1.817314</td>\n",
              "      <td>-1.396779</td>\n",
              "      <td>0.807566</td>\n",
              "      <td>0.729631</td>\n",
              "      <td>-0.335288</td>\n",
              "      <td>1.767037</td>\n",
              "      <td>-1.378036</td>\n",
              "      <td>-1.392645</td>\n",
              "      <td>0.802603</td>\n",
              "      <td>1.834516</td>\n",
              "      <td>0.777771</td>\n",
              "      <td>-0.287597</td>\n",
              "      <td>1.802051</td>\n",
              "      <td>0.780710</td>\n",
              "      <td>0.832245</td>\n",
              "      <td>-0.235318</td>\n",
              "      <td>-0.227449</td>\n",
              "      <td>0.902012</td>\n",
              "      <td>-0.240638</td>\n",
              "      <td>-0.295328</td>\n",
              "      <td>-0.333052</td>\n",
              "      <td>-0.33512</td>\n",
              "      <td>0.752680</td>\n",
              "      <td>0.897245</td>\n",
              "      <td>-0.337578</td>\n",
              "      <td>0.867023</td>\n",
              "      <td>-0.346804</td>\n",
              "      <td>1.933762</td>\n",
              "      <td>0.727784</td>\n",
              "      <td>1.875219</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>0.684671</td>\n",
              "      <td>1.724417</td>\n",
              "      <td>0.809111</td>\n",
              "      <td>-0.290185</td>\n",
              "      <td>-0.233027</td>\n",
              "      <td>0.890797</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>0.765501</td>\n",
              "      <td>0.733380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.637912</td>\n",
              "      <td>-1.349487</td>\n",
              "      <td>-0.256199</td>\n",
              "      <td>-0.357288</td>\n",
              "      <td>0.836795</td>\n",
              "      <td>0.772475</td>\n",
              "      <td>-1.263885</td>\n",
              "      <td>-0.250073</td>\n",
              "      <td>-0.354394</td>\n",
              "      <td>-0.306973</td>\n",
              "      <td>-1.388060</td>\n",
              "      <td>-0.377091</td>\n",
              "      <td>-1.375868</td>\n",
              "      <td>-1.331854</td>\n",
              "      <td>-0.357505</td>\n",
              "      <td>1.777389</td>\n",
              "      <td>1.842372</td>\n",
              "      <td>1.785280</td>\n",
              "      <td>1.882011</td>\n",
              "      <td>-1.337393</td>\n",
              "      <td>-1.405372</td>\n",
              "      <td>1.796318</td>\n",
              "      <td>0.894259</td>\n",
              "      <td>1.846198</td>\n",
              "      <td>-0.288570</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>-0.295241</td>\n",
              "      <td>-0.360344</td>\n",
              "      <td>-1.460930</td>\n",
              "      <td>0.912318</td>\n",
              "      <td>-0.308396</td>\n",
              "      <td>-0.223730</td>\n",
              "      <td>2.089667</td>\n",
              "      <td>1.780515</td>\n",
              "      <td>-1.356432</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>-1.460012</td>\n",
              "      <td>1.810115</td>\n",
              "      <td>1.901970</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323774</td>\n",
              "      <td>1.812507</td>\n",
              "      <td>-0.274467</td>\n",
              "      <td>-1.422518</td>\n",
              "      <td>-1.420564</td>\n",
              "      <td>-1.426090</td>\n",
              "      <td>-0.295671</td>\n",
              "      <td>-0.335266</td>\n",
              "      <td>-1.430886</td>\n",
              "      <td>-0.326839</td>\n",
              "      <td>0.777771</td>\n",
              "      <td>1.805567</td>\n",
              "      <td>-0.316996</td>\n",
              "      <td>0.780710</td>\n",
              "      <td>1.937711</td>\n",
              "      <td>-1.340055</td>\n",
              "      <td>0.882719</td>\n",
              "      <td>0.902012</td>\n",
              "      <td>-0.240638</td>\n",
              "      <td>0.805439</td>\n",
              "      <td>-1.388863</td>\n",
              "      <td>-0.33512</td>\n",
              "      <td>-0.313906</td>\n",
              "      <td>-1.275218</td>\n",
              "      <td>-0.337578</td>\n",
              "      <td>-1.441284</td>\n",
              "      <td>-0.346804</td>\n",
              "      <td>0.877578</td>\n",
              "      <td>1.808913</td>\n",
              "      <td>0.790308</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>-0.384042</td>\n",
              "      <td>-0.348929</td>\n",
              "      <td>-1.359095</td>\n",
              "      <td>-0.290185</td>\n",
              "      <td>-0.233027</td>\n",
              "      <td>1.979942</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>-1.369569</td>\n",
              "      <td>0.733380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.637912</td>\n",
              "      <td>0.849015</td>\n",
              "      <td>-0.256199</td>\n",
              "      <td>-0.357288</td>\n",
              "      <td>-0.237587</td>\n",
              "      <td>-0.299923</td>\n",
              "      <td>-1.263885</td>\n",
              "      <td>-0.250073</td>\n",
              "      <td>-0.354394</td>\n",
              "      <td>-0.306973</td>\n",
              "      <td>1.821177</td>\n",
              "      <td>-1.426462</td>\n",
              "      <td>0.766306</td>\n",
              "      <td>-0.284424</td>\n",
              "      <td>-1.424815</td>\n",
              "      <td>-1.415681</td>\n",
              "      <td>0.770415</td>\n",
              "      <td>1.785280</td>\n",
              "      <td>0.797253</td>\n",
              "      <td>-0.259416</td>\n",
              "      <td>-1.405372</td>\n",
              "      <td>-0.332267</td>\n",
              "      <td>-1.292497</td>\n",
              "      <td>-0.288035</td>\n",
              "      <td>-0.288570</td>\n",
              "      <td>-1.386420</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>-0.295241</td>\n",
              "      <td>0.689947</td>\n",
              "      <td>1.747899</td>\n",
              "      <td>-0.158437</td>\n",
              "      <td>-0.308396</td>\n",
              "      <td>0.851224</td>\n",
              "      <td>-1.316195</td>\n",
              "      <td>0.728626</td>\n",
              "      <td>-1.356432</td>\n",
              "      <td>0.670011</td>\n",
              "      <td>-0.356932</td>\n",
              "      <td>-0.328638</td>\n",
              "      <td>-0.248235</td>\n",
              "      <td>...</td>\n",
              "      <td>0.746770</td>\n",
              "      <td>-0.327017</td>\n",
              "      <td>-0.274467</td>\n",
              "      <td>-1.422518</td>\n",
              "      <td>-0.335288</td>\n",
              "      <td>-1.426090</td>\n",
              "      <td>1.869061</td>\n",
              "      <td>-0.335266</td>\n",
              "      <td>-1.430886</td>\n",
              "      <td>0.753838</td>\n",
              "      <td>0.777771</td>\n",
              "      <td>-1.334180</td>\n",
              "      <td>0.742528</td>\n",
              "      <td>-1.391854</td>\n",
              "      <td>0.832245</td>\n",
              "      <td>-0.235318</td>\n",
              "      <td>0.882719</td>\n",
              "      <td>-1.260707</td>\n",
              "      <td>0.889075</td>\n",
              "      <td>0.805439</td>\n",
              "      <td>0.722758</td>\n",
              "      <td>0.73275</td>\n",
              "      <td>-0.313906</td>\n",
              "      <td>0.897245</td>\n",
              "      <td>-0.337578</td>\n",
              "      <td>-0.287131</td>\n",
              "      <td>-1.407922</td>\n",
              "      <td>-0.178607</td>\n",
              "      <td>0.727784</td>\n",
              "      <td>0.790308</td>\n",
              "      <td>0.674459</td>\n",
              "      <td>-1.452755</td>\n",
              "      <td>-0.348929</td>\n",
              "      <td>-0.274992</td>\n",
              "      <td>-1.358830</td>\n",
              "      <td>-0.233027</td>\n",
              "      <td>-1.287493</td>\n",
              "      <td>-1.385978</td>\n",
              "      <td>-1.369569</td>\n",
              "      <td>0.733380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-1.389560</td>\n",
              "      <td>-0.250236</td>\n",
              "      <td>0.845636</td>\n",
              "      <td>-1.379299</td>\n",
              "      <td>-1.311969</td>\n",
              "      <td>-1.372320</td>\n",
              "      <td>1.891552</td>\n",
              "      <td>0.817946</td>\n",
              "      <td>-0.354394</td>\n",
              "      <td>-1.379636</td>\n",
              "      <td>-1.388060</td>\n",
              "      <td>0.672280</td>\n",
              "      <td>0.766306</td>\n",
              "      <td>0.763006</td>\n",
              "      <td>-0.357505</td>\n",
              "      <td>-1.415681</td>\n",
              "      <td>0.770415</td>\n",
              "      <td>0.718276</td>\n",
              "      <td>-1.372263</td>\n",
              "      <td>-1.337393</td>\n",
              "      <td>0.718225</td>\n",
              "      <td>1.796318</td>\n",
              "      <td>-1.292497</td>\n",
              "      <td>-1.355151</td>\n",
              "      <td>1.849632</td>\n",
              "      <td>0.831131</td>\n",
              "      <td>-0.277645</td>\n",
              "      <td>-0.295241</td>\n",
              "      <td>0.689947</td>\n",
              "      <td>0.678289</td>\n",
              "      <td>1.983074</td>\n",
              "      <td>0.781625</td>\n",
              "      <td>-0.223730</td>\n",
              "      <td>-0.180908</td>\n",
              "      <td>0.728626</td>\n",
              "      <td>0.841739</td>\n",
              "      <td>-0.417210</td>\n",
              "      <td>1.849229</td>\n",
              "      <td>-1.398014</td>\n",
              "      <td>-0.248235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323774</td>\n",
              "      <td>-0.327017</td>\n",
              "      <td>-1.356501</td>\n",
              "      <td>-0.346444</td>\n",
              "      <td>-1.420564</td>\n",
              "      <td>-1.426090</td>\n",
              "      <td>-1.378036</td>\n",
              "      <td>1.779491</td>\n",
              "      <td>-1.430886</td>\n",
              "      <td>-1.407516</td>\n",
              "      <td>-0.316804</td>\n",
              "      <td>0.758985</td>\n",
              "      <td>-0.316996</td>\n",
              "      <td>-0.305572</td>\n",
              "      <td>0.832245</td>\n",
              "      <td>-0.235318</td>\n",
              "      <td>-0.227449</td>\n",
              "      <td>-1.260707</td>\n",
              "      <td>-0.240638</td>\n",
              "      <td>1.906205</td>\n",
              "      <td>-1.388863</td>\n",
              "      <td>-0.33512</td>\n",
              "      <td>0.752680</td>\n",
              "      <td>-1.275218</td>\n",
              "      <td>1.836353</td>\n",
              "      <td>-0.287131</td>\n",
              "      <td>0.714313</td>\n",
              "      <td>-0.178607</td>\n",
              "      <td>1.808913</td>\n",
              "      <td>-0.294602</td>\n",
              "      <td>-0.365121</td>\n",
              "      <td>0.684671</td>\n",
              "      <td>1.724417</td>\n",
              "      <td>-0.274992</td>\n",
              "      <td>-0.290185</td>\n",
              "      <td>0.836463</td>\n",
              "      <td>0.890797</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>-0.302034</td>\n",
              "      <td>0.733380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>615 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2    ...       217       218       219\n",
              "0   0.637912 -1.349487 -0.256199  ... -1.385978  0.765501 -0.332882\n",
              "1  -1.389560 -1.349487  0.845636  ...  0.887026 -1.369569 -0.332882\n",
              "2   0.637912  0.849015 -0.256199  ... -0.249476 -0.302034 -0.332882\n",
              "3   1.651648 -1.349487 -0.256199  ... -1.385978 -0.302034 -1.399143\n",
              "4  -1.389560 -0.250236 -0.256199  ...  0.887026  0.765501 -0.332882\n",
              "..       ...       ...       ...  ...       ...       ...       ...\n",
              "5  -1.389560 -0.250236 -1.358034  ...  0.887026  0.765501 -1.399143\n",
              "6  -0.375824  0.849015 -0.256199  ...  0.887026  0.765501  0.733380\n",
              "7   0.637912 -1.349487 -0.256199  ...  0.887026 -1.369569  0.733380\n",
              "8   0.637912  0.849015 -0.256199  ... -1.385978 -1.369569  0.733380\n",
              "9  -1.389560 -0.250236  0.845636  ...  0.887026 -0.302034  0.733380\n",
              "\n",
              "[615 rows x 220 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GarjFYQMKNYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f9eeead-f946-4f68-d4e0-11d10014e558"
      },
      "source": [
        "train_y_norm = train_y_test_y_norm.iloc[:605, :]\n",
        "train_y_norm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(605, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMildzU6KZZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8056f79d-846b-466b-94f3-5da795c3a072"
      },
      "source": [
        "test_y_norm = train_y_test_y_norm.iloc[605:, :]\n",
        "test_y_norm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0w4MW9hpLhz",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Model （Dense,SGD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i7nSYmppOb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71e81420-dda5-4f1d-cfe7-61598b0c8cb1"
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=5)) #输入5个\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(220, )) #输出220个\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='mse',\n",
        "              optimizer=sgd\n",
        "              )\n",
        "\n",
        "history = model.fit(train_x, train_y,\n",
        "          epochs=1000,\n",
        "          batch_size=32,\n",
        "          #validation_data = (x_test, y_test)\n",
        "          validation_split = 0.2,\n",
        "          callbacks=[early_stop, tfdocs.modeling.EpochDots()],\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 2.4768\n",
            "Epoch: 0, loss:2.5068,  val_loss:2.4115,  \n",
            "16/16 [==============================] - 0s 8ms/step - loss: 2.5068 - val_loss: 2.4115\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.3918 - val_loss: 2.3036\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.2680 - val_loss: 2.1734\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 2.1168 - val_loss: 1.9925\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.9253 - val_loss: 1.7417\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.6675 - val_loss: 1.4337\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.4436 - val_loss: 1.1654\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.2975 - val_loss: 1.0272\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.2316 - val_loss: 0.9846\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1820 - val_loss: 0.9598\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1553 - val_loss: 0.9523\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1397 - val_loss: 0.9386\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1310 - val_loss: 0.9352\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.1003 - val_loss: 0.9287\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0903 - val_loss: 0.9167\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0875 - val_loss: 0.9133\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0711 - val_loss: 0.9144\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0666 - val_loss: 0.9073\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0553 - val_loss: 0.9026\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0506 - val_loss: 0.8984\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0461 - val_loss: 0.8938\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0379 - val_loss: 0.8941\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0333 - val_loss: 0.8962\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0233 - val_loss: 0.8947\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0267 - val_loss: 0.8877\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0050 - val_loss: 0.8875\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0158 - val_loss: 0.8863\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0107 - val_loss: 0.8873\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 1.0098 - val_loss: 0.8868\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9988 - val_loss: 0.8878\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9929 - val_loss: 0.8893\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9871 - val_loss: 0.8908\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9866 - val_loss: 0.8845\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9794 - val_loss: 0.8788\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9719 - val_loss: 0.8765\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9935 - val_loss: 0.8792\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9796 - val_loss: 0.8765\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9768 - val_loss: 0.8792\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9731 - val_loss: 0.8771\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9652 - val_loss: 0.8752\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9613 - val_loss: 0.8729\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9644 - val_loss: 0.8755\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9631 - val_loss: 0.8726\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9590 - val_loss: 0.8723\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9579 - val_loss: 0.8724\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9549 - val_loss: 0.8723\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9594 - val_loss: 0.8722\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9584 - val_loss: 0.8705\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9483 - val_loss: 0.8703\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9455 - val_loss: 0.8700\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9512 - val_loss: 0.8712\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9465 - val_loss: 0.8707\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9491 - val_loss: 0.8688\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9478 - val_loss: 0.8674\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9408 - val_loss: 0.8671\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.8664\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9394 - val_loss: 0.8671\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.9368 - val_loss: 0.8710\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9389 - val_loss: 0.8692\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9409 - val_loss: 0.8682\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9366 - val_loss: 0.8681\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9361 - val_loss: 0.8674\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 0.9344 - val_loss: 0.8681\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.8690\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9309 - val_loss: 0.8696\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 0.9291 - val_loss: 0.8672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgooluCFZCTO",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Model (Softmax)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THqcI2GXY_Iv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96c7ffc3-99ae-41db-f2e6-644b755b2389"
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_dim=5)) #输入5个\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(220, activation='softmax')) #输出220个\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "       optimizer='rmsprop',\n",
        "       metrics=['accuracy']\n",
        "              )\n",
        "\n",
        "history = model.fit(train_x, train_y,\n",
        "          epochs=1000,\n",
        "          batch_size=32,\n",
        "          #validation_data = (x_test, y_test)\n",
        "          validation_split = 0.2,\n",
        "          callbacks=tfdocs.modeling.EpochDots(),\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 1543.4539 - accuracy: 0.0000e+00\n",
            "Epoch: 0, accuracy:0.0062,  loss:1532.5759,  val_accuracy:0.0165,  val_loss:1522.6447,  \n",
            "16/16 [==============================] - 0s 10ms/step - loss: 1532.5759 - accuracy: 0.0062 - val_loss: 1522.6447 - val_accuracy: 0.0165\n",
            "Epoch 2/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1561.4824 - accuracy: 0.0041 - val_loss: 1539.9374 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1612.6146 - accuracy: 0.0083 - val_loss: 1569.3284 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1681.5049 - accuracy: 0.0041 - val_loss: 1615.4117 - val_accuracy: 0.0083\n",
            "Epoch 5/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1794.6479 - accuracy: 0.0062 - val_loss: 1677.1671 - val_accuracy: 0.0083\n",
            "Epoch 6/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1946.1494 - accuracy: 0.0041 - val_loss: 1756.9821 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2108.8262 - accuracy: 0.0083 - val_loss: 1863.8933 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2345.2632 - accuracy: 0.0062 - val_loss: 1988.8264 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2619.2800 - accuracy: 0.0145 - val_loss: 2137.2200 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2929.0327 - accuracy: 0.0062 - val_loss: 2297.8262 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3272.1106 - accuracy: 0.0041 - val_loss: 2493.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3552.8201 - accuracy: 0.0083 - val_loss: 2717.5583 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4034.8364 - accuracy: 0.0124 - val_loss: 2933.6846 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4479.3765 - accuracy: 0.0103 - val_loss: 3166.6472 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4933.2168 - accuracy: 0.0083 - val_loss: 3446.0684 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5362.7656 - accuracy: 0.0083 - val_loss: 3733.9204 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5803.9468 - accuracy: 0.0041 - val_loss: 4038.6699 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6374.7051 - accuracy: 0.0083 - val_loss: 4309.9448 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7023.5913 - accuracy: 0.0041 - val_loss: 4688.2739 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7618.6357 - accuracy: 0.0000e+00 - val_loss: 5039.9619 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8231.4932 - accuracy: 0.0021 - val_loss: 5495.7896 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8684.4805 - accuracy: 0.0062 - val_loss: 5800.1694 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9492.3242 - accuracy: 0.0021 - val_loss: 6131.8687 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10125.1680 - accuracy: 0.0103 - val_loss: 6434.9253 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10662.4111 - accuracy: 0.0145 - val_loss: 6783.4990 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11311.8828 - accuracy: 0.0124 - val_loss: 7365.6748 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12222.5703 - accuracy: 0.0083 - val_loss: 7785.9546 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12986.3613 - accuracy: 0.0000e+00 - val_loss: 8121.0342 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13753.3311 - accuracy: 0.0083 - val_loss: 8332.9043 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14319.5273 - accuracy: 0.0062 - val_loss: 8843.8584 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 15216.8760 - accuracy: 0.0083 - val_loss: 9484.4707 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 16161.7910 - accuracy: 0.0083 - val_loss: 9842.4619 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 17198.6621 - accuracy: 0.0083 - val_loss: 10305.2783 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 17696.9727 - accuracy: 0.0021 - val_loss: 10735.9600 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 18685.8496 - accuracy: 0.0021 - val_loss: 11502.7910 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 19505.6680 - accuracy: 0.0103 - val_loss: 12009.9365 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 20812.2852 - accuracy: 0.0124 - val_loss: 12514.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 21785.8203 - accuracy: 0.0165 - val_loss: 13171.4053 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 22647.1016 - accuracy: 0.0021 - val_loss: 13629.5762 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 24021.0020 - accuracy: 0.0103 - val_loss: 14343.1504 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 24851.7891 - accuracy: 0.0041 - val_loss: 14471.3057 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 25677.8906 - accuracy: 0.0124 - val_loss: 15254.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 27045.5820 - accuracy: 0.0041 - val_loss: 15449.2754 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 27966.6387 - accuracy: 0.0083 - val_loss: 16675.0566 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 28940.6367 - accuracy: 0.0062 - val_loss: 17114.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 30454.2266 - accuracy: 0.0041 - val_loss: 18236.1855 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 31156.3828 - accuracy: 0.0083 - val_loss: 18593.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 32877.0625 - accuracy: 0.0083 - val_loss: 18971.0586 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 33894.7305 - accuracy: 0.0083 - val_loss: 19812.0859 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 34878.0078 - accuracy: 0.0083 - val_loss: 20362.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 34867.5195 - accuracy: 0.0103 - val_loss: 21176.7129 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 37144.2383 - accuracy: 0.0021 - val_loss: 21928.2852 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 37880.4805 - accuracy: 0.0041 - val_loss: 22212.0859 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 40832.2734 - accuracy: 0.0083 - val_loss: 23439.7285 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 41800.1094 - accuracy: 0.0021 - val_loss: 24189.3809 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 43074.9102 - accuracy: 0.0124 - val_loss: 24430.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 43908.9336 - accuracy: 0.0103 - val_loss: 25176.1172 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 44662.9961 - accuracy: 0.0021 - val_loss: 26380.6328 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 47161.2344 - accuracy: 0.0103 - val_loss: 27831.0859 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 48536.1367 - accuracy: 0.0021 - val_loss: 28409.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 49203.1016 - accuracy: 0.0083 - val_loss: 28653.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 49744.0898 - accuracy: 0.0103 - val_loss: 28610.7734 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 52859.2773 - accuracy: 0.0062 - val_loss: 29404.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 54470.3164 - accuracy: 0.0124 - val_loss: 30805.9277 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 55472.1367 - accuracy: 0.0041 - val_loss: 30515.6836 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 56299.1406 - accuracy: 0.0083 - val_loss: 31216.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 59111.4141 - accuracy: 0.0103 - val_loss: 31401.5234 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 58952.2539 - accuracy: 0.0103 - val_loss: 33763.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 61841.2188 - accuracy: 0.0021 - val_loss: 34638.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 63949.5547 - accuracy: 0.0021 - val_loss: 35388.3008 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 66309.2500 - accuracy: 0.0083 - val_loss: 35400.2148 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 67449.3438 - accuracy: 0.0041 - val_loss: 36931.5156 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 69289.3203 - accuracy: 0.0062 - val_loss: 37434.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 70880.3906 - accuracy: 0.0000e+00 - val_loss: 39522.1367 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 72057.3281 - accuracy: 0.0062 - val_loss: 39124.3281 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 75073.5625 - accuracy: 0.0021 - val_loss: 40084.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76485.0625 - accuracy: 0.0062 - val_loss: 41554.6953 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 76444.9922 - accuracy: 0.0083 - val_loss: 41441.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 79340.1172 - accuracy: 0.0041 - val_loss: 42430.9688 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 81367.9141 - accuracy: 0.0083 - val_loss: 43859.0586 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84724.8047 - accuracy: 0.0083 - val_loss: 44089.2578 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 84734.5781 - accuracy: 0.0041 - val_loss: 44798.9883 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 85883.4375 - accuracy: 0.0103 - val_loss: 46581.4102 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90606.8047 - accuracy: 0.0103 - val_loss: 48236.3789 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 90642.2422 - accuracy: 0.0041 - val_loss: 48424.9961 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 94551.8047 - accuracy: 0.0041 - val_loss: 50240.9258 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 95039.3750 - accuracy: 0.0103 - val_loss: 50857.3359 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 97222.0391 - accuracy: 0.0041 - val_loss: 51216.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99393.2656 - accuracy: 0.0000e+00 - val_loss: 52390.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 99423.5703 - accuracy: 0.0145 - val_loss: 53001.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105573.0312 - accuracy: 0.0083 - val_loss: 54077.2812 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 105658.5703 - accuracy: 0.0021 - val_loss: 56083.3320 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 106949.6562 - accuracy: 0.0083 - val_loss: 57445.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 106826.7266 - accuracy: 0.0083 - val_loss: 58222.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 112865.0781 - accuracy: 0.0041 - val_loss: 60648.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 113309.8906 - accuracy: 0.0062 - val_loss: 61621.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 117493.4922 - accuracy: 0.0103 - val_loss: 63818.4336 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119247.6172 - accuracy: 0.0062 - val_loss: 65535.3867 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 119245.4844 - accuracy: 0.0103 - val_loss: 66102.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 122453.3359 - accuracy: 0.0103 - val_loss: 68280.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 126493.6094 - accuracy: 0.0041    \n",
            "Epoch: 100, accuracy:0.0041,  loss:126493.6094,  val_accuracy:0.0000,  val_loss:64292.2617,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 126493.6094 - accuracy: 0.0041 - val_loss: 64292.2617 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 127024.1406 - accuracy: 0.0083 - val_loss: 65505.5703 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 127545.6328 - accuracy: 0.0041 - val_loss: 67423.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 130481.4609 - accuracy: 0.0021 - val_loss: 69041.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 134036.7344 - accuracy: 0.0165 - val_loss: 70849.4453 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 137968.7656 - accuracy: 0.0021 - val_loss: 71847.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 139505.7969 - accuracy: 0.0062 - val_loss: 72793.7734 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 141427.6094 - accuracy: 0.0021 - val_loss: 75813.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 145966.5469 - accuracy: 0.0103 - val_loss: 75949.6172 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 146817.6562 - accuracy: 0.0062 - val_loss: 77171.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 149112.6562 - accuracy: 0.0062 - val_loss: 76919.8672 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 153214.6719 - accuracy: 0.0062 - val_loss: 79120.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 155695.3594 - accuracy: 0.0041 - val_loss: 78158.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 159745.1094 - accuracy: 0.0062 - val_loss: 78479.6172 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 157718.2500 - accuracy: 0.0062 - val_loss: 81254.9141 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 161039.8438 - accuracy: 0.0041 - val_loss: 81131.0391 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 163171.9688 - accuracy: 0.0145 - val_loss: 83198.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 166628.2344 - accuracy: 0.0041 - val_loss: 83684.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 168971.5312 - accuracy: 0.0062 - val_loss: 87150.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 174285.9531 - accuracy: 0.0021 - val_loss: 89228.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 172926.5312 - accuracy: 0.0083 - val_loss: 87475.3047 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 178615.9375 - accuracy: 0.0062 - val_loss: 87819.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 180382.8906 - accuracy: 0.0083 - val_loss: 88862.9922 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 183363.0156 - accuracy: 0.0021 - val_loss: 92492.8828 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 186972.1719 - accuracy: 0.0041 - val_loss: 92767.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 189325.8125 - accuracy: 0.0083 - val_loss: 97569.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 191117.6094 - accuracy: 0.0062 - val_loss: 98684.7578 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 192292.7344 - accuracy: 0.0062 - val_loss: 98638.7266 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 197729.3438 - accuracy: 0.0021 - val_loss: 99309.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 199716.6875 - accuracy: 0.0021 - val_loss: 102999.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 206634.2188 - accuracy: 0.0041 - val_loss: 105979.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 206611.7656 - accuracy: 0.0041 - val_loss: 108755.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 205767.0938 - accuracy: 0.0041 - val_loss: 108116.4141 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 207490.6250 - accuracy: 0.0083 - val_loss: 107561.6016 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219307.7031 - accuracy: 0.0062 - val_loss: 110889.5234 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 219424.5469 - accuracy: 0.0062 - val_loss: 113094.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 221671.7031 - accuracy: 0.0062 - val_loss: 113677.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 224557.7812 - accuracy: 0.0041 - val_loss: 116800.1328 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 227288.6094 - accuracy: 0.0062 - val_loss: 118403.7188 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 229915.4531 - accuracy: 0.0103 - val_loss: 121028.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 233551.6875 - accuracy: 0.0103 - val_loss: 118425.5234 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239293.8906 - accuracy: 0.0062 - val_loss: 126013.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 239629.4531 - accuracy: 0.0103 - val_loss: 125488.1484 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 244088.2031 - accuracy: 0.0041 - val_loss: 124114.5703 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 245105.6094 - accuracy: 0.0041 - val_loss: 121594.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 250945.0625 - accuracy: 0.0021 - val_loss: 127149.9609 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 253381.8438 - accuracy: 0.0083 - val_loss: 127673.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 253541.7188 - accuracy: 0.0062 - val_loss: 128003.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 256077.0156 - accuracy: 0.0062 - val_loss: 131552.9219 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 263980.5938 - accuracy: 0.0062 - val_loss: 135690.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 264271.2812 - accuracy: 0.0124 - val_loss: 136024.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 271341.1562 - accuracy: 0.0062 - val_loss: 137569.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 279233.7812 - accuracy: 0.0124 - val_loss: 139508.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 278664.9688 - accuracy: 0.0062 - val_loss: 140354.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 280980.8750 - accuracy: 0.0000e+00 - val_loss: 141047.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 285435.6875 - accuracy: 0.0041 - val_loss: 141576.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 286475.2812 - accuracy: 0.0021 - val_loss: 149638.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 289619.2188 - accuracy: 0.0021 - val_loss: 145322.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 291376.5312 - accuracy: 0.0103 - val_loss: 146985.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 304710.0312 - accuracy: 0.0021 - val_loss: 149633.0156 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 301323.0000 - accuracy: 0.0083 - val_loss: 153161.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 302194.6562 - accuracy: 0.0021 - val_loss: 155431.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 316722.0938 - accuracy: 0.0000e+00 - val_loss: 151538.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 312378.3125 - accuracy: 0.0103 - val_loss: 154692.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 319804.1562 - accuracy: 0.0041 - val_loss: 153152.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 321012.5000 - accuracy: 0.0083 - val_loss: 159719.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328273.1250 - accuracy: 0.0021 - val_loss: 162185.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 328658.7188 - accuracy: 0.0103 - val_loss: 159615.7031 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335286.5938 - accuracy: 0.0041 - val_loss: 164363.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 335161.1562 - accuracy: 0.0041 - val_loss: 162547.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 339210.1875 - accuracy: 0.0062 - val_loss: 164620.2969 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 346451.9062 - accuracy: 0.0021 - val_loss: 169778.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 343964.6250 - accuracy: 0.0021 - val_loss: 172881.6406 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 352632.3438 - accuracy: 0.0083 - val_loss: 171624.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 353356.3438 - accuracy: 0.0083 - val_loss: 174440.5156 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 358735.3125 - accuracy: 0.0062 - val_loss: 173225.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 362033.9688 - accuracy: 0.0083 - val_loss: 175196.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 363963.1250 - accuracy: 0.0041 - val_loss: 178207.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375885.6562 - accuracy: 0.0103 - val_loss: 179427.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 375454.4062 - accuracy: 0.0021 - val_loss: 187148.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 377457.3438 - accuracy: 0.0021 - val_loss: 188542.4844 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 384429.5625 - accuracy: 0.0021 - val_loss: 187225.2031 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 387841.8125 - accuracy: 0.0041 - val_loss: 190945.9844 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 393572.4375 - accuracy: 0.0083 - val_loss: 187164.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 394467.0938 - accuracy: 0.0124 - val_loss: 192712.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 392330.2188 - accuracy: 0.0083 - val_loss: 190576.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 402103.0625 - accuracy: 0.0145 - val_loss: 196434.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 409066.3438 - accuracy: 0.0021 - val_loss: 201674.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 411504.3438 - accuracy: 0.0083 - val_loss: 196874.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 412375.9062 - accuracy: 0.0062 - val_loss: 196064.9531 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 419635.8125 - accuracy: 0.0041 - val_loss: 200145.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 420384.0938 - accuracy: 0.0062 - val_loss: 208509.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 437233.4688 - accuracy: 0.0041 - val_loss: 215608.2969 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 438593.3125 - accuracy: 0.0062 - val_loss: 214616.9844 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 441664.4062 - accuracy: 0.0041 - val_loss: 216060.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 437918.2812 - accuracy: 0.0041 - val_loss: 223909.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 445925.6562 - accuracy: 0.0041 - val_loss: 221274.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 454172.5312 - accuracy: 0.0041 - val_loss: 220925.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 445663.2188 - accuracy: 0.0021 - val_loss: 225206.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 459281.2188 - accuracy: 0.0000e+00 - val_loss: 228532.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 479792.9062 - accuracy: 0.0312\n",
            "Epoch: 200, accuracy:0.0062,  loss:464418.0625,  val_accuracy:0.0000,  val_loss:224614.4062,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 464418.0625 - accuracy: 0.0062 - val_loss: 224614.4062 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 467843.2812 - accuracy: 0.0000e+00 - val_loss: 223072.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 466670.5312 - accuracy: 0.0021 - val_loss: 231128.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 476385.9688 - accuracy: 0.0021 - val_loss: 231878.1094 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 480709.1250 - accuracy: 0.0062 - val_loss: 239643.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 478399.6875 - accuracy: 0.0021 - val_loss: 243632.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 489901.1250 - accuracy: 0.0124 - val_loss: 247934.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 487557.2188 - accuracy: 0.0000e+00 - val_loss: 248457.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 502864.5938 - accuracy: 0.0062 - val_loss: 253358.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 504822.6562 - accuracy: 0.0083 - val_loss: 248766.5781 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 510846.8750 - accuracy: 0.0062 - val_loss: 258377.3906 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 515362.4688 - accuracy: 0.0083 - val_loss: 259677.6094 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 522071.8750 - accuracy: 0.0062 - val_loss: 265189.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 521570.7188 - accuracy: 0.0041 - val_loss: 267298.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 533750.7500 - accuracy: 0.0021 - val_loss: 262233.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 537902.2500 - accuracy: 0.0083 - val_loss: 264273.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 536141.5000 - accuracy: 0.0083 - val_loss: 271918.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 540310.3750 - accuracy: 0.0083 - val_loss: 275890.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 547094.0000 - accuracy: 0.0062 - val_loss: 271431.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 549429.5000 - accuracy: 0.0103 - val_loss: 275319.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 568203.0625 - accuracy: 0.0021 - val_loss: 279613.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 571273.0000 - accuracy: 0.0041 - val_loss: 277927.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 570545.1875 - accuracy: 0.0083 - val_loss: 275556.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 583982.9375 - accuracy: 0.0083 - val_loss: 281716.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 572956.2500 - accuracy: 0.0041 - val_loss: 293418.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 586212.6875 - accuracy: 0.0083 - val_loss: 295026.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 588904.1875 - accuracy: 0.0021 - val_loss: 307466.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 590741.9375 - accuracy: 0.0021 - val_loss: 307793.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 598236.6875 - accuracy: 0.0021 - val_loss: 295947.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 599697.0000 - accuracy: 0.0062 - val_loss: 302149.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 607458.2500 - accuracy: 0.0041 - val_loss: 308346.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 617270.1875 - accuracy: 0.0062 - val_loss: 308871.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 629963.4375 - accuracy: 0.0041 - val_loss: 315947.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 633572.2500 - accuracy: 0.0062 - val_loss: 318431.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 628337.3750 - accuracy: 0.0041 - val_loss: 320921.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 643387.2500 - accuracy: 0.0041 - val_loss: 319491.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 641149.6875 - accuracy: 0.0041 - val_loss: 326756.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 665522.2500 - accuracy: 0.0062 - val_loss: 319549.6562 - val_accuracy: 0.0083\n",
            "Epoch 239/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 644145.0000 - accuracy: 0.0000e+00 - val_loss: 331151.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 656277.8125 - accuracy: 0.0062 - val_loss: 326044.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 663963.8125 - accuracy: 0.0083 - val_loss: 326108.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 665675.0000 - accuracy: 0.0062 - val_loss: 328345.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 665807.1250 - accuracy: 0.0083 - val_loss: 336637.2188 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 684737.8750 - accuracy: 0.0021 - val_loss: 341035.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 679979.9375 - accuracy: 0.0103 - val_loss: 358803.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 703054.3750 - accuracy: 0.0083 - val_loss: 343938.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 692808.6875 - accuracy: 0.0041 - val_loss: 339488.5000 - val_accuracy: 0.0083\n",
            "Epoch 248/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 700165.3750 - accuracy: 0.0000e+00 - val_loss: 348124.3125 - val_accuracy: 0.0165\n",
            "Epoch 249/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 719104.6250 - accuracy: 0.0083 - val_loss: 352189.7500 - val_accuracy: 0.0165\n",
            "Epoch 250/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 723359.0000 - accuracy: 0.0041 - val_loss: 348011.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 714901.3750 - accuracy: 0.0103 - val_loss: 355374.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 742039.1250 - accuracy: 0.0021 - val_loss: 352960.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 752146.3125 - accuracy: 0.0021 - val_loss: 360003.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 743643.1250 - accuracy: 0.0062 - val_loss: 368943.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 756219.3750 - accuracy: 0.0103 - val_loss: 369220.6562 - val_accuracy: 0.0165\n",
            "Epoch 256/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 747861.4375 - accuracy: 0.0000e+00 - val_loss: 375456.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 770928.6250 - accuracy: 0.0041 - val_loss: 377434.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 759526.1250 - accuracy: 0.0062 - val_loss: 381418.1562 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 762474.2500 - accuracy: 0.0000e+00 - val_loss: 382331.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 779929.0625 - accuracy: 0.0062 - val_loss: 387958.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 784655.7500 - accuracy: 0.0083 - val_loss: 380814.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 790121.5000 - accuracy: 0.0103 - val_loss: 390825.5312 - val_accuracy: 0.0165\n",
            "Epoch 263/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 780618.0625 - accuracy: 0.0041 - val_loss: 388188.0312 - val_accuracy: 0.0083\n",
            "Epoch 264/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 796465.5625 - accuracy: 0.0103 - val_loss: 399886.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 809403.5625 - accuracy: 0.0041 - val_loss: 397717.6875 - val_accuracy: 0.0165\n",
            "Epoch 266/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 801781.2500 - accuracy: 0.0062 - val_loss: 405202.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 814521.3125 - accuracy: 0.0062 - val_loss: 406981.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 817783.5000 - accuracy: 0.0021 - val_loss: 410229.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 817818.1875 - accuracy: 0.0041 - val_loss: 408042.6250 - val_accuracy: 0.0083\n",
            "Epoch 270/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 858373.8125 - accuracy: 0.0041 - val_loss: 415525.5000 - val_accuracy: 0.0083\n",
            "Epoch 271/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 838334.3750 - accuracy: 0.0062 - val_loss: 420837.0625 - val_accuracy: 0.0165\n",
            "Epoch 272/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 862288.9375 - accuracy: 0.0021 - val_loss: 420386.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 859994.1875 - accuracy: 0.0083 - val_loss: 422240.0938 - val_accuracy: 0.0083\n",
            "Epoch 274/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 868455.3750 - accuracy: 0.0062 - val_loss: 432597.0938 - val_accuracy: 0.0165\n",
            "Epoch 275/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 871330.1250 - accuracy: 0.0021 - val_loss: 426591.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 873036.9375 - accuracy: 0.0021 - val_loss: 435167.0312 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 897083.3750 - accuracy: 0.0062 - val_loss: 444741.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 889912.4375 - accuracy: 0.0062 - val_loss: 441577.7188 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 890193.8125 - accuracy: 0.0083 - val_loss: 447417.7188 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 908431.6250 - accuracy: 0.0124 - val_loss: 447954.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 922015.0625 - accuracy: 0.0124 - val_loss: 450400.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 931574.1875 - accuracy: 0.0103 - val_loss: 458811.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 915322.6875 - accuracy: 0.0083 - val_loss: 457716.3125 - val_accuracy: 0.0083\n",
            "Epoch 284/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 918537.2500 - accuracy: 0.0041 - val_loss: 466110.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 906195.5625 - accuracy: 0.0083 - val_loss: 473367.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 928162.0000 - accuracy: 0.0062 - val_loss: 477245.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 950773.0625 - accuracy: 0.0041 - val_loss: 472622.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 954795.0625 - accuracy: 0.0021 - val_loss: 474997.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 956971.7500 - accuracy: 0.0041 - val_loss: 482238.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 972623.8750 - accuracy: 0.0062 - val_loss: 483592.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 970646.9375 - accuracy: 0.0041 - val_loss: 476871.9062 - val_accuracy: 0.0165\n",
            "Epoch 292/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 976127.3750 - accuracy: 0.0021 - val_loss: 481897.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 994851.3750 - accuracy: 0.0062 - val_loss: 488844.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1001732.5000 - accuracy: 0.0041 - val_loss: 497678.6250 - val_accuracy: 0.0165\n",
            "Epoch 295/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 997075.7500 - accuracy: 0.0062 - val_loss: 498693.6875 - val_accuracy: 0.0165\n",
            "Epoch 296/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 993212.1875 - accuracy: 0.0103 - val_loss: 498222.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1032131.9375 - accuracy: 0.0103 - val_loss: 515207.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1041749.5625 - accuracy: 0.0021 - val_loss: 511612.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1030833.3125 - accuracy: 0.0041 - val_loss: 512504.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1041820.5000 - accuracy: 0.0083 - val_loss: 524363.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 1077281.5000 - accuracy: 0.0000e+00\n",
            "Epoch: 300, accuracy:0.0062,  loss:1038937.3750,  val_accuracy:0.0000,  val_loss:525295.7500,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1038937.3750 - accuracy: 0.0062 - val_loss: 525295.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1039776.3750 - accuracy: 0.0062 - val_loss: 524656.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1065169.3750 - accuracy: 0.0041 - val_loss: 526858.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1059898.7500 - accuracy: 0.0000e+00 - val_loss: 523771.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1076594.3750 - accuracy: 0.0062 - val_loss: 532861.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1061570.0000 - accuracy: 0.0062 - val_loss: 537492.3125 - val_accuracy: 0.0083\n",
            "Epoch 307/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1081809.2500 - accuracy: 0.0041 - val_loss: 548322.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1096657.3750 - accuracy: 0.0041 - val_loss: 541390.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1093914.3750 - accuracy: 0.0103 - val_loss: 552775.7500 - val_accuracy: 0.0165\n",
            "Epoch 310/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1121049.8750 - accuracy: 0.0041 - val_loss: 574635.9375 - val_accuracy: 0.0165\n",
            "Epoch 311/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1122724.5000 - accuracy: 0.0021 - val_loss: 575365.3125 - val_accuracy: 0.0165\n",
            "Epoch 312/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1150109.7500 - accuracy: 0.0021 - val_loss: 580613.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1131384.6250 - accuracy: 0.0041 - val_loss: 572794.5625 - val_accuracy: 0.0165\n",
            "Epoch 314/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1158175.1250 - accuracy: 0.0083 - val_loss: 579122.0625 - val_accuracy: 0.0165\n",
            "Epoch 315/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1134320.2500 - accuracy: 0.0103 - val_loss: 591354.0625 - val_accuracy: 0.0165\n",
            "Epoch 316/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1170148.0000 - accuracy: 0.0124 - val_loss: 599807.1875 - val_accuracy: 0.0083\n",
            "Epoch 317/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1169434.7500 - accuracy: 0.0083 - val_loss: 600935.1875 - val_accuracy: 0.0165\n",
            "Epoch 318/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1167114.0000 - accuracy: 0.0041 - val_loss: 604286.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1176942.1250 - accuracy: 0.0145 - val_loss: 602766.4375 - val_accuracy: 0.0165\n",
            "Epoch 320/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1198119.0000 - accuracy: 0.0000e+00 - val_loss: 606635.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1220272.0000 - accuracy: 0.0083 - val_loss: 630916.5625 - val_accuracy: 0.0165\n",
            "Epoch 322/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1183938.0000 - accuracy: 0.0083 - val_loss: 621251.9375 - val_accuracy: 0.0165\n",
            "Epoch 323/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1196243.8750 - accuracy: 0.0062 - val_loss: 623688.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1204221.2500 - accuracy: 0.0062 - val_loss: 642056.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1247179.6250 - accuracy: 0.0041 - val_loss: 636226.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1231727.1250 - accuracy: 0.0062 - val_loss: 635597.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1237556.3750 - accuracy: 0.0041 - val_loss: 637367.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1244061.6250 - accuracy: 0.0041 - val_loss: 660458.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1268908.1250 - accuracy: 0.0062 - val_loss: 645481.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1296546.3750 - accuracy: 0.0062 - val_loss: 659442.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1285728.6250 - accuracy: 0.0041 - val_loss: 677333.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1278547.0000 - accuracy: 0.0000e+00 - val_loss: 681997.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1298906.8750 - accuracy: 0.0000e+00 - val_loss: 671113.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1295612.3750 - accuracy: 0.0041 - val_loss: 687742.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1283351.2500 - accuracy: 0.0103 - val_loss: 698337.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1312731.7500 - accuracy: 0.0041 - val_loss: 694869.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1341585.2500 - accuracy: 0.0062 - val_loss: 686405.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1330818.1250 - accuracy: 0.0062 - val_loss: 699335.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1328746.8750 - accuracy: 0.0021 - val_loss: 694195.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1360561.0000 - accuracy: 0.0041 - val_loss: 713934.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1351889.2500 - accuracy: 0.0041 - val_loss: 709763.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1363254.6250 - accuracy: 0.0041 - val_loss: 723603.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1358542.1250 - accuracy: 0.0062 - val_loss: 716058.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1369789.5000 - accuracy: 0.0021 - val_loss: 739410.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1373375.7500 - accuracy: 0.0062 - val_loss: 742442.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1381531.7500 - accuracy: 0.0103 - val_loss: 737617.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1407290.0000 - accuracy: 0.0083 - val_loss: 744347.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1372293.6250 - accuracy: 0.0021 - val_loss: 754387.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1394996.3750 - accuracy: 0.0021 - val_loss: 752398.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1441745.2500 - accuracy: 0.0062 - val_loss: 742908.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1431893.3750 - accuracy: 0.0083 - val_loss: 753064.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1467235.1250 - accuracy: 0.0103 - val_loss: 761309.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1464950.7500 - accuracy: 0.0062 - val_loss: 781078.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1457490.1250 - accuracy: 0.0062 - val_loss: 786929.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1462056.6250 - accuracy: 0.0041 - val_loss: 794284.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1512595.1250 - accuracy: 0.0083 - val_loss: 789111.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1504116.5000 - accuracy: 0.0062 - val_loss: 807864.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1505533.5000 - accuracy: 0.0041 - val_loss: 796534.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1487520.5000 - accuracy: 0.0083 - val_loss: 820079.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1504891.3750 - accuracy: 0.0041 - val_loss: 836235.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1535902.2500 - accuracy: 0.0041 - val_loss: 829873.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1546518.8750 - accuracy: 0.0041 - val_loss: 825539.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1543014.6250 - accuracy: 0.0041 - val_loss: 839654.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1532400.3750 - accuracy: 0.0000e+00 - val_loss: 829998.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1566573.3750 - accuracy: 0.0062 - val_loss: 847116.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1539255.8750 - accuracy: 0.0021 - val_loss: 860380.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1572968.6250 - accuracy: 0.0124 - val_loss: 883061.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1583023.0000 - accuracy: 0.0021 - val_loss: 867174.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1571966.6250 - accuracy: 0.0062 - val_loss: 881843.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1590961.0000 - accuracy: 0.0000e+00 - val_loss: 860236.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1614873.8750 - accuracy: 0.0021 - val_loss: 861034.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1624097.8750 - accuracy: 0.0021 - val_loss: 843626.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1630673.0000 - accuracy: 0.0062 - val_loss: 866614.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1648409.0000 - accuracy: 0.0021 - val_loss: 874387.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1641288.3750 - accuracy: 0.0103 - val_loss: 862042.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1654012.0000 - accuracy: 0.0103 - val_loss: 874613.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1633827.6250 - accuracy: 0.0000e+00 - val_loss: 883771.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1681588.0000 - accuracy: 0.0124 - val_loss: 904854.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1715347.2500 - accuracy: 0.0062 - val_loss: 910949.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1722348.3750 - accuracy: 0.0000e+00 - val_loss: 915317.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1722627.1250 - accuracy: 0.0062 - val_loss: 909856.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1716026.3750 - accuracy: 0.0062 - val_loss: 932890.4375 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1746587.5000 - accuracy: 0.0041 - val_loss: 933814.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1773039.0000 - accuracy: 0.0062 - val_loss: 953207.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1763765.3750 - accuracy: 0.0062 - val_loss: 945998.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1768155.5000 - accuracy: 0.0021 - val_loss: 960696.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1769657.8750 - accuracy: 0.0021 - val_loss: 958382.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1791477.1250 - accuracy: 0.0041 - val_loss: 972640.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1794467.5000 - accuracy: 0.0021 - val_loss: 986501.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1802026.1250 - accuracy: 0.0062 - val_loss: 1003911.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1809292.2500 - accuracy: 0.0062 - val_loss: 1013292.1875 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1833631.8750 - accuracy: 0.0083 - val_loss: 1036049.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1826756.3750 - accuracy: 0.0021 - val_loss: 1052906.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1829401.7500 - accuracy: 0.0062 - val_loss: 1048061.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1837502.7500 - accuracy: 0.0041 - val_loss: 1049869.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1876489.0000 - accuracy: 0.0041 - val_loss: 1038262.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1891119.0000 - accuracy: 0.0000e+00 - val_loss: 1052945.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1906193.6250 - accuracy: 0.0103 - val_loss: 1051799.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1865361.8750 - accuracy: 0.0041 - val_loss: 1059124.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1888116.7500 - accuracy: 0.0083 - val_loss: 1049584.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 1911927.8750 - accuracy: 0.0021    \n",
            "Epoch: 400, accuracy:0.0021,  loss:1911927.8750,  val_accuracy:0.0000,  val_loss:1065924.7500,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1911927.8750 - accuracy: 0.0021 - val_loss: 1065924.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1894836.5000 - accuracy: 0.0062 - val_loss: 1085548.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1925922.1250 - accuracy: 0.0000e+00 - val_loss: 1105069.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1927978.7500 - accuracy: 0.0041 - val_loss: 1102257.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1915764.8750 - accuracy: 0.0000e+00 - val_loss: 1096693.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1958225.7500 - accuracy: 0.0083 - val_loss: 1102438.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 1984477.6250 - accuracy: 0.0041 - val_loss: 1118834.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1967017.2500 - accuracy: 0.0083 - val_loss: 1138450.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1985839.5000 - accuracy: 0.0103 - val_loss: 1103589.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2010983.0000 - accuracy: 0.0083 - val_loss: 1136884.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 1982102.5000 - accuracy: 0.0021 - val_loss: 1115266.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2000303.3750 - accuracy: 0.0083 - val_loss: 1146964.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2032029.2500 - accuracy: 0.0062 - val_loss: 1140475.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2033721.0000 - accuracy: 0.0062 - val_loss: 1151193.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2024497.3750 - accuracy: 0.0062 - val_loss: 1161024.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2051412.8750 - accuracy: 0.0062 - val_loss: 1128157.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2056389.8750 - accuracy: 0.0000e+00 - val_loss: 1156884.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2083791.5000 - accuracy: 0.0083 - val_loss: 1182966.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2110589.5000 - accuracy: 0.0041 - val_loss: 1195019.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2092279.6250 - accuracy: 0.0000e+00 - val_loss: 1178551.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2089897.0000 - accuracy: 0.0124 - val_loss: 1203498.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2139816.0000 - accuracy: 0.0041 - val_loss: 1186698.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2110681.7500 - accuracy: 0.0000e+00 - val_loss: 1203037.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2116932.7500 - accuracy: 0.0041 - val_loss: 1211211.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2126511.0000 - accuracy: 0.0041 - val_loss: 1214478.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2148911.7500 - accuracy: 0.0000e+00 - val_loss: 1221526.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2180453.0000 - accuracy: 0.0083 - val_loss: 1230025.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2162871.0000 - accuracy: 0.0000e+00 - val_loss: 1232719.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2220400.7500 - accuracy: 0.0145 - val_loss: 1200845.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2172241.2500 - accuracy: 0.0041 - val_loss: 1248969.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2247286.2500 - accuracy: 0.0062 - val_loss: 1233684.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2208356.0000 - accuracy: 0.0062 - val_loss: 1254089.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2244218.7500 - accuracy: 0.0041 - val_loss: 1262169.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2293376.2500 - accuracy: 0.0062 - val_loss: 1272659.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2281878.2500 - accuracy: 0.0000e+00 - val_loss: 1259173.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2257694.2500 - accuracy: 0.0041 - val_loss: 1306374.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2276325.2500 - accuracy: 0.0083 - val_loss: 1259765.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2275749.7500 - accuracy: 0.0062 - val_loss: 1269226.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2304444.0000 - accuracy: 0.0000e+00 - val_loss: 1310088.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2269075.0000 - accuracy: 0.0021 - val_loss: 1290426.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2311971.5000 - accuracy: 0.0083 - val_loss: 1289318.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2326263.5000 - accuracy: 0.0021 - val_loss: 1304080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2370446.2500 - accuracy: 0.0021 - val_loss: 1300851.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2361092.2500 - accuracy: 0.0083 - val_loss: 1324711.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2374063.2500 - accuracy: 0.0041 - val_loss: 1331815.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2367264.2500 - accuracy: 0.0021 - val_loss: 1361563.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2399730.5000 - accuracy: 0.0021 - val_loss: 1306540.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2401581.5000 - accuracy: 0.0041 - val_loss: 1348447.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2411809.0000 - accuracy: 0.0021 - val_loss: 1357608.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2474188.0000 - accuracy: 0.0021 - val_loss: 1365310.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2483269.2500 - accuracy: 0.0062 - val_loss: 1357644.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2443584.2500 - accuracy: 0.0062 - val_loss: 1411067.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2475799.0000 - accuracy: 0.0062 - val_loss: 1384392.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2473262.5000 - accuracy: 0.0021 - val_loss: 1389273.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2505307.7500 - accuracy: 0.0124 - val_loss: 1403348.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2477829.2500 - accuracy: 0.0021 - val_loss: 1413665.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2542940.0000 - accuracy: 0.0021 - val_loss: 1420287.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2518924.7500 - accuracy: 0.0062 - val_loss: 1389685.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2483539.7500 - accuracy: 0.0021 - val_loss: 1412813.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2513718.0000 - accuracy: 0.0103 - val_loss: 1400530.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2535645.0000 - accuracy: 0.0021 - val_loss: 1413001.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2595435.7500 - accuracy: 0.0000e+00 - val_loss: 1404078.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2595222.0000 - accuracy: 0.0041 - val_loss: 1418625.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2541085.5000 - accuracy: 0.0041 - val_loss: 1453655.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2636095.7500 - accuracy: 0.0021 - val_loss: 1441915.5000 - val_accuracy: 0.0083\n",
            "Epoch 466/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2593876.0000 - accuracy: 0.0021 - val_loss: 1451034.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2593420.7500 - accuracy: 0.0062 - val_loss: 1476642.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2609403.7500 - accuracy: 0.0041 - val_loss: 1475495.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2663163.5000 - accuracy: 0.0062 - val_loss: 1492562.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2661475.5000 - accuracy: 0.0083 - val_loss: 1491660.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2694810.7500 - accuracy: 0.0041 - val_loss: 1497979.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2709251.7500 - accuracy: 0.0041 - val_loss: 1515700.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2676951.0000 - accuracy: 0.0021 - val_loss: 1507131.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2726339.5000 - accuracy: 0.0041 - val_loss: 1534116.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2736190.7500 - accuracy: 0.0021 - val_loss: 1556262.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2755378.2500 - accuracy: 0.0083 - val_loss: 1528391.8750 - val_accuracy: 0.0165\n",
            "Epoch 477/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2788211.7500 - accuracy: 0.0041 - val_loss: 1546410.6250 - val_accuracy: 0.0165\n",
            "Epoch 478/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2772740.2500 - accuracy: 0.0021 - val_loss: 1558225.5000 - val_accuracy: 0.0165\n",
            "Epoch 479/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2787215.5000 - accuracy: 0.0000e+00 - val_loss: 1587156.1250 - val_accuracy: 0.0165\n",
            "Epoch 480/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2752500.0000 - accuracy: 0.0083 - val_loss: 1557389.7500 - val_accuracy: 0.0165\n",
            "Epoch 481/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2783068.5000 - accuracy: 0.0021 - val_loss: 1563430.7500 - val_accuracy: 0.0165\n",
            "Epoch 482/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2809578.5000 - accuracy: 0.0062 - val_loss: 1623042.8750 - val_accuracy: 0.0165\n",
            "Epoch 483/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 2867421.5000 - accuracy: 0.0062 - val_loss: 1570794.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2848262.2500 - accuracy: 0.0083 - val_loss: 1631243.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2857507.5000 - accuracy: 0.0124 - val_loss: 1627035.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2914757.0000 - accuracy: 0.0021 - val_loss: 1641111.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2894634.7500 - accuracy: 0.0021 - val_loss: 1625293.8750 - val_accuracy: 0.0165\n",
            "Epoch 488/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2898841.5000 - accuracy: 0.0041 - val_loss: 1648991.7500 - val_accuracy: 0.0165\n",
            "Epoch 489/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2886468.2500 - accuracy: 0.0041 - val_loss: 1637752.8750 - val_accuracy: 0.0165\n",
            "Epoch 490/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2927319.5000 - accuracy: 0.0103 - val_loss: 1665541.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2954999.2500 - accuracy: 0.0041 - val_loss: 1654790.2500 - val_accuracy: 0.0165\n",
            "Epoch 492/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2929616.7500 - accuracy: 0.0083 - val_loss: 1671435.5000 - val_accuracy: 0.0165\n",
            "Epoch 493/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2983512.2500 - accuracy: 0.0041 - val_loss: 1713088.0000 - val_accuracy: 0.0165\n",
            "Epoch 494/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2939893.5000 - accuracy: 0.0021 - val_loss: 1660111.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2945402.7500 - accuracy: 0.0083 - val_loss: 1732217.7500 - val_accuracy: 0.0165\n",
            "Epoch 496/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3038813.0000 - accuracy: 0.0062 - val_loss: 1705202.2500 - val_accuracy: 0.0165\n",
            "Epoch 497/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3011964.5000 - accuracy: 0.0062 - val_loss: 1691465.0000 - val_accuracy: 0.0165\n",
            "Epoch 498/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 2979382.7500 - accuracy: 0.0062 - val_loss: 1700053.3750 - val_accuracy: 0.0165\n",
            "Epoch 499/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3108579.2500 - accuracy: 0.0041 - val_loss: 1726028.1250 - val_accuracy: 0.0083\n",
            "Epoch 500/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3046058.0000 - accuracy: 0.0041 - val_loss: 1761545.0000 - val_accuracy: 0.0165\n",
            "Epoch 501/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 3047791.7500 - accuracy: 0.0000e+00\n",
            "Epoch: 500, accuracy:0.0083,  loss:3075899.2500,  val_accuracy:0.0165,  val_loss:1770960.3750,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3075899.2500 - accuracy: 0.0083 - val_loss: 1770960.3750 - val_accuracy: 0.0165\n",
            "Epoch 502/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3091991.5000 - accuracy: 0.0062 - val_loss: 1751219.0000 - val_accuracy: 0.0083\n",
            "Epoch 503/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3068161.7500 - accuracy: 0.0041 - val_loss: 1790805.2500 - val_accuracy: 0.0165\n",
            "Epoch 504/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3073038.0000 - accuracy: 0.0021 - val_loss: 1789340.2500 - val_accuracy: 0.0165\n",
            "Epoch 505/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3114906.2500 - accuracy: 0.0062 - val_loss: 1820025.6250 - val_accuracy: 0.0165\n",
            "Epoch 506/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3135495.2500 - accuracy: 0.0062 - val_loss: 1803073.3750 - val_accuracy: 0.0165\n",
            "Epoch 507/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3136681.0000 - accuracy: 0.0000e+00 - val_loss: 1816607.7500 - val_accuracy: 0.0165\n",
            "Epoch 508/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3122850.5000 - accuracy: 0.0062 - val_loss: 1813436.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3201309.5000 - accuracy: 0.0041 - val_loss: 1843019.1250 - val_accuracy: 0.0165\n",
            "Epoch 510/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3176543.2500 - accuracy: 0.0062 - val_loss: 1826896.1250 - val_accuracy: 0.0165\n",
            "Epoch 511/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3165899.0000 - accuracy: 0.0062 - val_loss: 1836995.1250 - val_accuracy: 0.0165\n",
            "Epoch 512/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3237698.5000 - accuracy: 0.0021 - val_loss: 1875055.3750 - val_accuracy: 0.0165\n",
            "Epoch 513/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3253496.5000 - accuracy: 0.0083 - val_loss: 1871781.5000 - val_accuracy: 0.0165\n",
            "Epoch 514/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3231826.2500 - accuracy: 0.0103 - val_loss: 1872207.8750 - val_accuracy: 0.0165\n",
            "Epoch 515/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3242631.0000 - accuracy: 0.0021 - val_loss: 1874369.6250 - val_accuracy: 0.0165\n",
            "Epoch 516/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3237660.2500 - accuracy: 0.0062 - val_loss: 1919707.5000 - val_accuracy: 0.0165\n",
            "Epoch 517/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3293711.7500 - accuracy: 0.0000e+00 - val_loss: 1899247.1250 - val_accuracy: 0.0165\n",
            "Epoch 518/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3273010.2500 - accuracy: 0.0083 - val_loss: 1901666.1250 - val_accuracy: 0.0165\n",
            "Epoch 519/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3298448.7500 - accuracy: 0.0021 - val_loss: 1923585.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3379546.2500 - accuracy: 0.0041 - val_loss: 1904515.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3315496.5000 - accuracy: 0.0021 - val_loss: 1928467.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3327755.0000 - accuracy: 0.0021 - val_loss: 1953884.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3335868.5000 - accuracy: 0.0041 - val_loss: 1989682.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3392207.0000 - accuracy: 0.0021 - val_loss: 1997393.6250 - val_accuracy: 0.0165\n",
            "Epoch 525/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3451785.0000 - accuracy: 0.0083 - val_loss: 2021281.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3439548.7500 - accuracy: 0.0083 - val_loss: 2009699.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3424004.5000 - accuracy: 0.0062 - val_loss: 2019273.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3429676.2500 - accuracy: 0.0021 - val_loss: 2035101.6250 - val_accuracy: 0.0165\n",
            "Epoch 529/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3396686.7500 - accuracy: 0.0021 - val_loss: 2040515.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3438542.7500 - accuracy: 0.0041 - val_loss: 2020005.0000 - val_accuracy: 0.0165\n",
            "Epoch 531/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3461564.2500 - accuracy: 0.0041 - val_loss: 2047452.0000 - val_accuracy: 0.0083\n",
            "Epoch 532/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3548848.5000 - accuracy: 0.0062 - val_loss: 2107225.7500 - val_accuracy: 0.0165\n",
            "Epoch 533/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3508115.5000 - accuracy: 0.0041 - val_loss: 2092805.1250 - val_accuracy: 0.0165\n",
            "Epoch 534/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3532454.0000 - accuracy: 0.0041 - val_loss: 2070873.8750 - val_accuracy: 0.0165\n",
            "Epoch 535/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3520991.0000 - accuracy: 0.0083 - val_loss: 2066171.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3502774.7500 - accuracy: 0.0083 - val_loss: 2100369.0000 - val_accuracy: 0.0165\n",
            "Epoch 537/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3539462.5000 - accuracy: 0.0083 - val_loss: 2109315.0000 - val_accuracy: 0.0165\n",
            "Epoch 538/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3598206.2500 - accuracy: 0.0062 - val_loss: 2154188.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3552305.2500 - accuracy: 0.0103 - val_loss: 2101837.0000 - val_accuracy: 0.0165\n",
            "Epoch 540/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3606796.0000 - accuracy: 0.0021 - val_loss: 2113111.0000 - val_accuracy: 0.0165\n",
            "Epoch 541/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3628003.0000 - accuracy: 0.0062 - val_loss: 2137875.2500 - val_accuracy: 0.0165\n",
            "Epoch 542/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3651833.5000 - accuracy: 0.0021 - val_loss: 2154505.5000 - val_accuracy: 0.0165\n",
            "Epoch 543/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3692146.0000 - accuracy: 0.0186 - val_loss: 2181425.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3656042.0000 - accuracy: 0.0083 - val_loss: 2192368.5000 - val_accuracy: 0.0165\n",
            "Epoch 545/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3734558.2500 - accuracy: 0.0062 - val_loss: 2171946.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3726762.5000 - accuracy: 0.0021 - val_loss: 2211252.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3743256.2500 - accuracy: 0.0041 - val_loss: 2197304.2500 - val_accuracy: 0.0165\n",
            "Epoch 548/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3743520.5000 - accuracy: 0.0021 - val_loss: 2205364.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3765271.2500 - accuracy: 0.0103 - val_loss: 2212135.0000 - val_accuracy: 0.0165\n",
            "Epoch 550/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3757540.5000 - accuracy: 0.0124 - val_loss: 2210999.5000 - val_accuracy: 0.0165\n",
            "Epoch 551/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3741538.5000 - accuracy: 0.0083 - val_loss: 2200802.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3749077.0000 - accuracy: 0.0000e+00 - val_loss: 2245479.7500 - val_accuracy: 0.0165\n",
            "Epoch 553/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 3752787.0000 - accuracy: 0.0021 - val_loss: 2291037.2500 - val_accuracy: 0.0165\n",
            "Epoch 554/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3834518.5000 - accuracy: 0.0083 - val_loss: 2265204.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3883917.2500 - accuracy: 0.0041 - val_loss: 2217841.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3880760.5000 - accuracy: 0.0062 - val_loss: 2277896.2500 - val_accuracy: 0.0165\n",
            "Epoch 557/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3872544.7500 - accuracy: 0.0021 - val_loss: 2272152.5000 - val_accuracy: 0.0165\n",
            "Epoch 558/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3805582.0000 - accuracy: 0.0000e+00 - val_loss: 2316035.5000 - val_accuracy: 0.0165\n",
            "Epoch 559/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3937487.7500 - accuracy: 0.0124 - val_loss: 2323487.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3927668.2500 - accuracy: 0.0062 - val_loss: 2323691.7500 - val_accuracy: 0.0165\n",
            "Epoch 561/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3884241.0000 - accuracy: 0.0041 - val_loss: 2368658.5000 - val_accuracy: 0.0165\n",
            "Epoch 562/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3964195.0000 - accuracy: 0.0021 - val_loss: 2342989.7500 - val_accuracy: 0.0165\n",
            "Epoch 563/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3927337.0000 - accuracy: 0.0021 - val_loss: 2341897.5000 - val_accuracy: 0.0165\n",
            "Epoch 564/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 3935860.7500 - accuracy: 0.0062 - val_loss: 2356373.2500 - val_accuracy: 0.0165\n",
            "Epoch 565/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4017017.7500 - accuracy: 0.0000e+00 - val_loss: 2416495.5000 - val_accuracy: 0.0165\n",
            "Epoch 566/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4106972.7500 - accuracy: 0.0041 - val_loss: 2363715.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4029310.5000 - accuracy: 0.0021 - val_loss: 2400774.2500 - val_accuracy: 0.0165\n",
            "Epoch 568/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4019778.7500 - accuracy: 0.0103 - val_loss: 2426488.0000 - val_accuracy: 0.0165\n",
            "Epoch 569/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4079733.7500 - accuracy: 0.0021 - val_loss: 2419135.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4060484.0000 - accuracy: 0.0062 - val_loss: 2413936.5000 - val_accuracy: 0.0165\n",
            "Epoch 571/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4114781.2500 - accuracy: 0.0021 - val_loss: 2409637.0000 - val_accuracy: 0.0165\n",
            "Epoch 572/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4103692.5000 - accuracy: 0.0062 - val_loss: 2473773.2500 - val_accuracy: 0.0165\n",
            "Epoch 573/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4157510.0000 - accuracy: 0.0083 - val_loss: 2532538.2500 - val_accuracy: 0.0165\n",
            "Epoch 574/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4114790.2500 - accuracy: 0.0021 - val_loss: 2503363.7500 - val_accuracy: 0.0165\n",
            "Epoch 575/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4148455.5000 - accuracy: 0.0041 - val_loss: 2464017.5000 - val_accuracy: 0.0165\n",
            "Epoch 576/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4174396.5000 - accuracy: 0.0103 - val_loss: 2478439.2500 - val_accuracy: 0.0165\n",
            "Epoch 577/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4126508.5000 - accuracy: 0.0021 - val_loss: 2536361.7500 - val_accuracy: 0.0165\n",
            "Epoch 578/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4204463.5000 - accuracy: 0.0000e+00 - val_loss: 2493538.5000 - val_accuracy: 0.0165\n",
            "Epoch 579/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4227295.0000 - accuracy: 0.0021 - val_loss: 2520598.5000 - val_accuracy: 0.0165\n",
            "Epoch 580/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4231857.5000 - accuracy: 0.0000e+00 - val_loss: 2527146.2500 - val_accuracy: 0.0165\n",
            "Epoch 581/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4202857.0000 - accuracy: 0.0041 - val_loss: 2507746.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4204885.0000 - accuracy: 0.0062 - val_loss: 2513644.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4286796.5000 - accuracy: 0.0083 - val_loss: 2541870.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4251713.0000 - accuracy: 0.0083 - val_loss: 2559918.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4324711.5000 - accuracy: 0.0083 - val_loss: 2561115.7500 - val_accuracy: 0.0165\n",
            "Epoch 586/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4308504.0000 - accuracy: 0.0062 - val_loss: 2539473.5000 - val_accuracy: 0.0165\n",
            "Epoch 587/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4338234.0000 - accuracy: 0.0041 - val_loss: 2573977.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4321983.0000 - accuracy: 0.0083 - val_loss: 2590997.7500 - val_accuracy: 0.0165\n",
            "Epoch 589/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4353846.5000 - accuracy: 0.0000e+00 - val_loss: 2606173.5000 - val_accuracy: 0.0165\n",
            "Epoch 590/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4333850.0000 - accuracy: 0.0041 - val_loss: 2606506.0000 - val_accuracy: 0.0165\n",
            "Epoch 591/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4349020.5000 - accuracy: 0.0021 - val_loss: 2587438.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4384760.5000 - accuracy: 0.0021 - val_loss: 2672222.7500 - val_accuracy: 0.0165\n",
            "Epoch 593/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4403304.5000 - accuracy: 0.0021 - val_loss: 2688024.7500 - val_accuracy: 0.0165\n",
            "Epoch 594/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4394439.0000 - accuracy: 0.0041 - val_loss: 2691009.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4472959.0000 - accuracy: 0.0021 - val_loss: 2745685.7500 - val_accuracy: 0.0165\n",
            "Epoch 596/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4500675.5000 - accuracy: 0.0041 - val_loss: 2669783.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4508118.0000 - accuracy: 0.0041 - val_loss: 2691609.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4576281.0000 - accuracy: 0.0021 - val_loss: 2725591.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4538143.5000 - accuracy: 0.0021 - val_loss: 2739586.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4629312.0000 - accuracy: 0.0021 - val_loss: 2756843.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 601/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 5113765.0000 - accuracy: 0.0000e+00\n",
            "Epoch: 600, accuracy:0.0041,  loss:4552255.5000,  val_accuracy:0.0000,  val_loss:2817260.2500,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4552255.5000 - accuracy: 0.0041 - val_loss: 2817260.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4579722.5000 - accuracy: 0.0103 - val_loss: 2793457.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4570755.5000 - accuracy: 0.0000e+00 - val_loss: 2790519.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4678867.0000 - accuracy: 0.0041 - val_loss: 2797305.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4600514.0000 - accuracy: 0.0124 - val_loss: 2875801.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4659729.5000 - accuracy: 0.0062 - val_loss: 2797479.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4698666.5000 - accuracy: 0.0000e+00 - val_loss: 2796446.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4696785.5000 - accuracy: 0.0000e+00 - val_loss: 2834012.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4713755.5000 - accuracy: 0.0062 - val_loss: 2876325.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 4763859.0000 - accuracy: 0.0041 - val_loss: 2840822.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4740120.0000 - accuracy: 0.0062 - val_loss: 2869822.2500 - val_accuracy: 0.0083\n",
            "Epoch 612/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4696698.5000 - accuracy: 0.0062 - val_loss: 2890312.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4799907.0000 - accuracy: 0.0041 - val_loss: 2878017.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4805608.5000 - accuracy: 0.0021 - val_loss: 2869812.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4802739.0000 - accuracy: 0.0062 - val_loss: 2884609.7500 - val_accuracy: 0.0165\n",
            "Epoch 616/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4730078.0000 - accuracy: 0.0062 - val_loss: 2955510.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4831155.0000 - accuracy: 0.0021 - val_loss: 2992558.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4885440.5000 - accuracy: 0.0021 - val_loss: 2948613.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4915273.0000 - accuracy: 0.0062 - val_loss: 2926950.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4849583.0000 - accuracy: 0.0021 - val_loss: 3002924.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4885614.5000 - accuracy: 0.0041 - val_loss: 2987809.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4972894.5000 - accuracy: 0.0021 - val_loss: 2994515.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4940060.0000 - accuracy: 0.0041 - val_loss: 3022331.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4975783.5000 - accuracy: 0.0021 - val_loss: 3062624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4943726.0000 - accuracy: 0.0062 - val_loss: 3056227.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5019207.0000 - accuracy: 0.0000e+00 - val_loss: 3073932.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4957428.5000 - accuracy: 0.0000e+00 - val_loss: 3067376.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5036491.5000 - accuracy: 0.0021 - val_loss: 3084619.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5114574.5000 - accuracy: 0.0041 - val_loss: 3114199.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 4998582.5000 - accuracy: 0.0021 - val_loss: 3082613.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5091573.0000 - accuracy: 0.0021 - val_loss: 3091020.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5113443.0000 - accuracy: 0.0062 - val_loss: 3019598.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5106011.0000 - accuracy: 0.0062 - val_loss: 3113100.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5213087.0000 - accuracy: 0.0041 - val_loss: 3098650.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5200690.0000 - accuracy: 0.0041 - val_loss: 3094990.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5200439.0000 - accuracy: 0.0021 - val_loss: 3160949.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5213565.5000 - accuracy: 0.0103 - val_loss: 3129745.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5126191.0000 - accuracy: 0.0000e+00 - val_loss: 3190326.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5205098.5000 - accuracy: 0.0000e+00 - val_loss: 3166599.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5252806.5000 - accuracy: 0.0000e+00 - val_loss: 3131428.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5241365.0000 - accuracy: 0.0062 - val_loss: 3135342.0000 - val_accuracy: 0.0083\n",
            "Epoch 642/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5329660.5000 - accuracy: 0.0021 - val_loss: 3153121.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5298532.0000 - accuracy: 0.0041 - val_loss: 3177088.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5327435.0000 - accuracy: 0.0062 - val_loss: 3210858.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5423514.0000 - accuracy: 0.0000e+00 - val_loss: 3227302.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5318856.5000 - accuracy: 0.0021 - val_loss: 3233376.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5429656.0000 - accuracy: 0.0062 - val_loss: 3254445.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5384239.5000 - accuracy: 0.0083 - val_loss: 3285326.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5368540.5000 - accuracy: 0.0041 - val_loss: 3296660.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5461467.5000 - accuracy: 0.0083 - val_loss: 3295990.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5464805.0000 - accuracy: 0.0062 - val_loss: 3295387.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5542674.5000 - accuracy: 0.0041 - val_loss: 3345838.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5429409.0000 - accuracy: 0.0021 - val_loss: 3375796.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5449684.0000 - accuracy: 0.0041 - val_loss: 3363620.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5477907.0000 - accuracy: 0.0041 - val_loss: 3364876.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5547827.0000 - accuracy: 0.0021 - val_loss: 3373599.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5507948.0000 - accuracy: 0.0000e+00 - val_loss: 3428127.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5675451.0000 - accuracy: 0.0041 - val_loss: 3431932.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5636441.0000 - accuracy: 0.0000e+00 - val_loss: 3428529.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5607454.5000 - accuracy: 0.0021 - val_loss: 3512687.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5606188.5000 - accuracy: 0.0083 - val_loss: 3520346.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5644133.0000 - accuracy: 0.0000e+00 - val_loss: 3440690.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5641768.5000 - accuracy: 0.0041 - val_loss: 3521811.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5683166.0000 - accuracy: 0.0021 - val_loss: 3533173.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5706865.0000 - accuracy: 0.0021 - val_loss: 3528248.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5721143.5000 - accuracy: 0.0062 - val_loss: 3539787.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5766257.0000 - accuracy: 0.0041 - val_loss: 3570601.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5775705.5000 - accuracy: 0.0124 - val_loss: 3599297.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5718873.0000 - accuracy: 0.0021 - val_loss: 3590415.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5714663.0000 - accuracy: 0.0021 - val_loss: 3589941.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5884870.5000 - accuracy: 0.0041 - val_loss: 3593354.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5785057.0000 - accuracy: 0.0021 - val_loss: 3639935.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5870462.5000 - accuracy: 0.0021 - val_loss: 3605720.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5833037.0000 - accuracy: 0.0062 - val_loss: 3679835.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5910484.0000 - accuracy: 0.0021 - val_loss: 3701991.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5826728.5000 - accuracy: 0.0021 - val_loss: 3697372.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5936311.5000 - accuracy: 0.0021 - val_loss: 3733517.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5951988.0000 - accuracy: 0.0021 - val_loss: 3686662.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 5941430.0000 - accuracy: 0.0021 - val_loss: 3749003.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6085908.5000 - accuracy: 0.0021 - val_loss: 3787377.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5988702.0000 - accuracy: 0.0041 - val_loss: 3847925.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 5996415.0000 - accuracy: 0.0021 - val_loss: 3820859.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6096272.0000 - accuracy: 0.0083 - val_loss: 3886315.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6070369.5000 - accuracy: 0.0000e+00 - val_loss: 3863873.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6097204.0000 - accuracy: 0.0062 - val_loss: 3844933.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6059358.0000 - accuracy: 0.0000e+00 - val_loss: 3917570.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6155161.5000 - accuracy: 0.0021 - val_loss: 3888428.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6177482.5000 - accuracy: 0.0000e+00 - val_loss: 3986236.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6210737.0000 - accuracy: 0.0041 - val_loss: 3937742.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6230965.5000 - accuracy: 0.0062 - val_loss: 4046555.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6196614.0000 - accuracy: 0.0103 - val_loss: 3966822.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6284032.5000 - accuracy: 0.0041 - val_loss: 3948615.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6296819.0000 - accuracy: 0.0000e+00 - val_loss: 3945068.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6257812.5000 - accuracy: 0.0062 - val_loss: 4068196.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6367583.5000 - accuracy: 0.0041 - val_loss: 4002413.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6308484.0000 - accuracy: 0.0041 - val_loss: 3982940.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6437727.0000 - accuracy: 0.0021 - val_loss: 3994094.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6443176.0000 - accuracy: 0.0000e+00 - val_loss: 3983395.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6473645.0000 - accuracy: 0.0041 - val_loss: 4058726.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6505047.5000 - accuracy: 0.0062 - val_loss: 4038262.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 701/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 6549527.0000 - accuracy: 0.0000e+00\n",
            "Epoch: 700, accuracy:0.0021,  loss:6458816.0000,  val_accuracy:0.0000,  val_loss:4072174.5000,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6458816.0000 - accuracy: 0.0021 - val_loss: 4072174.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6444021.0000 - accuracy: 0.0062 - val_loss: 4066041.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6453446.0000 - accuracy: 0.0041 - val_loss: 4099873.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6484469.5000 - accuracy: 0.0062 - val_loss: 4162496.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6528929.0000 - accuracy: 0.0021 - val_loss: 4181686.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6549994.5000 - accuracy: 0.0021 - val_loss: 4146289.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6598474.5000 - accuracy: 0.0000e+00 - val_loss: 4157208.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6695502.0000 - accuracy: 0.0000e+00 - val_loss: 4235554.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6664284.5000 - accuracy: 0.0000e+00 - val_loss: 4203589.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6605041.0000 - accuracy: 0.0021 - val_loss: 4253070.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 6824445.0000 - accuracy: 0.0000e+00 - val_loss: 4306790.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6679032.5000 - accuracy: 0.0041 - val_loss: 4277869.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6705686.0000 - accuracy: 0.0062 - val_loss: 4270871.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6719269.5000 - accuracy: 0.0103 - val_loss: 4241453.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6696519.0000 - accuracy: 0.0124 - val_loss: 4286910.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6737914.5000 - accuracy: 0.0000e+00 - val_loss: 4360605.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6799800.5000 - accuracy: 0.0062 - val_loss: 4239173.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6836112.0000 - accuracy: 0.0021 - val_loss: 4284065.5000 - val_accuracy: 0.0083\n",
            "Epoch 719/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6797365.0000 - accuracy: 0.0041 - val_loss: 4311557.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6800469.5000 - accuracy: 0.0041 - val_loss: 4350985.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6801029.5000 - accuracy: 0.0041 - val_loss: 4379776.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6815151.0000 - accuracy: 0.0000e+00 - val_loss: 4366449.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6940651.5000 - accuracy: 0.0021 - val_loss: 4374803.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6865748.0000 - accuracy: 0.0062 - val_loss: 4401137.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6948156.5000 - accuracy: 0.0021 - val_loss: 4491666.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7064645.0000 - accuracy: 0.0083 - val_loss: 4493026.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7049791.0000 - accuracy: 0.0041 - val_loss: 4496772.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7127848.0000 - accuracy: 0.0000e+00 - val_loss: 4509856.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7051341.0000 - accuracy: 0.0062 - val_loss: 4508267.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 6996090.0000 - accuracy: 0.0041 - val_loss: 4638567.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7167689.5000 - accuracy: 0.0000e+00 - val_loss: 4564564.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7201392.0000 - accuracy: 0.0041 - val_loss: 4631441.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7278152.0000 - accuracy: 0.0000e+00 - val_loss: 4613867.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7254438.0000 - accuracy: 0.0000e+00 - val_loss: 4594863.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7199100.0000 - accuracy: 0.0041 - val_loss: 4561567.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7232793.5000 - accuracy: 0.0000e+00 - val_loss: 4620077.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7233461.0000 - accuracy: 0.0021 - val_loss: 4619469.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7342109.5000 - accuracy: 0.0000e+00 - val_loss: 4617072.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7391114.0000 - accuracy: 0.0041 - val_loss: 4629940.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7304924.0000 - accuracy: 0.0021 - val_loss: 4665446.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7395187.0000 - accuracy: 0.0000e+00 - val_loss: 4718352.5000 - val_accuracy: 0.0083\n",
            "Epoch 742/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7549262.0000 - accuracy: 0.0021 - val_loss: 4671455.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7367836.5000 - accuracy: 0.0021 - val_loss: 4708408.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7382796.0000 - accuracy: 0.0021 - val_loss: 4794589.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7461658.5000 - accuracy: 0.0041 - val_loss: 4724433.5000 - val_accuracy: 0.0083\n",
            "Epoch 746/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7395029.0000 - accuracy: 0.0083 - val_loss: 4762776.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7552500.0000 - accuracy: 0.0021 - val_loss: 4839013.5000 - val_accuracy: 0.0083\n",
            "Epoch 748/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7596877.0000 - accuracy: 0.0083 - val_loss: 4748708.5000 - val_accuracy: 0.0083\n",
            "Epoch 749/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7510756.5000 - accuracy: 0.0083 - val_loss: 4807918.5000 - val_accuracy: 0.0083\n",
            "Epoch 750/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7575562.0000 - accuracy: 0.0021 - val_loss: 4866793.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7511009.0000 - accuracy: 0.0062 - val_loss: 4784599.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7469974.5000 - accuracy: 0.0000e+00 - val_loss: 4816163.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7672590.0000 - accuracy: 0.0000e+00 - val_loss: 4842855.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7775354.5000 - accuracy: 0.0021 - val_loss: 4816194.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7722037.0000 - accuracy: 0.0083 - val_loss: 4825023.0000 - val_accuracy: 0.0083\n",
            "Epoch 756/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7666920.0000 - accuracy: 0.0041 - val_loss: 4824249.5000 - val_accuracy: 0.0083\n",
            "Epoch 757/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7818618.0000 - accuracy: 0.0062 - val_loss: 4879042.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7670830.5000 - accuracy: 0.0041 - val_loss: 4948454.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7711393.0000 - accuracy: 0.0062 - val_loss: 4913250.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7885818.0000 - accuracy: 0.0083 - val_loss: 4937428.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7786808.5000 - accuracy: 0.0021 - val_loss: 4975768.0000 - val_accuracy: 0.0083\n",
            "Epoch 762/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7856275.0000 - accuracy: 0.0000e+00 - val_loss: 4951092.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7835342.5000 - accuracy: 0.0041 - val_loss: 4922030.5000 - val_accuracy: 0.0083\n",
            "Epoch 764/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7790188.5000 - accuracy: 0.0000e+00 - val_loss: 4949955.5000 - val_accuracy: 0.0083\n",
            "Epoch 765/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7882296.5000 - accuracy: 0.0000e+00 - val_loss: 5030081.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7954040.0000 - accuracy: 0.0000e+00 - val_loss: 5016433.0000 - val_accuracy: 0.0083\n",
            "Epoch 767/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7962394.5000 - accuracy: 0.0083 - val_loss: 5084335.0000 - val_accuracy: 0.0083\n",
            "Epoch 768/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 7866902.5000 - accuracy: 0.0041 - val_loss: 5075837.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "16/16 [==============================] - 0s 6ms/step - loss: 8062308.5000 - accuracy: 0.0041 - val_loss: 5022043.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 7945916.0000 - accuracy: 0.0041 - val_loss: 5097145.5000 - val_accuracy: 0.0083\n",
            "Epoch 771/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8087828.0000 - accuracy: 0.0021 - val_loss: 5098538.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8003129.5000 - accuracy: 0.0021 - val_loss: 5164414.0000 - val_accuracy: 0.0083\n",
            "Epoch 773/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8057871.0000 - accuracy: 0.0021 - val_loss: 5162151.0000 - val_accuracy: 0.0083\n",
            "Epoch 774/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8134507.5000 - accuracy: 0.0083 - val_loss: 5206102.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8114013.5000 - accuracy: 0.0083 - val_loss: 5131417.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8115807.5000 - accuracy: 0.0041 - val_loss: 5133820.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8107579.0000 - accuracy: 0.0062 - val_loss: 5193931.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8293813.5000 - accuracy: 0.0041 - val_loss: 5205918.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8138011.0000 - accuracy: 0.0062 - val_loss: 5255175.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8146250.5000 - accuracy: 0.0021 - val_loss: 5237814.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8243641.0000 - accuracy: 0.0021 - val_loss: 5284695.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8252595.0000 - accuracy: 0.0083 - val_loss: 5341580.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8305959.5000 - accuracy: 0.0021 - val_loss: 5267138.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8327306.5000 - accuracy: 0.0041 - val_loss: 5357022.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8332071.5000 - accuracy: 0.0062 - val_loss: 5298768.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8375877.0000 - accuracy: 0.0021 - val_loss: 5362687.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8319177.0000 - accuracy: 0.0021 - val_loss: 5467371.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8524980.0000 - accuracy: 0.0021 - val_loss: 5380906.0000 - val_accuracy: 0.0083\n",
            "Epoch 789/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8400193.0000 - accuracy: 0.0041 - val_loss: 5356169.5000 - val_accuracy: 0.0083\n",
            "Epoch 790/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8547609.0000 - accuracy: 0.0103 - val_loss: 5358540.5000 - val_accuracy: 0.0083\n",
            "Epoch 791/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8411332.0000 - accuracy: 0.0041 - val_loss: 5471311.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8532977.0000 - accuracy: 0.0021 - val_loss: 5448656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8497342.0000 - accuracy: 0.0021 - val_loss: 5475968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8553117.0000 - accuracy: 0.0062 - val_loss: 5493192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8664592.0000 - accuracy: 0.0041 - val_loss: 5567903.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8653682.0000 - accuracy: 0.0041 - val_loss: 5538192.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8516314.0000 - accuracy: 0.0041 - val_loss: 5539816.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8617571.0000 - accuracy: 0.0021 - val_loss: 5538287.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8661723.0000 - accuracy: 0.0021 - val_loss: 5562156.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8735747.0000 - accuracy: 0.0000e+00 - val_loss: 5587703.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 801/1000\n",
            " 1/16 [>.............................] - ETA: 0s - loss: 8634698.0000 - accuracy: 0.0000e+00\n",
            "Epoch: 800, accuracy:0.0021,  loss:8716851.0000,  val_accuracy:0.0083,  val_loss:5600697.0000,  \n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8716851.0000 - accuracy: 0.0021 - val_loss: 5600697.0000 - val_accuracy: 0.0083\n",
            "Epoch 802/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8904458.0000 - accuracy: 0.0041 - val_loss: 5701941.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8926453.0000 - accuracy: 0.0021 - val_loss: 5554581.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8955523.0000 - accuracy: 0.0041 - val_loss: 5675032.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8778202.0000 - accuracy: 0.0062 - val_loss: 5662188.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8814911.0000 - accuracy: 0.0021 - val_loss: 5717531.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8817973.0000 - accuracy: 0.0021 - val_loss: 5717609.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9132470.0000 - accuracy: 0.0021 - val_loss: 5648736.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8960304.0000 - accuracy: 0.0062 - val_loss: 5770663.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 8898399.0000 - accuracy: 0.0021 - val_loss: 5671848.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9028081.0000 - accuracy: 0.0021 - val_loss: 5704867.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9039901.0000 - accuracy: 0.0021 - val_loss: 5711539.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9129812.0000 - accuracy: 0.0041 - val_loss: 5699515.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9058574.0000 - accuracy: 0.0083 - val_loss: 5772362.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9139684.0000 - accuracy: 0.0062 - val_loss: 5760449.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9082863.0000 - accuracy: 0.0021 - val_loss: 5770226.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 8985988.0000 - accuracy: 0.0041 - val_loss: 5730494.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9079443.0000 - accuracy: 0.0041 - val_loss: 5794788.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9257683.0000 - accuracy: 0.0000e+00 - val_loss: 5875016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9011055.0000 - accuracy: 0.0021 - val_loss: 5896570.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9188199.0000 - accuracy: 0.0021 - val_loss: 5925153.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9446197.0000 - accuracy: 0.0021 - val_loss: 5954065.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9311378.0000 - accuracy: 0.0041 - val_loss: 5938115.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9333884.0000 - accuracy: 0.0021 - val_loss: 6038840.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9506816.0000 - accuracy: 0.0000e+00 - val_loss: 6000567.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9347400.0000 - accuracy: 0.0000e+00 - val_loss: 6025533.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9335389.0000 - accuracy: 0.0021 - val_loss: 6088266.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9500014.0000 - accuracy: 0.0000e+00 - val_loss: 6050577.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9324877.0000 - accuracy: 0.0021 - val_loss: 6149582.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9451559.0000 - accuracy: 0.0041 - val_loss: 6145795.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9683203.0000 - accuracy: 0.0021 - val_loss: 6032190.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9510727.0000 - accuracy: 0.0021 - val_loss: 6130731.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9617128.0000 - accuracy: 0.0041 - val_loss: 6080326.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9624895.0000 - accuracy: 0.0083 - val_loss: 6168003.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9563160.0000 - accuracy: 0.0021 - val_loss: 6236766.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9473571.0000 - accuracy: 0.0083 - val_loss: 6212766.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9591989.0000 - accuracy: 0.0062 - val_loss: 6183847.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9853519.0000 - accuracy: 0.0041 - val_loss: 6162424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9735705.0000 - accuracy: 0.0021 - val_loss: 6225828.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 9708528.0000 - accuracy: 0.0041 - val_loss: 6338907.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9963761.0000 - accuracy: 0.0000e+00 - val_loss: 6281063.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9711140.0000 - accuracy: 0.0000e+00 - val_loss: 6314069.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9901852.0000 - accuracy: 0.0000e+00 - val_loss: 6310256.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9919471.0000 - accuracy: 0.0062 - val_loss: 6389203.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9941283.0000 - accuracy: 0.0083 - val_loss: 6401067.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9897418.0000 - accuracy: 0.0103 - val_loss: 6428229.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10107562.0000 - accuracy: 0.0041 - val_loss: 6473895.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9869758.0000 - accuracy: 0.0021 - val_loss: 6414883.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10118110.0000 - accuracy: 0.0000e+00 - val_loss: 6554482.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10004152.0000 - accuracy: 0.0021 - val_loss: 6604021.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 9886607.0000 - accuracy: 0.0041 - val_loss: 6649899.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10263231.0000 - accuracy: 0.0083 - val_loss: 6565686.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10305807.0000 - accuracy: 0.0000e+00 - val_loss: 6681247.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10324191.0000 - accuracy: 0.0062 - val_loss: 6712196.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10203147.0000 - accuracy: 0.0041 - val_loss: 6683812.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10208038.0000 - accuracy: 0.0062 - val_loss: 6584045.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10201796.0000 - accuracy: 0.0041 - val_loss: 6721395.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10218915.0000 - accuracy: 0.0062 - val_loss: 6641010.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10246638.0000 - accuracy: 0.0041 - val_loss: 6620476.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10194389.0000 - accuracy: 0.0000e+00 - val_loss: 6605479.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10448799.0000 - accuracy: 0.0000e+00 - val_loss: 6638354.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10500078.0000 - accuracy: 0.0000e+00 - val_loss: 6751829.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10362637.0000 - accuracy: 0.0021 - val_loss: 6780927.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10399587.0000 - accuracy: 0.0021 - val_loss: 6662977.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10614000.0000 - accuracy: 0.0041 - val_loss: 6698486.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10417713.0000 - accuracy: 0.0041 - val_loss: 6711080.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10619472.0000 - accuracy: 0.0062 - val_loss: 6729435.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10389171.0000 - accuracy: 0.0000e+00 - val_loss: 6764802.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10257806.0000 - accuracy: 0.0021 - val_loss: 6818468.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10496786.0000 - accuracy: 0.0062 - val_loss: 6914834.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10652470.0000 - accuracy: 0.0041 - val_loss: 6952246.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10721431.0000 - accuracy: 0.0000e+00 - val_loss: 7030661.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10533469.0000 - accuracy: 0.0000e+00 - val_loss: 7025124.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10686326.0000 - accuracy: 0.0041 - val_loss: 7055653.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10736318.0000 - accuracy: 0.0021 - val_loss: 7052647.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10630507.0000 - accuracy: 0.0021 - val_loss: 7149049.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10776716.0000 - accuracy: 0.0041 - val_loss: 7113698.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10718078.0000 - accuracy: 0.0000e+00 - val_loss: 7032118.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10732657.0000 - accuracy: 0.0041 - val_loss: 7200391.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10944445.0000 - accuracy: 0.0041 - val_loss: 7231836.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10859077.0000 - accuracy: 0.0041 - val_loss: 7234481.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10627683.0000 - accuracy: 0.0000e+00 - val_loss: 7118638.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10832025.0000 - accuracy: 0.0041 - val_loss: 7205030.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10673366.0000 - accuracy: 0.0000e+00 - val_loss: 7129011.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 10724293.0000 - accuracy: 0.0041 - val_loss: 7327531.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11009862.0000 - accuracy: 0.0000e+00 - val_loss: 7317619.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11101164.0000 - accuracy: 0.0062 - val_loss: 7325761.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11207097.0000 - accuracy: 0.0041 - val_loss: 7287998.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11161936.0000 - accuracy: 0.0062 - val_loss: 7428973.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11288953.0000 - accuracy: 0.0041 - val_loss: 7276437.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11110883.0000 - accuracy: 0.0041 - val_loss: 7446160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 10932148.0000 - accuracy: 0.0021 - val_loss: 7478946.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11193948.0000 - accuracy: 0.0083 - val_loss: 7334985.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11109169.0000 - accuracy: 0.0021 - val_loss: 7512700.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11341395.0000 - accuracy: 0.0041 - val_loss: 7442757.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11342448.0000 - accuracy: 0.0041 - val_loss: 7315552.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11265132.0000 - accuracy: 0.0041 - val_loss: 7354144.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11359995.0000 - accuracy: 0.0062 - val_loss: 7421583.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11267681.0000 - accuracy: 0.0041 - val_loss: 7530444.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11538785.0000 - accuracy: 0.0041 - val_loss: 7462284.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "16/16 [==============================] - ETA: 0s - loss: 11444752.0000 - accuracy: 0.0041    \n",
            "Epoch: 900, accuracy:0.0041,  loss:11444752.0000,  val_accuracy:0.0000,  val_loss:7468289.0000,  \n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11444752.0000 - accuracy: 0.0041 - val_loss: 7468289.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11633877.0000 - accuracy: 0.0062 - val_loss: 7549111.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11498865.0000 - accuracy: 0.0041 - val_loss: 7633528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11584127.0000 - accuracy: 0.0021 - val_loss: 7695551.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11618272.0000 - accuracy: 0.0041 - val_loss: 7715856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11397898.0000 - accuracy: 0.0083 - val_loss: 7654564.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11618266.0000 - accuracy: 0.0021 - val_loss: 7790052.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11620750.0000 - accuracy: 0.0041 - val_loss: 7784289.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11737059.0000 - accuracy: 0.0000e+00 - val_loss: 7694227.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11660768.0000 - accuracy: 0.0021 - val_loss: 7680850.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11719705.0000 - accuracy: 0.0041 - val_loss: 7738805.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11764496.0000 - accuracy: 0.0062 - val_loss: 7754981.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11519657.0000 - accuracy: 0.0041 - val_loss: 7870566.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 11791943.0000 - accuracy: 0.0021 - val_loss: 7715354.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11967880.0000 - accuracy: 0.0021 - val_loss: 7738151.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12010680.0000 - accuracy: 0.0021 - val_loss: 7875077.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11787845.0000 - accuracy: 0.0021 - val_loss: 7942169.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12043659.0000 - accuracy: 0.0062 - val_loss: 7964726.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11819391.0000 - accuracy: 0.0021 - val_loss: 8015697.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11747565.0000 - accuracy: 0.0021 - val_loss: 7956269.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12146959.0000 - accuracy: 0.0083 - val_loss: 7999828.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 11944168.0000 - accuracy: 0.0062 - val_loss: 8011775.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12036814.0000 - accuracy: 0.0041 - val_loss: 8121785.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12259329.0000 - accuracy: 0.0083 - val_loss: 8150270.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12177586.0000 - accuracy: 0.0000e+00 - val_loss: 8127296.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12122874.0000 - accuracy: 0.0041 - val_loss: 8178561.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12358569.0000 - accuracy: 0.0062 - val_loss: 8142090.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12457607.0000 - accuracy: 0.0000e+00 - val_loss: 8031315.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12382742.0000 - accuracy: 0.0021 - val_loss: 8276774.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12294203.0000 - accuracy: 0.0083 - val_loss: 8165351.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12322237.0000 - accuracy: 0.0021 - val_loss: 8202782.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12541251.0000 - accuracy: 0.0062 - val_loss: 8320012.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12614797.0000 - accuracy: 0.0000e+00 - val_loss: 8261509.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12339779.0000 - accuracy: 0.0000e+00 - val_loss: 8384071.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12479258.0000 - accuracy: 0.0062 - val_loss: 8384026.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12518751.0000 - accuracy: 0.0021 - val_loss: 8307987.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12677638.0000 - accuracy: 0.0021 - val_loss: 8413114.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12520651.0000 - accuracy: 0.0062 - val_loss: 8386310.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12564810.0000 - accuracy: 0.0083 - val_loss: 8580515.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12440491.0000 - accuracy: 0.0083 - val_loss: 8305328.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12647410.0000 - accuracy: 0.0021 - val_loss: 8301973.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12573865.0000 - accuracy: 0.0062 - val_loss: 8392470.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12812792.0000 - accuracy: 0.0041 - val_loss: 8476465.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12762388.0000 - accuracy: 0.0041 - val_loss: 8506795.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12763239.0000 - accuracy: 0.0041 - val_loss: 8476871.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12706788.0000 - accuracy: 0.0021 - val_loss: 8450154.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12933771.0000 - accuracy: 0.0062 - val_loss: 8495143.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12761503.0000 - accuracy: 0.0000e+00 - val_loss: 8472126.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 12900564.0000 - accuracy: 0.0041 - val_loss: 8529593.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13039748.0000 - accuracy: 0.0041 - val_loss: 8595322.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12768395.0000 - accuracy: 0.0000e+00 - val_loss: 8688373.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12915354.0000 - accuracy: 0.0021 - val_loss: 8651740.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13297478.0000 - accuracy: 0.0041 - val_loss: 8763663.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 12885406.0000 - accuracy: 0.0000e+00 - val_loss: 8776697.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13139839.0000 - accuracy: 0.0062 - val_loss: 8943091.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13205386.0000 - accuracy: 0.0062 - val_loss: 8688206.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13198877.0000 - accuracy: 0.0041 - val_loss: 8806410.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13215941.0000 - accuracy: 0.0041 - val_loss: 8807838.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13326584.0000 - accuracy: 0.0021 - val_loss: 8858529.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13234342.0000 - accuracy: 0.0124 - val_loss: 9100881.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13335380.0000 - accuracy: 0.0124 - val_loss: 8882493.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13231648.0000 - accuracy: 0.0021 - val_loss: 9065111.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13508469.0000 - accuracy: 0.0021 - val_loss: 8859300.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13477622.0000 - accuracy: 0.0021 - val_loss: 8945554.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13382330.0000 - accuracy: 0.0000e+00 - val_loss: 9046180.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13526596.0000 - accuracy: 0.0021 - val_loss: 9039745.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13724802.0000 - accuracy: 0.0041 - val_loss: 9003826.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13523298.0000 - accuracy: 0.0041 - val_loss: 9039791.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13463641.0000 - accuracy: 0.0000e+00 - val_loss: 9139558.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13664754.0000 - accuracy: 0.0021 - val_loss: 9167082.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13809726.0000 - accuracy: 0.0041 - val_loss: 9197232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13847756.0000 - accuracy: 0.0000e+00 - val_loss: 9155610.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13801937.0000 - accuracy: 0.0041 - val_loss: 9302222.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13647604.0000 - accuracy: 0.0000e+00 - val_loss: 9242069.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13770494.0000 - accuracy: 0.0083 - val_loss: 9257415.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13492499.0000 - accuracy: 0.0000e+00 - val_loss: 9225452.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13681608.0000 - accuracy: 0.0021 - val_loss: 9285460.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13634073.0000 - accuracy: 0.0021 - val_loss: 9315566.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13826511.0000 - accuracy: 0.0021 - val_loss: 9216000.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13735965.0000 - accuracy: 0.0041 - val_loss: 9385937.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13886212.0000 - accuracy: 0.0041 - val_loss: 9431723.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 13978629.0000 - accuracy: 0.0041 - val_loss: 9335605.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14137909.0000 - accuracy: 0.0103 - val_loss: 9460135.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 13964298.0000 - accuracy: 0.0041 - val_loss: 9359766.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14059281.0000 - accuracy: 0.0041 - val_loss: 9440203.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14347242.0000 - accuracy: 0.0041 - val_loss: 9405262.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14198844.0000 - accuracy: 0.0083 - val_loss: 9574749.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14396522.0000 - accuracy: 0.0062 - val_loss: 9618091.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14065510.0000 - accuracy: 0.0000e+00 - val_loss: 9616255.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14366916.0000 - accuracy: 0.0041 - val_loss: 9535137.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14182365.0000 - accuracy: 0.0000e+00 - val_loss: 9788099.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14264276.0000 - accuracy: 0.0062 - val_loss: 9737060.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14203495.0000 - accuracy: 0.0041 - val_loss: 9700618.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "16/16 [==============================] - 0s 5ms/step - loss: 14047650.0000 - accuracy: 0.0000e+00 - val_loss: 9623937.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14381487.0000 - accuracy: 0.0062 - val_loss: 9672716.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14718197.0000 - accuracy: 0.0021 - val_loss: 9809090.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14401390.0000 - accuracy: 0.0000e+00 - val_loss: 9834434.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14525954.0000 - accuracy: 0.0041 - val_loss: 9808740.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14628212.0000 - accuracy: 0.0041 - val_loss: 9769460.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "16/16 [==============================] - 0s 4ms/step - loss: 14777649.0000 - accuracy: 0.0000e+00 - val_loss: 9781457.0000 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7mg0A_wlnif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "c027873e-143e-48df-ddbd-5d4c0555c72a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 64)                384       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 220)               14300     \n",
            "=================================================================\n",
            "Total params: 18,844\n",
            "Trainable params: 18,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu5-G0YkpJWX",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ2op0IDKtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bc22e928-e694-423e-e05a-a7883355b94f"
      },
      "source": [
        "test_predictions = model.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f7f40173488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57FnCwYfu9ef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af203d66-250e-4604-a48c-06e5a0f5242d"
      },
      "source": [
        "test_predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMdxdYIaurjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = pd.DataFrame(test_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ2w_yAoMSfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "1edbc127-2753-435c-e01c-162eb2ba11f0"
      },
      "source": [
        "test_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.297256</td>\n",
              "      <td>1.189361</td>\n",
              "      <td>1.132536</td>\n",
              "      <td>1.302260</td>\n",
              "      <td>1.169439</td>\n",
              "      <td>1.252599</td>\n",
              "      <td>1.184923</td>\n",
              "      <td>1.103148</td>\n",
              "      <td>1.212186</td>\n",
              "      <td>1.266332</td>\n",
              "      <td>1.232296</td>\n",
              "      <td>1.308228</td>\n",
              "      <td>1.209856</td>\n",
              "      <td>1.217574</td>\n",
              "      <td>1.318938</td>\n",
              "      <td>1.273919</td>\n",
              "      <td>1.206169</td>\n",
              "      <td>1.248824</td>\n",
              "      <td>1.181691</td>\n",
              "      <td>1.110913</td>\n",
              "      <td>1.253744</td>\n",
              "      <td>1.262384</td>\n",
              "      <td>1.140153</td>\n",
              "      <td>1.252629</td>\n",
              "      <td>1.164091</td>\n",
              "      <td>1.189390</td>\n",
              "      <td>1.206530</td>\n",
              "      <td>1.194076</td>\n",
              "      <td>1.282547</td>\n",
              "      <td>1.289580</td>\n",
              "      <td>1.080059</td>\n",
              "      <td>1.260352</td>\n",
              "      <td>1.149923</td>\n",
              "      <td>1.124912</td>\n",
              "      <td>1.232630</td>\n",
              "      <td>1.179067</td>\n",
              "      <td>1.298462</td>\n",
              "      <td>1.258388</td>\n",
              "      <td>1.173152</td>\n",
              "      <td>1.192249</td>\n",
              "      <td>...</td>\n",
              "      <td>1.186101</td>\n",
              "      <td>1.213589</td>\n",
              "      <td>1.196523</td>\n",
              "      <td>1.168819</td>\n",
              "      <td>1.234037</td>\n",
              "      <td>1.253356</td>\n",
              "      <td>1.228481</td>\n",
              "      <td>1.280059</td>\n",
              "      <td>1.203528</td>\n",
              "      <td>1.197553</td>\n",
              "      <td>1.206674</td>\n",
              "      <td>1.199048</td>\n",
              "      <td>1.267492</td>\n",
              "      <td>1.189786</td>\n",
              "      <td>1.162275</td>\n",
              "      <td>1.096708</td>\n",
              "      <td>1.123636</td>\n",
              "      <td>1.122166</td>\n",
              "      <td>1.167188</td>\n",
              "      <td>1.184142</td>\n",
              "      <td>1.243164</td>\n",
              "      <td>1.269007</td>\n",
              "      <td>1.231575</td>\n",
              "      <td>1.088177</td>\n",
              "      <td>1.230852</td>\n",
              "      <td>1.173689</td>\n",
              "      <td>1.297969</td>\n",
              "      <td>1.060149</td>\n",
              "      <td>1.313246</td>\n",
              "      <td>1.228178</td>\n",
              "      <td>1.331168</td>\n",
              "      <td>1.276224</td>\n",
              "      <td>1.211964</td>\n",
              "      <td>1.215018</td>\n",
              "      <td>1.194930</td>\n",
              "      <td>1.211493</td>\n",
              "      <td>1.153677</td>\n",
              "      <td>1.117755</td>\n",
              "      <td>1.139819</td>\n",
              "      <td>1.260445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.327115</td>\n",
              "      <td>1.142003</td>\n",
              "      <td>1.163430</td>\n",
              "      <td>1.270357</td>\n",
              "      <td>1.130347</td>\n",
              "      <td>1.195816</td>\n",
              "      <td>1.120640</td>\n",
              "      <td>1.103970</td>\n",
              "      <td>1.219769</td>\n",
              "      <td>1.181871</td>\n",
              "      <td>1.223658</td>\n",
              "      <td>1.332418</td>\n",
              "      <td>1.186794</td>\n",
              "      <td>1.183458</td>\n",
              "      <td>1.272051</td>\n",
              "      <td>1.241971</td>\n",
              "      <td>1.225142</td>\n",
              "      <td>1.268425</td>\n",
              "      <td>1.194432</td>\n",
              "      <td>1.156589</td>\n",
              "      <td>1.241038</td>\n",
              "      <td>1.224666</td>\n",
              "      <td>1.096950</td>\n",
              "      <td>1.196099</td>\n",
              "      <td>1.143495</td>\n",
              "      <td>1.153259</td>\n",
              "      <td>1.142155</td>\n",
              "      <td>1.184550</td>\n",
              "      <td>1.233270</td>\n",
              "      <td>1.261168</td>\n",
              "      <td>1.058254</td>\n",
              "      <td>1.175549</td>\n",
              "      <td>1.140278</td>\n",
              "      <td>1.085573</td>\n",
              "      <td>1.213219</td>\n",
              "      <td>1.178857</td>\n",
              "      <td>1.240433</td>\n",
              "      <td>1.221825</td>\n",
              "      <td>1.199255</td>\n",
              "      <td>1.149395</td>\n",
              "      <td>...</td>\n",
              "      <td>1.166261</td>\n",
              "      <td>1.223579</td>\n",
              "      <td>1.183960</td>\n",
              "      <td>1.156094</td>\n",
              "      <td>1.273979</td>\n",
              "      <td>1.254469</td>\n",
              "      <td>1.220472</td>\n",
              "      <td>1.265917</td>\n",
              "      <td>1.220980</td>\n",
              "      <td>1.229691</td>\n",
              "      <td>1.223691</td>\n",
              "      <td>1.149421</td>\n",
              "      <td>1.274404</td>\n",
              "      <td>1.186850</td>\n",
              "      <td>1.141265</td>\n",
              "      <td>1.103994</td>\n",
              "      <td>1.163800</td>\n",
              "      <td>1.108644</td>\n",
              "      <td>1.147498</td>\n",
              "      <td>1.130603</td>\n",
              "      <td>1.210496</td>\n",
              "      <td>1.255641</td>\n",
              "      <td>1.193401</td>\n",
              "      <td>1.101594</td>\n",
              "      <td>1.231972</td>\n",
              "      <td>1.238052</td>\n",
              "      <td>1.253018</td>\n",
              "      <td>1.078172</td>\n",
              "      <td>1.244361</td>\n",
              "      <td>1.220966</td>\n",
              "      <td>1.259896</td>\n",
              "      <td>1.267038</td>\n",
              "      <td>1.210528</td>\n",
              "      <td>1.207428</td>\n",
              "      <td>1.189874</td>\n",
              "      <td>1.149068</td>\n",
              "      <td>1.092033</td>\n",
              "      <td>1.119489</td>\n",
              "      <td>1.134648</td>\n",
              "      <td>1.242739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.366864</td>\n",
              "      <td>1.169779</td>\n",
              "      <td>1.198631</td>\n",
              "      <td>1.307396</td>\n",
              "      <td>1.224856</td>\n",
              "      <td>1.279887</td>\n",
              "      <td>1.173073</td>\n",
              "      <td>1.178774</td>\n",
              "      <td>1.306439</td>\n",
              "      <td>1.273728</td>\n",
              "      <td>1.270337</td>\n",
              "      <td>1.370119</td>\n",
              "      <td>1.241489</td>\n",
              "      <td>1.243023</td>\n",
              "      <td>1.352678</td>\n",
              "      <td>1.315099</td>\n",
              "      <td>1.209998</td>\n",
              "      <td>1.317940</td>\n",
              "      <td>1.235593</td>\n",
              "      <td>1.191536</td>\n",
              "      <td>1.314927</td>\n",
              "      <td>1.270892</td>\n",
              "      <td>1.169984</td>\n",
              "      <td>1.285327</td>\n",
              "      <td>1.196757</td>\n",
              "      <td>1.216472</td>\n",
              "      <td>1.236964</td>\n",
              "      <td>1.222694</td>\n",
              "      <td>1.320738</td>\n",
              "      <td>1.352087</td>\n",
              "      <td>1.105927</td>\n",
              "      <td>1.212589</td>\n",
              "      <td>1.198550</td>\n",
              "      <td>1.139443</td>\n",
              "      <td>1.264057</td>\n",
              "      <td>1.224962</td>\n",
              "      <td>1.349521</td>\n",
              "      <td>1.282406</td>\n",
              "      <td>1.275052</td>\n",
              "      <td>1.216791</td>\n",
              "      <td>...</td>\n",
              "      <td>1.208878</td>\n",
              "      <td>1.293635</td>\n",
              "      <td>1.222590</td>\n",
              "      <td>1.228574</td>\n",
              "      <td>1.291061</td>\n",
              "      <td>1.304609</td>\n",
              "      <td>1.294303</td>\n",
              "      <td>1.308733</td>\n",
              "      <td>1.272877</td>\n",
              "      <td>1.211273</td>\n",
              "      <td>1.273798</td>\n",
              "      <td>1.221198</td>\n",
              "      <td>1.302945</td>\n",
              "      <td>1.196652</td>\n",
              "      <td>1.176506</td>\n",
              "      <td>1.155794</td>\n",
              "      <td>1.197688</td>\n",
              "      <td>1.086556</td>\n",
              "      <td>1.173920</td>\n",
              "      <td>1.172170</td>\n",
              "      <td>1.291111</td>\n",
              "      <td>1.293598</td>\n",
              "      <td>1.256632</td>\n",
              "      <td>1.163860</td>\n",
              "      <td>1.207528</td>\n",
              "      <td>1.254616</td>\n",
              "      <td>1.293296</td>\n",
              "      <td>1.101834</td>\n",
              "      <td>1.301377</td>\n",
              "      <td>1.269699</td>\n",
              "      <td>1.353710</td>\n",
              "      <td>1.314361</td>\n",
              "      <td>1.261687</td>\n",
              "      <td>1.249773</td>\n",
              "      <td>1.291845</td>\n",
              "      <td>1.195573</td>\n",
              "      <td>1.164096</td>\n",
              "      <td>1.161016</td>\n",
              "      <td>1.224749</td>\n",
              "      <td>1.289310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.329310</td>\n",
              "      <td>1.181041</td>\n",
              "      <td>1.167684</td>\n",
              "      <td>1.241564</td>\n",
              "      <td>1.142548</td>\n",
              "      <td>1.229880</td>\n",
              "      <td>1.143544</td>\n",
              "      <td>1.101485</td>\n",
              "      <td>1.207441</td>\n",
              "      <td>1.264979</td>\n",
              "      <td>1.194637</td>\n",
              "      <td>1.278807</td>\n",
              "      <td>1.233290</td>\n",
              "      <td>1.198820</td>\n",
              "      <td>1.273201</td>\n",
              "      <td>1.283649</td>\n",
              "      <td>1.220910</td>\n",
              "      <td>1.250398</td>\n",
              "      <td>1.191236</td>\n",
              "      <td>1.181810</td>\n",
              "      <td>1.309355</td>\n",
              "      <td>1.235784</td>\n",
              "      <td>1.168283</td>\n",
              "      <td>1.244176</td>\n",
              "      <td>1.204378</td>\n",
              "      <td>1.240948</td>\n",
              "      <td>1.191147</td>\n",
              "      <td>1.180547</td>\n",
              "      <td>1.277906</td>\n",
              "      <td>1.260639</td>\n",
              "      <td>1.084857</td>\n",
              "      <td>1.257480</td>\n",
              "      <td>1.110626</td>\n",
              "      <td>1.099000</td>\n",
              "      <td>1.229652</td>\n",
              "      <td>1.186714</td>\n",
              "      <td>1.333432</td>\n",
              "      <td>1.272419</td>\n",
              "      <td>1.170872</td>\n",
              "      <td>1.136378</td>\n",
              "      <td>...</td>\n",
              "      <td>1.194533</td>\n",
              "      <td>1.237542</td>\n",
              "      <td>1.168100</td>\n",
              "      <td>1.184326</td>\n",
              "      <td>1.294242</td>\n",
              "      <td>1.292353</td>\n",
              "      <td>1.222468</td>\n",
              "      <td>1.251635</td>\n",
              "      <td>1.241282</td>\n",
              "      <td>1.225189</td>\n",
              "      <td>1.179232</td>\n",
              "      <td>1.191870</td>\n",
              "      <td>1.280598</td>\n",
              "      <td>1.173245</td>\n",
              "      <td>1.180964</td>\n",
              "      <td>1.166436</td>\n",
              "      <td>1.179450</td>\n",
              "      <td>1.090128</td>\n",
              "      <td>1.187284</td>\n",
              "      <td>1.175694</td>\n",
              "      <td>1.220266</td>\n",
              "      <td>1.261718</td>\n",
              "      <td>1.210505</td>\n",
              "      <td>1.163747</td>\n",
              "      <td>1.208758</td>\n",
              "      <td>1.185177</td>\n",
              "      <td>1.252824</td>\n",
              "      <td>1.120215</td>\n",
              "      <td>1.278781</td>\n",
              "      <td>1.285496</td>\n",
              "      <td>1.326240</td>\n",
              "      <td>1.304006</td>\n",
              "      <td>1.195950</td>\n",
              "      <td>1.172507</td>\n",
              "      <td>1.202718</td>\n",
              "      <td>1.192876</td>\n",
              "      <td>1.143127</td>\n",
              "      <td>1.178923</td>\n",
              "      <td>1.151727</td>\n",
              "      <td>1.258866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.285454</td>\n",
              "      <td>1.166745</td>\n",
              "      <td>1.124959</td>\n",
              "      <td>1.274007</td>\n",
              "      <td>1.150614</td>\n",
              "      <td>1.217064</td>\n",
              "      <td>1.141791</td>\n",
              "      <td>1.098535</td>\n",
              "      <td>1.208206</td>\n",
              "      <td>1.254137</td>\n",
              "      <td>1.209977</td>\n",
              "      <td>1.318646</td>\n",
              "      <td>1.180807</td>\n",
              "      <td>1.209292</td>\n",
              "      <td>1.310155</td>\n",
              "      <td>1.287302</td>\n",
              "      <td>1.148256</td>\n",
              "      <td>1.240628</td>\n",
              "      <td>1.183448</td>\n",
              "      <td>1.109997</td>\n",
              "      <td>1.248156</td>\n",
              "      <td>1.218959</td>\n",
              "      <td>1.173167</td>\n",
              "      <td>1.242317</td>\n",
              "      <td>1.151035</td>\n",
              "      <td>1.203702</td>\n",
              "      <td>1.172203</td>\n",
              "      <td>1.172990</td>\n",
              "      <td>1.302207</td>\n",
              "      <td>1.273484</td>\n",
              "      <td>1.068389</td>\n",
              "      <td>1.223353</td>\n",
              "      <td>1.141722</td>\n",
              "      <td>1.124560</td>\n",
              "      <td>1.203342</td>\n",
              "      <td>1.152227</td>\n",
              "      <td>1.295139</td>\n",
              "      <td>1.234600</td>\n",
              "      <td>1.173619</td>\n",
              "      <td>1.175376</td>\n",
              "      <td>...</td>\n",
              "      <td>1.180207</td>\n",
              "      <td>1.220034</td>\n",
              "      <td>1.161146</td>\n",
              "      <td>1.158836</td>\n",
              "      <td>1.211117</td>\n",
              "      <td>1.238383</td>\n",
              "      <td>1.218625</td>\n",
              "      <td>1.259559</td>\n",
              "      <td>1.186143</td>\n",
              "      <td>1.167219</td>\n",
              "      <td>1.193230</td>\n",
              "      <td>1.186719</td>\n",
              "      <td>1.253057</td>\n",
              "      <td>1.171997</td>\n",
              "      <td>1.132582</td>\n",
              "      <td>1.098605</td>\n",
              "      <td>1.125008</td>\n",
              "      <td>1.083232</td>\n",
              "      <td>1.128017</td>\n",
              "      <td>1.166911</td>\n",
              "      <td>1.234400</td>\n",
              "      <td>1.260356</td>\n",
              "      <td>1.210716</td>\n",
              "      <td>1.079162</td>\n",
              "      <td>1.205614</td>\n",
              "      <td>1.137698</td>\n",
              "      <td>1.281618</td>\n",
              "      <td>1.054016</td>\n",
              "      <td>1.303092</td>\n",
              "      <td>1.224458</td>\n",
              "      <td>1.306099</td>\n",
              "      <td>1.237522</td>\n",
              "      <td>1.196378</td>\n",
              "      <td>1.165671</td>\n",
              "      <td>1.194251</td>\n",
              "      <td>1.198773</td>\n",
              "      <td>1.105454</td>\n",
              "      <td>1.106809</td>\n",
              "      <td>1.151457</td>\n",
              "      <td>1.252445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.302743</td>\n",
              "      <td>1.187342</td>\n",
              "      <td>1.132481</td>\n",
              "      <td>1.284718</td>\n",
              "      <td>1.158201</td>\n",
              "      <td>1.225252</td>\n",
              "      <td>1.165443</td>\n",
              "      <td>1.070200</td>\n",
              "      <td>1.143733</td>\n",
              "      <td>1.251778</td>\n",
              "      <td>1.196060</td>\n",
              "      <td>1.294261</td>\n",
              "      <td>1.186139</td>\n",
              "      <td>1.208508</td>\n",
              "      <td>1.312217</td>\n",
              "      <td>1.258152</td>\n",
              "      <td>1.206250</td>\n",
              "      <td>1.199007</td>\n",
              "      <td>1.173769</td>\n",
              "      <td>1.122256</td>\n",
              "      <td>1.257588</td>\n",
              "      <td>1.241879</td>\n",
              "      <td>1.086644</td>\n",
              "      <td>1.249860</td>\n",
              "      <td>1.168296</td>\n",
              "      <td>1.195592</td>\n",
              "      <td>1.205566</td>\n",
              "      <td>1.205725</td>\n",
              "      <td>1.290261</td>\n",
              "      <td>1.257262</td>\n",
              "      <td>1.029428</td>\n",
              "      <td>1.285901</td>\n",
              "      <td>1.088705</td>\n",
              "      <td>1.144854</td>\n",
              "      <td>1.237754</td>\n",
              "      <td>1.141155</td>\n",
              "      <td>1.306091</td>\n",
              "      <td>1.228469</td>\n",
              "      <td>1.146040</td>\n",
              "      <td>1.166446</td>\n",
              "      <td>...</td>\n",
              "      <td>1.156057</td>\n",
              "      <td>1.205066</td>\n",
              "      <td>1.191464</td>\n",
              "      <td>1.146045</td>\n",
              "      <td>1.248221</td>\n",
              "      <td>1.250634</td>\n",
              "      <td>1.140499</td>\n",
              "      <td>1.273021</td>\n",
              "      <td>1.199648</td>\n",
              "      <td>1.231133</td>\n",
              "      <td>1.202052</td>\n",
              "      <td>1.181661</td>\n",
              "      <td>1.226832</td>\n",
              "      <td>1.189675</td>\n",
              "      <td>1.158190</td>\n",
              "      <td>1.081136</td>\n",
              "      <td>1.121633</td>\n",
              "      <td>1.128868</td>\n",
              "      <td>1.176809</td>\n",
              "      <td>1.217725</td>\n",
              "      <td>1.234118</td>\n",
              "      <td>1.223701</td>\n",
              "      <td>1.203920</td>\n",
              "      <td>1.100417</td>\n",
              "      <td>1.215707</td>\n",
              "      <td>1.122318</td>\n",
              "      <td>1.263235</td>\n",
              "      <td>1.064600</td>\n",
              "      <td>1.304201</td>\n",
              "      <td>1.176788</td>\n",
              "      <td>1.279100</td>\n",
              "      <td>1.275166</td>\n",
              "      <td>1.171375</td>\n",
              "      <td>1.173712</td>\n",
              "      <td>1.104654</td>\n",
              "      <td>1.205126</td>\n",
              "      <td>1.162174</td>\n",
              "      <td>1.118234</td>\n",
              "      <td>1.134196</td>\n",
              "      <td>1.218161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.312949</td>\n",
              "      <td>1.152707</td>\n",
              "      <td>1.173616</td>\n",
              "      <td>1.230052</td>\n",
              "      <td>1.122915</td>\n",
              "      <td>1.198203</td>\n",
              "      <td>1.136683</td>\n",
              "      <td>1.123859</td>\n",
              "      <td>1.177624</td>\n",
              "      <td>1.231871</td>\n",
              "      <td>1.200690</td>\n",
              "      <td>1.294047</td>\n",
              "      <td>1.202878</td>\n",
              "      <td>1.184310</td>\n",
              "      <td>1.285229</td>\n",
              "      <td>1.263213</td>\n",
              "      <td>1.179320</td>\n",
              "      <td>1.215601</td>\n",
              "      <td>1.175799</td>\n",
              "      <td>1.178383</td>\n",
              "      <td>1.281241</td>\n",
              "      <td>1.214205</td>\n",
              "      <td>1.116455</td>\n",
              "      <td>1.217956</td>\n",
              "      <td>1.172074</td>\n",
              "      <td>1.194553</td>\n",
              "      <td>1.173418</td>\n",
              "      <td>1.175351</td>\n",
              "      <td>1.277497</td>\n",
              "      <td>1.282899</td>\n",
              "      <td>1.066393</td>\n",
              "      <td>1.211414</td>\n",
              "      <td>1.105075</td>\n",
              "      <td>1.090448</td>\n",
              "      <td>1.223337</td>\n",
              "      <td>1.179316</td>\n",
              "      <td>1.301328</td>\n",
              "      <td>1.235772</td>\n",
              "      <td>1.203604</td>\n",
              "      <td>1.147218</td>\n",
              "      <td>...</td>\n",
              "      <td>1.180854</td>\n",
              "      <td>1.232822</td>\n",
              "      <td>1.158216</td>\n",
              "      <td>1.176195</td>\n",
              "      <td>1.276887</td>\n",
              "      <td>1.261518</td>\n",
              "      <td>1.206230</td>\n",
              "      <td>1.237822</td>\n",
              "      <td>1.241415</td>\n",
              "      <td>1.211055</td>\n",
              "      <td>1.221822</td>\n",
              "      <td>1.138976</td>\n",
              "      <td>1.260928</td>\n",
              "      <td>1.163510</td>\n",
              "      <td>1.188803</td>\n",
              "      <td>1.118895</td>\n",
              "      <td>1.176214</td>\n",
              "      <td>1.070720</td>\n",
              "      <td>1.163067</td>\n",
              "      <td>1.181331</td>\n",
              "      <td>1.259237</td>\n",
              "      <td>1.248983</td>\n",
              "      <td>1.177200</td>\n",
              "      <td>1.145400</td>\n",
              "      <td>1.202927</td>\n",
              "      <td>1.172433</td>\n",
              "      <td>1.216428</td>\n",
              "      <td>1.108672</td>\n",
              "      <td>1.248153</td>\n",
              "      <td>1.221787</td>\n",
              "      <td>1.274739</td>\n",
              "      <td>1.259793</td>\n",
              "      <td>1.199676</td>\n",
              "      <td>1.187201</td>\n",
              "      <td>1.170950</td>\n",
              "      <td>1.131944</td>\n",
              "      <td>1.115962</td>\n",
              "      <td>1.149290</td>\n",
              "      <td>1.141987</td>\n",
              "      <td>1.261891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.272042</td>\n",
              "      <td>1.161499</td>\n",
              "      <td>1.105000</td>\n",
              "      <td>1.208269</td>\n",
              "      <td>1.121041</td>\n",
              "      <td>1.194464</td>\n",
              "      <td>1.124770</td>\n",
              "      <td>1.059695</td>\n",
              "      <td>1.179548</td>\n",
              "      <td>1.207051</td>\n",
              "      <td>1.167701</td>\n",
              "      <td>1.267485</td>\n",
              "      <td>1.167606</td>\n",
              "      <td>1.179757</td>\n",
              "      <td>1.275391</td>\n",
              "      <td>1.243271</td>\n",
              "      <td>1.155570</td>\n",
              "      <td>1.195873</td>\n",
              "      <td>1.122752</td>\n",
              "      <td>1.107901</td>\n",
              "      <td>1.247378</td>\n",
              "      <td>1.189238</td>\n",
              "      <td>1.106392</td>\n",
              "      <td>1.215609</td>\n",
              "      <td>1.148882</td>\n",
              "      <td>1.196050</td>\n",
              "      <td>1.162335</td>\n",
              "      <td>1.165663</td>\n",
              "      <td>1.231344</td>\n",
              "      <td>1.209415</td>\n",
              "      <td>1.043097</td>\n",
              "      <td>1.235725</td>\n",
              "      <td>1.105240</td>\n",
              "      <td>1.091018</td>\n",
              "      <td>1.183066</td>\n",
              "      <td>1.125704</td>\n",
              "      <td>1.281685</td>\n",
              "      <td>1.219738</td>\n",
              "      <td>1.136538</td>\n",
              "      <td>1.135447</td>\n",
              "      <td>...</td>\n",
              "      <td>1.129269</td>\n",
              "      <td>1.185239</td>\n",
              "      <td>1.146817</td>\n",
              "      <td>1.141200</td>\n",
              "      <td>1.225513</td>\n",
              "      <td>1.228177</td>\n",
              "      <td>1.165154</td>\n",
              "      <td>1.235542</td>\n",
              "      <td>1.200130</td>\n",
              "      <td>1.172702</td>\n",
              "      <td>1.170003</td>\n",
              "      <td>1.181468</td>\n",
              "      <td>1.209325</td>\n",
              "      <td>1.151763</td>\n",
              "      <td>1.126986</td>\n",
              "      <td>1.084336</td>\n",
              "      <td>1.105327</td>\n",
              "      <td>1.054265</td>\n",
              "      <td>1.131519</td>\n",
              "      <td>1.151902</td>\n",
              "      <td>1.210007</td>\n",
              "      <td>1.216188</td>\n",
              "      <td>1.202237</td>\n",
              "      <td>1.089815</td>\n",
              "      <td>1.198748</td>\n",
              "      <td>1.133165</td>\n",
              "      <td>1.238947</td>\n",
              "      <td>1.069440</td>\n",
              "      <td>1.264443</td>\n",
              "      <td>1.187663</td>\n",
              "      <td>1.254554</td>\n",
              "      <td>1.276242</td>\n",
              "      <td>1.160143</td>\n",
              "      <td>1.150916</td>\n",
              "      <td>1.156392</td>\n",
              "      <td>1.165118</td>\n",
              "      <td>1.115274</td>\n",
              "      <td>1.120895</td>\n",
              "      <td>1.107053</td>\n",
              "      <td>1.216963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.245005</td>\n",
              "      <td>1.095031</td>\n",
              "      <td>1.066996</td>\n",
              "      <td>1.223554</td>\n",
              "      <td>1.092505</td>\n",
              "      <td>1.193291</td>\n",
              "      <td>1.086480</td>\n",
              "      <td>1.061774</td>\n",
              "      <td>1.147933</td>\n",
              "      <td>1.162082</td>\n",
              "      <td>1.155488</td>\n",
              "      <td>1.261850</td>\n",
              "      <td>1.143899</td>\n",
              "      <td>1.146771</td>\n",
              "      <td>1.255115</td>\n",
              "      <td>1.207932</td>\n",
              "      <td>1.140553</td>\n",
              "      <td>1.183877</td>\n",
              "      <td>1.116593</td>\n",
              "      <td>1.077793</td>\n",
              "      <td>1.204877</td>\n",
              "      <td>1.176257</td>\n",
              "      <td>1.066314</td>\n",
              "      <td>1.169149</td>\n",
              "      <td>1.108769</td>\n",
              "      <td>1.108564</td>\n",
              "      <td>1.128189</td>\n",
              "      <td>1.142654</td>\n",
              "      <td>1.215107</td>\n",
              "      <td>1.200090</td>\n",
              "      <td>1.032804</td>\n",
              "      <td>1.149380</td>\n",
              "      <td>1.079056</td>\n",
              "      <td>1.071849</td>\n",
              "      <td>1.164294</td>\n",
              "      <td>1.103029</td>\n",
              "      <td>1.244072</td>\n",
              "      <td>1.177700</td>\n",
              "      <td>1.141413</td>\n",
              "      <td>1.114361</td>\n",
              "      <td>...</td>\n",
              "      <td>1.117163</td>\n",
              "      <td>1.151419</td>\n",
              "      <td>1.137154</td>\n",
              "      <td>1.100498</td>\n",
              "      <td>1.165041</td>\n",
              "      <td>1.180051</td>\n",
              "      <td>1.159889</td>\n",
              "      <td>1.195666</td>\n",
              "      <td>1.149879</td>\n",
              "      <td>1.132466</td>\n",
              "      <td>1.162562</td>\n",
              "      <td>1.116954</td>\n",
              "      <td>1.184695</td>\n",
              "      <td>1.106499</td>\n",
              "      <td>1.096013</td>\n",
              "      <td>1.039718</td>\n",
              "      <td>1.080715</td>\n",
              "      <td>1.026545</td>\n",
              "      <td>1.113891</td>\n",
              "      <td>1.115812</td>\n",
              "      <td>1.181763</td>\n",
              "      <td>1.184286</td>\n",
              "      <td>1.137551</td>\n",
              "      <td>1.046796</td>\n",
              "      <td>1.147440</td>\n",
              "      <td>1.127926</td>\n",
              "      <td>1.213161</td>\n",
              "      <td>1.029929</td>\n",
              "      <td>1.220058</td>\n",
              "      <td>1.163651</td>\n",
              "      <td>1.239461</td>\n",
              "      <td>1.218801</td>\n",
              "      <td>1.146123</td>\n",
              "      <td>1.142094</td>\n",
              "      <td>1.126157</td>\n",
              "      <td>1.142661</td>\n",
              "      <td>1.070654</td>\n",
              "      <td>1.082994</td>\n",
              "      <td>1.092018</td>\n",
              "      <td>1.176787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.377602</td>\n",
              "      <td>1.192639</td>\n",
              "      <td>1.159087</td>\n",
              "      <td>1.349648</td>\n",
              "      <td>1.162806</td>\n",
              "      <td>1.296877</td>\n",
              "      <td>1.144672</td>\n",
              "      <td>1.077177</td>\n",
              "      <td>1.165043</td>\n",
              "      <td>1.263292</td>\n",
              "      <td>1.227904</td>\n",
              "      <td>1.372473</td>\n",
              "      <td>1.190848</td>\n",
              "      <td>1.244898</td>\n",
              "      <td>1.310316</td>\n",
              "      <td>1.305556</td>\n",
              "      <td>1.284850</td>\n",
              "      <td>1.246700</td>\n",
              "      <td>1.217089</td>\n",
              "      <td>1.176630</td>\n",
              "      <td>1.347770</td>\n",
              "      <td>1.262972</td>\n",
              "      <td>1.149566</td>\n",
              "      <td>1.273995</td>\n",
              "      <td>1.235876</td>\n",
              "      <td>1.200477</td>\n",
              "      <td>1.233350</td>\n",
              "      <td>1.209856</td>\n",
              "      <td>1.335611</td>\n",
              "      <td>1.322443</td>\n",
              "      <td>1.078280</td>\n",
              "      <td>1.282241</td>\n",
              "      <td>1.099767</td>\n",
              "      <td>1.189579</td>\n",
              "      <td>1.255586</td>\n",
              "      <td>1.222229</td>\n",
              "      <td>1.332308</td>\n",
              "      <td>1.295802</td>\n",
              "      <td>1.191689</td>\n",
              "      <td>1.158546</td>\n",
              "      <td>...</td>\n",
              "      <td>1.205154</td>\n",
              "      <td>1.220090</td>\n",
              "      <td>1.193041</td>\n",
              "      <td>1.200653</td>\n",
              "      <td>1.292048</td>\n",
              "      <td>1.275637</td>\n",
              "      <td>1.166908</td>\n",
              "      <td>1.276114</td>\n",
              "      <td>1.275403</td>\n",
              "      <td>1.245753</td>\n",
              "      <td>1.226302</td>\n",
              "      <td>1.219027</td>\n",
              "      <td>1.273993</td>\n",
              "      <td>1.209785</td>\n",
              "      <td>1.178717</td>\n",
              "      <td>1.154198</td>\n",
              "      <td>1.167725</td>\n",
              "      <td>1.167801</td>\n",
              "      <td>1.238903</td>\n",
              "      <td>1.235727</td>\n",
              "      <td>1.232981</td>\n",
              "      <td>1.258385</td>\n",
              "      <td>1.254689</td>\n",
              "      <td>1.113910</td>\n",
              "      <td>1.233173</td>\n",
              "      <td>1.180340</td>\n",
              "      <td>1.299005</td>\n",
              "      <td>1.112757</td>\n",
              "      <td>1.377053</td>\n",
              "      <td>1.290832</td>\n",
              "      <td>1.314692</td>\n",
              "      <td>1.326672</td>\n",
              "      <td>1.177432</td>\n",
              "      <td>1.153992</td>\n",
              "      <td>1.156601</td>\n",
              "      <td>1.264157</td>\n",
              "      <td>1.217663</td>\n",
              "      <td>1.173379</td>\n",
              "      <td>1.205707</td>\n",
              "      <td>1.297691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       217       218       219\n",
              "0  1.297256  1.189361  1.132536  ...  1.117755  1.139819  1.260445\n",
              "1  1.327115  1.142003  1.163430  ...  1.119489  1.134648  1.242739\n",
              "2  1.366864  1.169779  1.198631  ...  1.161016  1.224749  1.289310\n",
              "3  1.329310  1.181041  1.167684  ...  1.178923  1.151727  1.258866\n",
              "4  1.285454  1.166745  1.124959  ...  1.106809  1.151457  1.252445\n",
              "5  1.302743  1.187342  1.132481  ...  1.118234  1.134196  1.218161\n",
              "6  1.312949  1.152707  1.173616  ...  1.149290  1.141987  1.261891\n",
              "7  1.272042  1.161499  1.105000  ...  1.120895  1.107053  1.216963\n",
              "8  1.245005  1.095031  1.066996  ...  1.082994  1.092018  1.176787\n",
              "9  1.377602  1.192639  1.159087  ...  1.173379  1.205707  1.297691\n",
              "\n",
              "[10 rows x 220 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBitr2f3LVcS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "3b1dc2b4-1e25-45df-89c2-2c3b974634b2"
      },
      "source": [
        "test_predictions * train_y_test_y_stats['std'] + train_y_test_y_stats['mean']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.628733</td>\n",
              "      <td>2.308827</td>\n",
              "      <td>2.281555</td>\n",
              "      <td>2.619576</td>\n",
              "      <td>2.290637</td>\n",
              "      <td>2.387015</td>\n",
              "      <td>2.269662</td>\n",
              "      <td>2.280428</td>\n",
              "      <td>2.550808</td>\n",
              "      <td>2.413184</td>\n",
              "      <td>2.429984</td>\n",
              "      <td>2.587444</td>\n",
              "      <td>2.400849</td>\n",
              "      <td>2.378126</td>\n",
              "      <td>2.565844</td>\n",
              "      <td>2.525153</td>\n",
              "      <td>2.369223</td>\n",
              "      <td>2.509301</td>\n",
              "      <td>2.348417</td>\n",
              "      <td>2.332151</td>\n",
              "      <td>2.500804</td>\n",
              "      <td>2.452207</td>\n",
              "      <td>2.199232</td>\n",
              "      <td>2.418787</td>\n",
              "      <td>2.350722</td>\n",
              "      <td>2.319492</td>\n",
              "      <td>2.308131</td>\n",
              "      <td>2.337476</td>\n",
              "      <td>2.551229</td>\n",
              "      <td>2.612617</td>\n",
              "      <td>2.125126</td>\n",
              "      <td>2.360901</td>\n",
              "      <td>2.253608</td>\n",
              "      <td>2.122853</td>\n",
              "      <td>2.476902</td>\n",
              "      <td>2.268956</td>\n",
              "      <td>2.558829</td>\n",
              "      <td>2.428721</td>\n",
              "      <td>2.400394</td>\n",
              "      <td>2.312306</td>\n",
              "      <td>...</td>\n",
              "      <td>2.418033</td>\n",
              "      <td>2.435334</td>\n",
              "      <td>2.373111</td>\n",
              "      <td>2.464767</td>\n",
              "      <td>2.441807</td>\n",
              "      <td>2.508824</td>\n",
              "      <td>2.377651</td>\n",
              "      <td>2.488770</td>\n",
              "      <td>2.401070</td>\n",
              "      <td>2.415385</td>\n",
              "      <td>2.357364</td>\n",
              "      <td>2.370675</td>\n",
              "      <td>2.508624</td>\n",
              "      <td>2.351369</td>\n",
              "      <td>2.279599</td>\n",
              "      <td>2.209681</td>\n",
              "      <td>2.250709</td>\n",
              "      <td>2.159618</td>\n",
              "      <td>2.214695</td>\n",
              "      <td>2.345911</td>\n",
              "      <td>2.452912</td>\n",
              "      <td>2.461107</td>\n",
              "      <td>2.439569</td>\n",
              "      <td>2.189150</td>\n",
              "      <td>2.434983</td>\n",
              "      <td>2.254537</td>\n",
              "      <td>2.519381</td>\n",
              "      <td>2.185282</td>\n",
              "      <td>2.500601</td>\n",
              "      <td>2.427163</td>\n",
              "      <td>2.607009</td>\n",
              "      <td>2.562439</td>\n",
              "      <td>2.502143</td>\n",
              "      <td>2.331126</td>\n",
              "      <td>2.368241</td>\n",
              "      <td>2.323990</td>\n",
              "      <td>2.215729</td>\n",
              "      <td>2.201903</td>\n",
              "      <td>2.321458</td>\n",
              "      <td>2.430239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.688621</td>\n",
              "      <td>2.327542</td>\n",
              "      <td>2.287974</td>\n",
              "      <td>2.595419</td>\n",
              "      <td>2.352269</td>\n",
              "      <td>2.388644</td>\n",
              "      <td>2.266447</td>\n",
              "      <td>2.276934</td>\n",
              "      <td>2.606352</td>\n",
              "      <td>2.473355</td>\n",
              "      <td>2.425833</td>\n",
              "      <td>2.650512</td>\n",
              "      <td>2.357382</td>\n",
              "      <td>2.440268</td>\n",
              "      <td>2.582072</td>\n",
              "      <td>2.522901</td>\n",
              "      <td>2.417977</td>\n",
              "      <td>2.573590</td>\n",
              "      <td>2.366508</td>\n",
              "      <td>2.329349</td>\n",
              "      <td>2.526825</td>\n",
              "      <td>2.499411</td>\n",
              "      <td>2.251157</td>\n",
              "      <td>2.453767</td>\n",
              "      <td>2.371553</td>\n",
              "      <td>2.344712</td>\n",
              "      <td>2.305493</td>\n",
              "      <td>2.372750</td>\n",
              "      <td>2.616004</td>\n",
              "      <td>2.603236</td>\n",
              "      <td>2.191947</td>\n",
              "      <td>2.421958</td>\n",
              "      <td>2.257647</td>\n",
              "      <td>2.140655</td>\n",
              "      <td>2.470683</td>\n",
              "      <td>2.338836</td>\n",
              "      <td>2.567429</td>\n",
              "      <td>2.478099</td>\n",
              "      <td>2.475107</td>\n",
              "      <td>2.316432</td>\n",
              "      <td>...</td>\n",
              "      <td>2.455583</td>\n",
              "      <td>2.482214</td>\n",
              "      <td>2.362702</td>\n",
              "      <td>2.451276</td>\n",
              "      <td>2.508717</td>\n",
              "      <td>2.531386</td>\n",
              "      <td>2.433935</td>\n",
              "      <td>2.539505</td>\n",
              "      <td>2.378102</td>\n",
              "      <td>2.408430</td>\n",
              "      <td>2.439497</td>\n",
              "      <td>2.414135</td>\n",
              "      <td>2.500997</td>\n",
              "      <td>2.384116</td>\n",
              "      <td>2.265472</td>\n",
              "      <td>2.274704</td>\n",
              "      <td>2.236005</td>\n",
              "      <td>2.172168</td>\n",
              "      <td>2.298446</td>\n",
              "      <td>2.323144</td>\n",
              "      <td>2.519212</td>\n",
              "      <td>2.486149</td>\n",
              "      <td>2.443498</td>\n",
              "      <td>2.250358</td>\n",
              "      <td>2.410727</td>\n",
              "      <td>2.317104</td>\n",
              "      <td>2.519462</td>\n",
              "      <td>2.232438</td>\n",
              "      <td>2.480605</td>\n",
              "      <td>2.374739</td>\n",
              "      <td>2.574420</td>\n",
              "      <td>2.593884</td>\n",
              "      <td>2.537404</td>\n",
              "      <td>2.364128</td>\n",
              "      <td>2.397650</td>\n",
              "      <td>2.305927</td>\n",
              "      <td>2.243525</td>\n",
              "      <td>2.269905</td>\n",
              "      <td>2.407200</td>\n",
              "      <td>2.488512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.681221</td>\n",
              "      <td>2.362780</td>\n",
              "      <td>2.307868</td>\n",
              "      <td>2.650259</td>\n",
              "      <td>2.327815</td>\n",
              "      <td>2.437772</td>\n",
              "      <td>2.314506</td>\n",
              "      <td>2.325528</td>\n",
              "      <td>2.585402</td>\n",
              "      <td>2.434379</td>\n",
              "      <td>2.447038</td>\n",
              "      <td>2.661682</td>\n",
              "      <td>2.422856</td>\n",
              "      <td>2.449665</td>\n",
              "      <td>2.567882</td>\n",
              "      <td>2.534542</td>\n",
              "      <td>2.418365</td>\n",
              "      <td>2.558234</td>\n",
              "      <td>2.391165</td>\n",
              "      <td>2.360056</td>\n",
              "      <td>2.514274</td>\n",
              "      <td>2.492912</td>\n",
              "      <td>2.213658</td>\n",
              "      <td>2.475950</td>\n",
              "      <td>2.421412</td>\n",
              "      <td>2.333884</td>\n",
              "      <td>2.353368</td>\n",
              "      <td>2.384061</td>\n",
              "      <td>2.629268</td>\n",
              "      <td>2.627203</td>\n",
              "      <td>2.192982</td>\n",
              "      <td>2.406244</td>\n",
              "      <td>2.271990</td>\n",
              "      <td>2.172765</td>\n",
              "      <td>2.536330</td>\n",
              "      <td>2.332006</td>\n",
              "      <td>2.611233</td>\n",
              "      <td>2.433477</td>\n",
              "      <td>2.437378</td>\n",
              "      <td>2.321816</td>\n",
              "      <td>...</td>\n",
              "      <td>2.485378</td>\n",
              "      <td>2.483913</td>\n",
              "      <td>2.396026</td>\n",
              "      <td>2.499976</td>\n",
              "      <td>2.496846</td>\n",
              "      <td>2.552048</td>\n",
              "      <td>2.402235</td>\n",
              "      <td>2.545511</td>\n",
              "      <td>2.419465</td>\n",
              "      <td>2.448797</td>\n",
              "      <td>2.411865</td>\n",
              "      <td>2.385369</td>\n",
              "      <td>2.528933</td>\n",
              "      <td>2.354372</td>\n",
              "      <td>2.291564</td>\n",
              "      <td>2.253263</td>\n",
              "      <td>2.302175</td>\n",
              "      <td>2.216849</td>\n",
              "      <td>2.245082</td>\n",
              "      <td>2.367999</td>\n",
              "      <td>2.530126</td>\n",
              "      <td>2.516567</td>\n",
              "      <td>2.429734</td>\n",
              "      <td>2.253857</td>\n",
              "      <td>2.449277</td>\n",
              "      <td>2.289021</td>\n",
              "      <td>2.547288</td>\n",
              "      <td>2.235298</td>\n",
              "      <td>2.539273</td>\n",
              "      <td>2.436055</td>\n",
              "      <td>2.664647</td>\n",
              "      <td>2.605583</td>\n",
              "      <td>2.577544</td>\n",
              "      <td>2.385488</td>\n",
              "      <td>2.400878</td>\n",
              "      <td>2.368778</td>\n",
              "      <td>2.238636</td>\n",
              "      <td>2.213926</td>\n",
              "      <td>2.373105</td>\n",
              "      <td>2.466803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.731391</td>\n",
              "      <td>2.356005</td>\n",
              "      <td>2.324149</td>\n",
              "      <td>2.667740</td>\n",
              "      <td>2.358357</td>\n",
              "      <td>2.455835</td>\n",
              "      <td>2.324040</td>\n",
              "      <td>2.342363</td>\n",
              "      <td>2.577667</td>\n",
              "      <td>2.438117</td>\n",
              "      <td>2.476028</td>\n",
              "      <td>2.694395</td>\n",
              "      <td>2.418649</td>\n",
              "      <td>2.465576</td>\n",
              "      <td>2.533845</td>\n",
              "      <td>2.564945</td>\n",
              "      <td>2.443647</td>\n",
              "      <td>2.531897</td>\n",
              "      <td>2.415156</td>\n",
              "      <td>2.384091</td>\n",
              "      <td>2.548829</td>\n",
              "      <td>2.467165</td>\n",
              "      <td>2.242693</td>\n",
              "      <td>2.455238</td>\n",
              "      <td>2.396961</td>\n",
              "      <td>2.332330</td>\n",
              "      <td>2.351869</td>\n",
              "      <td>2.383345</td>\n",
              "      <td>2.610631</td>\n",
              "      <td>2.631703</td>\n",
              "      <td>2.229944</td>\n",
              "      <td>2.413333</td>\n",
              "      <td>2.250221</td>\n",
              "      <td>2.183137</td>\n",
              "      <td>2.574415</td>\n",
              "      <td>2.314832</td>\n",
              "      <td>2.612242</td>\n",
              "      <td>2.472943</td>\n",
              "      <td>2.464615</td>\n",
              "      <td>2.330389</td>\n",
              "      <td>...</td>\n",
              "      <td>2.474983</td>\n",
              "      <td>2.480676</td>\n",
              "      <td>2.401732</td>\n",
              "      <td>2.490711</td>\n",
              "      <td>2.500479</td>\n",
              "      <td>2.558294</td>\n",
              "      <td>2.409542</td>\n",
              "      <td>2.578413</td>\n",
              "      <td>2.392083</td>\n",
              "      <td>2.452992</td>\n",
              "      <td>2.442916</td>\n",
              "      <td>2.420330</td>\n",
              "      <td>2.511117</td>\n",
              "      <td>2.373852</td>\n",
              "      <td>2.330232</td>\n",
              "      <td>2.284878</td>\n",
              "      <td>2.263687</td>\n",
              "      <td>2.215357</td>\n",
              "      <td>2.266837</td>\n",
              "      <td>2.356448</td>\n",
              "      <td>2.524024</td>\n",
              "      <td>2.512902</td>\n",
              "      <td>2.454167</td>\n",
              "      <td>2.238013</td>\n",
              "      <td>2.428007</td>\n",
              "      <td>2.298153</td>\n",
              "      <td>2.539598</td>\n",
              "      <td>2.157871</td>\n",
              "      <td>2.524069</td>\n",
              "      <td>2.408281</td>\n",
              "      <td>2.625889</td>\n",
              "      <td>2.621409</td>\n",
              "      <td>2.578142</td>\n",
              "      <td>2.378295</td>\n",
              "      <td>2.394969</td>\n",
              "      <td>2.359993</td>\n",
              "      <td>2.247559</td>\n",
              "      <td>2.238639</td>\n",
              "      <td>2.412806</td>\n",
              "      <td>2.485888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.664892</td>\n",
              "      <td>2.320478</td>\n",
              "      <td>2.305416</td>\n",
              "      <td>2.611919</td>\n",
              "      <td>2.283757</td>\n",
              "      <td>2.402112</td>\n",
              "      <td>2.298400</td>\n",
              "      <td>2.276627</td>\n",
              "      <td>2.531204</td>\n",
              "      <td>2.409598</td>\n",
              "      <td>2.433290</td>\n",
              "      <td>2.600818</td>\n",
              "      <td>2.404902</td>\n",
              "      <td>2.427361</td>\n",
              "      <td>2.563756</td>\n",
              "      <td>2.515672</td>\n",
              "      <td>2.370514</td>\n",
              "      <td>2.506275</td>\n",
              "      <td>2.361457</td>\n",
              "      <td>2.310880</td>\n",
              "      <td>2.480618</td>\n",
              "      <td>2.449144</td>\n",
              "      <td>2.191924</td>\n",
              "      <td>2.418680</td>\n",
              "      <td>2.363302</td>\n",
              "      <td>2.305907</td>\n",
              "      <td>2.310084</td>\n",
              "      <td>2.358118</td>\n",
              "      <td>2.557789</td>\n",
              "      <td>2.597478</td>\n",
              "      <td>2.160092</td>\n",
              "      <td>2.367962</td>\n",
              "      <td>2.238756</td>\n",
              "      <td>2.135798</td>\n",
              "      <td>2.487470</td>\n",
              "      <td>2.286126</td>\n",
              "      <td>2.563347</td>\n",
              "      <td>2.425395</td>\n",
              "      <td>2.413856</td>\n",
              "      <td>2.298316</td>\n",
              "      <td>...</td>\n",
              "      <td>2.431139</td>\n",
              "      <td>2.447347</td>\n",
              "      <td>2.366244</td>\n",
              "      <td>2.462976</td>\n",
              "      <td>2.428822</td>\n",
              "      <td>2.518550</td>\n",
              "      <td>2.388343</td>\n",
              "      <td>2.498611</td>\n",
              "      <td>2.379842</td>\n",
              "      <td>2.410382</td>\n",
              "      <td>2.390763</td>\n",
              "      <td>2.355520</td>\n",
              "      <td>2.489175</td>\n",
              "      <td>2.329206</td>\n",
              "      <td>2.261226</td>\n",
              "      <td>2.230296</td>\n",
              "      <td>2.255379</td>\n",
              "      <td>2.195686</td>\n",
              "      <td>2.230423</td>\n",
              "      <td>2.354364</td>\n",
              "      <td>2.471234</td>\n",
              "      <td>2.480339</td>\n",
              "      <td>2.414530</td>\n",
              "      <td>2.214002</td>\n",
              "      <td>2.408349</td>\n",
              "      <td>2.254142</td>\n",
              "      <td>2.527125</td>\n",
              "      <td>2.188918</td>\n",
              "      <td>2.512064</td>\n",
              "      <td>2.417259</td>\n",
              "      <td>2.599769</td>\n",
              "      <td>2.569554</td>\n",
              "      <td>2.508104</td>\n",
              "      <td>2.325130</td>\n",
              "      <td>2.377856</td>\n",
              "      <td>2.340196</td>\n",
              "      <td>2.218839</td>\n",
              "      <td>2.211272</td>\n",
              "      <td>2.338783</td>\n",
              "      <td>2.438032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.639735</td>\n",
              "      <td>2.317055</td>\n",
              "      <td>2.302321</td>\n",
              "      <td>2.622239</td>\n",
              "      <td>2.298635</td>\n",
              "      <td>2.392957</td>\n",
              "      <td>2.273449</td>\n",
              "      <td>2.323811</td>\n",
              "      <td>2.525311</td>\n",
              "      <td>2.398386</td>\n",
              "      <td>2.448866</td>\n",
              "      <td>2.585497</td>\n",
              "      <td>2.407199</td>\n",
              "      <td>2.425073</td>\n",
              "      <td>2.606507</td>\n",
              "      <td>2.534373</td>\n",
              "      <td>2.383889</td>\n",
              "      <td>2.541100</td>\n",
              "      <td>2.347789</td>\n",
              "      <td>2.302148</td>\n",
              "      <td>2.510894</td>\n",
              "      <td>2.541412</td>\n",
              "      <td>2.231713</td>\n",
              "      <td>2.453932</td>\n",
              "      <td>2.373863</td>\n",
              "      <td>2.349997</td>\n",
              "      <td>2.316569</td>\n",
              "      <td>2.400376</td>\n",
              "      <td>2.581901</td>\n",
              "      <td>2.581204</td>\n",
              "      <td>2.127476</td>\n",
              "      <td>2.416077</td>\n",
              "      <td>2.304358</td>\n",
              "      <td>2.134857</td>\n",
              "      <td>2.468025</td>\n",
              "      <td>2.316912</td>\n",
              "      <td>2.595994</td>\n",
              "      <td>2.462182</td>\n",
              "      <td>2.435731</td>\n",
              "      <td>2.320461</td>\n",
              "      <td>...</td>\n",
              "      <td>2.435525</td>\n",
              "      <td>2.487414</td>\n",
              "      <td>2.388359</td>\n",
              "      <td>2.505295</td>\n",
              "      <td>2.465947</td>\n",
              "      <td>2.537507</td>\n",
              "      <td>2.397767</td>\n",
              "      <td>2.464769</td>\n",
              "      <td>2.410489</td>\n",
              "      <td>2.467981</td>\n",
              "      <td>2.420815</td>\n",
              "      <td>2.380174</td>\n",
              "      <td>2.491681</td>\n",
              "      <td>2.401989</td>\n",
              "      <td>2.291448</td>\n",
              "      <td>2.245397</td>\n",
              "      <td>2.286474</td>\n",
              "      <td>2.164872</td>\n",
              "      <td>2.248356</td>\n",
              "      <td>2.358002</td>\n",
              "      <td>2.483763</td>\n",
              "      <td>2.509187</td>\n",
              "      <td>2.452248</td>\n",
              "      <td>2.205246</td>\n",
              "      <td>2.442091</td>\n",
              "      <td>2.279219</td>\n",
              "      <td>2.512878</td>\n",
              "      <td>2.230914</td>\n",
              "      <td>2.539977</td>\n",
              "      <td>2.431489</td>\n",
              "      <td>2.579032</td>\n",
              "      <td>2.583972</td>\n",
              "      <td>2.534424</td>\n",
              "      <td>2.370871</td>\n",
              "      <td>2.396027</td>\n",
              "      <td>2.356696</td>\n",
              "      <td>2.277199</td>\n",
              "      <td>2.256001</td>\n",
              "      <td>2.382046</td>\n",
              "      <td>2.452692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.693933</td>\n",
              "      <td>2.325058</td>\n",
              "      <td>2.305252</td>\n",
              "      <td>2.626103</td>\n",
              "      <td>2.307819</td>\n",
              "      <td>2.406756</td>\n",
              "      <td>2.317334</td>\n",
              "      <td>2.295212</td>\n",
              "      <td>2.565705</td>\n",
              "      <td>2.446379</td>\n",
              "      <td>2.427427</td>\n",
              "      <td>2.616411</td>\n",
              "      <td>2.410523</td>\n",
              "      <td>2.401496</td>\n",
              "      <td>2.544093</td>\n",
              "      <td>2.525367</td>\n",
              "      <td>2.397446</td>\n",
              "      <td>2.529716</td>\n",
              "      <td>2.349498</td>\n",
              "      <td>2.364423</td>\n",
              "      <td>2.489083</td>\n",
              "      <td>2.463071</td>\n",
              "      <td>2.232035</td>\n",
              "      <td>2.435046</td>\n",
              "      <td>2.376403</td>\n",
              "      <td>2.318877</td>\n",
              "      <td>2.339039</td>\n",
              "      <td>2.375243</td>\n",
              "      <td>2.574953</td>\n",
              "      <td>2.629619</td>\n",
              "      <td>2.199202</td>\n",
              "      <td>2.383923</td>\n",
              "      <td>2.238214</td>\n",
              "      <td>2.149548</td>\n",
              "      <td>2.490688</td>\n",
              "      <td>2.299819</td>\n",
              "      <td>2.600949</td>\n",
              "      <td>2.433632</td>\n",
              "      <td>2.397446</td>\n",
              "      <td>2.314606</td>\n",
              "      <td>...</td>\n",
              "      <td>2.469366</td>\n",
              "      <td>2.470459</td>\n",
              "      <td>2.384240</td>\n",
              "      <td>2.471898</td>\n",
              "      <td>2.481369</td>\n",
              "      <td>2.507347</td>\n",
              "      <td>2.428987</td>\n",
              "      <td>2.524886</td>\n",
              "      <td>2.372645</td>\n",
              "      <td>2.438998</td>\n",
              "      <td>2.413595</td>\n",
              "      <td>2.386244</td>\n",
              "      <td>2.531328</td>\n",
              "      <td>2.340293</td>\n",
              "      <td>2.303746</td>\n",
              "      <td>2.261188</td>\n",
              "      <td>2.279646</td>\n",
              "      <td>2.167538</td>\n",
              "      <td>2.251159</td>\n",
              "      <td>2.315133</td>\n",
              "      <td>2.491263</td>\n",
              "      <td>2.504950</td>\n",
              "      <td>2.438565</td>\n",
              "      <td>2.232576</td>\n",
              "      <td>2.395410</td>\n",
              "      <td>2.245541</td>\n",
              "      <td>2.526970</td>\n",
              "      <td>2.158618</td>\n",
              "      <td>2.507912</td>\n",
              "      <td>2.404981</td>\n",
              "      <td>2.615475</td>\n",
              "      <td>2.579213</td>\n",
              "      <td>2.536266</td>\n",
              "      <td>2.380871</td>\n",
              "      <td>2.386730</td>\n",
              "      <td>2.337650</td>\n",
              "      <td>2.248416</td>\n",
              "      <td>2.232226</td>\n",
              "      <td>2.366100</td>\n",
              "      <td>2.482552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.651045</td>\n",
              "      <td>2.282344</td>\n",
              "      <td>2.287502</td>\n",
              "      <td>2.580246</td>\n",
              "      <td>2.288791</td>\n",
              "      <td>2.366195</td>\n",
              "      <td>2.266252</td>\n",
              "      <td>2.274518</td>\n",
              "      <td>2.540983</td>\n",
              "      <td>2.408945</td>\n",
              "      <td>2.428161</td>\n",
              "      <td>2.595615</td>\n",
              "      <td>2.380609</td>\n",
              "      <td>2.409137</td>\n",
              "      <td>2.561453</td>\n",
              "      <td>2.511296</td>\n",
              "      <td>2.351312</td>\n",
              "      <td>2.509626</td>\n",
              "      <td>2.354639</td>\n",
              "      <td>2.307070</td>\n",
              "      <td>2.486692</td>\n",
              "      <td>2.476223</td>\n",
              "      <td>2.201952</td>\n",
              "      <td>2.420922</td>\n",
              "      <td>2.341029</td>\n",
              "      <td>2.305369</td>\n",
              "      <td>2.301125</td>\n",
              "      <td>2.337557</td>\n",
              "      <td>2.545710</td>\n",
              "      <td>2.586149</td>\n",
              "      <td>2.154949</td>\n",
              "      <td>2.372856</td>\n",
              "      <td>2.241770</td>\n",
              "      <td>2.123743</td>\n",
              "      <td>2.447980</td>\n",
              "      <td>2.283077</td>\n",
              "      <td>2.560707</td>\n",
              "      <td>2.439927</td>\n",
              "      <td>2.416845</td>\n",
              "      <td>2.287903</td>\n",
              "      <td>...</td>\n",
              "      <td>2.397362</td>\n",
              "      <td>2.452360</td>\n",
              "      <td>2.344758</td>\n",
              "      <td>2.441683</td>\n",
              "      <td>2.433106</td>\n",
              "      <td>2.501659</td>\n",
              "      <td>2.403094</td>\n",
              "      <td>2.479644</td>\n",
              "      <td>2.382970</td>\n",
              "      <td>2.395834</td>\n",
              "      <td>2.405010</td>\n",
              "      <td>2.367781</td>\n",
              "      <td>2.478539</td>\n",
              "      <td>2.330229</td>\n",
              "      <td>2.277414</td>\n",
              "      <td>2.238420</td>\n",
              "      <td>2.232621</td>\n",
              "      <td>2.166054</td>\n",
              "      <td>2.244052</td>\n",
              "      <td>2.314632</td>\n",
              "      <td>2.457129</td>\n",
              "      <td>2.479737</td>\n",
              "      <td>2.419286</td>\n",
              "      <td>2.191889</td>\n",
              "      <td>2.393957</td>\n",
              "      <td>2.245881</td>\n",
              "      <td>2.512059</td>\n",
              "      <td>2.196070</td>\n",
              "      <td>2.493435</td>\n",
              "      <td>2.374002</td>\n",
              "      <td>2.547680</td>\n",
              "      <td>2.569074</td>\n",
              "      <td>2.501617</td>\n",
              "      <td>2.313068</td>\n",
              "      <td>2.377913</td>\n",
              "      <td>2.333770</td>\n",
              "      <td>2.239295</td>\n",
              "      <td>2.215763</td>\n",
              "      <td>2.367879</td>\n",
              "      <td>2.447322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.605788</td>\n",
              "      <td>2.278579</td>\n",
              "      <td>2.241837</td>\n",
              "      <td>2.565767</td>\n",
              "      <td>2.287902</td>\n",
              "      <td>2.353735</td>\n",
              "      <td>2.241373</td>\n",
              "      <td>2.239851</td>\n",
              "      <td>2.509410</td>\n",
              "      <td>2.397172</td>\n",
              "      <td>2.381341</td>\n",
              "      <td>2.573681</td>\n",
              "      <td>2.349527</td>\n",
              "      <td>2.357842</td>\n",
              "      <td>2.523156</td>\n",
              "      <td>2.488034</td>\n",
              "      <td>2.353868</td>\n",
              "      <td>2.497328</td>\n",
              "      <td>2.307749</td>\n",
              "      <td>2.283168</td>\n",
              "      <td>2.468245</td>\n",
              "      <td>2.423819</td>\n",
              "      <td>2.188546</td>\n",
              "      <td>2.397142</td>\n",
              "      <td>2.307926</td>\n",
              "      <td>2.287512</td>\n",
              "      <td>2.274276</td>\n",
              "      <td>2.309291</td>\n",
              "      <td>2.514840</td>\n",
              "      <td>2.567772</td>\n",
              "      <td>2.110024</td>\n",
              "      <td>2.337986</td>\n",
              "      <td>2.203098</td>\n",
              "      <td>2.100297</td>\n",
              "      <td>2.439166</td>\n",
              "      <td>2.261074</td>\n",
              "      <td>2.529406</td>\n",
              "      <td>2.412233</td>\n",
              "      <td>2.386598</td>\n",
              "      <td>2.276757</td>\n",
              "      <td>...</td>\n",
              "      <td>2.376387</td>\n",
              "      <td>2.407400</td>\n",
              "      <td>2.331784</td>\n",
              "      <td>2.417955</td>\n",
              "      <td>2.420333</td>\n",
              "      <td>2.477949</td>\n",
              "      <td>2.362639</td>\n",
              "      <td>2.467068</td>\n",
              "      <td>2.351375</td>\n",
              "      <td>2.377371</td>\n",
              "      <td>2.351963</td>\n",
              "      <td>2.347967</td>\n",
              "      <td>2.473979</td>\n",
              "      <td>2.327543</td>\n",
              "      <td>2.245626</td>\n",
              "      <td>2.199047</td>\n",
              "      <td>2.222196</td>\n",
              "      <td>2.128131</td>\n",
              "      <td>2.202982</td>\n",
              "      <td>2.298136</td>\n",
              "      <td>2.416329</td>\n",
              "      <td>2.424056</td>\n",
              "      <td>2.401894</td>\n",
              "      <td>2.167357</td>\n",
              "      <td>2.374169</td>\n",
              "      <td>2.233969</td>\n",
              "      <td>2.476960</td>\n",
              "      <td>2.164889</td>\n",
              "      <td>2.451635</td>\n",
              "      <td>2.353888</td>\n",
              "      <td>2.564833</td>\n",
              "      <td>2.524208</td>\n",
              "      <td>2.484733</td>\n",
              "      <td>2.296491</td>\n",
              "      <td>2.329283</td>\n",
              "      <td>2.273759</td>\n",
              "      <td>2.190300</td>\n",
              "      <td>2.188632</td>\n",
              "      <td>2.315411</td>\n",
              "      <td>2.425982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.668904</td>\n",
              "      <td>2.362790</td>\n",
              "      <td>2.337592</td>\n",
              "      <td>2.626224</td>\n",
              "      <td>2.361520</td>\n",
              "      <td>2.475432</td>\n",
              "      <td>2.336782</td>\n",
              "      <td>2.339533</td>\n",
              "      <td>2.534250</td>\n",
              "      <td>2.421600</td>\n",
              "      <td>2.470870</td>\n",
              "      <td>2.637891</td>\n",
              "      <td>2.397924</td>\n",
              "      <td>2.484679</td>\n",
              "      <td>2.625668</td>\n",
              "      <td>2.587656</td>\n",
              "      <td>2.435711</td>\n",
              "      <td>2.522063</td>\n",
              "      <td>2.387734</td>\n",
              "      <td>2.318504</td>\n",
              "      <td>2.555520</td>\n",
              "      <td>2.529078</td>\n",
              "      <td>2.231773</td>\n",
              "      <td>2.424821</td>\n",
              "      <td>2.396764</td>\n",
              "      <td>2.361172</td>\n",
              "      <td>2.354873</td>\n",
              "      <td>2.398949</td>\n",
              "      <td>2.595111</td>\n",
              "      <td>2.608216</td>\n",
              "      <td>2.157081</td>\n",
              "      <td>2.421194</td>\n",
              "      <td>2.289257</td>\n",
              "      <td>2.156608</td>\n",
              "      <td>2.556211</td>\n",
              "      <td>2.356318</td>\n",
              "      <td>2.640500</td>\n",
              "      <td>2.450664</td>\n",
              "      <td>2.479862</td>\n",
              "      <td>2.385079</td>\n",
              "      <td>...</td>\n",
              "      <td>2.470306</td>\n",
              "      <td>2.508566</td>\n",
              "      <td>2.392230</td>\n",
              "      <td>2.510005</td>\n",
              "      <td>2.476558</td>\n",
              "      <td>2.596264</td>\n",
              "      <td>2.357619</td>\n",
              "      <td>2.526068</td>\n",
              "      <td>2.395219</td>\n",
              "      <td>2.436071</td>\n",
              "      <td>2.450549</td>\n",
              "      <td>2.420079</td>\n",
              "      <td>2.502285</td>\n",
              "      <td>2.423220</td>\n",
              "      <td>2.291999</td>\n",
              "      <td>2.276872</td>\n",
              "      <td>2.326967</td>\n",
              "      <td>2.214158</td>\n",
              "      <td>2.250423</td>\n",
              "      <td>2.398300</td>\n",
              "      <td>2.501406</td>\n",
              "      <td>2.547882</td>\n",
              "      <td>2.424504</td>\n",
              "      <td>2.220450</td>\n",
              "      <td>2.479183</td>\n",
              "      <td>2.294289</td>\n",
              "      <td>2.543388</td>\n",
              "      <td>2.232281</td>\n",
              "      <td>2.559016</td>\n",
              "      <td>2.467163</td>\n",
              "      <td>2.649224</td>\n",
              "      <td>2.626092</td>\n",
              "      <td>2.617321</td>\n",
              "      <td>2.393450</td>\n",
              "      <td>2.372714</td>\n",
              "      <td>2.363334</td>\n",
              "      <td>2.287326</td>\n",
              "      <td>2.295925</td>\n",
              "      <td>2.427395</td>\n",
              "      <td>2.480248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 220 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       217       218       219\n",
              "0  2.628733  2.308827  2.281555  ...  2.201903  2.321458  2.430239\n",
              "1  2.688621  2.327542  2.287974  ...  2.269905  2.407200  2.488512\n",
              "2  2.681221  2.362780  2.307868  ...  2.213926  2.373105  2.466803\n",
              "3  2.731391  2.356005  2.324149  ...  2.238639  2.412806  2.485888\n",
              "4  2.664892  2.320478  2.305416  ...  2.211272  2.338783  2.438032\n",
              "5  2.639735  2.317055  2.302321  ...  2.256001  2.382046  2.452692\n",
              "6  2.693933  2.325058  2.305252  ...  2.232226  2.366100  2.482552\n",
              "7  2.651045  2.282344  2.287502  ...  2.215763  2.367879  2.447322\n",
              "8  2.605788  2.278579  2.241837  ...  2.188632  2.315411  2.425982\n",
              "9  2.668904  2.362790  2.337592  ...  2.295925  2.427395  2.480248\n",
              "\n",
              "[10 rows x 220 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    }
  ]
}